{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first part of the assignment, IDS 2020-2021\n",
    "In this Jupiter notebook, please, document your results and the way you have obtained them. Please use the _Python environment_ provided at the beginning of the course. In addition to the _Jupiter notebook_, please submit _one zip-file_ containing all datasets and other outputs you have generated (such as pdf, jpg, and others). Please make sure that the datasets and other outputs are easily identifiable, i.e. use names as requested in the corresponding question.\n",
    "\n",
    "This is the _only_ submission that is required (Jupiter notebook + zip-file). A separate report is _not_ needed and will not be considered for grading. \n",
    "\n",
    "Give your commented Python code and answers in the corresponding provided cells. Make sure to answer all questions in a clear and explicit manner and discuss your outputs. _Please do not change the general structure of this notebook_. You can, however, add additional markdown or code cells if necessary. <b>Please DO NOT CLEAR THE OUTPUT of the notebook you are submitting! </b>\n",
    "\n",
    "<font color=\"red\"> *Please make sure to include names and matriculation numbers of all group members in the slot provided below.* </font> If a name or a student id is missing, the student will not receive any points.\n",
    "\n",
    "Hint 1: While working on the assignment, you will get a better understanding of the dataset. Feel free to generate additional results and visualizations to support your answers. For example, this might be useful regarding data modification and simplification. <font color=\"red\">Ensure that all your claims are supported.</font>\n",
    "\n",
    "Hint 2: <font color=\"red\">Plan your time wisely. </font> A few parts of this assignment might take some time to run. It might be necessary to consider time management when you plan your group work.\n",
    "\n",
    "Hint 3: RWTHmoodle allows multiple submissions, with every new submission overwriting the previous one. <b>Partial submissions are therefore possible and encouraged. </b> This might be helpful in case of technical issues with RWTHMoodle, which may occur close to the deadline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Dataset (5 points)\n",
    " Carry out the following preprocessing steps before starting the analysis:\n",
    " - Select 90% of dataset provided for this assignment by random sampling.\n",
    "     - Use one of the group member's student numbers as a seed.\n",
    "     - Rename the new generated dataset (which contains 90% of the data) to \"sampled_data\".\n",
    " - <font color='red'>Important!</font>  Export your *sampled_data* dataset and submit it with your assignment solution.\n",
    " - If it is not otherwise mentioned, you should always use your below created *sampled_data* as input for the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import subprocess\n",
    "import graphviz\n",
    "import warnings\n",
    "import random\n",
    "from p_decision_tree.DecisionTree import DecisionTree\n",
    "from graphviz import Digraph\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#read the dataset through pandas\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "#get the 90% of the dataset by fraction and \n",
    "sampled_data = df.sample(frac=0.9, random_state=414760)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Insights into the Data (15 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a)  Generate a dataset by removing those rows of the sampled_data dataset for which the value of \"SurfaceR\" is equal or bigger than 50000. Let's call this data set \"new_sampled_data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing dataset to the instances where SurfaceR feature is less than 50k\n",
    "new_sampled_data = sampled_data[sampled_data[\"SurfaceR\"] < 50000]\n",
    "\n",
    "#saving the dataset\n",
    "#new_sampled_data.to_csv('new_sampled_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b)  Use a boxplot to find and remove the outliers from \"SurfaceR\". Note that based on the boxplot the values greater than the upper-whisker and lower than the lower-whisker are considered as outliers. Let's call the dataset after removing the outliers \"cleaned_data\". Now you should  have three datasets (sampled_data, new_sampled_data, and cleaned_data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='SurfaceR'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing dataset before cleaning\n",
    "sns.boxplot(x=new_sampled_data['SurfaceR'])\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('new_sampled_data_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='SurfaceR'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculating first quantile\n",
    "#Q1 = 300\n",
    "Q1 = new_sampled_data.SurfaceR.quantile(0.25)\n",
    "#Calculating third quantile\n",
    "#Q3 = 2500\n",
    "Q3 = new_sampled_data.SurfaceR.quantile(0.75)\n",
    "\n",
    "#Calculating IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "#Upper Fence = 5800\n",
    "Upper_Fence = Q3 + 1.5*IQR\n",
    "#Lower Fence = -3000 -> 0 -> no outliers under the lower fence\n",
    "Lower_Fence = Q1 - 1.5*IQR\n",
    "\n",
    "#Upper_Whisker = 5000\n",
    "#Calculating Upper whisker\n",
    "Upper_Whisker = new_sampled_data[new_sampled_data[\"SurfaceR\"] < Upper_Fence].max()[\"SurfaceR\"]\n",
    "\n",
    "#Lower_Whisker = 30\n",
    "#Calculating Lower whisker\n",
    "Lower_Whisker = new_sampled_data[new_sampled_data[\"SurfaceR\"] > Lower_Fence].min()[\"SurfaceR\"]\n",
    "\n",
    "#Removing instances that are above upper whisker\n",
    "cleaned_data = new_sampled_data[new_sampled_data[\"SurfaceR\"] <= Upper_Whisker]\n",
    "\n",
    "#Removing instances that are below lower whisker (for the given dataset, nothing is removed, as all values are above the lower whisker)\n",
    "cleaned_data = cleaned_data[cleaned_data[\"SurfaceR\"] >= Lower_Whisker]\n",
    "\n",
    "#Creating boxplot, for the SurfaceR feature in the cleaned dataset\n",
    "sns.boxplot(x=cleaned_data['SurfaceR'])\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('cleaned_data_boxplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Compare basic statistical features of \"SurfaceR\" (median, mean, and mode, standard deviation, variance) in the new_sampled_data and cleaned_data datasets. Interpret the differences for these statistical values between the cleaned_data and new_sampled_data datasets. Explain why the statistics of these two datasets are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New sampled data:\n",
      "count      164.000000\n",
      "mean      3427.926829\n",
      "std       6987.327045\n",
      "min         30.000000\n",
      "25%        300.000000\n",
      "50%        600.000000\n",
      "75%       2500.000000\n",
      "max      40000.000000\n",
      "Name: SurfaceR, dtype: float64\n",
      "\n",
      "Cleaned data:\n",
      "count     139.000000\n",
      "mean     1020.719424\n",
      "std      1120.473916\n",
      "min        30.000000\n",
      "25%       300.000000\n",
      "50%       450.000000\n",
      "75%      1500.000000\n",
      "max      5000.000000\n",
      "Name: SurfaceR, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNew sampled data:\")\n",
    "print(new_sampled_data[\"SurfaceR\"].describe())\n",
    "\n",
    "print(\"\\nCleaned data:\")\n",
    "print(cleaned_data[\"SurfaceR\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "25 Instances(Outliers) were removed.<br>\n",
    "New_sampled_data has bigger mean, standard deviation and maximum value than the cleaned_data, \n",
    "while the minimum value is the same for both.\n",
    "New_sampled_data has bigger values in 2nd(600 > 450), and 3nd quantiles (2500 > 1500) \n",
    "and also bigger median value (600 > 450).\n",
    "\n",
    "New_sampled_data has significantly bigger standard deviation, it means that values were scattered very far from the mean, \n",
    "since the both datasets have the same minimum, and the difference between median is not very big.\n",
    "\n",
    "Mean is very fluctuating variable, removing 25 outline instances caused mean and std to be significantly reduced.\n",
    "This indicates that removed 25 outliers were much larger than the mean value.\n",
    "The std-value is reduced, thus, observations are now more clustered than before.\n",
    "\n",
    "\n",
    "\n",
    "According to the rules of normal distribution\n",
    "\n",
    "1) new_sampled_data\n",
    "\n",
    "2.5% of new_sampled_data = 300 <br>\n",
    "Lower Specification Limit of new_sampled_data is null, thus it does not exceed the LSL.<br>\n",
    "\n",
    "97.5% of new_sampled_data = 28947.49999999999 (Upper Specification Limit)<br>\n",
    "99.7 Quartile of new_sampled_data = 35598.999999999956<br>\n",
    "\n",
    "μ + 2σ of new_sampled_data = 17402.580919<br>\n",
    "μ + 3σ of new_sampled_data = 24389.907964 <br>\n",
    "\n",
    "Values from above exceed both values of μ + 2σ and μ + 3σ, which indicates that this is less likely normal distribution.<br>\n",
    "\n",
    "\n",
    "\n",
    "2) cleaned data\n",
    "\n",
    "2.5% of cleaned_data = 300<br>\n",
    "Lower Specification Limit of new_sampled_data is null,<br>\n",
    "thus it does not exceed the LSL<br>\n",
    "\n",
    "cleaned_data.SurfaceR.quantile(0.975) = 4000.000<br>\n",
    "cleaned_data.SurfaceR.quantile(0.997) = 4710.200<br>\n",
    "\n",
    "μ + 2σ of cleaned_data = 3261,667256<br>\n",
    "μ + 3σ of cleaned_data = 4382,141171<br>\n",
    "\n",
    "Values from above exceed both values of μ + 2σ and μ + 3σ, which indicates that this is less likely normal distribution.<br>\n",
    "\n",
    "Cleaned_data differs from the both values less than of new_sampled_data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Visualization (10 points)\n",
    "(d) Visualize mean and median of \"SurfaceR\" in the cleaned dataset. Specify the \"Surroundings3\" values for which the mean and median of \"SurfaceR\" is maximal and for which it is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting mean and median of SurfaceR over each category of Surroundings3\n",
    "cleaned_data[[\"Surroundings3\",\"SurfaceR\"]].groupby([\"Surroundings3\"]).agg(['mean', 'median']).plot(kind='bar');\n",
    "plt.legend(title=False, loc=\"upper center\")\n",
    "plt.title(\"SurfaceR mean and median per Surroundings3 category\");\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('SurfaceR_per_Surroundings.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: <br>\n",
    "Based on the figure above, we can see that the **maximal** mean and median are for category *i*. <br>\n",
    "The **minimal** mean and median are in category *d*. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Plot the distribution of \"SurfaceR\" in the new_sampled_data and cleaned_data datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting SurfaceR distribution for cleand_data and new_sampled_data\n",
    "sns.distplot(cleaned_data[['SurfaceR']],label='Cleaned_data SurfaceR', color=\"blue\", hist=False, rug=False)\n",
    "sns.distplot(new_sampled_data[['SurfaceR']],label='New_sampled_data SurfaceR', color=\"orange\", hist=False, rug=False)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"SurfaceR distribution in new_sampled_data and cleaned_data\")\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('SurfaceR_distr.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(f) Explore the distribution of \"SurfaceR\" and \"AcessR\" together in the new_sampled_data and cleaned_data datasets. Specify the ranges of \"SurfaceR\" and \"AcessR\" for which the frequency of the data is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x3600 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram without boxplot\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2,figsize=(50,50))\n",
    "ax0, ax1, ax2, ax3 = axes.flatten()\n",
    "\n",
    "ax0.hist(new_sampled_data[['SurfaceR']], density=True, histtype='bar', color='#f55442', width = 5000)\n",
    "ax0.set_title('SurfaceR - New_sampled_data', size = 40)\n",
    "ax0.set_ylabel('Density', fontsize = 40.0) # Y label\n",
    "ax0.set_xlabel('SurfaceR', fontsize = 40) # X label\n",
    "ax0.tick_params(labelsize = 30)\n",
    "\n",
    "ax1.hist(new_sampled_data[['AcessR']], density=True, histtype='bar', color='#4287f5', width = 5000)\n",
    "ax1.set_title('AcessR - New_sampled_data', size = 40)\n",
    "ax1.set_ylabel('Density', fontsize = 40.0) # Y label\n",
    "ax1.set_xlabel('AcessR', fontsize = 40) # X label\n",
    "ax1.tick_params(labelsize = 30)\n",
    "\n",
    "ax2.hist(cleaned_data[['SurfaceR']], density=True, histtype='bar', color='#f5c842', width = 500)\n",
    "ax2.set_title('SurfaceR - cleaned_data', size = 40)\n",
    "ax2.set_ylabel('Density', fontsize = 40.0) # Y label\n",
    "ax2.set_xlabel('SurfaceR', fontsize = 40) # X label\n",
    "ax2.tick_params(labelsize = 30)\n",
    "\n",
    "ax3.hist(cleaned_data[['AcessR']], density=True, histtype='bar', color='#37ab52', width = 25)\n",
    "ax3.set_title('AcessR - cleaned_data', size = 40)\n",
    "ax3.set_ylabel('Density', fontsize = 40.0) # Y label\n",
    "ax3.set_xlabel('AcessR', fontsize = 40) # X label\n",
    "ax3.tick_params(labelsize = 30)\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('SurfaceR_AcessR_distr.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "\n",
    "The highest frequency of feature \"AcessR\" for new_sampled_data and cleaned_data is between 90 and 100. <br>\n",
    "The highest frequency of feature \"SurfaceR\" for new_sampled_data is between 0 and 5000, and for cleaned_data it is between 0 and 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Decision Trees (15 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Add a categorical column \"number_frogs\" to the new_sampled_data which indicate the number of different frogs in each region (row). For example, if in a row we have:\n",
    "       - \"Green frogs\" = 1, \"Brown frogs\" = 1, \"Common toad\" = 0, \"Fire-bellied toad\" = 0, \"Tree frog\" = 0, \"Common newt\" = 0, and \"Great crested newt\" = 0, then \"number_frogs\" = 'two'.\n",
    "       - \"Green frogs\" = 1, \"Brown frogs\" = 1, \"Common toad\" = 0, \"Fire-bellied toad\" = 0, \"Tree frog\" = 1, \"Common newt\" = 1, and \"Great crested newt\" = 0, then \"number_frogs\" = 'four'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with related frog column names\n",
    "frog_names = [\"Green frogs\", \n",
    "              \"Brown frogs\", \n",
    "              \"Common toad\", \n",
    "              \"Fire-bellied toad\", \n",
    "              \"Tree frog\", \n",
    "              \"Common newt\",\n",
    "              \"Great crested newt\"]\n",
    "\n",
    "\n",
    "\n",
    "#Function that converts integer value into word representation\n",
    "def num2word(index):\n",
    "    number_list = [\"zero\",\n",
    "               \"one\", \n",
    "               \"two\", \n",
    "               \"three\", \n",
    "               \"four\", \n",
    "               \"five\", \n",
    "               \"six\", \n",
    "               \"seven\"]\n",
    "    return number_list[index]\n",
    "\n",
    "#creating number_frogs column, first it counts different frog types, and then it converts it into categorical variable\n",
    "new_sampled_data[\"number_frogs\"] = new_sampled_data[frog_names].sum(axis=1).apply(num2word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) In the new dataset (created in Section 'a'), consider \"TypeR\", \"VegetationR\", \"Surroundings1\", \"Surroundings2\", \"Surroundings3\" as    the descriptive features and \"number_frogs\" as the target feature. Generate two decision trees. Let's call them \"tree1\" and \"tree2\". In tree1 set the minimum number of samples for splitting to 15 and in tree2 set the minimum number of samples for splitting to 1. Create both decision trees based on entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To create decision tree, we use p_decision_tree library.\n",
    "\n",
    "descriptive_features = [\"TypeR\", \"VegetationR\", \"Surroundings1\", \"Surroundings2\", \"Surroundings3\" ]\n",
    "label = \"number_frogs\"\n",
    "\n",
    "#converting \"VegetationR\" to String\n",
    "new_sampled_data[\"VegetationR\"] = new_sampled_data[\"VegetationR\"].astype(str)\n",
    "\n",
    "#getting values\n",
    "data_descriptive = new_sampled_data[descriptive_features].values\n",
    "data_label = new_sampled_data[label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"2098pt\" height=\"476pt\"\r\n",
       " viewBox=\"0.00 0.00 2098.00 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-472 2094,-472 2094,4 -4,4\"/>\r\n",
       "<!-- root -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>root</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1704\" cy=\"-450\" rx=\"36.2938\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1704\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">TypeR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8558178423083743 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>0.8558178423083743</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1227\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1227\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.8558178423083743 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>root&#45;&gt;0.8558178423083743</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1669.7,-443.966C1582.37,-431.15 1352.26,-397.382 1263.05,-384.291\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1263.54,-380.825 1253.14,-382.836 1262.52,-387.751 1263.54,-380.825\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.09275848796019459 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>0.09275848796019459</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1503\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1503\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.09275848796019459 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>root&#45;&gt;0.09275848796019459</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1675.2,-438.971C1638.43,-426.165 1574.94,-404.055 1536.18,-390.556\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1537.02,-387.14 1526.42,-387.157 1534.71,-393.751 1537.02,-387.14\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7913492806358497 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>0.7913492806358497</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1595\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1595\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.7913492806358497 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>root&#45;&gt;0.7913492806358497</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1682.72,-435.337C1665.58,-424.327 1641.34,-408.762 1622.69,-396.781\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1624.34,-393.682 1614.03,-391.224 1620.56,-399.572 1624.34,-393.682\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.019620089335125934 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>0.019620089335125934</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1668\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1668\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">i</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.019620089335125934 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>root&#45;&gt;0.019620089335125934</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1695.47,-432.411C1691.16,-424.042 1685.85,-413.71 1681.05,-404.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1684.16,-402.762 1676.47,-395.47 1677.93,-405.964 1684.16,-402.762\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9284530356741095 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>0.9284530356741095</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1740\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1740\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.9284530356741095 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>root&#45;&gt;0.9284530356741095</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1712.53,-432.411C1716.84,-424.042 1722.15,-413.71 1726.95,-404.37\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1730.07,-405.964 1731.53,-395.47 1723.84,-402.762 1730.07,-405.964\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.989421864675009 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>0.989421864675009</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1822\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1822\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">j</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.989421864675009 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>root&#45;&gt;0.989421864675009</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1726.47,-435.669C1745.58,-424.335 1773.11,-408.003 1793.71,-395.781\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1795.54,-398.767 1802.35,-390.655 1791.97,-392.747 1795.54,-398.767\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6891117007444182 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>0.6891117007444182</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1913\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1913\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.6891117007444182 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>root&#45;&gt;0.6891117007444182</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1733.5,-439.119C1772.09,-426.195 1839.51,-403.613 1879.83,-390.108\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1881.1,-393.377 1889.47,-386.882 1878.87,-386.739 1881.1,-393.377\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2158643653500949 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>0.2158643653500949</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2024\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2024\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.2158643653500949 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>root&#45;&gt;0.2158643653500949</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1736.91,-441.988C1783.97,-431.938 1873.16,-412.798 1949,-396 1961.93,-393.135 1976.11,-389.938 1988.62,-387.095\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1989.7,-390.439 1998.67,-384.806 1988.14,-383.614 1989.7,-390.439\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>0.6143087465921159</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1046\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1046\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8558178423083743&#45;&gt;0.6143087465921159 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0.8558178423083743&#45;&gt;0.6143087465921159</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1204.08,-368.134C1175.99,-357.273 1127.73,-338.609 1091.91,-324.754\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1092.75,-321.326 1082.16,-320.984 1090.22,-327.855 1092.75,-321.326\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4211126033637299 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>0.4211126033637299</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"408\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"408\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.4211126033637299 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.4211126033637299</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M987.69,-298.602C858.471,-284.425 551.072,-250.698 444.854,-239.044\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"444.96,-235.534 434.638,-237.923 444.196,-242.492 444.96,-235.534\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7171567666718314 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>0.7171567666718314</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"682\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.7171567666718314 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.7171567666718314</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M995.004,-295.193C920.311,-280.829 782.995,-254.422 717.963,-241.916\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"718.278,-238.412 707.797,-239.961 716.956,-245.287 718.278,-238.412\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7582478976795889 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>0.7582478976795889</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"847\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"847\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.7582478976795889 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.7582478976795889</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1007.63,-291.503C970.624,-278.486 915.198,-258.989 880.083,-246.637\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"880.91,-243.218 870.315,-243.201 878.587,-249.821 880.91,-243.218\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9587672669854608 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>0.9587672669854608</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"956\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"956\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.9587672669854608 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.9587672669854608</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1025.13,-288.765C1011.97,-278.53 994.901,-265.256 981.018,-254.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"982.891,-251.482 972.849,-248.105 978.594,-257.007 982.891,-251.482\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24669781313223416 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>0.24669781313223416</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1046\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1046\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.24669781313223416 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.24669781313223416</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1046,-287.697C1046,-279.983 1046,-270.712 1046,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1049.5,-262.104 1046,-252.104 1042.5,-262.104 1049.5,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7093203761206368 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>0.7093203761206368</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1119\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1119\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.7093203761206368 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.7093203761206368</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1063.3,-288.411C1073.34,-278.781 1086.1,-266.552 1096.86,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1099.49,-258.555 1104.29,-249.108 1094.65,-253.503 1099.49,-258.555\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.941501343964291 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>0.941501343964291</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1193\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1193\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">i</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.941501343964291 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.941501343964291</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1077.17,-290.155C1102.28,-278.198 1137.39,-261.48 1162.36,-249.591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1163.86,-252.751 1171.39,-245.291 1160.86,-246.431 1163.86,-252.751\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.07786575982517907 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>0.07786575982517907</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1266\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1266\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6143087465921159&#45;&gt;0.07786575982517907 -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>0.6143087465921159&#45;&gt;0.07786575982517907</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1092.49,-293.581C1129.86,-283.918 1183.43,-268.96 1229,-252 1231.1,-251.219 1233.25,-250.37 1235.4,-249.483\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1236.93,-252.633 1244.71,-245.438 1234.14,-246.213 1236.93,-252.633\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8698840805766892 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>0.8698840805766892</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1484\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1484\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.09275848796019459&#45;&gt;0.8698840805766892 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0.09275848796019459&#45;&gt;0.8698840805766892</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1498.4,-360.055C1496.29,-352.261 1493.72,-342.822 1491.35,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1494.69,-333.009 1488.69,-324.275 1487.93,-334.843 1494.69,-333.009\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3467911525656786 -->\r\n",
       "<g id=\"node34\" class=\"node\"><title>0.3467911525656786</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1341\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1341\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8698840805766892&#45;&gt;0.3467911525656786 -->\r\n",
       "<g id=\"edge33\" class=\"edge\"><title>0.8698840805766892&#45;&gt;0.3467911525656786</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1453.67,-290.155C1429.5,-278.321 1395.8,-261.825 1371.56,-249.961\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1372.98,-246.756 1362.46,-245.503 1369.9,-253.044 1372.98,-246.756\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8737309516699617 -->\r\n",
       "<g id=\"node36\" class=\"node\"><title>0.8737309516699617</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1414\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1414\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8698840805766892&#45;&gt;0.8737309516699617 -->\r\n",
       "<g id=\"edge35\" class=\"edge\"><title>0.8698840805766892&#45;&gt;0.8737309516699617</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1467.41,-288.411C1457.91,-278.911 1445.88,-266.882 1435.65,-256.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1438.12,-254.167 1428.57,-249.57 1433.17,-259.116 1438.12,-254.167\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.48814066890547325 -->\r\n",
       "<g id=\"node38\" class=\"node\"><title>0.48814066890547325</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1486\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1486\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8698840805766892&#45;&gt;0.48814066890547325 -->\r\n",
       "<g id=\"edge37\" class=\"edge\"><title>0.8698840805766892&#45;&gt;0.48814066890547325</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1484.49,-287.697C1484.71,-279.983 1484.98,-270.712 1485.23,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1488.72,-262.2 1485.51,-252.104 1481.73,-262 1488.72,-262.2\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1752943271256182 -->\r\n",
       "<g id=\"node40\" class=\"node\"><title>0.1752943271256182</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1558\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1558\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8698840805766892&#45;&gt;0.1752943271256182 -->\r\n",
       "<g id=\"edge39\" class=\"edge\"><title>0.8698840805766892&#45;&gt;0.1752943271256182</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1501.54,-288.411C1511.72,-278.781 1524.65,-266.552 1535.56,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1538.23,-258.522 1543.09,-249.108 1533.42,-253.437 1538.23,-258.522\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8756756116268245 -->\r\n",
       "<g id=\"node42\" class=\"node\"><title>0.8756756116268245</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1630\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1630\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8698840805766892&#45;&gt;0.8756756116268245 -->\r\n",
       "<g id=\"edge41\" class=\"edge\"><title>0.8698840805766892&#45;&gt;0.8756756116268245</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1514.96,-290.155C1539.79,-278.25 1574.46,-261.627 1599.24,-249.749\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1601.03,-252.77 1608.54,-245.291 1598.01,-246.458 1601.03,-252.77\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5176007640737649 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>0.5176007640737649</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1594\" cy=\"-306\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1594\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7913492806358497&#45;&gt;0.5176007640737649 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>0.7913492806358497&#45;&gt;0.5176007640737649</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1594.75,-359.697C1594.64,-351.983 1594.51,-342.712 1594.39,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.89,-334.053 1594.24,-324.104 1590.89,-334.153 1597.89,-334.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2190820828392227 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>0.2190820828392227</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1668\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1668\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.019620089335125934&#45;&gt;0.2190820828392227 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>0.019620089335125934&#45;&gt;0.2190820828392227</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1668,-359.697C1668,-351.983 1668,-342.712 1668,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1671.5,-334.104 1668,-324.104 1664.5,-334.104 1671.5,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4545428793230303 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>0.4545428793230303</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1740\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1740\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9284530356741095&#45;&gt;0.4545428793230303 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>0.9284530356741095&#45;&gt;0.4545428793230303</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1740,-359.697C1740,-351.983 1740,-342.712 1740,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1743.5,-334.104 1740,-324.104 1736.5,-334.104 1743.5,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>0.8181348533031729</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1849\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1849\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.989421864675009&#45;&gt;0.8181348533031729 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0.989421864675009&#45;&gt;0.8181348533031729</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1828.4,-360.411C1831.51,-352.335 1835.33,-342.431 1838.83,-333.355\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1842.13,-334.546 1842.46,-323.956 1835.6,-332.027 1842.13,-334.546\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.41365524346015736 -->\r\n",
       "<g id=\"node44\" class=\"node\"><title>0.41365524346015736</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1703\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1703\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729&#45;&gt;0.41365524346015736 -->\r\n",
       "<g id=\"edge43\" class=\"edge\"><title>0.8181348533031729&#45;&gt;0.41365524346015736</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1818.04,-290.155C1793.21,-278.25 1758.54,-261.627 1733.76,-249.749\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1734.99,-246.458 1724.46,-245.291 1731.97,-252.77 1734.99,-246.458\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0011609525247660013 -->\r\n",
       "<g id=\"node46\" class=\"node\"><title>0.0011609525247660013</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1775\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1775\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729&#45;&gt;0.0011609525247660013 -->\r\n",
       "<g id=\"edge45\" class=\"edge\"><title>0.8181348533031729&#45;&gt;0.0011609525247660013</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1831.46,-288.411C1821.28,-278.781 1808.35,-266.552 1797.44,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1799.58,-253.437 1789.91,-249.108 1794.77,-258.522 1799.58,-253.437\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5298538521794254 -->\r\n",
       "<g id=\"node48\" class=\"node\"><title>0.5298538521794254</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1847\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1847\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729&#45;&gt;0.5298538521794254 -->\r\n",
       "<g id=\"edge47\" class=\"edge\"><title>0.8181348533031729&#45;&gt;0.5298538521794254</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1848.51,-287.697C1848.29,-279.983 1848.02,-270.712 1847.77,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1851.27,-262 1847.49,-252.104 1844.28,-262.2 1851.27,-262\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8530205652507762 -->\r\n",
       "<g id=\"node50\" class=\"node\"><title>0.8530205652507762</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1919\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1919\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729&#45;&gt;0.8530205652507762 -->\r\n",
       "<g id=\"edge49\" class=\"edge\"><title>0.8181348533031729&#45;&gt;0.8530205652507762</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1865.59,-288.411C1875.09,-278.911 1887.12,-266.882 1897.35,-256.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1899.83,-259.116 1904.43,-249.57 1894.88,-254.167 1899.83,-259.116\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5102952299242905 -->\r\n",
       "<g id=\"node52\" class=\"node\"><title>0.5102952299242905</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1991\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1991\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729&#45;&gt;0.5102952299242905 -->\r\n",
       "<g id=\"edge51\" class=\"edge\"><title>0.8181348533031729&#45;&gt;0.5102952299242905</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1879.46,-289.983C1903.49,-278.138 1936.84,-261.7 1960.8,-249.889\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1962.38,-253.012 1969.8,-245.451 1959.28,-246.733 1962.38,-253.012\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8765129313998026 -->\r\n",
       "<g id=\"node54\" class=\"node\"><title>0.8765129313998026</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2063\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2063\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8181348533031729&#45;&gt;0.8765129313998026 -->\r\n",
       "<g id=\"edge53\" class=\"edge\"><title>0.8181348533031729&#45;&gt;0.8765129313998026</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1895,-293.367C1931.32,-283.69 1983.03,-268.816 2027,-252 2028.84,-251.296 2030.72,-250.539 2032.6,-249.748\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2034.19,-252.869 2041.91,-245.612 2031.35,-246.472 2034.19,-252.869\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0199946658467256 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>0.0199946658467256</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1958\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1958\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6891117007444182&#45;&gt;0.0199946658467256 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>0.6891117007444182&#45;&gt;0.0199946658467256</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1923.21,-361.116C1928.85,-352.345 1935.97,-341.264 1942.3,-331.416\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1945.37,-333.126 1947.83,-322.821 1939.48,-329.34 1945.37,-333.126\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.21683451410879195 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>0.21683451410879195</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2034\" cy=\"-306\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2034\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2158643653500949&#45;&gt;0.21683451410879195 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>0.2158643653500949&#45;&gt;0.21683451410879195</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2026.42,-360.055C2027.52,-352.346 2028.85,-343.027 2030.09,-334.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2033.58,-334.67 2031.53,-324.275 2026.65,-333.68 2033.58,-334.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.40100384326348093 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>0.40100384326348093</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"207\" cy=\"-162\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4211126033637299&#45;&gt;0.40100384326348093 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>0.4211126033637299&#45;&gt;0.40100384326348093</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M384.549,-224.833C352.432,-213.648 294.078,-193.326 253.057,-179.04\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.143,-175.712 243.548,-175.728 251.841,-182.322 254.143,-175.712\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5216295802561377 -->\r\n",
       "<g id=\"node56\" class=\"node\"><title>0.5216295802561377</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40100384326348093&#45;&gt;0.5216295802561377 -->\r\n",
       "<g id=\"edge55\" class=\"edge\"><title>0.40100384326348093&#45;&gt;0.5216295802561377</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.956,-148.381C140.663,-138.16 98.8699,-123.036 63,-108 61.1833,-107.238 59.3249,-106.436 57.4566,-105.611\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.7311,-102.345 48.1801,-101.383 55.8281,-108.715 58.7311,-102.345\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6297791241649701 -->\r\n",
       "<g id=\"node58\" class=\"node\"><title>0.6297791241649701</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40100384326348093&#45;&gt;0.6297791241649701 -->\r\n",
       "<g id=\"edge57\" class=\"edge\"><title>0.40100384326348093&#45;&gt;0.6297791241649701</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.299,-145.638C166.484,-134.74 143.875,-120.086 126.304,-108.697\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.927,-105.578 117.632,-103.076 124.12,-111.452 127.927,-105.578\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.10031874832017529 -->\r\n",
       "<g id=\"node60\" class=\"node\"><title>0.10031874832017529</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40100384326348093&#45;&gt;0.10031874832017529 -->\r\n",
       "<g id=\"edge59\" class=\"edge\"><title>0.40100384326348093&#45;&gt;0.10031874832017529</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.285,-144.055C194.023,-135.767 188.803,-125.618 184.075,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.073,-114.599 179.386,-107.307 180.847,-117.801 187.073,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.45300281257318176 -->\r\n",
       "<g id=\"node62\" class=\"node\"><title>0.45300281257318176</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"243\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40100384326348093&#45;&gt;0.45300281257318176 -->\r\n",
       "<g id=\"edge61\" class=\"edge\"><title>0.40100384326348093&#45;&gt;0.45300281257318176</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215.715,-144.055C219.977,-135.767 225.197,-125.618 229.925,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.153,-117.801 234.614,-107.307 226.927,-114.599 233.153,-117.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8429894047454582 -->\r\n",
       "<g id=\"node64\" class=\"node\"><title>0.8429894047454582</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"315\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40100384326348093&#45;&gt;0.8429894047454582 -->\r\n",
       "<g id=\"edge63\" class=\"edge\"><title>0.40100384326348093&#45;&gt;0.8429894047454582</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.701,-145.638C247.516,-134.74 270.125,-120.086 287.696,-108.697\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.88,-111.452 296.368,-103.076 286.073,-105.578 289.88,-111.452\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>0.8588718727712741</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"607\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"607\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7171567666718314&#45;&gt;0.8588718727712741 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>0.7171567666718314&#45;&gt;0.8588718727712741</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M666.823,-218.834C656.876,-209.551 643.636,-197.193 632.14,-186.464\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"634.221,-183.618 624.522,-179.354 629.444,-188.736 634.221,-183.618\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9579805786468345 -->\r\n",
       "<g id=\"node66\" class=\"node\"><title>0.9579805786468345</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"388\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"388\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741&#45;&gt;0.9579805786468345 -->\r\n",
       "<g id=\"edge65\" class=\"edge\"><title>0.8588718727712741&#45;&gt;0.9579805786468345</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M560.458,-149.711C523.068,-140.121 469.479,-125.199 424,-108 422.157,-107.303 420.279,-106.551 418.395,-105.764\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"419.639,-102.487 409.078,-101.639 416.805,-108.888 419.639,-102.487\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6443853381831282 -->\r\n",
       "<g id=\"node68\" class=\"node\"><title>0.6443853381831282</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"460\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"460\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741&#45;&gt;0.6443853381831282 -->\r\n",
       "<g id=\"edge67\" class=\"edge\"><title>0.8588718727712741&#45;&gt;0.6443853381831282</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.825,-146.155C550.715,-134.198 515.608,-117.48 490.642,-105.591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"492.145,-102.431 481.611,-101.291 489.135,-108.751 492.145,-102.431\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.10553093067961306 -->\r\n",
       "<g id=\"node70\" class=\"node\"><title>0.10553093067961306</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"534\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"534\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741&#45;&gt;0.10553093067961306 -->\r\n",
       "<g id=\"edge69\" class=\"edge\"><title>0.8588718727712741&#45;&gt;0.10553093067961306</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M589.7,-144.411C579.657,-134.781 566.904,-122.552 556.136,-112.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"558.353,-109.503 548.712,-105.108 553.508,-114.555 558.353,-109.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.34369024903603995 -->\r\n",
       "<g id=\"node72\" class=\"node\"><title>0.34369024903603995</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"607\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"607\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741&#45;&gt;0.34369024903603995 -->\r\n",
       "<g id=\"edge71\" class=\"edge\"><title>0.8588718727712741&#45;&gt;0.34369024903603995</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M607,-143.697C607,-135.983 607,-126.712 607,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"610.5,-118.104 607,-108.104 603.5,-118.104 610.5,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.40630156851154586 -->\r\n",
       "<g id=\"node74\" class=\"node\"><title>0.40630156851154586</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"679\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"679\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741&#45;&gt;0.40630156851154586 -->\r\n",
       "<g id=\"edge73\" class=\"edge\"><title>0.8588718727712741&#45;&gt;0.40630156851154586</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M624.063,-144.411C633.834,-134.911 646.207,-122.882 656.736,-112.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"659.283,-115.051 664.013,-105.57 654.403,-110.032 659.283,-115.051\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9621481268256066 -->\r\n",
       "<g id=\"node76\" class=\"node\"><title>0.9621481268256066</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"752\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"752\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8588718727712741&#45;&gt;0.9621481268256066 -->\r\n",
       "<g id=\"edge75\" class=\"edge\"><title>0.8588718727712741&#45;&gt;0.9621481268256066</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M637.751,-146.155C662.41,-134.25 696.843,-117.627 721.449,-105.749\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"723.199,-108.791 730.683,-101.291 720.155,-102.487 723.199,-108.791\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.15154934505501427 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>0.15154934505501427</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"828\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"828\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7582478976795889&#45;&gt;0.15154934505501427 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>0.7582478976795889&#45;&gt;0.15154934505501427</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M842.401,-216.055C840.254,-208.145 837.647,-198.54 835.244,-189.688\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"838.554,-188.523 832.557,-179.789 831.799,-190.357 838.554,-188.523\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>0.4619616090012346</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"937\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9587672669854608&#45;&gt;0.4619616090012346 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>0.9587672669854608&#45;&gt;0.4619616090012346</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M951.401,-216.055C949.285,-208.261 946.723,-198.822 944.35,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"947.686,-189.009 941.689,-180.275 940.931,-190.843 947.686,-189.009\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9509132110828267 -->\r\n",
       "<g id=\"node78\" class=\"node\"><title>0.9509132110828267</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"828\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"828\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346&#45;&gt;0.9509132110828267 -->\r\n",
       "<g id=\"edge77\" class=\"edge\"><title>0.4619616090012346&#45;&gt;0.9509132110828267</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M912.538,-145.291C895.648,-134.444 873.16,-120.002 855.624,-108.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"857.267,-105.636 846.961,-103.177 853.484,-111.526 857.267,-105.636\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.33893141326588816 -->\r\n",
       "<g id=\"node80\" class=\"node\"><title>0.33893141326588816</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"901\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"901\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346&#45;&gt;0.33893141326588816 -->\r\n",
       "<g id=\"edge79\" class=\"edge\"><title>0.4619616090012346&#45;&gt;0.33893141326588816</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M928.285,-144.055C924.023,-135.767 918.803,-125.618 914.075,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"917.073,-114.599 909.386,-107.307 910.847,-117.801 917.073,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.42459401412313014 -->\r\n",
       "<g id=\"node82\" class=\"node\"><title>0.42459401412313014</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"974\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"974\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346&#45;&gt;0.42459401412313014 -->\r\n",
       "<g id=\"edge81\" class=\"edge\"><title>0.4619616090012346&#45;&gt;0.42459401412313014</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M945.957,-144.055C950.338,-135.767 955.702,-125.618 960.562,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"963.802,-117.784 965.381,-107.307 957.613,-114.512 963.802,-117.784\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.10111560982943557 -->\r\n",
       "<g id=\"node84\" class=\"node\"><title>0.10111560982943557</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1046\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1046\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346&#45;&gt;0.10111560982943557 -->\r\n",
       "<g id=\"edge83\" class=\"edge\"><title>0.4619616090012346&#45;&gt;0.10111560982943557</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M961.462,-145.291C978.352,-134.444 1000.84,-120.002 1018.38,-108.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1020.52,-111.526 1027.04,-103.177 1016.73,-105.636 1020.52,-111.526\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3662383241301117 -->\r\n",
       "<g id=\"node86\" class=\"node\"><title>0.3662383241301117</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1118\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1118\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346&#45;&gt;0.3662383241301117 -->\r\n",
       "<g id=\"edge85\" class=\"edge\"><title>0.4619616090012346&#45;&gt;0.3662383241301117</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M976.143,-147.774C1005.54,-137.583 1046.64,-122.777 1082,-108 1083.82,-107.241 1085.68,-106.439 1087.55,-105.615\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1089.17,-108.72 1096.82,-101.391 1086.27,-102.35 1089.17,-108.72\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.033320193601979464 -->\r\n",
       "<g id=\"node88\" class=\"node\"><title>0.033320193601979464</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1190\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4619616090012346&#45;&gt;0.033320193601979464 -->\r\n",
       "<g id=\"edge87\" class=\"edge\"><title>0.4619616090012346&#45;&gt;0.033320193601979464</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M984.381,-149.963C1043.29,-136.157 1138.08,-113.64 1154,-108 1155.91,-107.325 1157.85,-106.582 1159.79,-105.796\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1161.6,-108.826 1169.36,-101.617 1158.8,-102.411 1161.6,-108.826\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4150580140931701 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>0.4150580140931701</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1046\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1046\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24669781313223416&#45;&gt;0.4150580140931701 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>0.24669781313223416&#45;&gt;0.4150580140931701</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1046,-215.697C1046,-207.983 1046,-198.712 1046,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1049.5,-190.104 1046,-180.104 1042.5,-190.104 1049.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5870922024330659 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>0.5870922024330659</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1120\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1120\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7093203761206368&#45;&gt;0.5870922024330659 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>0.7093203761206368&#45;&gt;0.5870922024330659</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1119.25,-215.697C1119.36,-207.983 1119.49,-198.712 1119.61,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1123.11,-190.153 1119.76,-180.104 1116.11,-190.053 1123.11,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.16520933439016972 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>0.16520933439016972</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1194\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1194\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.941501343964291&#45;&gt;0.16520933439016972 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>0.941501343964291&#45;&gt;0.16520933439016972</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1193.25,-215.697C1193.36,-207.983 1193.49,-198.712 1193.61,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1197.11,-190.153 1193.76,-180.104 1190.11,-190.053 1197.11,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0976511756258408 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>0.0976511756258408</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1266\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1266\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.07786575982517907&#45;&gt;0.0976511756258408 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>0.07786575982517907&#45;&gt;0.0976511756258408</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1266,-215.697C1266,-207.983 1266,-198.712 1266,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1269.5,-190.104 1266,-180.104 1262.5,-190.104 1269.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9441430502761184 -->\r\n",
       "<g id=\"node35\" class=\"node\"><title>0.9441430502761184</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1340\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1340\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3467911525656786&#45;&gt;0.9441430502761184 -->\r\n",
       "<g id=\"edge34\" class=\"edge\"><title>0.3467911525656786&#45;&gt;0.9441430502761184</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1340.75,-215.697C1340.64,-207.983 1340.51,-198.712 1340.39,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1343.89,-190.053 1340.24,-180.104 1336.89,-190.153 1343.89,-190.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9305466785712486 -->\r\n",
       "<g id=\"node37\" class=\"node\"><title>0.9305466785712486</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1414\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1414\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8737309516699617&#45;&gt;0.9305466785712486 -->\r\n",
       "<g id=\"edge36\" class=\"edge\"><title>0.8737309516699617&#45;&gt;0.9305466785712486</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1414,-215.697C1414,-207.983 1414,-198.712 1414,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1417.5,-190.104 1414,-180.104 1410.5,-190.104 1417.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.36662279986494706 -->\r\n",
       "<g id=\"node39\" class=\"node\"><title>0.36662279986494706</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1486\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1486\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.48814066890547325&#45;&gt;0.36662279986494706 -->\r\n",
       "<g id=\"edge38\" class=\"edge\"><title>0.48814066890547325&#45;&gt;0.36662279986494706</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1486,-215.697C1486,-207.983 1486,-198.712 1486,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1489.5,-190.104 1486,-180.104 1482.5,-190.104 1489.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2357084980443771 -->\r\n",
       "<g id=\"node41\" class=\"node\"><title>0.2357084980443771</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1558\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1558\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1752943271256182&#45;&gt;0.2357084980443771 -->\r\n",
       "<g id=\"edge40\" class=\"edge\"><title>0.1752943271256182&#45;&gt;0.2357084980443771</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1558,-215.697C1558,-207.983 1558,-198.712 1558,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1561.5,-190.104 1558,-180.104 1554.5,-190.104 1561.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.37797780167218686 -->\r\n",
       "<g id=\"node43\" class=\"node\"><title>0.37797780167218686</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1630\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1630\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8756756116268245&#45;&gt;0.37797780167218686 -->\r\n",
       "<g id=\"edge42\" class=\"edge\"><title>0.8756756116268245&#45;&gt;0.37797780167218686</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1630,-215.697C1630,-207.983 1630,-198.712 1630,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1633.5,-190.104 1630,-180.104 1626.5,-190.104 1633.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.48401352641312023 -->\r\n",
       "<g id=\"node45\" class=\"node\"><title>0.48401352641312023</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1703\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1703\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zero</text>\r\n",
       "</g>\r\n",
       "<!-- 0.41365524346015736&#45;&gt;0.48401352641312023 -->\r\n",
       "<g id=\"edge44\" class=\"edge\"><title>0.41365524346015736&#45;&gt;0.48401352641312023</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1703,-215.697C1703,-207.983 1703,-198.712 1703,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1706.5,-190.104 1703,-180.104 1699.5,-190.104 1706.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6996857044885638 -->\r\n",
       "<g id=\"node47\" class=\"node\"><title>0.6996857044885638</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1775\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1775\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0011609525247660013&#45;&gt;0.6996857044885638 -->\r\n",
       "<g id=\"edge46\" class=\"edge\"><title>0.0011609525247660013&#45;&gt;0.6996857044885638</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1775,-215.697C1775,-207.983 1775,-198.712 1775,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1778.5,-190.104 1775,-180.104 1771.5,-190.104 1778.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9686461900259137 -->\r\n",
       "<g id=\"node49\" class=\"node\"><title>0.9686461900259137</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1847\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1847\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5298538521794254&#45;&gt;0.9686461900259137 -->\r\n",
       "<g id=\"edge48\" class=\"edge\"><title>0.5298538521794254&#45;&gt;0.9686461900259137</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1847,-215.697C1847,-207.983 1847,-198.712 1847,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1850.5,-190.104 1847,-180.104 1843.5,-190.104 1850.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9920192674632796 -->\r\n",
       "<g id=\"node51\" class=\"node\"><title>0.9920192674632796</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1919\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1919\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8530205652507762&#45;&gt;0.9920192674632796 -->\r\n",
       "<g id=\"edge50\" class=\"edge\"><title>0.8530205652507762&#45;&gt;0.9920192674632796</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1919,-215.697C1919,-207.983 1919,-198.712 1919,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1922.5,-190.104 1919,-180.104 1915.5,-190.104 1922.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.13776971879785327 -->\r\n",
       "<g id=\"node53\" class=\"node\"><title>0.13776971879785327</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1991\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1991\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5102952299242905&#45;&gt;0.13776971879785327 -->\r\n",
       "<g id=\"edge52\" class=\"edge\"><title>0.5102952299242905&#45;&gt;0.13776971879785327</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1991,-215.697C1991,-207.983 1991,-198.712 1991,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1994.5,-190.104 1991,-180.104 1987.5,-190.104 1994.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.16498486854487593 -->\r\n",
       "<g id=\"node55\" class=\"node\"><title>0.16498486854487593</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2063\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2063\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8765129313998026&#45;&gt;0.16498486854487593 -->\r\n",
       "<g id=\"edge54\" class=\"edge\"><title>0.8765129313998026&#45;&gt;0.16498486854487593</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2063,-215.697C2063,-207.983 2063,-198.712 2063,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2066.5,-190.104 2063,-180.104 2059.5,-190.104 2066.5,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.030951084949993102 -->\r\n",
       "<g id=\"node57\" class=\"node\"><title>0.030951084949993102</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5216295802561377&#45;&gt;0.030951084949993102 -->\r\n",
       "<g id=\"edge56\" class=\"edge\"><title>0.5216295802561377&#45;&gt;0.030951084949993102</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-71.6966C27,-63.9827 27,-54.7125 27,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5001,-46.1043 27,-36.1043 23.5001,-46.1044 30.5001,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.10908569731743767 -->\r\n",
       "<g id=\"node59\" class=\"node\"><title>0.10908569731743767</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6297791241649701&#45;&gt;0.10908569731743767 -->\r\n",
       "<g id=\"edge58\" class=\"edge\"><title>0.6297791241649701&#45;&gt;0.10908569731743767</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-71.6966C99,-63.9827 99,-54.7125 99,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-46.1043 99,-36.1043 95.5001,-46.1044 102.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2541196578965631 -->\r\n",
       "<g id=\"node61\" class=\"node\"><title>0.2541196578965631</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.10031874832017529&#45;&gt;0.2541196578965631 -->\r\n",
       "<g id=\"edge60\" class=\"edge\"><title>0.10031874832017529&#45;&gt;0.2541196578965631</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171,-71.6966C171,-63.9827 171,-54.7125 171,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.5,-46.1043 171,-36.1043 167.5,-46.1044 174.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5778727292922763 -->\r\n",
       "<g id=\"node63\" class=\"node\"><title>0.5778727292922763</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"243\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.45300281257318176&#45;&gt;0.5778727292922763 -->\r\n",
       "<g id=\"edge62\" class=\"edge\"><title>0.45300281257318176&#45;&gt;0.5778727292922763</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243,-71.6966C243,-63.9827 243,-54.7125 243,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.5,-46.1043 243,-36.1043 239.5,-46.1044 246.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.969365748715822 -->\r\n",
       "<g id=\"node65\" class=\"node\"><title>0.969365748715822</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"315\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8429894047454582&#45;&gt;0.969365748715822 -->\r\n",
       "<g id=\"edge64\" class=\"edge\"><title>0.8429894047454582&#45;&gt;0.969365748715822</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M315,-71.6966C315,-63.9827 315,-54.7125 315,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318.5,-46.1043 315,-36.1043 311.5,-46.1044 318.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.30117205976126893 -->\r\n",
       "<g id=\"node67\" class=\"node\"><title>0.30117205976126893</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"387\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"387\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9579805786468345&#45;&gt;0.30117205976126893 -->\r\n",
       "<g id=\"edge66\" class=\"edge\"><title>0.9579805786468345&#45;&gt;0.30117205976126893</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M387.753,-71.6966C387.643,-63.9827 387.51,-54.7125 387.387,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"390.887,-46.0533 387.244,-36.1043 383.888,-46.1533 390.887,-46.0533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.14640864617342553 -->\r\n",
       "<g id=\"node69\" class=\"node\"><title>0.14640864617342553</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"459\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"459\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6443853381831282&#45;&gt;0.14640864617342553 -->\r\n",
       "<g id=\"edge68\" class=\"edge\"><title>0.6443853381831282&#45;&gt;0.14640864617342553</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M459.753,-71.6966C459.643,-63.9827 459.51,-54.7125 459.387,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.887,-46.0533 459.244,-36.1043 455.888,-46.1533 462.887,-46.0533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8370191855187387 -->\r\n",
       "<g id=\"node71\" class=\"node\"><title>0.8370191855187387</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"533\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"533\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.10553093067961306&#45;&gt;0.8370191855187387 -->\r\n",
       "<g id=\"edge70\" class=\"edge\"><title>0.10553093067961306&#45;&gt;0.8370191855187387</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M533.753,-71.6966C533.643,-63.9827 533.51,-54.7125 533.387,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"536.887,-46.0533 533.244,-36.1043 529.888,-46.1533 536.887,-46.0533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4612633774386835 -->\r\n",
       "<g id=\"node73\" class=\"node\"><title>0.4612633774386835</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"607\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"607\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.34369024903603995&#45;&gt;0.4612633774386835 -->\r\n",
       "<g id=\"edge72\" class=\"edge\"><title>0.34369024903603995&#45;&gt;0.4612633774386835</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M607,-71.6966C607,-63.9827 607,-54.7125 607,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"610.5,-46.1043 607,-36.1043 603.5,-46.1044 610.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.20595708229069332 -->\r\n",
       "<g id=\"node75\" class=\"node\"><title>0.20595708229069332</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"679\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"679\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40630156851154586&#45;&gt;0.20595708229069332 -->\r\n",
       "<g id=\"edge74\" class=\"edge\"><title>0.40630156851154586&#45;&gt;0.20595708229069332</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M679,-71.6966C679,-63.9827 679,-54.7125 679,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"682.5,-46.1043 679,-36.1043 675.5,-46.1044 682.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.023939235593556263 -->\r\n",
       "<g id=\"node77\" class=\"node\"><title>0.023939235593556263</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"753\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"753\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9621481268256066&#45;&gt;0.023939235593556263 -->\r\n",
       "<g id=\"edge76\" class=\"edge\"><title>0.9621481268256066&#45;&gt;0.023939235593556263</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M752.247,-71.6966C752.357,-63.9827 752.49,-54.7125 752.613,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"756.112,-46.1533 752.756,-36.1043 749.113,-46.0533 756.112,-46.1533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3112938026369735 -->\r\n",
       "<g id=\"node79\" class=\"node\"><title>0.3112938026369735</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"827\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"827\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9509132110828267&#45;&gt;0.3112938026369735 -->\r\n",
       "<g id=\"edge78\" class=\"edge\"><title>0.9509132110828267&#45;&gt;0.3112938026369735</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M827.753,-71.6966C827.643,-63.9827 827.51,-54.7125 827.387,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"830.887,-46.0533 827.244,-36.1043 823.888,-46.1533 830.887,-46.0533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.41208136348913116 -->\r\n",
       "<g id=\"node81\" class=\"node\"><title>0.41208136348913116</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"901\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"901\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.33893141326588816&#45;&gt;0.41208136348913116 -->\r\n",
       "<g id=\"edge80\" class=\"edge\"><title>0.33893141326588816&#45;&gt;0.41208136348913116</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M901,-71.6966C901,-63.9827 901,-54.7125 901,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"904.5,-46.1043 901,-36.1043 897.5,-46.1044 904.5,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.05356433925457027 -->\r\n",
       "<g id=\"node83\" class=\"node\"><title>0.05356433925457027</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"975\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"975\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.42459401412313014&#45;&gt;0.05356433925457027 -->\r\n",
       "<g id=\"edge82\" class=\"edge\"><title>0.42459401412313014&#45;&gt;0.05356433925457027</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M974.247,-71.6966C974.357,-63.9827 974.49,-54.7125 974.613,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"978.112,-46.1533 974.756,-36.1043 971.113,-46.0533 978.112,-46.1533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.020554116518903598 -->\r\n",
       "<g id=\"node85\" class=\"node\"><title>0.020554116518903598</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1047\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1047\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.10111560982943557&#45;&gt;0.020554116518903598 -->\r\n",
       "<g id=\"edge84\" class=\"edge\"><title>0.10111560982943557&#45;&gt;0.020554116518903598</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1046.25,-71.6966C1046.36,-63.9827 1046.49,-54.7125 1046.61,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1050.11,-46.1533 1046.76,-36.1043 1043.11,-46.0533 1050.11,-46.1533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5946751011807877 -->\r\n",
       "<g id=\"node87\" class=\"node\"><title>0.5946751011807877</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1119\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1119\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3662383241301117&#45;&gt;0.5946751011807877 -->\r\n",
       "<g id=\"edge86\" class=\"edge\"><title>0.3662383241301117&#45;&gt;0.5946751011807877</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1118.25,-71.6966C1118.36,-63.9827 1118.49,-54.7125 1118.61,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1122.11,-46.1533 1118.76,-36.1043 1115.11,-46.0533 1122.11,-46.1533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7010764418201068 -->\r\n",
       "<g id=\"node89\" class=\"node\"><title>0.7010764418201068</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1191\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1191\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.033320193601979464&#45;&gt;0.7010764418201068 -->\r\n",
       "<g id=\"edge88\" class=\"edge\"><title>0.033320193601979464&#45;&gt;0.7010764418201068</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1190.25,-71.6966C1190.36,-63.9827 1190.49,-54.7125 1190.61,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1194.11,-46.1533 1190.76,-36.1043 1187.11,-46.0533 1194.11,-46.1533\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x19c1be24248>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System entropy:  2.7780537123291715\n"
     ]
    }
   ],
   "source": [
    "#Calling DecisionTree constructor\n",
    "tree1 = DecisionTree(data_descriptive, descriptive_features, data_label, \"entropy\")\n",
    "\n",
    "#Passing pruning features for tree1\n",
    "tree1.id3(0,15)\n",
    "\n",
    "#Visualizing decision tree by Graphviz\n",
    "dot1 = tree1.print_visualTree( render=True )\n",
    "display(dot1)\n",
    "\n",
    "print(\"System entropy: \", format(tree1.entropy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"8578pt\" height=\"764pt\"\r\n",
       " viewBox=\"0.00 0.00 8577.69 764.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 760)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-760 8573.69,-760 8573.69,4 -4,4\"/>\r\n",
       "<!-- root -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>root</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7238.69\" cy=\"-738\" rx=\"36.2938\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7238.69\" y=\"-734.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">TypeR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9282823878128134 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>0.9282823878128134</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5456.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5456.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.9282823878128134 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>root&#45;&gt;0.9282823878128134</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7202.29,-735.57C6972.58,-726.547 5726.18,-677.586 5493.96,-668.464\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5493.8,-664.955 5483.67,-668.06 5493.53,-671.95 5493.8,-664.955\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9999680683471178 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>0.9999680683471178</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6476.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6476.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.9999680683471178 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>root&#45;&gt;0.9999680683471178</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7203.22,-733.741C7075.91,-722.046 6642.78,-682.257 6513.45,-670.376\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6513.55,-666.871 6503.27,-669.442 6512.91,-673.842 6513.55,-666.871\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.27354645193869176 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>0.27354645193869176</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6886.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6886.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.27354645193869176 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>root&#45;&gt;0.27354645193869176</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7205.58,-730.415C7139.16,-717.207 6990.23,-687.589 6922.02,-674.025\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6922.67,-670.585 6912.18,-672.068 6921.3,-677.451 6922.67,-670.585\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.03453813625335833 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>0.03453813625335833</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7170.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7170.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">i</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.03453813625335833 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>root&#45;&gt;0.03453813625335833</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7223.6,-721.465C7214.28,-711.871 7202.18,-699.416 7191.91,-688.839\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7194.29,-686.27 7184.81,-681.536 7189.27,-691.147 7194.29,-686.27\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.043577089100561794 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>0.043577089100561794</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7306.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7306.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.043577089100561794 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>root&#45;&gt;0.043577089100561794</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7253.79,-721.465C7263.11,-711.871 7275.2,-699.416 7285.48,-688.839\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7288.12,-691.147 7292.57,-681.536 7283.1,-686.27 7288.12,-691.147\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7686841822436205 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>0.7686841822436205</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7507.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7507.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">j</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.7686841822436205 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>root&#45;&gt;0.7686841822436205</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7270.08,-728.833C7320.75,-715.647 7420.23,-689.761 7472.96,-676.038\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7474.06,-679.369 7482.86,-673.463 7472.3,-672.595 7474.06,-679.369\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7533002488468112 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>0.7533002488468112</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7836.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7836.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.7533002488468112 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>root&#45;&gt;0.7533002488468112</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7273.87,-732.883C7379.51,-720.517 7693.28,-683.787 7800.39,-671.25\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7800.86,-674.718 7810.39,-670.079 7800.05,-667.766 7800.86,-674.718\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.06919245277922592 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>0.06919245277922592</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8422.69\" cy=\"-666\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8422.69\" y=\"-662.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- root&#45;&gt;0.06919245277922592 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>root&#45;&gt;0.06919245277922592</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7274.78,-734.867C7449.77,-724.521 8208.88,-679.641 8385.76,-669.184\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8386.08,-672.671 8395.86,-668.587 8385.67,-665.683 8386.08,-672.671\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>0.1639814892635959</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4636.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4636.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9282823878128134&#45;&gt;0.1639814892635959 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0.9282823878128134&#45;&gt;0.1639814892635959</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5429.88,-662.711C5317.09,-653.083 4879.14,-615.697 4706.87,-600.99\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4707.15,-597.502 4696.89,-600.139 4706.56,-604.477 4707.15,-597.502\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9566548093409132 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>0.9566548093409132</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1981.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1981.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.9566548093409132 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.9566548093409132</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4573.68,-591.339C4202.7,-581.558 2309.55,-531.644 2019.11,-523.986\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2018.79,-520.477 2008.71,-523.712 2018.61,-527.475 2018.79,-520.477\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.89193401013 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>0.89193401013</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3373.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3373.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.89193401013 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.89193401013</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4574.92,-589.576C4351.3,-577.182 3587.87,-534.871 3410.65,-525.048\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3410.71,-521.546 3400.53,-524.487 3410.32,-528.536 3410.71,-521.546\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5071562507090677 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>0.5071562507090677</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3919.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3919.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.5071562507090677 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.5071562507090677</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4577.41,-587.212C4434.25,-573.236 4072.92,-537.96 3956.47,-526.591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3956.59,-523.086 3946.3,-525.597 3955.91,-530.052 3956.59,-523.086\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7806289996939307 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>0.7806289996939307</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4393.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4393.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.7806289996939307 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.7806289996939307</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4593.81,-580.647C4546.51,-567.02 4471.35,-545.369 4427.85,-532.84\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4428.61,-529.417 4418.04,-530.012 4426.68,-536.143 4428.61,-529.417\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9776705814657936 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>0.9776705814657936</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4636.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4636.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.9776705814657936 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.9776705814657936</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4636.69,-575.697C4636.69,-567.983 4636.69,-558.712 4636.69,-550.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4640.19,-550.104 4636.69,-540.104 4633.19,-550.104 4640.19,-550.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3606379895298152 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>0.3606379895298152</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4727.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4727.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.3606379895298152 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.3606379895298152</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4657.8,-576.765C4671.11,-566.53 4688.36,-553.256 4702.4,-542.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4704.87,-544.976 4710.66,-536.105 4700.6,-539.428 4704.87,-544.976\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.34425621765885006 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>0.34425621765885006</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4810.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4810.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">i</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.34425621765885006 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.34425621765885006</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4671.91,-578.834C4703.13,-566.272 4748.35,-548.08 4778.6,-535.911\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4780.27,-539.012 4788.24,-532.033 4777.66,-532.518 4780.27,-539.012\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3644633808541732 -->\r\n",
       "<g id=\"node32\" class=\"node\"><title>0.3644633808541732</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5003.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5003.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1639814892635959&#45;&gt;0.3644633808541732 -->\r\n",
       "<g id=\"edge31\" class=\"edge\"><title>0.1639814892635959&#45;&gt;0.3644633808541732</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4688.11,-583.193C4763.61,-568.793 4902.55,-542.291 4967.92,-529.823\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4968.96,-533.187 4978.13,-527.876 4967.65,-526.311 4968.96,-533.187\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2710924898468129 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>0.2710924898468129</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5987.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5987.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9999680683471178&#45;&gt;0.2710924898468129 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0.9999680683471178&#45;&gt;0.2710924898468129</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6450.4,-661.236C6376.03,-650.59 6162.48,-620.021 6053.46,-604.414\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6053.63,-600.904 6043.24,-602.951 6052.64,-607.833 6053.63,-600.904\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2562198334124841 -->\r\n",
       "<g id=\"node34\" class=\"node\"><title>0.2562198334124841</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5526.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5526.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2710924898468129&#45;&gt;0.2562198334124841 -->\r\n",
       "<g id=\"edge33\" class=\"edge\"><title>0.2710924898468129&#45;&gt;0.2562198334124841</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5932.83,-584.721C5863.91,-574.315 5742.04,-555.891 5637.69,-540 5612.68,-536.191 5584.51,-531.876 5562.8,-528.546\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5563.12,-525.054 5552.71,-526.997 5562.06,-531.973 5563.12,-525.054\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4192472543801965 -->\r\n",
       "<g id=\"node36\" class=\"node\"><title>0.4192472543801965</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5673.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5673.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2710924898468129&#45;&gt;0.4192472543801965 -->\r\n",
       "<g id=\"edge35\" class=\"edge\"><title>0.2710924898468129&#45;&gt;0.4192472543801965</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5939.32,-582.216C5875.67,-568.027 5765.31,-543.424 5708.98,-530.866\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5709.64,-527.427 5699.11,-528.667 5708.11,-534.259 5709.64,-527.427\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.11021112378459386 -->\r\n",
       "<g id=\"node38\" class=\"node\"><title>0.11021112378459386</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5919.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5919.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2710924898468129&#45;&gt;0.11021112378459386 -->\r\n",
       "<g id=\"edge37\" class=\"edge\"><title>0.2710924898468129&#45;&gt;0.11021112378459386</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5971.58,-576.411C5962.44,-567.004 5950.89,-555.115 5941.01,-544.944\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5943.33,-542.305 5933.85,-537.57 5938.31,-547.182 5943.33,-542.305\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9795480807663823 -->\r\n",
       "<g id=\"node40\" class=\"node\"><title>0.9795480807663823</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6023.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6023.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2710924898468129&#45;&gt;0.9795480807663823 -->\r\n",
       "<g id=\"edge39\" class=\"edge\"><title>0.2710924898468129&#45;&gt;0.9795480807663823</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5996.41,-576.055C6000.67,-567.767 6005.89,-557.618 6010.62,-548.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6013.85,-549.801 6015.31,-539.307 6007.62,-546.599 6013.85,-549.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.829526115160897 -->\r\n",
       "<g id=\"node42\" class=\"node\"><title>0.829526115160897</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6200.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6200.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2710924898468129&#45;&gt;0.829526115160897 -->\r\n",
       "<g id=\"edge41\" class=\"edge\"><title>0.2710924898468129&#45;&gt;0.829526115160897</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6027.76,-579.834C6068.14,-566.564 6129.73,-546.323 6167.47,-533.917\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6168.58,-537.237 6176.99,-530.79 6166.4,-530.587 6168.58,-537.237\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.35710505966883577 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>0.35710505966883577</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6623.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6623.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.27354645193869176&#45;&gt;0.35710505966883577 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>0.27354645193869176&#45;&gt;0.35710505966883577</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6861.95,-658.415C6820.21,-647.306 6734.86,-624.588 6678.47,-609.578\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6679.2,-606.152 6668.64,-606.962 6677.4,-612.916 6679.2,-606.152\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7947183106297023 -->\r\n",
       "<g id=\"node44\" class=\"node\"><title>0.7947183106297023</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6463.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6463.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.35710505966883577&#45;&gt;0.7947183106297023 -->\r\n",
       "<g id=\"edge43\" class=\"edge\"><title>0.35710505966883577&#45;&gt;0.7947183106297023</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6590.54,-578.496C6562.54,-566.245 6522.71,-548.821 6495.19,-536.779\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6496.57,-533.564 6486.01,-532.762 6493.77,-539.977 6496.57,-533.564\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2177506454014969 -->\r\n",
       "<g id=\"node46\" class=\"node\"><title>0.2177506454014969</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6550.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6550.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.35710505966883577&#45;&gt;0.2177506454014969 -->\r\n",
       "<g id=\"edge45\" class=\"edge\"><title>0.35710505966883577&#45;&gt;0.2177506454014969</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6606.39,-576.411C6596.35,-566.781 6583.6,-554.552 6572.83,-544.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6575.05,-541.503 6565.41,-537.108 6570.2,-546.555 6575.05,-541.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.26330903724042976 -->\r\n",
       "<g id=\"node48\" class=\"node\"><title>0.26330903724042976</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6623.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6623.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.35710505966883577&#45;&gt;0.26330903724042976 -->\r\n",
       "<g id=\"edge47\" class=\"edge\"><title>0.35710505966883577&#45;&gt;0.26330903724042976</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6623.69,-575.697C6623.69,-567.983 6623.69,-558.712 6623.69,-550.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6627.19,-550.104 6623.69,-540.104 6620.19,-550.104 6627.19,-550.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5282402128395085 -->\r\n",
       "<g id=\"node50\" class=\"node\"><title>0.5282402128395085</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6696.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6696.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.35710505966883577&#45;&gt;0.5282402128395085 -->\r\n",
       "<g id=\"edge49\" class=\"edge\"><title>0.35710505966883577&#45;&gt;0.5282402128395085</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6640.99,-576.411C6651.04,-566.781 6663.79,-554.552 6674.56,-544.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6677.19,-546.555 6681.98,-537.108 6672.34,-541.503 6677.19,-546.555\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>0.96343454596104</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7120.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7120.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.03453813625335833&#45;&gt;0.96343454596104 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>0.03453813625335833&#45;&gt;0.96343454596104</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7159.6,-649.465C7153.46,-640.867 7145.67,-629.97 7138.69,-620.187\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7141.47,-618.065 7132.81,-611.962 7135.77,-622.133 7141.47,-618.065\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7325113727943973 -->\r\n",
       "<g id=\"node52\" class=\"node\"><title>0.7325113727943973</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6846.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6846.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104&#45;&gt;0.7325113727943973 -->\r\n",
       "<g id=\"edge51\" class=\"edge\"><title>0.96343454596104&#45;&gt;0.7325113727943973</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7075.14,-581.362C7020.59,-567.425 6930.43,-544.392 6881.27,-531.834\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6881.99,-528.404 6871.43,-529.32 6880.26,-535.186 6881.99,-528.404\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0222176695373012 -->\r\n",
       "<g id=\"node54\" class=\"node\"><title>0.0222176695373012</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6959.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6959.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104&#45;&gt;0.0222176695373012 -->\r\n",
       "<g id=\"edge53\" class=\"edge\"><title>0.96343454596104&#45;&gt;0.0222176695373012</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7087.34,-578.496C7058.99,-566.173 7018.61,-548.617 6990.9,-536.569\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6992.24,-533.332 6981.67,-532.554 6989.44,-539.752 6992.24,-533.332\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9685937912958483 -->\r\n",
       "<g id=\"node56\" class=\"node\"><title>0.9685937912958483</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7047.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7047.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104&#45;&gt;0.9685937912958483 -->\r\n",
       "<g id=\"edge55\" class=\"edge\"><title>0.96343454596104&#45;&gt;0.9685937912958483</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7103.39,-576.411C7093.35,-566.781 7080.6,-554.552 7069.83,-544.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7072.05,-541.503 7062.41,-537.108 7067.2,-546.555 7072.05,-541.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9321411293065703 -->\r\n",
       "<g id=\"node58\" class=\"node\"><title>0.9321411293065703</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7120.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7120.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104&#45;&gt;0.9321411293065703 -->\r\n",
       "<g id=\"edge57\" class=\"edge\"><title>0.96343454596104&#45;&gt;0.9321411293065703</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7120.69,-575.697C7120.69,-567.983 7120.69,-558.712 7120.69,-550.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7124.19,-550.104 7120.69,-540.104 7117.19,-550.104 7124.19,-550.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.722478027704729 -->\r\n",
       "<g id=\"node60\" class=\"node\"><title>0.722478027704729</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7192.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7192.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104&#45;&gt;0.722478027704729 -->\r\n",
       "<g id=\"edge59\" class=\"edge\"><title>0.96343454596104&#45;&gt;0.722478027704729</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7137.76,-576.411C7147.53,-566.911 7159.9,-554.882 7170.43,-544.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7172.98,-547.051 7177.71,-537.57 7168.1,-542.032 7172.98,-547.051\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6637795276358762 -->\r\n",
       "<g id=\"node62\" class=\"node\"><title>0.6637795276358762</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7279.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7279.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96343454596104&#45;&gt;0.6637795276358762 -->\r\n",
       "<g id=\"edge61\" class=\"edge\"><title>0.96343454596104&#45;&gt;0.6637795276358762</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7153.64,-578.496C7181.35,-566.298 7220.7,-548.973 7248.04,-536.937\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7249.78,-539.995 7257.52,-532.762 7246.96,-533.588 7249.78,-539.995\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3766968201814711 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>0.3766968201814711</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7468.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7468.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.043577089100561794&#45;&gt;0.3766968201814711 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>0.043577089100561794&#45;&gt;0.3766968201814711</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7328.88,-655.414C7353.77,-644.657 7394.75,-626.951 7425.92,-613.481\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7427.46,-616.629 7435.25,-609.449 7424.69,-610.203 7427.46,-616.629\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.07768285465605107 -->\r\n",
       "<g id=\"node64\" class=\"node\"><title>0.07768285465605107</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7395.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7395.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3766968201814711&#45;&gt;0.07768285465605107 -->\r\n",
       "<g id=\"edge63\" class=\"edge\"><title>0.3766968201814711&#45;&gt;0.07768285465605107</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7451.39,-576.411C7441.35,-566.781 7428.6,-554.552 7417.83,-544.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7420.05,-541.503 7410.41,-537.108 7415.2,-546.555 7420.05,-541.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6548558542866013 -->\r\n",
       "<g id=\"node66\" class=\"node\"><title>0.6548558542866013</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7468.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7468.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3766968201814711&#45;&gt;0.6548558542866013 -->\r\n",
       "<g id=\"edge65\" class=\"edge\"><title>0.3766968201814711&#45;&gt;0.6548558542866013</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7468.69,-575.697C7468.69,-567.983 7468.69,-558.712 7468.69,-550.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7472.19,-550.104 7468.69,-540.104 7465.19,-550.104 7472.19,-550.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8104967991391757 -->\r\n",
       "<g id=\"node68\" class=\"node\"><title>0.8104967991391757</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7541.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7541.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3766968201814711&#45;&gt;0.8104967991391757 -->\r\n",
       "<g id=\"edge67\" class=\"edge\"><title>0.3766968201814711&#45;&gt;0.8104967991391757</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7485.99,-576.411C7496.04,-566.781 7508.79,-554.552 7519.56,-544.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7522.19,-546.555 7526.98,-537.108 7517.34,-541.503 7522.19,-546.555\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7310851178126108 -->\r\n",
       "<g id=\"node70\" class=\"node\"><title>0.7310851178126108</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7614.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7614.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3766968201814711&#45;&gt;0.7310851178126108 -->\r\n",
       "<g id=\"edge69\" class=\"edge\"><title>0.3766968201814711&#45;&gt;0.7310851178126108</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7499.66,-578.155C7524.49,-566.25 7559.16,-549.627 7583.93,-537.749\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7585.73,-540.77 7593.23,-533.291 7582.7,-534.458 7585.73,-540.77\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>0.5511659709918106</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7867.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7867.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7686841822436205&#45;&gt;0.5511659709918106 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0.7686841822436205&#45;&gt;0.5511659709918106</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7533.3,-660.022C7589.83,-649.029 7726.65,-622.425 7806.67,-606.867\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7807.46,-610.278 7816.61,-604.933 7806.13,-603.406 7807.46,-610.278\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.750534363986897 -->\r\n",
       "<g id=\"node72\" class=\"node\"><title>0.750534363986897</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7686.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7686.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106&#45;&gt;0.750534363986897 -->\r\n",
       "<g id=\"edge71\" class=\"edge\"><title>0.5511659709918106&#45;&gt;0.750534363986897</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7831.5,-579.003C7798.64,-566.294 7750.62,-547.723 7719.02,-535.502\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7719.97,-532.116 7709.38,-531.773 7717.44,-538.645 7719.97,-532.116\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5011062607844455 -->\r\n",
       "<g id=\"node74\" class=\"node\"><title>0.5011062607844455</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7777.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7777.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106&#45;&gt;0.5011062607844455 -->\r\n",
       "<g id=\"edge73\" class=\"edge\"><title>0.5511659709918106&#45;&gt;0.5011062607844455</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7846.82,-576.765C7833.66,-566.53 7816.6,-553.256 7802.71,-542.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7804.59,-539.482 7794.54,-536.105 7800.29,-545.007 7804.59,-539.482\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24437965548096474 -->\r\n",
       "<g id=\"node76\" class=\"node\"><title>0.24437965548096474</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7867.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7867.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106&#45;&gt;0.24437965548096474 -->\r\n",
       "<g id=\"edge75\" class=\"edge\"><title>0.5511659709918106&#45;&gt;0.24437965548096474</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7867.69,-575.697C7867.69,-567.983 7867.69,-558.712 7867.69,-550.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7871.19,-550.104 7867.69,-540.104 7864.19,-550.104 7871.19,-550.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2205849422848586 -->\r\n",
       "<g id=\"node78\" class=\"node\"><title>0.2205849422848586</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7976.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7976.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106&#45;&gt;0.2205849422848586 -->\r\n",
       "<g id=\"edge77\" class=\"edge\"><title>0.5511659709918106&#45;&gt;0.2205849422848586</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7892.16,-577.291C7909.05,-566.444 7931.53,-552.002 7949.07,-540.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7951.21,-543.526 7957.73,-535.177 7947.43,-537.636 7951.21,-543.526\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.18058753083898316 -->\r\n",
       "<g id=\"node80\" class=\"node\"><title>0.18058753083898316</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8085.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8085.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106&#45;&gt;0.18058753083898316 -->\r\n",
       "<g id=\"edge79\" class=\"edge\"><title>0.5511659709918106&#45;&gt;0.18058753083898316</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7908.19,-579.998C7949.67,-566.677 8013.42,-546.209 8052.17,-533.766\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8053.47,-537.023 8061.92,-530.634 8051.33,-530.359 8053.47,-537.023\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6864473249522036 -->\r\n",
       "<g id=\"node82\" class=\"node\"><title>0.6864473249522036</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8190.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8190.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5511659709918106&#45;&gt;0.6864473249522036 -->\r\n",
       "<g id=\"edge81\" class=\"edge\"><title>0.5511659709918106&#45;&gt;0.6864473249522036</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7918.41,-582.974C7969.77,-572.692 8051.41,-555.985 8121.69,-540 8132.82,-537.47 8144.9,-534.551 8155.81,-531.852\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8156.98,-535.169 8165.83,-529.353 8155.28,-528.377 8156.98,-535.169\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8145707079726703 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>0.8145707079726703</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8360.69\" cy=\"-594\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8360.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7533002488468112&#45;&gt;0.8145707079726703 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>0.7533002488468112&#45;&gt;0.8145707079726703</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7863.04,-661.481C7941.91,-650.945 8177.87,-619.423 8294.27,-603.873\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8295.03,-607.304 8304.47,-602.51 8294.1,-600.365 8295.03,-607.304\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8061800540877742 -->\r\n",
       "<g id=\"node84\" class=\"node\"><title>0.8061800540877742</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8324.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8324.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8145707079726703&#45;&gt;0.8061800540877742 -->\r\n",
       "<g id=\"edge83\" class=\"edge\"><title>0.8145707079726703&#45;&gt;0.8061800540877742</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8351.98,-576.055C8347.72,-567.767 8342.5,-557.618 8337.77,-548.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8340.77,-546.599 8333.08,-539.307 8334.54,-549.801 8340.77,-546.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3590252153990894 -->\r\n",
       "<g id=\"node86\" class=\"node\"><title>0.3590252153990894</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8397.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8397.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8145707079726703&#45;&gt;0.3590252153990894 -->\r\n",
       "<g id=\"edge85\" class=\"edge\"><title>0.8145707079726703&#45;&gt;0.3590252153990894</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8369.65,-576.055C8374.03,-567.767 8379.4,-557.618 8384.26,-548.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8387.5,-549.784 8389.07,-539.307 8381.31,-546.512 8387.5,-549.784\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6310455678959187 -->\r\n",
       "<g id=\"node88\" class=\"node\"><title>0.6310455678959187</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8469.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8469.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8145707079726703&#45;&gt;0.6310455678959187 -->\r\n",
       "<g id=\"edge87\" class=\"edge\"><title>0.8145707079726703&#45;&gt;0.6310455678959187</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8385.16,-577.291C8402.05,-566.444 8424.53,-552.002 8442.07,-540.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8444.21,-543.526 8450.73,-535.177 8440.43,-537.636 8444.21,-543.526\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.27668332629604053 -->\r\n",
       "<g id=\"node90\" class=\"node\"><title>0.27668332629604053</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8541.69\" cy=\"-522\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8541.69\" y=\"-518.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8145707079726703&#45;&gt;0.27668332629604053 -->\r\n",
       "<g id=\"edge89\" class=\"edge\"><title>0.8145707079726703&#45;&gt;0.27668332629604053</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8399.84,-579.774C8429.23,-569.583 8470.33,-554.777 8505.69,-540 8507.51,-539.241 8509.37,-538.439 8511.24,-537.615\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8512.87,-540.72 8520.52,-533.391 8509.97,-534.35 8512.87,-540.72\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6073487192449103 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>0.6073487192449103</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8473.69\" cy=\"-594\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8473.69\" y=\"-590.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.06919245277922592&#45;&gt;0.6073487192449103 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>0.06919245277922592&#45;&gt;0.6073487192449103</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8434.01,-649.465C8440.46,-640.617 8448.68,-629.337 8455.96,-619.339\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8458.99,-621.121 8462.05,-610.977 8453.34,-616.999 8458.99,-621.121\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7843739151488026 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>0.7843739151488026</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"815.694\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"815.694\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9566548093409132&#45;&gt;0.7843739151488026 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>0.9566548093409132&#45;&gt;0.7843739151488026</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1954.87,-519.39C1807.91,-510.567 1099.07,-468.012 880.2,-454.873\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"880.344,-451.375 870.153,-454.269 879.925,-458.362 880.344,-451.375\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.96717016444266 -->\r\n",
       "<g id=\"node92\" class=\"node\"><title>0.96717016444266</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"339.694\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"339.694\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7843739151488026&#45;&gt;0.96717016444266 -->\r\n",
       "<g id=\"edge91\" class=\"edge\"><title>0.7843739151488026&#45;&gt;0.96717016444266</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M765.654,-441.641C669.285,-427.469 460.038,-396.698 375.852,-384.317\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"376.158,-380.825 365.755,-382.833 375.14,-387.75 376.158,-380.825\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2013407662702893 -->\r\n",
       "<g id=\"node94\" class=\"node\"><title>0.2013407662702893</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"579.694\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"579.694\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7843739151488026&#45;&gt;0.2013407662702893 -->\r\n",
       "<g id=\"edge93\" class=\"edge\"><title>0.7843739151488026&#45;&gt;0.2013407662702893</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M775.927,-437.205C730.443,-423.714 656.736,-401.851 613.778,-389.109\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"614.652,-385.718 604.069,-386.23 612.661,-392.429 614.652,-385.718\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0995713661631289 -->\r\n",
       "<g id=\"node96\" class=\"node\"><title>0.0995713661631289</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"769.694\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"769.694\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7843739151488026&#45;&gt;0.0995713661631289 -->\r\n",
       "<g id=\"edge95\" class=\"edge\"><title>0.7843739151488026&#45;&gt;0.0995713661631289</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M804.559,-432.055C798.917,-423.469 791.963,-412.888 785.754,-403.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.513,-401.264 780.097,-394.829 782.663,-405.109 788.513,-401.264\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7959930635740706 -->\r\n",
       "<g id=\"node98\" class=\"node\"><title>0.7959930635740706</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"860.694\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"860.694\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7843739151488026&#45;&gt;0.7959930635740706 -->\r\n",
       "<g id=\"edge97\" class=\"edge\"><title>0.7843739151488026&#45;&gt;0.7959930635740706</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M826.588,-432.055C832.107,-423.469 838.909,-412.888 844.983,-403.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"848.055,-405.134 850.518,-394.829 842.167,-401.349 848.055,-405.134\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8074661793041445 -->\r\n",
       "<g id=\"node100\" class=\"node\"><title>0.8074661793041445</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1061.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1061.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7843739151488026&#45;&gt;0.8074661793041445 -->\r\n",
       "<g id=\"edge99\" class=\"edge\"><title>0.7843739151488026&#45;&gt;0.8074661793041445</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M856.041,-437.519C903.842,-423.917 982.64,-401.495 1027.55,-388.716\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1028.74,-392.018 1037.4,-385.914 1026.82,-385.285 1028.74,-392.018\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>0.5019018410820465</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2405.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2405.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.89193401013&#45;&gt;0.5019018410820465 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>0.89193401013&#45;&gt;0.5019018410820465</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3347.05,-519.073C3219.97,-509.883 2673.52,-470.368 2476.69,-456.134\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2476.7,-452.625 2466.47,-455.395 2476.19,-459.607 2476.7,-452.625\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24602247453061665 -->\r\n",
       "<g id=\"node102\" class=\"node\"><title>0.24602247453061665</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1726.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1726.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465&#45;&gt;0.24602247453061665 -->\r\n",
       "<g id=\"edge101\" class=\"edge\"><title>0.5019018410820465&#45;&gt;0.24602247453061665</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2346.17,-443.501C2247.2,-434.273 2042.6,-414.824 1869.69,-396 1833.39,-392.048 1791.96,-387.071 1763.08,-383.526\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1763.39,-380.038 1753.03,-382.289 1762.53,-386.985 1763.39,-380.038\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4734923176217931 -->\r\n",
       "<g id=\"node104\" class=\"node\"><title>0.4734923176217931</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1905.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1905.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465&#45;&gt;0.4734923176217931 -->\r\n",
       "<g id=\"edge103\" class=\"edge\"><title>0.5019018410820465&#45;&gt;0.4734923176217931</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2349.79,-441.174C2246.44,-426.704 2028.15,-396.144 1941.88,-384.066\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1942.18,-380.574 1931.79,-382.654 1941.21,-387.506 1942.18,-380.574\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.44529859511996495 -->\r\n",
       "<g id=\"node106\" class=\"node\"><title>0.44529859511996495</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2182.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2182.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465&#45;&gt;0.44529859511996495 -->\r\n",
       "<g id=\"edge105\" class=\"edge\"><title>0.5019018410820465&#45;&gt;0.44529859511996495</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2364.79,-436.161C2322.11,-422.763 2255.98,-402.005 2216.26,-389.535\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2217.11,-386.133 2206.52,-386.478 2215.01,-392.812 2217.11,-386.133\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.32298951801016895 -->\r\n",
       "<g id=\"node108\" class=\"node\"><title>0.32298951801016895</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2405.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2405.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465&#45;&gt;0.32298951801016895 -->\r\n",
       "<g id=\"edge107\" class=\"edge\"><title>0.5019018410820465&#45;&gt;0.32298951801016895</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2405.69,-431.697C2405.69,-423.983 2405.69,-414.712 2405.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2409.19,-406.104 2405.69,-396.104 2402.19,-406.104 2409.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.895886590279147 -->\r\n",
       "<g id=\"node110\" class=\"node\"><title>0.895886590279147</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2548.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2548.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465&#45;&gt;0.895886590279147 -->\r\n",
       "<g id=\"edge109\" class=\"edge\"><title>0.5019018410820465&#45;&gt;0.895886590279147</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2436.02,-434.155C2460.2,-422.321 2493.89,-405.825 2518.13,-393.961\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2519.79,-397.044 2527.24,-389.503 2516.72,-390.756 2519.79,-397.044\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7448890270904971 -->\r\n",
       "<g id=\"node112\" class=\"node\"><title>0.7448890270904971</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2712.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2712.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5019018410820465&#45;&gt;0.7448890270904971 -->\r\n",
       "<g id=\"edge111\" class=\"edge\"><title>0.5019018410820465&#45;&gt;0.7448890270904971</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2453.66,-438.063C2515.77,-423.902 2622.54,-399.556 2677.6,-387.003\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2678.6,-390.364 2687.57,-384.728 2677.04,-383.539 2678.6,-390.364\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.04411803349892218 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>0.04411803349892218</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3458.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3458.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5071562507090677&#45;&gt;0.04411803349892218 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>0.5071562507090677&#45;&gt;0.04411803349892218</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3893.59,-517.036C3821.77,-506.131 3619.88,-475.474 3518.44,-460.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3518.76,-456.581 3508.35,-458.54 3517.71,-463.502 3518.76,-456.581\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9842916698245636 -->\r\n",
       "<g id=\"node114\" class=\"node\"><title>0.9842916698245636</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3286.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3286.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.04411803349892218&#45;&gt;0.9842916698245636 -->\r\n",
       "<g id=\"edge113\" class=\"edge\"><title>0.04411803349892218&#45;&gt;0.9842916698245636</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3425.53,-435.503C3394.61,-422.92 3348.82,-404.283 3318.38,-391.897\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3319.66,-388.639 3309.08,-388.111 3317.02,-395.122 3319.66,-388.639\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6218884301526906 -->\r\n",
       "<g id=\"node116\" class=\"node\"><title>0.6218884301526906</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3404.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3404.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.04411803349892218&#45;&gt;0.6218884301526906 -->\r\n",
       "<g id=\"edge115\" class=\"edge\"><title>0.04411803349892218&#45;&gt;0.6218884301526906</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3445.9,-432.411C3439.05,-423.53 3430.49,-412.439 3422.95,-402.668\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3425.54,-400.291 3416.66,-394.511 3420,-404.567 3425.54,-400.291\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8747826757794844 -->\r\n",
       "<g id=\"node118\" class=\"node\"><title>0.8747826757794844</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3486.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3486.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.04411803349892218&#45;&gt;0.8747826757794844 -->\r\n",
       "<g id=\"edge117\" class=\"edge\"><title>0.04411803349892218&#45;&gt;0.8747826757794844</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3465.47,-432.055C3468.71,-423.973 3472.65,-414.121 3476.25,-405.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3479.51,-406.374 3479.98,-395.789 3473.02,-403.774 3479.51,-406.374\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>0.00640223042340482</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4132.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4132.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7806289996939307&#45;&gt;0.00640223042340482 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>0.7806289996939307&#45;&gt;0.00640223042340482</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4369.14,-514.415C4327.72,-503.306 4243.02,-480.588 4187.05,-465.578\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4187.86,-462.172 4177.3,-462.962 4186.05,-468.933 4187.86,-462.172\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.34262469833850173 -->\r\n",
       "<g id=\"node120\" class=\"node\"><title>0.34262469833850173</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3706.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3706.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482&#45;&gt;0.34262469833850173 -->\r\n",
       "<g id=\"edge119\" class=\"edge\"><title>0.00640223042340482&#45;&gt;0.34262469833850173</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4079.17,-440.205C3991.03,-425.721 3817.62,-397.228 3742.64,-384.907\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3743.17,-381.447 3732.74,-383.279 3742.04,-388.354 3743.17,-381.447\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.16799191751908227 -->\r\n",
       "<g id=\"node122\" class=\"node\"><title>0.16799191751908227</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3894.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3894.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482&#45;&gt;0.16799191751908227 -->\r\n",
       "<g id=\"edge121\" class=\"edge\"><title>0.00640223042340482&#45;&gt;0.16799191751908227</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4090.14,-436.485C4043.97,-422.906 3971.18,-401.495 3928.67,-388.993\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3929.64,-385.631 3919.06,-386.167 3927.67,-392.346 3929.64,-385.631\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.209711999370511 -->\r\n",
       "<g id=\"node124\" class=\"node\"><title>0.209711999370511</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4045.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4045.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482&#45;&gt;0.209711999370511 -->\r\n",
       "<g id=\"edge123\" class=\"edge\"><title>0.00640223042340482&#45;&gt;0.209711999370511</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4112.52,-432.765C4099.88,-422.597 4083.51,-409.43 4070.14,-398.671\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4072.25,-395.873 4062.26,-392.331 4067.86,-401.327 4072.25,-395.873\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3798047979293897 -->\r\n",
       "<g id=\"node126\" class=\"node\"><title>0.3798047979293897</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4132.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4132.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482&#45;&gt;0.3798047979293897 -->\r\n",
       "<g id=\"edge125\" class=\"edge\"><title>0.00640223042340482&#45;&gt;0.3798047979293897</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4132.69,-431.697C4132.69,-423.983 4132.69,-414.712 4132.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4136.19,-406.104 4132.69,-396.104 4129.19,-406.104 4136.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.44117039905476274 -->\r\n",
       "<g id=\"node128\" class=\"node\"><title>0.44117039905476274</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4231.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4231.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482&#45;&gt;0.44117039905476274 -->\r\n",
       "<g id=\"edge127\" class=\"edge\"><title>0.00640223042340482&#45;&gt;0.44117039905476274</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4155.16,-433.116C4170.18,-422.497 4189.98,-408.492 4205.69,-397.389\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4207.79,-400.191 4213.93,-391.56 4203.75,-394.476 4207.79,-400.191\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.823348341496976 -->\r\n",
       "<g id=\"node130\" class=\"node\"><title>0.823348341496976</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4338.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4338.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.00640223042340482&#45;&gt;0.823348341496976 -->\r\n",
       "<g id=\"edge129\" class=\"edge\"><title>0.00640223042340482&#45;&gt;0.823348341496976</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4171.93,-435.669C4210.55,-422.543 4268.91,-402.714 4305.36,-390.329\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4306.68,-393.576 4315.02,-387.044 4304.43,-386.948 4306.68,-393.576\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>0.40527962583560617</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4636.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4636.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9776705814657936&#45;&gt;0.40527962583560617 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>0.9776705814657936&#45;&gt;0.40527962583560617</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4636.69,-503.697C4636.69,-495.983 4636.69,-486.712 4636.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4640.19,-478.104 4636.69,-468.104 4633.19,-478.104 4640.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5849365089269531 -->\r\n",
       "<g id=\"node132\" class=\"node\"><title>0.5849365089269531</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4492.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4492.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617&#45;&gt;0.5849365089269531 -->\r\n",
       "<g id=\"edge131\" class=\"edge\"><title>0.40527962583560617&#45;&gt;0.5849365089269531</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4606.16,-434.155C4581.67,-422.25 4547.47,-405.627 4523.03,-393.749\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4524.39,-390.515 4513.86,-389.291 4521.33,-396.811 4524.39,-390.515\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7743721994425291 -->\r\n",
       "<g id=\"node134\" class=\"node\"><title>0.7743721994425291</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4591.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4591.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617&#45;&gt;0.7743721994425291 -->\r\n",
       "<g id=\"edge133\" class=\"edge\"><title>0.40527962583560617&#45;&gt;0.7743721994425291</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4625.8,-432.055C4620.28,-423.469 4613.48,-412.888 4607.41,-403.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4610.22,-401.349 4601.87,-394.829 4604.33,-405.134 4610.22,-401.349\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.02340463051152475 -->\r\n",
       "<g id=\"node136\" class=\"node\"><title>0.02340463051152475</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4680.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4680.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617&#45;&gt;0.02340463051152475 -->\r\n",
       "<g id=\"edge135\" class=\"edge\"><title>0.40527962583560617&#45;&gt;0.02340463051152475</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4647.35,-432.055C4652.74,-423.469 4659.39,-412.888 4665.33,-403.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4668.39,-405.158 4670.74,-394.829 4662.46,-401.433 4668.39,-405.158\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5256041754815182 -->\r\n",
       "<g id=\"node138\" class=\"node\"><title>0.5256041754815182</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4798.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4798.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617&#45;&gt;0.5256041754815182 -->\r\n",
       "<g id=\"edge137\" class=\"edge\"><title>0.40527962583560617&#45;&gt;0.5256041754815182</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4670.26,-434.496C4698.78,-422.173 4739.41,-404.617 4767.29,-392.569\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4768.79,-395.734 4776.58,-388.554 4766.01,-389.308 4768.79,-395.734\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3459194778693324 -->\r\n",
       "<g id=\"node140\" class=\"node\"><title>0.3459194778693324</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4884.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4884.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617&#45;&gt;0.3459194778693324 -->\r\n",
       "<g id=\"edge139\" class=\"edge\"><title>0.40527962583560617&#45;&gt;0.3459194778693324</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4682.95,-437.542C4723.23,-427.343 4783.11,-411.656 4834.69,-396 4840.18,-394.336 4845.96,-392.471 4851.58,-390.603\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4853.05,-393.801 4861.4,-387.278 4850.8,-387.171 4853.05,-393.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3019976258171191 -->\r\n",
       "<g id=\"node142\" class=\"node\"><title>0.3019976258171191</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4963.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4963.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.40527962583560617&#45;&gt;0.3019976258171191 -->\r\n",
       "<g id=\"edge141\" class=\"edge\"><title>0.40527962583560617&#45;&gt;0.3019976258171191</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4683.08,-437.591C4691.58,-435.63 4700.39,-433.684 4708.69,-432 4802.36,-413.01 4828.65,-421.708 4920.69,-396 4924.5,-394.937 4928.43,-393.655 4932.3,-392.276\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4933.57,-395.539 4941.68,-388.722 4931.09,-388.993 4933.57,-395.539\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7639719400806773 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>0.7639719400806773</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4746.69\" cy=\"-450\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4746.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3606379895298152&#45;&gt;0.7639719400806773 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>0.3606379895298152&#45;&gt;0.7639719400806773</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4732.29,-504.055C4734.44,-496.145 4737.05,-486.54 4739.45,-477.688\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4742.9,-478.357 4742.14,-467.789 4736.14,-476.523 4742.9,-478.357\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5906142577387659 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>0.5906142577387659</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4820.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4820.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.34425621765885006&#45;&gt;0.5906142577387659 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>0.34425621765885006&#45;&gt;0.5906142577387659</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4813.12,-504.055C4814.22,-496.346 4815.55,-487.027 4816.79,-478.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4820.28,-478.67 4818.23,-468.275 4813.35,-477.68 4820.28,-478.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.41662673163421216 -->\r\n",
       "<g id=\"node33\" class=\"node\"><title>0.41662673163421216</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5124.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5124.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3644633808541732&#45;&gt;0.41662673163421216 -->\r\n",
       "<g id=\"edge32\" class=\"edge\"><title>0.3644633808541732&#45;&gt;0.41662673163421216</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5023.4,-509.597C5041.1,-499.36 5067.51,-484.081 5088.93,-471.692\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5090.86,-474.619 5097.76,-466.582 5087.35,-468.56 5090.86,-474.619\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4179122592134912 -->\r\n",
       "<g id=\"node144\" class=\"node\"><title>0.4179122592134912</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5088.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5088.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.41662673163421216&#45;&gt;0.4179122592134912 -->\r\n",
       "<g id=\"edge143\" class=\"edge\"><title>0.41662673163421216&#45;&gt;0.4179122592134912</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5115.98,-432.055C5111.72,-423.767 5106.5,-413.618 5101.77,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5104.77,-402.599 5097.08,-395.307 5098.54,-405.801 5104.77,-402.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.32497389273943866 -->\r\n",
       "<g id=\"node146\" class=\"node\"><title>0.32497389273943866</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5160.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5160.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.41662673163421216&#45;&gt;0.32497389273943866 -->\r\n",
       "<g id=\"edge145\" class=\"edge\"><title>0.41662673163421216&#45;&gt;0.32497389273943866</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5133.41,-432.055C5137.67,-423.767 5142.89,-413.618 5147.62,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5150.85,-405.801 5152.31,-395.307 5144.62,-402.599 5150.85,-405.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8793808970133554 -->\r\n",
       "<g id=\"node148\" class=\"node\"><title>0.8793808970133554</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5232.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5232.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.41662673163421216&#45;&gt;0.8793808970133554 -->\r\n",
       "<g id=\"edge147\" class=\"edge\"><title>0.41662673163421216&#45;&gt;0.8793808970133554</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5148.93,-433.291C5165.67,-422.444 5187.95,-408.002 5205.32,-396.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5207.42,-399.553 5213.91,-391.177 5203.61,-393.679 5207.42,-399.553\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.20415222483472084 -->\r\n",
       "<g id=\"node35\" class=\"node\"><title>0.20415222483472084</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5416.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5416.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2562198334124841&#45;&gt;0.20415222483472084 -->\r\n",
       "<g id=\"edge34\" class=\"edge\"><title>0.2562198334124841&#45;&gt;0.20415222483472084</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5507.53,-508.807C5491.59,-498.662 5468.54,-483.99 5449.64,-471.966\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5451.34,-468.897 5441.02,-466.481 5447.58,-474.803 5451.34,-468.897\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7826016885995789 -->\r\n",
       "<g id=\"node150\" class=\"node\"><title>0.7826016885995789</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5307.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5307.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.20415222483472084&#45;&gt;0.7826016885995789 -->\r\n",
       "<g id=\"edge149\" class=\"edge\"><title>0.20415222483472084&#45;&gt;0.7826016885995789</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5392.77,-433.638C5375.8,-422.74 5352.98,-408.086 5335.25,-396.697\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5336.8,-393.535 5326.5,-391.076 5333.02,-399.425 5336.8,-393.535\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5067304013187766 -->\r\n",
       "<g id=\"node152\" class=\"node\"><title>0.5067304013187766</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5380.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5380.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.20415222483472084&#45;&gt;0.5067304013187766 -->\r\n",
       "<g id=\"edge151\" class=\"edge\"><title>0.20415222483472084&#45;&gt;0.5067304013187766</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5407.98,-432.055C5403.72,-423.767 5398.5,-413.618 5393.77,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5396.77,-402.599 5389.08,-395.307 5390.54,-405.801 5396.77,-402.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.030289076737484932 -->\r\n",
       "<g id=\"node154\" class=\"node\"><title>0.030289076737484932</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5452.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5452.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.20415222483472084&#45;&gt;0.030289076737484932 -->\r\n",
       "<g id=\"edge153\" class=\"edge\"><title>0.20415222483472084&#45;&gt;0.030289076737484932</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5425.41,-432.055C5429.67,-423.767 5434.89,-413.618 5439.62,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5442.85,-405.801 5444.31,-395.307 5436.62,-402.599 5442.85,-405.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8567608260726699 -->\r\n",
       "<g id=\"node37\" class=\"node\"><title>0.8567608260726699</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5596.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5596.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4192472543801965&#45;&gt;0.8567608260726699 -->\r\n",
       "<g id=\"edge36\" class=\"edge\"><title>0.4192472543801965&#45;&gt;0.8567608260726699</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5658.11,-506.834C5647.8,-497.462 5634.05,-484.955 5622.16,-474.155\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5624.44,-471.491 5614.68,-467.354 5619.73,-476.67 5624.44,-471.491\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.17048204915354304 -->\r\n",
       "<g id=\"node156\" class=\"node\"><title>0.17048204915354304</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5524.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5524.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8567608260726699&#45;&gt;0.17048204915354304 -->\r\n",
       "<g id=\"edge155\" class=\"edge\"><title>0.8567608260726699&#45;&gt;0.17048204915354304</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5579.63,-432.411C5569.86,-422.911 5557.49,-410.882 5546.96,-400.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5549.29,-398.032 5539.68,-393.57 5544.41,-403.051 5549.29,-398.032\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9743879372361316 -->\r\n",
       "<g id=\"node158\" class=\"node\"><title>0.9743879372361316</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5596.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5596.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8567608260726699&#45;&gt;0.9743879372361316 -->\r\n",
       "<g id=\"edge157\" class=\"edge\"><title>0.8567608260726699&#45;&gt;0.9743879372361316</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5596.69,-431.697C5596.69,-423.983 5596.69,-414.712 5596.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5600.19,-406.104 5596.69,-396.104 5593.19,-406.104 5600.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6013480967966285 -->\r\n",
       "<g id=\"node39\" class=\"node\"><title>0.6013480967966285</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5886.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5886.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.11021112378459386&#45;&gt;0.6013480967966285 -->\r\n",
       "<g id=\"edge38\" class=\"edge\"><title>0.11021112378459386&#45;&gt;0.6013480967966285</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5911.87,-504.411C5908.03,-496.249 5903.3,-486.22 5898.98,-477.065\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5902.12,-475.509 5894.69,-467.956 5895.79,-478.494 5902.12,-475.509\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.38309356241782866 -->\r\n",
       "<g id=\"node160\" class=\"node\"><title>0.38309356241782866</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5724.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5724.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6013480967966285&#45;&gt;0.38309356241782866 -->\r\n",
       "<g id=\"edge159\" class=\"edge\"><title>0.6013480967966285&#45;&gt;0.38309356241782866</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5853.13,-434.496C5824.61,-422.173 5783.98,-404.617 5756.1,-392.569\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5757.37,-389.308 5746.81,-388.554 5754.6,-395.734 5757.37,-389.308\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5554583246289788 -->\r\n",
       "<g id=\"node162\" class=\"node\"><title>0.5554583246289788</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5814.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5814.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6013480967966285&#45;&gt;0.5554583246289788 -->\r\n",
       "<g id=\"edge161\" class=\"edge\"><title>0.6013480967966285&#45;&gt;0.5554583246289788</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5869.63,-432.411C5859.86,-422.911 5847.49,-410.882 5836.96,-400.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5839.29,-398.032 5829.68,-393.57 5834.41,-403.051 5839.29,-398.032\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7787818220238037 -->\r\n",
       "<g id=\"node164\" class=\"node\"><title>0.7787818220238037</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5886.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5886.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6013480967966285&#45;&gt;0.7787818220238037 -->\r\n",
       "<g id=\"edge163\" class=\"edge\"><title>0.6013480967966285&#45;&gt;0.7787818220238037</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5886.69,-431.697C5886.69,-423.983 5886.69,-414.712 5886.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5890.19,-406.104 5886.69,-396.104 5883.19,-406.104 5890.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.10960599450060593 -->\r\n",
       "<g id=\"node166\" class=\"node\"><title>0.10960599450060593</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5972.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5972.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6013480967966285&#45;&gt;0.10960599450060593 -->\r\n",
       "<g id=\"edge165\" class=\"edge\"><title>0.6013480967966285&#45;&gt;0.10960599450060593</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5906.64,-432.765C5919.13,-422.597 5935.31,-409.43 5948.53,-398.671\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5950.77,-401.358 5956.32,-392.331 5946.35,-395.93 5950.77,-401.358\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9843441543059429 -->\r\n",
       "<g id=\"node41\" class=\"node\"><title>0.9843441543059429</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6088.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6088.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9795480807663823&#45;&gt;0.9843441543059429 -->\r\n",
       "<g id=\"edge40\" class=\"edge\"><title>0.9795480807663823&#45;&gt;0.9843441543059429</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6037.48,-506.155C6045.79,-497.2 6056.59,-485.576 6066.12,-475.309\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6068.86,-477.499 6073.1,-467.789 6063.74,-472.735 6068.86,-477.499\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2317996130647354 -->\r\n",
       "<g id=\"node168\" class=\"node\"><title>0.2317996130647354</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6088.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6088.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9843441543059429&#45;&gt;0.2317996130647354 -->\r\n",
       "<g id=\"edge167\" class=\"edge\"><title>0.9843441543059429&#45;&gt;0.2317996130647354</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6088.69,-431.697C6088.69,-423.983 6088.69,-414.712 6088.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6092.19,-406.104 6088.69,-396.104 6085.19,-406.104 6092.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1863675156343616 -->\r\n",
       "<g id=\"node170\" class=\"node\"><title>0.1863675156343616</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6160.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6160.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9843441543059429&#45;&gt;0.1863675156343616 -->\r\n",
       "<g id=\"edge169\" class=\"edge\"><title>0.9843441543059429&#45;&gt;0.1863675156343616</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6105.76,-432.411C6115.53,-422.911 6127.9,-410.882 6138.43,-400.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6140.98,-403.051 6145.71,-393.57 6136.1,-398.032 6140.98,-403.051\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.47421543910516584 -->\r\n",
       "<g id=\"node43\" class=\"node\"><title>0.47421543910516584</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6268.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6268.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.829526115160897&#45;&gt;0.47421543910516584 -->\r\n",
       "<g id=\"edge42\" class=\"edge\"><title>0.829526115160897&#45;&gt;0.47421543910516584</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6214.78,-506.496C6223.67,-497.344 6235.37,-485.306 6245.59,-474.781\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6248.26,-477.059 6252.72,-467.448 6243.24,-472.182 6248.26,-477.059\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7424221044968857 -->\r\n",
       "<g id=\"node172\" class=\"node\"><title>0.7424221044968857</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6232.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6232.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.47421543910516584&#45;&gt;0.7424221044968857 -->\r\n",
       "<g id=\"edge171\" class=\"edge\"><title>0.47421543910516584&#45;&gt;0.7424221044968857</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6259.98,-432.055C6255.72,-423.767 6250.5,-413.618 6245.77,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6248.77,-402.599 6241.08,-395.307 6242.54,-405.801 6248.77,-402.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7616221199195248 -->\r\n",
       "<g id=\"node174\" class=\"node\"><title>0.7616221199195248</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6304.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6304.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.47421543910516584&#45;&gt;0.7616221199195248 -->\r\n",
       "<g id=\"edge173\" class=\"edge\"><title>0.47421543910516584&#45;&gt;0.7616221199195248</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6277.41,-432.055C6281.67,-423.767 6286.89,-413.618 6291.62,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6294.85,-405.801 6296.31,-395.307 6288.62,-402.599 6294.85,-405.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8332507683158114 -->\r\n",
       "<g id=\"node176\" class=\"node\"><title>0.8332507683158114</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6376.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6376.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.47421543910516584&#45;&gt;0.8332507683158114 -->\r\n",
       "<g id=\"edge175\" class=\"edge\"><title>0.47421543910516584&#45;&gt;0.8332507683158114</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6292.4,-433.638C6309.21,-422.74 6331.82,-408.086 6349.39,-396.697\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6351.57,-399.452 6358.06,-391.076 6347.77,-393.578 6351.57,-399.452\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7230329543564794 -->\r\n",
       "<g id=\"node45\" class=\"node\"><title>0.7230329543564794</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6448.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6448.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7947183106297023&#45;&gt;0.7230329543564794 -->\r\n",
       "<g id=\"edge44\" class=\"edge\"><title>0.7947183106297023&#45;&gt;0.7230329543564794</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6460.06,-504.055C6458.39,-496.261 6456.37,-486.822 6454.5,-478.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6457.91,-477.32 6452.4,-468.275 6451.07,-478.787 6457.91,-477.32\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.35724570164555025 -->\r\n",
       "<g id=\"node178\" class=\"node\"><title>0.35724570164555025</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6448.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6448.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7230329543564794&#45;&gt;0.35724570164555025 -->\r\n",
       "<g id=\"edge177\" class=\"edge\"><title>0.7230329543564794&#45;&gt;0.35724570164555025</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6448.69,-431.697C6448.69,-423.983 6448.69,-414.712 6448.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6452.19,-406.104 6448.69,-396.104 6445.19,-406.104 6452.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4075129667547601 -->\r\n",
       "<g id=\"node180\" class=\"node\"><title>0.4075129667547601</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6539.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6539.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7230329543564794&#45;&gt;0.4075129667547601 -->\r\n",
       "<g id=\"edge179\" class=\"edge\"><title>0.7230329543564794&#45;&gt;0.4075129667547601</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6469.34,-433.116C6482.76,-422.798 6500.33,-409.282 6514.55,-398.339\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6516.69,-401.109 6522.49,-392.237 6512.43,-395.56 6516.69,-401.109\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7468714053456937 -->\r\n",
       "<g id=\"node182\" class=\"node\"><title>0.7468714053456937</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6639.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6639.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7230329543564794&#45;&gt;0.7468714053456937 -->\r\n",
       "<g id=\"edge181\" class=\"edge\"><title>0.7230329543564794&#45;&gt;0.7468714053456937</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6484.17,-435.998C6519.32,-423.115 6572.72,-403.545 6606.91,-391.017\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6608.25,-394.253 6616.43,-387.526 6605.84,-387.681 6608.25,-394.253\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6892433586156906 -->\r\n",
       "<g id=\"node47\" class=\"node\"><title>0.6892433586156906</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6549.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6549.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2177506454014969&#45;&gt;0.6892433586156906 -->\r\n",
       "<g id=\"edge46\" class=\"edge\"><title>0.2177506454014969&#45;&gt;0.6892433586156906</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6550.45,-503.697C6550.34,-495.983 6550.2,-486.712 6550.08,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6553.58,-478.053 6549.94,-468.104 6546.58,-478.153 6553.58,-478.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4514859109067417 -->\r\n",
       "<g id=\"node49\" class=\"node\"><title>0.4514859109067417</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6623.69\" cy=\"-450\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6623.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.26330903724042976&#45;&gt;0.4514859109067417 -->\r\n",
       "<g id=\"edge48\" class=\"edge\"><title>0.26330903724042976&#45;&gt;0.4514859109067417</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6623.69,-503.697C6623.69,-495.983 6623.69,-486.712 6623.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6627.19,-478.104 6623.69,-468.104 6620.19,-478.104 6627.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5186483719858216 -->\r\n",
       "<g id=\"node51\" class=\"node\"><title>0.5186483719858216</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6697.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6697.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zero</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5282402128395085&#45;&gt;0.5186483719858216 -->\r\n",
       "<g id=\"edge50\" class=\"edge\"><title>0.5282402128395085&#45;&gt;0.5186483719858216</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6696.94,-503.697C6697.05,-495.983 6697.18,-486.712 6697.31,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6700.81,-478.153 6697.45,-468.104 6693.81,-478.053 6700.81,-478.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5573006831888677 -->\r\n",
       "<g id=\"node53\" class=\"node\"><title>0.5573006831888677</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6806.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6806.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7325113727943973&#45;&gt;0.5573006831888677 -->\r\n",
       "<g id=\"edge52\" class=\"edge\"><title>0.7325113727943973&#45;&gt;0.5573006831888677</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6837.42,-504.765C6832.71,-496.525 6826.88,-486.317 6821.56,-477.016\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6824.48,-475.07 6816.48,-468.124 6818.4,-478.543 6824.48,-475.07\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.34284931634097504 -->\r\n",
       "<g id=\"node184\" class=\"node\"><title>0.34284931634097504</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6751.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6751.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5573006831888677&#45;&gt;0.34284931634097504 -->\r\n",
       "<g id=\"edge183\" class=\"edge\"><title>0.5573006831888677&#45;&gt;0.34284931634097504</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6793.38,-432.055C6786.4,-423.167 6777.73,-412.14 6770.12,-402.446\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6772.69,-400.057 6763.76,-394.356 6767.19,-404.382 6772.69,-400.057\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.17240146940182022 -->\r\n",
       "<g id=\"node186\" class=\"node\"><title>0.17240146940182022</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6823.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6823.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5573006831888677&#45;&gt;0.17240146940182022 -->\r\n",
       "<g id=\"edge185\" class=\"edge\"><title>0.5573006831888677&#45;&gt;0.17240146940182022</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6810.9,-431.697C6812.79,-423.898 6815.07,-414.509 6817.18,-405.829\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6820.58,-406.648 6819.54,-396.104 6813.78,-404.996 6820.58,-406.648\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7421208506030961 -->\r\n",
       "<g id=\"node55\" class=\"node\"><title>0.7421208506030961</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0222176695373012&#45;&gt;0.7421208506030961 -->\r\n",
       "<g id=\"edge54\" class=\"edge\"><title>0.0222176695373012&#45;&gt;0.7421208506030961</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6956.06,-504.055C6954.39,-496.261 6952.37,-486.822 6950.5,-478.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6953.91,-477.32 6948.4,-468.275 6947.07,-478.787 6953.91,-477.32\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.22405833316055135 -->\r\n",
       "<g id=\"node188\" class=\"node\"><title>0.22405833316055135</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7421208506030961&#45;&gt;0.22405833316055135 -->\r\n",
       "<g id=\"edge187\" class=\"edge\"><title>0.7421208506030961&#45;&gt;0.22405833316055135</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6944.69,-431.697C6944.69,-423.983 6944.69,-414.712 6944.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6948.19,-406.104 6944.69,-396.104 6941.19,-406.104 6948.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2910582119619415 -->\r\n",
       "<g id=\"node57\" class=\"node\"><title>0.2910582119619415</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7046.69\" cy=\"-450\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7046.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9685937912958483&#45;&gt;0.2910582119619415 -->\r\n",
       "<g id=\"edge56\" class=\"edge\"><title>0.9685937912958483&#45;&gt;0.2910582119619415</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7047.45,-503.697C7047.34,-495.983 7047.2,-486.712 7047.08,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7050.58,-478.053 7046.94,-468.104 7043.58,-478.153 7050.58,-478.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4543712002778135 -->\r\n",
       "<g id=\"node59\" class=\"node\"><title>0.4543712002778135</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7120.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7120.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9321411293065703&#45;&gt;0.4543712002778135 -->\r\n",
       "<g id=\"edge58\" class=\"edge\"><title>0.9321411293065703&#45;&gt;0.4543712002778135</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7120.69,-503.697C7120.69,-495.983 7120.69,-486.712 7120.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7124.19,-478.104 7120.69,-468.104 7117.19,-478.104 7124.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6240762479739859 -->\r\n",
       "<g id=\"node61\" class=\"node\"><title>0.6240762479739859</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7192.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7192.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.722478027704729&#45;&gt;0.6240762479739859 -->\r\n",
       "<g id=\"edge60\" class=\"edge\"><title>0.722478027704729&#45;&gt;0.6240762479739859</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7192.69,-503.697C7192.69,-495.983 7192.69,-486.712 7192.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7196.19,-478.104 7192.69,-468.104 7189.19,-478.104 7196.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7443003154818649 -->\r\n",
       "<g id=\"node63\" class=\"node\"><title>0.7443003154818649</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7293.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7293.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6637795276358762&#45;&gt;0.7443003154818649 -->\r\n",
       "<g id=\"edge62\" class=\"edge\"><title>0.6637795276358762&#45;&gt;0.7443003154818649</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7283.08,-504.055C7284.63,-496.346 7286.49,-487.027 7288.22,-478.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7291.71,-478.768 7290.24,-468.275 7284.85,-477.395 7291.71,-478.768\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6354217052708109 -->\r\n",
       "<g id=\"node190\" class=\"node\"><title>0.6354217052708109</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7257.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7257.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7443003154818649&#45;&gt;0.6354217052708109 -->\r\n",
       "<g id=\"edge189\" class=\"edge\"><title>0.7443003154818649&#45;&gt;0.6354217052708109</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7284.98,-432.055C7280.72,-423.767 7275.5,-413.618 7270.77,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7273.77,-402.599 7266.08,-395.307 7267.54,-405.801 7273.77,-402.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.532452289593514 -->\r\n",
       "<g id=\"node192\" class=\"node\"><title>0.532452289593514</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7329.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7329.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7443003154818649&#45;&gt;0.532452289593514 -->\r\n",
       "<g id=\"edge191\" class=\"edge\"><title>0.7443003154818649&#45;&gt;0.532452289593514</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7302.41,-432.055C7306.67,-423.767 7311.89,-413.618 7316.62,-404.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7319.85,-405.801 7321.31,-395.307 7313.62,-402.599 7319.85,-405.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4316386992312591 -->\r\n",
       "<g id=\"node65\" class=\"node\"><title>0.4316386992312591</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7394.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7394.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.07768285465605107&#45;&gt;0.4316386992312591 -->\r\n",
       "<g id=\"edge64\" class=\"edge\"><title>0.07768285465605107&#45;&gt;0.4316386992312591</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7395.45,-503.697C7395.34,-495.983 7395.2,-486.712 7395.08,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7398.58,-478.053 7394.94,-468.104 7391.58,-478.153 7398.58,-478.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9895207283378373 -->\r\n",
       "<g id=\"node67\" class=\"node\"><title>0.9895207283378373</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7468.69\" cy=\"-450\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7468.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6548558542866013&#45;&gt;0.9895207283378373 -->\r\n",
       "<g id=\"edge66\" class=\"edge\"><title>0.6548558542866013&#45;&gt;0.9895207283378373</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7468.69,-503.697C7468.69,-495.983 7468.69,-486.712 7468.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7472.19,-478.104 7468.69,-468.104 7465.19,-478.104 7472.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6530447099696648 -->\r\n",
       "<g id=\"node69\" class=\"node\"><title>0.6530447099696648</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7542.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7542.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8104967991391757&#45;&gt;0.6530447099696648 -->\r\n",
       "<g id=\"edge68\" class=\"edge\"><title>0.8104967991391757&#45;&gt;0.6530447099696648</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7541.94,-503.697C7542.05,-495.983 7542.18,-486.712 7542.31,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7545.81,-478.153 7542.45,-468.104 7538.81,-478.053 7545.81,-478.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8664989890407891 -->\r\n",
       "<g id=\"node71\" class=\"node\"><title>0.8664989890407891</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7614.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7614.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7310851178126108&#45;&gt;0.8664989890407891 -->\r\n",
       "<g id=\"edge70\" class=\"edge\"><title>0.7310851178126108&#45;&gt;0.8664989890407891</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7614.69,-503.697C7614.69,-495.983 7614.69,-486.712 7614.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7618.19,-478.104 7614.69,-468.104 7611.19,-478.104 7618.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.23349388507964175 -->\r\n",
       "<g id=\"node73\" class=\"node\"><title>0.23349388507964175</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7686.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7686.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zero</text>\r\n",
       "</g>\r\n",
       "<!-- 0.750534363986897&#45;&gt;0.23349388507964175 -->\r\n",
       "<g id=\"edge72\" class=\"edge\"><title>0.750534363986897&#45;&gt;0.23349388507964175</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7686.69,-503.697C7686.69,-495.983 7686.69,-486.712 7686.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7690.19,-478.104 7686.69,-468.104 7683.19,-478.104 7690.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5132819169129156 -->\r\n",
       "<g id=\"node75\" class=\"node\"><title>0.5132819169129156</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7758.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7758.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5011062607844455&#45;&gt;0.5132819169129156 -->\r\n",
       "<g id=\"edge74\" class=\"edge\"><title>0.5011062607844455&#45;&gt;0.5132819169129156</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7773.09,-504.055C7770.95,-496.145 7768.34,-486.54 7765.94,-477.688\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7769.25,-476.523 7763.25,-467.789 7762.49,-478.357 7769.25,-476.523\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8565024254719178 -->\r\n",
       "<g id=\"node77\" class=\"node\"><title>0.8565024254719178</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7867.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7867.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24437965548096474&#45;&gt;0.8565024254719178 -->\r\n",
       "<g id=\"edge76\" class=\"edge\"><title>0.24437965548096474&#45;&gt;0.8565024254719178</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7867.69,-503.697C7867.69,-495.983 7867.69,-486.712 7867.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7871.19,-478.104 7867.69,-468.104 7864.19,-478.104 7871.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.28813373249162044 -->\r\n",
       "<g id=\"node194\" class=\"node\"><title>0.28813373249162044</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7747.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7747.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8565024254719178&#45;&gt;0.28813373249162044 -->\r\n",
       "<g id=\"edge193\" class=\"edge\"><title>0.8565024254719178&#45;&gt;0.28813373249162044</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7841.06,-433.465C7821.87,-422.268 7795.99,-407.175 7776.35,-395.717\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7777.94,-392.592 7767.54,-390.576 7774.41,-398.638 7777.94,-392.592\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.527623909467128 -->\r\n",
       "<g id=\"node196\" class=\"node\"><title>0.527623909467128</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7837.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7837.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8565024254719178&#45;&gt;0.527623909467128 -->\r\n",
       "<g id=\"edge195\" class=\"edge\"><title>0.8565024254719178&#45;&gt;0.527623909467128</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7860.43,-432.055C7856.97,-423.973 7852.75,-414.121 7848.89,-405.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7852.05,-403.602 7844.89,-395.789 7845.61,-406.359 7852.05,-403.602\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.14742676543745947 -->\r\n",
       "<g id=\"node198\" class=\"node\"><title>0.14742676543745947</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7928.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7928.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8565024254719178&#45;&gt;0.14742676543745947 -->\r\n",
       "<g id=\"edge197\" class=\"edge\"><title>0.8565024254719178&#45;&gt;0.14742676543745947</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7882.15,-432.411C7890.16,-423.223 7900.23,-411.67 7908.95,-401.66\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7911.66,-403.877 7915.59,-394.038 7906.38,-399.278 7911.66,-403.877\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.34001578445081126 -->\r\n",
       "<g id=\"node79\" class=\"node\"><title>0.34001578445081126</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8012.69\" cy=\"-450\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8012.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2205849422848586&#45;&gt;0.34001578445081126 -->\r\n",
       "<g id=\"edge78\" class=\"edge\"><title>0.2205849422848586&#45;&gt;0.34001578445081126</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7985.04,-504.765C7989.24,-496.611 7994.42,-486.529 7999.17,-477.307\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8002.43,-478.618 8003.89,-468.124 7996.2,-475.416 8002.43,-478.618\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6032485550052269 -->\r\n",
       "<g id=\"node200\" class=\"node\"><title>0.6032485550052269</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8012.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8012.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.34001578445081126&#45;&gt;0.6032485550052269 -->\r\n",
       "<g id=\"edge199\" class=\"edge\"><title>0.34001578445081126&#45;&gt;0.6032485550052269</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8012.69,-431.697C8012.69,-423.983 8012.69,-414.712 8012.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8016.19,-406.104 8012.69,-396.104 8009.19,-406.104 8016.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9168065343560666 -->\r\n",
       "<g id=\"node202\" class=\"node\"><title>0.9168065343560666</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8084.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8084.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.34001578445081126&#45;&gt;0.9168065343560666 -->\r\n",
       "<g id=\"edge201\" class=\"edge\"><title>0.34001578445081126&#45;&gt;0.9168065343560666</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8029.76,-432.411C8039.53,-422.911 8051.9,-410.882 8062.43,-400.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8064.98,-403.051 8069.71,-393.57 8060.1,-398.032 8064.98,-403.051\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5884074985385663 -->\r\n",
       "<g id=\"node81\" class=\"node\"><title>0.5884074985385663</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8121.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8121.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.18058753083898316&#45;&gt;0.5884074985385663 -->\r\n",
       "<g id=\"edge80\" class=\"edge\"><title>0.18058753083898316&#45;&gt;0.5884074985385663</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8094.04,-504.765C8098.41,-496.283 8103.84,-485.714 8108.74,-476.197\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8111.93,-477.641 8113.39,-467.147 8105.7,-474.439 8111.93,-477.641\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3940357358760245 -->\r\n",
       "<g id=\"node83\" class=\"node\"><title>0.3940357358760245</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-450\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6864473249522036&#45;&gt;0.3940357358760245 -->\r\n",
       "<g id=\"edge82\" class=\"edge\"><title>0.6864473249522036&#45;&gt;0.3940357358760245</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8198.28,-504.411C8202.01,-496.249 8206.59,-486.22 8210.78,-477.065\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8213.97,-478.506 8214.94,-467.956 8207.6,-475.596 8213.97,-478.506\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.39360408117314727 -->\r\n",
       "<g id=\"node204\" class=\"node\"><title>0.39360408117314727</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-374.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3940357358760245&#45;&gt;0.39360408117314727 -->\r\n",
       "<g id=\"edge203\" class=\"edge\"><title>0.3940357358760245&#45;&gt;0.39360408117314727</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8222.69,-431.697C8222.69,-423.983 8222.69,-414.712 8222.69,-406.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8226.19,-406.104 8222.69,-396.104 8219.19,-406.104 8226.19,-406.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5839666186538054 -->\r\n",
       "<g id=\"node85\" class=\"node\"><title>0.5839666186538054</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8324.69\" cy=\"-450\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8324.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8061800540877742&#45;&gt;0.5839666186538054 -->\r\n",
       "<g id=\"edge84\" class=\"edge\"><title>0.8061800540877742&#45;&gt;0.5839666186538054</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8324.69,-503.697C8324.69,-495.983 8324.69,-486.712 8324.69,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8328.19,-478.104 8324.69,-468.104 8321.19,-478.104 8328.19,-478.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.33880655598979237 -->\r\n",
       "<g id=\"node87\" class=\"node\"><title>0.33880655598979237</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8398.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8398.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3590252153990894&#45;&gt;0.33880655598979237 -->\r\n",
       "<g id=\"edge86\" class=\"edge\"><title>0.3590252153990894&#45;&gt;0.33880655598979237</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8397.94,-503.697C8398.05,-495.983 8398.18,-486.712 8398.31,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8401.81,-478.153 8398.45,-468.104 8394.81,-478.053 8401.81,-478.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.36163698607446615 -->\r\n",
       "<g id=\"node89\" class=\"node\"><title>0.36163698607446615</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8470.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8470.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6310455678959187&#45;&gt;0.36163698607446615 -->\r\n",
       "<g id=\"edge88\" class=\"edge\"><title>0.6310455678959187&#45;&gt;0.36163698607446615</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8469.94,-503.697C8470.05,-495.983 8470.18,-486.712 8470.31,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8473.81,-478.153 8470.45,-468.104 8466.81,-478.053 8473.81,-478.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.07440714152684336 -->\r\n",
       "<g id=\"node91\" class=\"node\"><title>0.07440714152684336</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8542.69\" cy=\"-450\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8542.69\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.27668332629604053&#45;&gt;0.07440714152684336 -->\r\n",
       "<g id=\"edge90\" class=\"edge\"><title>0.27668332629604053&#45;&gt;0.07440714152684336</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8541.94,-503.697C8542.05,-495.983 8542.18,-486.712 8542.31,-478.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8545.81,-478.153 8542.45,-468.104 8538.81,-478.053 8545.81,-478.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5887408052026905 -->\r\n",
       "<g id=\"node93\" class=\"node\"><title>0.5887408052026905</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"172.694\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"172.694\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.96717016444266&#45;&gt;0.5887408052026905 -->\r\n",
       "<g id=\"edge92\" class=\"edge\"><title>0.96717016444266&#45;&gt;0.5887408052026905</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M317.518,-367.705C291.758,-356.907 248.642,-338.835 216.139,-325.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"217.426,-321.955 206.85,-321.317 214.72,-328.411 217.426,-321.955\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6793962967183612 -->\r\n",
       "<g id=\"node206\" class=\"node\"><title>0.6793962967183612</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"82.6943\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"82.6943\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5887408052026905&#45;&gt;0.6793962967183612 -->\r\n",
       "<g id=\"edge205\" class=\"edge\"><title>0.5887408052026905&#45;&gt;0.6793962967183612</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.82,-288.765C138.662,-278.53 121.595,-265.256 107.713,-254.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.586,-251.482 99.5435,-248.105 105.288,-257.007 109.586,-251.482\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6676336004425883 -->\r\n",
       "<g id=\"node208\" class=\"node\"><title>0.6676336004425883</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"172.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"172.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5887408052026905&#45;&gt;0.6676336004425883 -->\r\n",
       "<g id=\"edge207\" class=\"edge\"><title>0.5887408052026905&#45;&gt;0.6676336004425883</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.694,-287.697C172.694,-279.983 172.694,-270.712 172.694,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.194,-262.104 172.694,-252.104 169.194,-262.104 176.194,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.739627858714974 -->\r\n",
       "<g id=\"node95\" class=\"node\"><title>0.739627858714974</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"462.694\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"462.694\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2013407662702893&#45;&gt;0.739627858714974 -->\r\n",
       "<g id=\"edge94\" class=\"edge\"><title>0.2013407662702893&#45;&gt;0.739627858714974</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M560.111,-365.284C543.111,-355.113 518.086,-340.141 497.657,-327.918\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"499.309,-324.828 488.931,-322.697 495.715,-330.835 499.309,-324.828\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3982833292473734 -->\r\n",
       "<g id=\"node210\" class=\"node\"><title>0.3982833292473734</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"272.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"272.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.739627858714974&#45;&gt;0.3982833292473734 -->\r\n",
       "<g id=\"edge209\" class=\"edge\"><title>0.739627858714974&#45;&gt;0.3982833292473734</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M425.609,-291.337C390.767,-278.501 339.119,-259.472 305.678,-247.152\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.517,-243.731 295.924,-243.558 304.097,-250.3 306.517,-243.731\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.17062656189173098 -->\r\n",
       "<g id=\"node212\" class=\"node\"><title>0.17062656189173098</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"372.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"372.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.739627858714974&#45;&gt;0.17062656189173098 -->\r\n",
       "<g id=\"edge211\" class=\"edge\"><title>0.739627858714974&#45;&gt;0.17062656189173098</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M441.82,-288.765C428.662,-278.53 411.595,-265.256 397.713,-254.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"399.586,-251.482 389.543,-248.105 395.288,-257.007 399.586,-251.482\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.010937608914960317 -->\r\n",
       "<g id=\"node214\" class=\"node\"><title>0.010937608914960317</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"462.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"462.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.739627858714974&#45;&gt;0.010937608914960317 -->\r\n",
       "<g id=\"edge213\" class=\"edge\"><title>0.739627858714974&#45;&gt;0.010937608914960317</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462.694,-287.697C462.694,-279.983 462.694,-270.712 462.694,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"466.194,-262.104 462.694,-252.104 459.194,-262.104 466.194,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7880360180574769 -->\r\n",
       "<g id=\"node216\" class=\"node\"><title>0.7880360180574769</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"553.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"553.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.739627858714974&#45;&gt;0.7880360180574769 -->\r\n",
       "<g id=\"edge215\" class=\"edge\"><title>0.739627858714974&#45;&gt;0.7880360180574769</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M483.8,-288.765C497.105,-278.53 514.361,-265.256 528.398,-254.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"530.866,-256.976 536.658,-248.105 526.598,-251.428 530.866,-256.976\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.33291968843294073 -->\r\n",
       "<g id=\"node97\" class=\"node\"><title>0.33291968843294073</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"751.694\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"751.694\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0995713661631289&#45;&gt;0.33291968843294073 -->\r\n",
       "<g id=\"edge96\" class=\"edge\"><title>0.0995713661631289&#45;&gt;0.33291968843294073</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M765.337,-360.055C763.333,-352.261 760.906,-342.822 758.657,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"762.017,-333.089 756.137,-324.275 755.237,-334.832 762.017,-333.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6499169084921309 -->\r\n",
       "<g id=\"node218\" class=\"node\"><title>0.6499169084921309</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"680.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"680.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.33291968843294073&#45;&gt;0.6499169084921309 -->\r\n",
       "<g id=\"edge217\" class=\"edge\"><title>0.33291968843294073&#45;&gt;0.6499169084921309</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M734.868,-288.411C725.233,-278.911 713.032,-266.882 702.649,-256.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"705.051,-254.099 695.473,-249.57 700.137,-259.084 705.051,-254.099\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7803270503023466 -->\r\n",
       "<g id=\"node220\" class=\"node\"><title>0.7803270503023466</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"752.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"752.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">g</text>\r\n",
       "</g>\r\n",
       "<!-- 0.33291968843294073&#45;&gt;0.7803270503023466 -->\r\n",
       "<g id=\"edge219\" class=\"edge\"><title>0.33291968843294073&#45;&gt;0.7803270503023466</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M751.942,-287.697C752.052,-279.983 752.184,-270.712 752.307,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"755.807,-262.153 752.45,-252.104 748.807,-262.053 755.807,-262.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24381296512056827 -->\r\n",
       "<g id=\"node99\" class=\"node\"><title>0.24381296512056827</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"896.694\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"896.694\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7959930635740706&#45;&gt;0.24381296512056827 -->\r\n",
       "<g id=\"edge98\" class=\"edge\"><title>0.7959930635740706&#45;&gt;0.24381296512056827</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M869.044,-360.765C873.237,-352.611 878.422,-342.529 883.165,-333.307\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"886.427,-334.618 887.888,-324.124 880.202,-331.416 886.427,-334.618\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7678746564177727 -->\r\n",
       "<g id=\"node222\" class=\"node\"><title>0.7678746564177727</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"824.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"824.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24381296512056827&#45;&gt;0.7678746564177727 -->\r\n",
       "<g id=\"edge221\" class=\"edge\"><title>0.24381296512056827&#45;&gt;0.7678746564177727</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.631,-288.411C869.86,-278.911 857.487,-266.882 846.958,-256.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"849.291,-254.032 839.681,-249.57 844.411,-259.051 849.291,-254.032\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4806058890358671 -->\r\n",
       "<g id=\"node224\" class=\"node\"><title>0.4806058890358671</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"896.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"896.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24381296512056827&#45;&gt;0.4806058890358671 -->\r\n",
       "<g id=\"edge223\" class=\"edge\"><title>0.24381296512056827&#45;&gt;0.4806058890358671</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M896.694,-287.697C896.694,-279.983 896.694,-270.712 896.694,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"900.194,-262.104 896.694,-252.104 893.194,-262.104 900.194,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.16154328920106253 -->\r\n",
       "<g id=\"node226\" class=\"node\"><title>0.16154328920106253</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"987.694\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"987.694\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24381296512056827&#45;&gt;0.16154328920106253 -->\r\n",
       "<g id=\"edge225\" class=\"edge\"><title>0.24381296512056827&#45;&gt;0.16154328920106253</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M917.8,-288.765C931.105,-278.53 948.361,-265.256 962.398,-254.459\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"964.866,-256.976 970.658,-248.105 960.598,-251.428 964.866,-256.976\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.13706333104879342 -->\r\n",
       "<g id=\"node228\" class=\"node\"><title>0.13706333104879342</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1077.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1077.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24381296512056827&#45;&gt;0.13706333104879342 -->\r\n",
       "<g id=\"edge227\" class=\"edge\"><title>0.24381296512056827&#45;&gt;0.13706333104879342</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M932.887,-291.003C965.748,-278.294 1013.77,-259.723 1045.37,-247.502\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1046.94,-250.645 1055.01,-243.773 1044.42,-244.116 1046.94,-250.645\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6206331093449756 -->\r\n",
       "<g id=\"node101\" class=\"node\"><title>0.6206331093449756</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1190.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1190.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8074661793041445&#45;&gt;0.6206331093449756 -->\r\n",
       "<g id=\"edge100\" class=\"edge\"><title>0.8074661793041445&#45;&gt;0.6206331093449756</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1082.13,-365.908C1101.33,-355.494 1130.49,-339.67 1153.76,-327.045\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1155.55,-330.052 1162.67,-322.206 1152.21,-323.899 1155.55,-330.052\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3432875918131765 -->\r\n",
       "<g id=\"node230\" class=\"node\"><title>0.3432875918131765</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1190.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1190.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6206331093449756&#45;&gt;0.3432875918131765 -->\r\n",
       "<g id=\"edge229\" class=\"edge\"><title>0.6206331093449756&#45;&gt;0.3432875918131765</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1190.69,-287.697C1190.69,-279.983 1190.69,-270.712 1190.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1194.19,-262.104 1190.69,-252.104 1187.19,-262.104 1194.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5600210187659853 -->\r\n",
       "<g id=\"node232\" class=\"node\"><title>0.5600210187659853</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1264.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1264.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6206331093449756&#45;&gt;0.5600210187659853 -->\r\n",
       "<g id=\"edge231\" class=\"edge\"><title>0.6206331093449756&#45;&gt;0.5600210187659853</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1208.23,-288.411C1218.41,-278.781 1231.34,-266.552 1242.26,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1244.92,-258.522 1249.78,-249.108 1240.11,-253.437 1244.92,-258.522\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7036378190138244 -->\r\n",
       "<g id=\"node103\" class=\"node\"><title>0.7036378190138244</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1619.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1619.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24602247453061665&#45;&gt;0.7036378190138244 -->\r\n",
       "<g id=\"edge102\" class=\"edge\"><title>0.24602247453061665&#45;&gt;0.7036378190138244</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1708.06,-364.807C1691.21,-353.783 1666.18,-337.413 1647.06,-324.904\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1648.76,-321.834 1638.48,-319.288 1644.93,-327.692 1648.76,-321.834\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9042760422782804 -->\r\n",
       "<g id=\"node105\" class=\"node\"><title>0.9042760422782804</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1720.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1720.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4734923176217931&#45;&gt;0.9042760422782804 -->\r\n",
       "<g id=\"edge104\" class=\"edge\"><title>0.4734923176217931&#45;&gt;0.9042760422782804</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1882.64,-368.276C1853.3,-357.174 1801.98,-337.759 1764.97,-323.754\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1766.01,-320.404 1755.42,-320.139 1763.53,-326.951 1766.01,-320.404\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.11045969728691007 -->\r\n",
       "<g id=\"node234\" class=\"node\"><title>0.11045969728691007</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1425.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1425.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9042760422782804&#45;&gt;0.11045969728691007 -->\r\n",
       "<g id=\"edge233\" class=\"edge\"><title>0.9042760422782804&#45;&gt;0.11045969728691007</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1679.13,-293.936C1671.35,-291.92 1663.28,-289.866 1655.69,-288 1586.85,-271.068 1506,-252.813 1460.82,-242.758\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1461.46,-239.314 1450.94,-240.562 1459.94,-246.148 1461.46,-239.314\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.44720058825849573 -->\r\n",
       "<g id=\"node236\" class=\"node\"><title>0.44720058825849573</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1548.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1548.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9042760422782804&#45;&gt;0.44720058825849573 -->\r\n",
       "<g id=\"edge235\" class=\"edge\"><title>0.9042760422782804&#45;&gt;0.44720058825849573</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1687.53,-291.503C1656.61,-278.92 1610.82,-260.283 1580.38,-247.897\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1581.66,-244.639 1571.08,-244.111 1579.02,-251.122 1581.66,-244.639\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.660795539797365 -->\r\n",
       "<g id=\"node238\" class=\"node\"><title>0.660795539797365</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1675.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1675.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9042760422782804&#45;&gt;0.660795539797365 -->\r\n",
       "<g id=\"edge237\" class=\"edge\"><title>0.9042760422782804&#45;&gt;0.660795539797365</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1709.8,-288.055C1704.28,-279.469 1697.48,-268.888 1691.41,-259.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1694.22,-257.349 1685.87,-250.829 1688.33,-261.134 1694.22,-257.349\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7037818392500385 -->\r\n",
       "<g id=\"node240\" class=\"node\"><title>0.7037818392500385</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1765.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1765.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9042760422782804&#45;&gt;0.7037818392500385 -->\r\n",
       "<g id=\"edge239\" class=\"edge\"><title>0.9042760422782804&#45;&gt;0.7037818392500385</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1731.59,-288.055C1737.11,-279.469 1743.91,-268.888 1749.98,-259.439\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1753.05,-261.134 1755.52,-250.829 1747.17,-257.349 1753.05,-261.134\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.36586286660964806 -->\r\n",
       "<g id=\"node107\" class=\"node\"><title>0.36586286660964806</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2106.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2106.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44529859511996495&#45;&gt;0.36586286660964806 -->\r\n",
       "<g id=\"edge106\" class=\"edge\"><title>0.44529859511996495&#45;&gt;0.36586286660964806</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2167.31,-362.834C2157.07,-353.396 2143.37,-340.78 2131.59,-329.929\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2133.9,-327.304 2124.18,-323.103 2129.16,-332.453 2133.9,-327.304\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9815937077759338 -->\r\n",
       "<g id=\"node242\" class=\"node\"><title>0.9815937077759338</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1868.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1868.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.36586286660964806&#45;&gt;0.9815937077759338 -->\r\n",
       "<g id=\"edge241\" class=\"edge\"><title>0.36586286660964806&#45;&gt;0.9815937077759338</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2066.86,-293.284C2020.92,-279.772 1946.17,-257.787 1902.8,-245.031\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1903.59,-241.615 1893.01,-242.151 1901.61,-248.33 1903.59,-241.615\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8330410674367088 -->\r\n",
       "<g id=\"node244\" class=\"node\"><title>0.8330410674367088</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1978.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1978.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.36586286660964806&#45;&gt;0.8330410674367088 -->\r\n",
       "<g id=\"edge243\" class=\"edge\"><title>0.36586286660964806&#45;&gt;0.8330410674367088</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2079.55,-290.155C2058.58,-278.688 2029.61,-262.843 2008.09,-251.078\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2009.54,-247.877 1999.08,-246.15 2006.18,-254.019 2009.54,-247.877\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.41731988881946147 -->\r\n",
       "<g id=\"node246\" class=\"node\"><title>0.41731988881946147</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2069.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2069.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.36586286660964806&#45;&gt;0.41731988881946147 -->\r\n",
       "<g id=\"edge245\" class=\"edge\"><title>0.36586286660964806&#45;&gt;0.41731988881946147</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2097.74,-288.055C2093.36,-279.767 2087.99,-269.618 2083.13,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2086.08,-258.512 2078.31,-251.307 2079.89,-261.784 2086.08,-258.512\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6589375052403923 -->\r\n",
       "<g id=\"node248\" class=\"node\"><title>0.6589375052403923</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2142.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2142.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.36586286660964806&#45;&gt;0.6589375052403923 -->\r\n",
       "<g id=\"edge247\" class=\"edge\"><title>0.36586286660964806&#45;&gt;0.6589375052403923</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2115.41,-288.055C2119.67,-279.767 2124.89,-269.618 2129.62,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2132.85,-261.801 2134.31,-251.307 2126.62,-258.599 2132.85,-261.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7425605747809193 -->\r\n",
       "<g id=\"node250\" class=\"node\"><title>0.7425605747809193</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2216.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2216.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.36586286660964806&#45;&gt;0.7425605747809193 -->\r\n",
       "<g id=\"edge249\" class=\"edge\"><title>0.36586286660964806&#45;&gt;0.7425605747809193</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2130.83,-289.638C2147.96,-278.74 2170.99,-264.086 2188.88,-252.697\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2191.16,-255.398 2197.72,-247.076 2187.4,-249.492 2191.16,-255.398\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0495481983557865 -->\r\n",
       "<g id=\"node109\" class=\"node\"><title>0.0495481983557865</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2405.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2405.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.32298951801016895&#45;&gt;0.0495481983557865 -->\r\n",
       "<g id=\"edge108\" class=\"edge\"><title>0.32298951801016895&#45;&gt;0.0495481983557865</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2405.69,-359.697C2405.69,-351.983 2405.69,-342.712 2405.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2409.19,-334.104 2405.69,-324.104 2402.19,-334.104 2409.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8667050231079826 -->\r\n",
       "<g id=\"node252\" class=\"node\"><title>0.8667050231079826</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2292.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2292.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0495481983557865&#45;&gt;0.8667050231079826 -->\r\n",
       "<g id=\"edge251\" class=\"edge\"><title>0.0495481983557865&#45;&gt;0.8667050231079826</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2381.18,-289.811C2363.32,-278.753 2339.12,-263.762 2320.54,-252.252\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2322.27,-249.205 2311.93,-246.914 2318.59,-255.156 2322.27,-249.205\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6640136068709913 -->\r\n",
       "<g id=\"node254\" class=\"node\"><title>0.6640136068709913</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2367.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2367.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0495481983557865&#45;&gt;0.6640136068709913 -->\r\n",
       "<g id=\"edge253\" class=\"edge\"><title>0.0495481983557865&#45;&gt;0.6640136068709913</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2396.5,-288.055C2391.95,-279.679 2386.37,-269.404 2381.34,-260.134\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2384.39,-258.426 2376.55,-251.307 2378.24,-261.765 2384.39,-258.426\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4087297087584484 -->\r\n",
       "<g id=\"node256\" class=\"node\"><title>0.4087297087584484</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2440.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2440.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0495481983557865&#45;&gt;0.4087297087584484 -->\r\n",
       "<g id=\"edge255\" class=\"edge\"><title>0.0495481983557865&#45;&gt;0.4087297087584484</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2414.17,-288.055C2418.31,-279.767 2423.39,-269.618 2427.98,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2431.2,-261.817 2432.54,-251.307 2424.94,-258.686 2431.2,-261.817\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.39433255386287647 -->\r\n",
       "<g id=\"node258\" class=\"node\"><title>0.39433255386287647</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2530.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2530.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0495481983557865&#45;&gt;0.39433255386287647 -->\r\n",
       "<g id=\"edge257\" class=\"edge\"><title>0.0495481983557865&#45;&gt;0.39433255386287647</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2432.51,-289.983C2452.88,-278.575 2480.86,-262.908 2501.74,-251.215\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2503.48,-254.252 2510.49,-246.312 2500.06,-248.144 2503.48,-254.252\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3960627480944656 -->\r\n",
       "<g id=\"node111\" class=\"node\"><title>0.3960627480944656</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2659.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2659.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.895886590279147&#45;&gt;0.3960627480944656 -->\r\n",
       "<g id=\"edge110\" class=\"edge\"><title>0.895886590279147&#45;&gt;0.3960627480944656</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2567.78,-364.967C2584.01,-354.729 2607.69,-339.799 2626.94,-327.654\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2628.85,-330.592 2635.44,-322.298 2625.11,-324.671 2628.85,-330.592\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8521123338461256 -->\r\n",
       "<g id=\"node260\" class=\"node\"><title>0.8521123338461256</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2659.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2659.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3960627480944656&#45;&gt;0.8521123338461256 -->\r\n",
       "<g id=\"edge259\" class=\"edge\"><title>0.3960627480944656&#45;&gt;0.8521123338461256</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2659.69,-287.697C2659.69,-279.983 2659.69,-270.712 2659.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2663.19,-262.104 2659.69,-252.104 2656.19,-262.104 2663.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8769294764034938 -->\r\n",
       "<g id=\"node262\" class=\"node\"><title>0.8769294764034938</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2731.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2731.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3960627480944656&#45;&gt;0.8769294764034938 -->\r\n",
       "<g id=\"edge261\" class=\"edge\"><title>0.3960627480944656&#45;&gt;0.8769294764034938</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2676.39,-288.765C2686.29,-279.145 2698.95,-266.84 2709.65,-256.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2712.31,-258.73 2717.04,-249.25 2707.43,-253.711 2712.31,-258.73\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.02557102932277222 -->\r\n",
       "<g id=\"node113\" class=\"node\"><title>0.02557102932277222</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2869.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2869.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7448890270904971&#45;&gt;0.02557102932277222 -->\r\n",
       "<g id=\"edge112\" class=\"edge\"><title>0.7448890270904971&#45;&gt;0.02557102932277222</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2734.52,-367.267C2758.85,-356.419 2798.73,-338.639 2828.88,-325.195\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2830.59,-328.266 2838.3,-320.997 2827.74,-321.873 2830.59,-328.266\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7968775526266042 -->\r\n",
       "<g id=\"node264\" class=\"node\"><title>0.7968775526266042</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2814.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2814.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.02557102932277222&#45;&gt;0.7968775526266042 -->\r\n",
       "<g id=\"edge263\" class=\"edge\"><title>0.02557102932277222&#45;&gt;0.7968775526266042</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2856.66,-288.411C2849.68,-279.53 2840.97,-268.439 2833.29,-258.668\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2835.81,-256.212 2826.88,-250.511 2830.31,-260.536 2835.81,-256.212\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1381350271565699 -->\r\n",
       "<g id=\"node266\" class=\"node\"><title>0.1381350271565699</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2896.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2896.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.02557102932277222&#45;&gt;0.1381350271565699 -->\r\n",
       "<g id=\"edge265\" class=\"edge\"><title>0.02557102932277222&#45;&gt;0.1381350271565699</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2876.23,-288.055C2879.31,-280.059 2883.07,-270.331 2886.51,-261.4\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2889.89,-262.379 2890.22,-251.789 2883.35,-259.859 2889.89,-262.379\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.42264446244682263 -->\r\n",
       "<g id=\"node268\" class=\"node\"><title>0.42264446244682263</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2996.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2996.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.02557102932277222&#45;&gt;0.42264446244682263 -->\r\n",
       "<g id=\"edge267\" class=\"edge\"><title>0.02557102932277222&#45;&gt;0.42264446244682263</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2896.63,-290.155C2917.43,-278.688 2946.18,-262.843 2967.52,-251.078\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2969.4,-254.042 2976.47,-246.15 2966.02,-247.912 2969.4,-254.042\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6198206205868276 -->\r\n",
       "<g id=\"node115\" class=\"node\"><title>0.6198206205868276</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3204.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3204.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9842916698245636&#45;&gt;0.6198206205868276 -->\r\n",
       "<g id=\"edge114\" class=\"edge\"><title>0.9842916698245636&#45;&gt;0.6198206205868276</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3270.49,-363.17C3259.36,-353.667 3244.32,-340.83 3231.43,-329.826\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3233.62,-327.088 3223.74,-323.257 3229.07,-332.412 3233.62,-327.088\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.30237319061973733 -->\r\n",
       "<g id=\"node270\" class=\"node\"><title>0.30237319061973733</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3096.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3096.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6198206205868276&#45;&gt;0.30237319061973733 -->\r\n",
       "<g id=\"edge269\" class=\"edge\"><title>0.6198206205868276&#45;&gt;0.30237319061973733</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3180.46,-289.291C3163.72,-278.444 3141.44,-264.002 3124.06,-252.74\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3125.78,-249.679 3115.48,-247.177 3121.97,-255.553 3125.78,-249.679\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.21568019283365125 -->\r\n",
       "<g id=\"node272\" class=\"node\"><title>0.21568019283365125</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3168.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3168.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6198206205868276&#45;&gt;0.21568019283365125 -->\r\n",
       "<g id=\"edge271\" class=\"edge\"><title>0.6198206205868276&#45;&gt;0.21568019283365125</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3195.98,-288.055C3191.72,-279.767 3186.5,-269.618 3181.77,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3184.77,-258.599 3177.08,-251.307 3178.54,-261.801 3184.77,-258.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9786072757870522 -->\r\n",
       "<g id=\"node274\" class=\"node\"><title>0.9786072757870522</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3240.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3240.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6198206205868276&#45;&gt;0.9786072757870522 -->\r\n",
       "<g id=\"edge273\" class=\"edge\"><title>0.6198206205868276&#45;&gt;0.9786072757870522</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3213.41,-288.055C3217.67,-279.767 3222.89,-269.618 3227.62,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3230.85,-261.801 3232.31,-251.307 3224.62,-258.599 3230.85,-261.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.09182420915684075 -->\r\n",
       "<g id=\"node117\" class=\"node\"><title>0.09182420915684075</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3386.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3386.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6218884301526906&#45;&gt;0.09182420915684075 -->\r\n",
       "<g id=\"edge116\" class=\"edge\"><title>0.6218884301526906&#45;&gt;0.09182420915684075</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3400.34,-360.055C3398.33,-352.261 3395.91,-342.822 3393.66,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3397.02,-333.089 3391.14,-324.275 3390.24,-334.832 3397.02,-333.089\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24095904597997164 -->\r\n",
       "<g id=\"node276\" class=\"node\"><title>0.24095904597997164</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3313.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3313.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.09182420915684075&#45;&gt;0.24095904597997164 -->\r\n",
       "<g id=\"edge275\" class=\"edge\"><title>0.09182420915684075&#45;&gt;0.24095904597997164</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3369.39,-288.411C3359.35,-278.781 3346.6,-266.552 3335.83,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3338.05,-253.503 3328.41,-249.108 3333.2,-258.555 3338.05,-253.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.25085197028462547 -->\r\n",
       "<g id=\"node278\" class=\"node\"><title>0.25085197028462547</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3386.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3386.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.09182420915684075&#45;&gt;0.25085197028462547 -->\r\n",
       "<g id=\"edge277\" class=\"edge\"><title>0.09182420915684075&#45;&gt;0.25085197028462547</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3386.69,-287.697C3386.69,-279.983 3386.69,-270.712 3386.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3390.19,-262.104 3386.69,-252.104 3383.19,-262.104 3390.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2810484131503791 -->\r\n",
       "<g id=\"node280\" class=\"node\"><title>0.2810484131503791</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3459.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3459.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.09182420915684075&#45;&gt;0.2810484131503791 -->\r\n",
       "<g id=\"edge279\" class=\"edge\"><title>0.09182420915684075&#45;&gt;0.2810484131503791</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3403.99,-288.411C3414.04,-278.781 3426.79,-266.552 3437.56,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3440.19,-258.555 3444.98,-249.108 3435.34,-253.503 3440.19,-258.555\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.11918760328464306 -->\r\n",
       "<g id=\"node119\" class=\"node\"><title>0.11918760328464306</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3495.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3495.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8747826757794844&#45;&gt;0.11918760328464306 -->\r\n",
       "<g id=\"edge118\" class=\"edge\"><title>0.8747826757794844&#45;&gt;0.11918760328464306</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3488.87,-360.055C3489.86,-352.346 3491.06,-343.027 3492.18,-334.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3495.67,-334.64 3493.47,-324.275 3488.73,-333.747 3495.67,-334.64\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2010096750220146 -->\r\n",
       "<g id=\"node121\" class=\"node\"><title>0.2010096750220146</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3604.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3604.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.34262469833850173&#45;&gt;0.2010096750220146 -->\r\n",
       "<g id=\"edge120\" class=\"edge\"><title>0.34262469833850173&#45;&gt;0.2010096750220146</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3688.46,-364.485C3673.92,-354.506 3653.21,-340.297 3636.03,-328.503\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3637.64,-325.364 3627.41,-322.591 3633.68,-331.135 3637.64,-325.364\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.46616197618207156 -->\r\n",
       "<g id=\"node282\" class=\"node\"><title>0.46616197618207156</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3532.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3532.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2010096750220146&#45;&gt;0.46616197618207156 -->\r\n",
       "<g id=\"edge281\" class=\"edge\"><title>0.2010096750220146&#45;&gt;0.46616197618207156</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3588,-288.765C3578.1,-279.145 3565.44,-266.84 3554.74,-256.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3556.96,-253.711 3547.35,-249.25 3552.08,-258.73 3556.96,-253.711\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.23556982151038042 -->\r\n",
       "<g id=\"node284\" class=\"node\"><title>0.23556982151038042</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3604.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3604.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2010096750220146&#45;&gt;0.23556982151038042 -->\r\n",
       "<g id=\"edge283\" class=\"edge\"><title>0.2010096750220146&#45;&gt;0.23556982151038042</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3604.69,-287.697C3604.69,-279.983 3604.69,-270.712 3604.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3608.19,-262.104 3604.69,-252.104 3601.19,-262.104 3608.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.39631843133089983 -->\r\n",
       "<g id=\"node123\" class=\"node\"><title>0.39631843133089983</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3849.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3849.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.16799191751908227&#45;&gt;0.39631843133089983 -->\r\n",
       "<g id=\"edge122\" class=\"edge\"><title>0.16799191751908227&#45;&gt;0.39631843133089983</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3884.48,-361.116C3879,-352.592 3872.12,-341.886 3865.93,-332.251\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3868.84,-330.316 3860.49,-323.797 3862.96,-334.102 3868.84,-330.316\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6142973186856004 -->\r\n",
       "<g id=\"node286\" class=\"node\"><title>0.6142973186856004</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3701.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3701.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.39631843133089983&#45;&gt;0.6142973186856004 -->\r\n",
       "<g id=\"edge285\" class=\"edge\"><title>0.39631843133089983&#45;&gt;0.6142973186856004</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3819.39,-290.666C3794.04,-278.677 3758.04,-261.65 3732.54,-249.591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3733.87,-246.345 3723.33,-245.233 3730.87,-252.673 3733.87,-246.345\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.25449535920259625 -->\r\n",
       "<g id=\"node288\" class=\"node\"><title>0.25449535920259625</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3797.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3797.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.39631843133089983&#45;&gt;0.25449535920259625 -->\r\n",
       "<g id=\"edge287\" class=\"edge\"><title>0.39631843133089983&#45;&gt;0.25449535920259625</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3837.37,-288.411C3830.77,-279.53 3822.53,-268.439 3815.28,-258.668\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3817.99,-256.451 3809.22,-250.511 3812.37,-260.625 3817.99,-256.451\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9182927983007992 -->\r\n",
       "<g id=\"node290\" class=\"node\"><title>0.9182927983007992</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3879.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3879.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.39631843133089983&#45;&gt;0.9182927983007992 -->\r\n",
       "<g id=\"edge289\" class=\"edge\"><title>0.39631843133089983&#45;&gt;0.9182927983007992</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3856.96,-288.055C3860.42,-279.973 3864.64,-270.121 3868.5,-261.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3871.78,-262.359 3872.5,-251.789 3865.34,-259.602 3871.78,-262.359\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8830217334529187 -->\r\n",
       "<g id=\"node125\" class=\"node\"><title>0.8830217334529187</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4031.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4031.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.209711999370511&#45;&gt;0.8830217334529187 -->\r\n",
       "<g id=\"edge124\" class=\"edge\"><title>0.209711999370511&#45;&gt;0.8830217334529187</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4042.31,-360.055C4040.76,-352.346 4038.9,-343.027 4037.17,-334.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4040.54,-333.395 4035.15,-324.275 4033.68,-334.768 4040.54,-333.395\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6744051385704244 -->\r\n",
       "<g id=\"node127\" class=\"node\"><title>0.6744051385704244</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4132.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4132.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3798047979293897&#45;&gt;0.6744051385704244 -->\r\n",
       "<g id=\"edge126\" class=\"edge\"><title>0.3798047979293897&#45;&gt;0.6744051385704244</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4132.69,-359.697C4132.69,-351.983 4132.69,-342.712 4132.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4136.19,-334.104 4132.69,-324.104 4129.19,-334.104 4136.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.32492317609440335 -->\r\n",
       "<g id=\"node292\" class=\"node\"><title>0.32492317609440335</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4027.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4027.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6744051385704244&#45;&gt;0.32492317609440335 -->\r\n",
       "<g id=\"edge291\" class=\"edge\"><title>0.6744051385704244&#45;&gt;0.32492317609440335</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4109.39,-289.465C4093.13,-278.626 4071.4,-264.136 4054.43,-252.826\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4056.31,-249.873 4046.05,-247.238 4052.43,-255.697 4056.31,-249.873\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9557055937061032 -->\r\n",
       "<g id=\"node294\" class=\"node\"><title>0.9557055937061032</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4121.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4121.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6744051385704244&#45;&gt;0.9557055937061032 -->\r\n",
       "<g id=\"edge293\" class=\"edge\"><title>0.6744051385704244&#45;&gt;0.9557055937061032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4129.98,-287.697C4128.76,-279.983 4127.31,-270.712 4125.95,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4129.39,-261.44 4124.38,-252.104 4122.48,-262.526 4129.39,-261.44\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4220792418873872 -->\r\n",
       "<g id=\"node296\" class=\"node\"><title>0.4220792418873872</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4194.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4194.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6744051385704244&#45;&gt;0.4220792418873872 -->\r\n",
       "<g id=\"edge295\" class=\"edge\"><title>0.6744051385704244&#45;&gt;0.4220792418873872</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4147.39,-288.411C4155.53,-279.223 4165.76,-267.67 4174.62,-257.66\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4177.36,-259.845 4181.37,-250.038 4172.12,-255.204 4177.36,-259.845\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.44718455594708695 -->\r\n",
       "<g id=\"node129\" class=\"node\"><title>0.44718455594708695</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4271.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4271.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44117039905476274&#45;&gt;0.44718455594708695 -->\r\n",
       "<g id=\"edge128\" class=\"edge\"><title>0.44117039905476274&#45;&gt;0.44718455594708695</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4240.97,-360.765C4245.68,-352.525 4251.51,-342.317 4256.83,-333.016\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4259.99,-334.543 4261.91,-324.124 4253.91,-331.07 4259.99,-334.543\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8824816748847272 -->\r\n",
       "<g id=\"node298\" class=\"node\"><title>0.8824816748847272</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4271.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4271.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44718455594708695&#45;&gt;0.8824816748847272 -->\r\n",
       "<g id=\"edge297\" class=\"edge\"><title>0.44718455594708695&#45;&gt;0.8824816748847272</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4271.69,-287.697C4271.69,-279.983 4271.69,-270.712 4271.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4275.19,-262.104 4271.69,-252.104 4268.19,-262.104 4275.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.16025820144932845 -->\r\n",
       "<g id=\"node300\" class=\"node\"><title>0.16025820144932845</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4345.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4345.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44718455594708695&#45;&gt;0.16025820144932845 -->\r\n",
       "<g id=\"edge299\" class=\"edge\"><title>0.44718455594708695&#45;&gt;0.16025820144932845</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4288.86,-288.765C4299.13,-279.051 4312.29,-266.6 4323.36,-256.127\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4325.77,-258.665 4330.63,-249.25 4320.96,-253.579 4325.77,-258.665\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6731444134173338 -->\r\n",
       "<g id=\"node302\" class=\"node\"><title>0.6731444134173338</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4418.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4418.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44718455594708695&#45;&gt;0.6731444134173338 -->\r\n",
       "<g id=\"edge301\" class=\"edge\"><title>0.44718455594708695&#45;&gt;0.6731444134173338</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4301.8,-290.666C4326.97,-278.677 4362.73,-261.65 4388.05,-249.591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4389.68,-252.692 4397.2,-245.233 4386.67,-246.372 4389.68,-252.692\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5881686440927896 -->\r\n",
       "<g id=\"node131\" class=\"node\"><title>0.5881686440927896</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4372.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4372.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.823348341496976&#45;&gt;0.5881686440927896 -->\r\n",
       "<g id=\"edge130\" class=\"edge\"><title>0.823348341496976&#45;&gt;0.5881686440927896</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4346.58,-360.765C4350.6,-352.491 4355.58,-342.232 4360.11,-332.9\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4363.39,-334.158 4364.62,-323.633 4357.1,-331.099 4363.39,-334.158\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.28094830223927203 -->\r\n",
       "<g id=\"node133\" class=\"node\"><title>0.28094830223927203</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4466.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4466.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5849365089269531&#45;&gt;0.28094830223927203 -->\r\n",
       "<g id=\"edge132\" class=\"edge\"><title>0.5849365089269531&#45;&gt;0.28094830223927203</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4486.53,-360.411C4483.53,-352.335 4479.85,-342.431 4476.48,-333.355\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4479.76,-332.112 4472.99,-323.956 4473.19,-334.549 4479.76,-332.112\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.70357671160901 -->\r\n",
       "<g id=\"node135\" class=\"node\"><title>0.70357671160901</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4575.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4575.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7743721994425291&#45;&gt;0.70357671160901 -->\r\n",
       "<g id=\"edge134\" class=\"edge\"><title>0.7743721994425291&#45;&gt;0.70357671160901</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4587.82,-360.055C4586.04,-352.261 4583.88,-342.822 4581.88,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4585.28,-333.244 4579.64,-324.275 4578.46,-334.804 4585.28,-333.244\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4446705263565319 -->\r\n",
       "<g id=\"node304\" class=\"node\"><title>0.4446705263565319</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4492.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4492.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.70357671160901&#45;&gt;0.4446705263565319 -->\r\n",
       "<g id=\"edge303\" class=\"edge\"><title>0.70357671160901&#45;&gt;0.4446705263565319</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4556.44,-288.765C4544.58,-278.759 4529.27,-265.849 4516.63,-255.187\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4518.67,-252.33 4508.77,-248.559 4514.16,-257.682 4518.67,-252.33\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2536574865628032 -->\r\n",
       "<g id=\"node306\" class=\"node\"><title>0.2536574865628032</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4566.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4566.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.70357671160901&#45;&gt;0.2536574865628032 -->\r\n",
       "<g id=\"edge305\" class=\"edge\"><title>0.70357671160901&#45;&gt;0.2536574865628032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4573.47,-287.697C4572.48,-279.983 4571.29,-270.712 4570.18,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4573.64,-261.576 4568.89,-252.104 4566.7,-262.469 4573.64,-261.576\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.11145777283486735 -->\r\n",
       "<g id=\"node308\" class=\"node\"><title>0.11145777283486735</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4638.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4638.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.70357671160901&#45;&gt;0.11145777283486735 -->\r\n",
       "<g id=\"edge307\" class=\"edge\"><title>0.70357671160901&#45;&gt;0.11145777283486735</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4590.62,-288.411C4598.89,-279.223 4609.29,-267.67 4618.3,-257.66\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4621.07,-259.813 4625.16,-250.038 4615.87,-255.13 4621.07,-259.813\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5044861564170116 -->\r\n",
       "<g id=\"node137\" class=\"node\"><title>0.5044861564170116</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4713.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4713.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.02340463051152475&#45;&gt;0.5044861564170116 -->\r\n",
       "<g id=\"edge136\" class=\"edge\"><title>0.02340463051152475&#45;&gt;0.5044861564170116</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4688.51,-360.411C4692.36,-352.249 4697.09,-342.22 4701.41,-333.065\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4704.6,-334.494 4705.7,-323.956 4698.27,-331.509 4704.6,-334.494\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.32950187075328785 -->\r\n",
       "<g id=\"node310\" class=\"node\"><title>0.32950187075328785</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4713.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4713.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5044861564170116&#45;&gt;0.32950187075328785 -->\r\n",
       "<g id=\"edge309\" class=\"edge\"><title>0.5044861564170116&#45;&gt;0.32950187075328785</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4713.69,-287.697C4713.69,-279.983 4713.69,-270.712 4713.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4717.19,-262.104 4713.69,-252.104 4710.19,-262.104 4717.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.20368201692623256 -->\r\n",
       "<g id=\"node312\" class=\"node\"><title>0.20368201692623256</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4786.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4786.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5044861564170116&#45;&gt;0.20368201692623256 -->\r\n",
       "<g id=\"edge311\" class=\"edge\"><title>0.5044861564170116&#45;&gt;0.20368201692623256</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4730.63,-288.765C4740.66,-279.145 4753.49,-266.84 4764.35,-256.43\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4767.04,-258.697 4771.83,-249.25 4762.19,-253.645 4767.04,-258.697\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.31068509057140015 -->\r\n",
       "<g id=\"node314\" class=\"node\"><title>0.31068509057140015</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4858.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4858.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5044861564170116&#45;&gt;0.31068509057140015 -->\r\n",
       "<g id=\"edge313\" class=\"edge\"><title>0.5044861564170116&#45;&gt;0.31068509057140015</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4743.39,-290.666C4768.22,-278.677 4803.49,-261.65 4828.47,-249.591\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4830.01,-252.733 4837.5,-245.233 4826.97,-246.429 4830.01,-252.733\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8026270101424691 -->\r\n",
       "<g id=\"node139\" class=\"node\"><title>0.8026270101424691</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4843.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4843.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5256041754815182&#45;&gt;0.8026270101424691 -->\r\n",
       "<g id=\"edge138\" class=\"edge\"><title>0.5256041754815182&#45;&gt;0.8026270101424691</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4808.91,-361.116C4814.39,-352.592 4821.27,-341.886 4827.46,-332.251\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4830.43,-334.102 4832.9,-323.797 4824.54,-330.316 4830.43,-334.102\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6625009551009192 -->\r\n",
       "<g id=\"node316\" class=\"node\"><title>0.6625009551009192</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4930.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4930.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8026270101424691&#45;&gt;0.6625009551009192 -->\r\n",
       "<g id=\"edge315\" class=\"edge\"><title>0.8026270101424691&#45;&gt;0.6625009551009192</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4863.44,-289.116C4876.06,-278.961 4892.53,-265.709 4906.01,-254.86\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4908.36,-257.461 4913.96,-248.466 4903.97,-252.008 4908.36,-257.461\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.44313654468022057 -->\r\n",
       "<g id=\"node318\" class=\"node\"><title>0.44313654468022057</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5002.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5002.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8026270101424691&#45;&gt;0.44313654468022057 -->\r\n",
       "<g id=\"edge317\" class=\"edge\"><title>0.8026270101424691&#45;&gt;0.44313654468022057</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4876.2,-291.353C4901.07,-280.823 4936.18,-265.776 4966.69,-252 4968.49,-251.19 4970.33,-250.349 4972.19,-249.495\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4973.84,-252.585 4981.43,-245.189 4970.89,-246.239 4973.84,-252.585\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.21983613269807334 -->\r\n",
       "<g id=\"node320\" class=\"node\"><title>0.21983613269807334</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5075.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5075.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8026270101424691&#45;&gt;0.21983613269807334 -->\r\n",
       "<g id=\"edge319\" class=\"edge\"><title>0.8026270101424691&#45;&gt;0.21983613269807334</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4885.57,-294.012C4938.44,-280.079 5024.27,-257.235 5038.69,-252 5040.8,-251.236 5042.95,-250.401 5045.1,-249.523\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5046.63,-252.677 5054.42,-245.5 5043.86,-246.251 5046.63,-252.677\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.34715858659549825 -->\r\n",
       "<g id=\"node141\" class=\"node\"><title>0.34715858659549825</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4944.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4944.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3459194778693324&#45;&gt;0.34715858659549825 -->\r\n",
       "<g id=\"edge140\" class=\"edge\"><title>0.3459194778693324&#45;&gt;0.34715858659549825</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4897.71,-361.811C4905.73,-352.455 4916.17,-340.282 4925.16,-329.785\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4927.85,-332.03 4931.7,-322.159 4922.54,-327.474 4927.85,-332.03\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4086860710203788 -->\r\n",
       "<g id=\"node143\" class=\"node\"><title>0.4086860710203788</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5016.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5016.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3019976258171191&#45;&gt;0.4086860710203788 -->\r\n",
       "<g id=\"edge142\" class=\"edge\"><title>0.3019976258171191&#45;&gt;0.4086860710203788</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4975.46,-361.465C4982.32,-352.402 4991.11,-340.786 4998.82,-330.612\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5001.72,-332.577 5004.96,-322.492 4996.14,-328.352 5001.72,-332.577\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8637178568239099 -->\r\n",
       "<g id=\"node145\" class=\"node\"><title>0.8637178568239099</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5088.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5088.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4179122592134912&#45;&gt;0.8637178568239099 -->\r\n",
       "<g id=\"edge144\" class=\"edge\"><title>0.4179122592134912&#45;&gt;0.8637178568239099</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5088.69,-359.697C5088.69,-351.983 5088.69,-342.712 5088.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5092.19,-334.104 5088.69,-324.104 5085.19,-334.104 5092.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24745432572844483 -->\r\n",
       "<g id=\"node147\" class=\"node\"><title>0.24745432572844483</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5160.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5160.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.32497389273943866&#45;&gt;0.24745432572844483 -->\r\n",
       "<g id=\"edge146\" class=\"edge\"><title>0.32497389273943866&#45;&gt;0.24745432572844483</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5160.69,-359.697C5160.69,-351.983 5160.69,-342.712 5160.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5164.19,-334.104 5160.69,-324.104 5157.19,-334.104 5164.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4953753654141021 -->\r\n",
       "<g id=\"node149\" class=\"node\"><title>0.4953753654141021</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5232.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5232.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8793808970133554&#45;&gt;0.4953753654141021 -->\r\n",
       "<g id=\"edge148\" class=\"edge\"><title>0.8793808970133554&#45;&gt;0.4953753654141021</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5232.69,-359.697C5232.69,-351.983 5232.69,-342.712 5232.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5236.19,-334.104 5232.69,-324.104 5229.19,-334.104 5236.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3961311155982925 -->\r\n",
       "<g id=\"node151\" class=\"node\"><title>0.3961311155982925</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5306.69\" cy=\"-306\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5306.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7826016885995789&#45;&gt;0.3961311155982925 -->\r\n",
       "<g id=\"edge150\" class=\"edge\"><title>0.7826016885995789&#45;&gt;0.3961311155982925</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5307.45,-359.697C5307.34,-351.983 5307.2,-342.712 5307.08,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5310.58,-334.053 5306.94,-324.104 5303.58,-334.153 5310.58,-334.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.20187998659546758 -->\r\n",
       "<g id=\"node153\" class=\"node\"><title>0.20187998659546758</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5380.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5380.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5067304013187766&#45;&gt;0.20187998659546758 -->\r\n",
       "<g id=\"edge152\" class=\"edge\"><title>0.5067304013187766&#45;&gt;0.20187998659546758</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5380.69,-359.697C5380.69,-351.983 5380.69,-342.712 5380.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5384.19,-334.104 5380.69,-324.104 5377.19,-334.104 5384.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9619289548070227 -->\r\n",
       "<g id=\"node155\" class=\"node\"><title>0.9619289548070227</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5452.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5452.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.030289076737484932&#45;&gt;0.9619289548070227 -->\r\n",
       "<g id=\"edge154\" class=\"edge\"><title>0.030289076737484932&#45;&gt;0.9619289548070227</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5452.69,-359.697C5452.69,-351.983 5452.69,-342.712 5452.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5456.19,-334.104 5452.69,-324.104 5449.19,-334.104 5456.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.919729177606936 -->\r\n",
       "<g id=\"node157\" class=\"node\"><title>0.919729177606936</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5524.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5524.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.17048204915354304&#45;&gt;0.919729177606936 -->\r\n",
       "<g id=\"edge156\" class=\"edge\"><title>0.17048204915354304&#45;&gt;0.919729177606936</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5524.69,-359.697C5524.69,-351.983 5524.69,-342.712 5524.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5528.19,-334.104 5524.69,-324.104 5521.19,-334.104 5528.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4267313240171262 -->\r\n",
       "<g id=\"node159\" class=\"node\"><title>0.4267313240171262</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5596.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5596.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9743879372361316&#45;&gt;0.4267313240171262 -->\r\n",
       "<g id=\"edge158\" class=\"edge\"><title>0.9743879372361316&#45;&gt;0.4267313240171262</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5596.69,-359.697C5596.69,-351.983 5596.69,-342.712 5596.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5600.19,-334.104 5596.69,-324.104 5593.19,-334.104 5600.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6928857036962776 -->\r\n",
       "<g id=\"node161\" class=\"node\"><title>0.6928857036962776</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5705.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5705.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.38309356241782866&#45;&gt;0.6928857036962776 -->\r\n",
       "<g id=\"edge160\" class=\"edge\"><title>0.38309356241782866&#45;&gt;0.6928857036962776</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5720.09,-360.055C5717.98,-352.261 5715.42,-342.822 5713.04,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5716.38,-333.009 5710.38,-324.275 5709.63,-334.843 5716.38,-333.009\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3809222976402993 -->\r\n",
       "<g id=\"node322\" class=\"node\"><title>0.3809222976402993</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5665.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5665.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6928857036962776&#45;&gt;0.3809222976402993 -->\r\n",
       "<g id=\"edge321\" class=\"edge\"><title>0.6928857036962776&#45;&gt;0.3809222976402993</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5696.01,-288.055C5691.23,-279.679 5685.35,-269.404 5680.06,-260.134\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5683.01,-258.253 5675.01,-251.307 5676.94,-261.726 5683.01,-258.253\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.20040879530889555 -->\r\n",
       "<g id=\"node324\" class=\"node\"><title>0.20040879530889555</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5745.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5745.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6928857036962776&#45;&gt;0.20040879530889555 -->\r\n",
       "<g id=\"edge323\" class=\"edge\"><title>0.6928857036962776&#45;&gt;0.20040879530889555</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5715.38,-288.055C5720.16,-279.679 5726.03,-269.404 5731.33,-260.134\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5734.45,-261.726 5736.38,-251.307 5728.38,-258.253 5734.45,-261.726\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7585724697038002 -->\r\n",
       "<g id=\"node163\" class=\"node\"><title>0.7585724697038002</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5814.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5814.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5554583246289788&#45;&gt;0.7585724697038002 -->\r\n",
       "<g id=\"edge162\" class=\"edge\"><title>0.5554583246289788&#45;&gt;0.7585724697038002</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5814.69,-359.697C5814.69,-351.983 5814.69,-342.712 5814.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5818.19,-334.104 5814.69,-324.104 5811.19,-334.104 5818.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9980525156180151 -->\r\n",
       "<g id=\"node165\" class=\"node\"><title>0.9980525156180151</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5886.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5886.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7787818220238037&#45;&gt;0.9980525156180151 -->\r\n",
       "<g id=\"edge164\" class=\"edge\"><title>0.7787818220238037&#45;&gt;0.9980525156180151</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5886.69,-359.697C5886.69,-351.983 5886.69,-342.712 5886.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5890.19,-334.104 5886.69,-324.104 5883.19,-334.104 5890.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6849779836349038 -->\r\n",
       "<g id=\"node167\" class=\"node\"><title>0.6849779836349038</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5987.69\" cy=\"-306\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5987.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.10960599450060593&#45;&gt;0.6849779836349038 -->\r\n",
       "<g id=\"edge166\" class=\"edge\"><title>0.10960599450060593&#45;&gt;0.6849779836349038</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5976.33,-360.055C5978,-352.261 5980.02,-342.822 5981.89,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5985.32,-334.787 5983.99,-324.275 5978.47,-333.32 5985.32,-334.787\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5815881942574035 -->\r\n",
       "<g id=\"node326\" class=\"node\"><title>0.5815881942574035</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5951.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5951.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6849779836349038&#45;&gt;0.5815881942574035 -->\r\n",
       "<g id=\"edge325\" class=\"edge\"><title>0.6849779836349038&#45;&gt;0.5815881942574035</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5978.98,-288.055C5974.72,-279.767 5969.5,-269.618 5964.77,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5967.77,-258.599 5960.08,-251.307 5961.54,-261.801 5967.77,-258.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9743843847178872 -->\r\n",
       "<g id=\"node328\" class=\"node\"><title>0.9743843847178872</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6023.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6023.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6849779836349038&#45;&gt;0.9743843847178872 -->\r\n",
       "<g id=\"edge327\" class=\"edge\"><title>0.6849779836349038&#45;&gt;0.9743843847178872</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5996.41,-288.055C6000.67,-279.767 6005.89,-269.618 6010.62,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6013.85,-261.801 6015.31,-251.307 6007.62,-258.599 6013.85,-261.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.09438085504820048 -->\r\n",
       "<g id=\"node169\" class=\"node\"><title>0.09438085504820048</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6088.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6088.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2317996130647354&#45;&gt;0.09438085504820048 -->\r\n",
       "<g id=\"edge168\" class=\"edge\"><title>0.2317996130647354&#45;&gt;0.09438085504820048</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6088.69,-359.697C6088.69,-351.983 6088.69,-342.712 6088.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6092.19,-334.104 6088.69,-324.104 6085.19,-334.104 6092.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7756783977952227 -->\r\n",
       "<g id=\"node171\" class=\"node\"><title>0.7756783977952227</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6160.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6160.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1863675156343616&#45;&gt;0.7756783977952227 -->\r\n",
       "<g id=\"edge170\" class=\"edge\"><title>0.1863675156343616&#45;&gt;0.7756783977952227</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6160.69,-359.697C6160.69,-351.983 6160.69,-342.712 6160.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6164.19,-334.104 6160.69,-324.104 6157.19,-334.104 6164.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.047069038976555344 -->\r\n",
       "<g id=\"node173\" class=\"node\"><title>0.047069038976555344</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6232.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6232.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7424221044968857&#45;&gt;0.047069038976555344 -->\r\n",
       "<g id=\"edge172\" class=\"edge\"><title>0.7424221044968857&#45;&gt;0.047069038976555344</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6232.69,-359.697C6232.69,-351.983 6232.69,-342.712 6232.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6236.19,-334.104 6232.69,-324.104 6229.19,-334.104 6236.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.07608493224893809 -->\r\n",
       "<g id=\"node175\" class=\"node\"><title>0.07608493224893809</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6304.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6304.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7616221199195248&#45;&gt;0.07608493224893809 -->\r\n",
       "<g id=\"edge174\" class=\"edge\"><title>0.7616221199195248&#45;&gt;0.07608493224893809</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6304.69,-359.697C6304.69,-351.983 6304.69,-342.712 6304.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6308.19,-334.104 6304.69,-324.104 6301.19,-334.104 6308.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.14356628696666995 -->\r\n",
       "<g id=\"node177\" class=\"node\"><title>0.14356628696666995</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6376.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6376.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8332507683158114&#45;&gt;0.14356628696666995 -->\r\n",
       "<g id=\"edge176\" class=\"edge\"><title>0.8332507683158114&#45;&gt;0.14356628696666995</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6376.69,-359.697C6376.69,-351.983 6376.69,-342.712 6376.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6380.19,-334.104 6376.69,-324.104 6373.19,-334.104 6380.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4820717086225722 -->\r\n",
       "<g id=\"node179\" class=\"node\"><title>0.4820717086225722</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6448.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6448.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.35724570164555025&#45;&gt;0.4820717086225722 -->\r\n",
       "<g id=\"edge178\" class=\"edge\"><title>0.35724570164555025&#45;&gt;0.4820717086225722</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6448.69,-359.697C6448.69,-351.983 6448.69,-342.712 6448.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6452.19,-334.104 6448.69,-324.104 6445.19,-334.104 6452.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7709353569330603 -->\r\n",
       "<g id=\"node181\" class=\"node\"><title>0.7709353569330603</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6557.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6557.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4075129667547601&#45;&gt;0.7709353569330603 -->\r\n",
       "<g id=\"edge180\" class=\"edge\"><title>0.4075129667547601&#45;&gt;0.7709353569330603</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6544.05,-360.055C6546.06,-352.261 6548.48,-342.822 6550.73,-334.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6554.15,-334.832 6553.25,-324.275 6547.37,-333.089 6554.15,-334.832\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.317425748234474 -->\r\n",
       "<g id=\"node330\" class=\"node\"><title>0.317425748234474</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6484.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6484.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7709353569330603&#45;&gt;0.317425748234474 -->\r\n",
       "<g id=\"edge329\" class=\"edge\"><title>0.7709353569330603&#45;&gt;0.317425748234474</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6540.39,-288.411C6530.35,-278.781 6517.6,-266.552 6506.83,-256.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6509.05,-253.503 6499.41,-249.108 6504.2,-258.555 6509.05,-253.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7615186875048336 -->\r\n",
       "<g id=\"node332\" class=\"node\"><title>0.7615186875048336</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6557.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6557.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7709353569330603&#45;&gt;0.7615186875048336 -->\r\n",
       "<g id=\"edge331\" class=\"edge\"><title>0.7709353569330603&#45;&gt;0.7615186875048336</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6557.69,-287.697C6557.69,-279.983 6557.69,-270.712 6557.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6561.19,-262.104 6557.69,-252.104 6554.19,-262.104 6561.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9250304866711132 -->\r\n",
       "<g id=\"node334\" class=\"node\"><title>0.9250304866711132</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6629.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6629.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7709353569330603&#45;&gt;0.9250304866711132 -->\r\n",
       "<g id=\"edge333\" class=\"edge\"><title>0.7709353569330603&#45;&gt;0.9250304866711132</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6574.76,-288.411C6584.53,-278.911 6596.9,-266.882 6607.43,-256.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6609.98,-259.051 6614.71,-249.57 6605.1,-254.032 6609.98,-259.051\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.316160627209333 -->\r\n",
       "<g id=\"node183\" class=\"node\"><title>0.316160627209333</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6666.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6666.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7468714053456937&#45;&gt;0.316160627209333 -->\r\n",
       "<g id=\"edge182\" class=\"edge\"><title>0.7468714053456937&#45;&gt;0.316160627209333</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6646.09,-360.411C6649.21,-352.335 6653.03,-342.431 6656.53,-333.355\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6659.82,-334.546 6660.15,-323.956 6653.29,-332.027 6659.82,-334.546\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.930262987294818 -->\r\n",
       "<g id=\"node185\" class=\"node\"><title>0.930262987294818</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6751.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6751.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.34284931634097504&#45;&gt;0.930262987294818 -->\r\n",
       "<g id=\"edge184\" class=\"edge\"><title>0.34284931634097504&#45;&gt;0.930262987294818</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6751.69,-359.697C6751.69,-351.983 6751.69,-342.712 6751.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6755.19,-334.104 6751.69,-324.104 6748.19,-334.104 6755.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.41412735547944246 -->\r\n",
       "<g id=\"node187\" class=\"node\"><title>0.41412735547944246</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6823.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6823.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.17240146940182022&#45;&gt;0.41412735547944246 -->\r\n",
       "<g id=\"edge186\" class=\"edge\"><title>0.17240146940182022&#45;&gt;0.41412735547944246</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6823.69,-359.697C6823.69,-351.983 6823.69,-342.712 6823.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6827.19,-334.104 6823.69,-324.104 6820.19,-334.104 6827.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6530136609230146 -->\r\n",
       "<g id=\"node189\" class=\"node\"><title>0.6530136609230146</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.22405833316055135&#45;&gt;0.6530136609230146 -->\r\n",
       "<g id=\"edge188\" class=\"edge\"><title>0.22405833316055135&#45;&gt;0.6530136609230146</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6944.69,-359.697C6944.69,-351.983 6944.69,-342.712 6944.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6948.19,-334.104 6944.69,-324.104 6941.19,-334.104 6948.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2684080686997762 -->\r\n",
       "<g id=\"node336\" class=\"node\"><title>0.2684080686997762</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6530136609230146&#45;&gt;0.2684080686997762 -->\r\n",
       "<g id=\"edge335\" class=\"edge\"><title>0.6530136609230146&#45;&gt;0.2684080686997762</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6944.69,-287.697C6944.69,-279.983 6944.69,-270.712 6944.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6948.19,-262.104 6944.69,-252.104 6941.19,-262.104 6948.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8603345065225437 -->\r\n",
       "<g id=\"node191\" class=\"node\"><title>0.8603345065225437</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7257.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7257.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6354217052708109&#45;&gt;0.8603345065225437 -->\r\n",
       "<g id=\"edge190\" class=\"edge\"><title>0.6354217052708109&#45;&gt;0.8603345065225437</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7257.69,-359.697C7257.69,-351.983 7257.69,-342.712 7257.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7261.19,-334.104 7257.69,-324.104 7254.19,-334.104 7261.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2163654057972969 -->\r\n",
       "<g id=\"node193\" class=\"node\"><title>0.2163654057972969</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7329.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7329.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.532452289593514&#45;&gt;0.2163654057972969 -->\r\n",
       "<g id=\"edge192\" class=\"edge\"><title>0.532452289593514&#45;&gt;0.2163654057972969</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7329.69,-359.697C7329.69,-351.983 7329.69,-342.712 7329.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7333.19,-334.104 7329.69,-324.104 7326.19,-334.104 7333.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.17433690352034592 -->\r\n",
       "<g id=\"node195\" class=\"node\"><title>0.17433690352034592</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7719.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7719.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.28813373249162044&#45;&gt;0.17433690352034592 -->\r\n",
       "<g id=\"edge194\" class=\"edge\"><title>0.28813373249162044&#45;&gt;0.17433690352034592</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7741.06,-360.411C7737.78,-352.216 7733.75,-342.14 7730.08,-332.955\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7733.25,-331.455 7726.28,-323.47 7726.75,-334.055 7733.25,-331.455\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.677964154280324 -->\r\n",
       "<g id=\"node197\" class=\"node\"><title>0.677964154280324</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7828.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7828.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.527623909467128&#45;&gt;0.677964154280324 -->\r\n",
       "<g id=\"edge196\" class=\"edge\"><title>0.527623909467128&#45;&gt;0.677964154280324</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7835.52,-360.055C7834.52,-352.346 7833.33,-343.027 7832.21,-334.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7835.66,-333.747 7830.92,-324.275 7828.72,-334.64 7835.66,-333.747\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.025600142969882334 -->\r\n",
       "<g id=\"node338\" class=\"node\"><title>0.025600142969882334</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7792.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7792.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.677964154280324&#45;&gt;0.025600142969882334 -->\r\n",
       "<g id=\"edge337\" class=\"edge\"><title>0.677964154280324&#45;&gt;0.025600142969882334</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7819.98,-288.055C7815.72,-279.767 7810.5,-269.618 7805.77,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7808.77,-258.599 7801.08,-251.307 7802.54,-261.801 7808.77,-258.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.11195806396668573 -->\r\n",
       "<g id=\"node340\" class=\"node\"><title>0.11195806396668573</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7864.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7864.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.677964154280324&#45;&gt;0.11195806396668573 -->\r\n",
       "<g id=\"edge339\" class=\"edge\"><title>0.677964154280324&#45;&gt;0.11195806396668573</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7837.41,-288.055C7841.67,-279.767 7846.89,-269.618 7851.62,-260.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7854.85,-261.801 7856.31,-251.307 7848.62,-258.599 7854.85,-261.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7220007598198648 -->\r\n",
       "<g id=\"node199\" class=\"node\"><title>0.7220007598198648</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7938.69\" cy=\"-306\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7938.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.14742676543745947&#45;&gt;0.7220007598198648 -->\r\n",
       "<g id=\"edge198\" class=\"edge\"><title>0.14742676543745947&#45;&gt;0.7220007598198648</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7931.12,-360.055C7932.22,-352.346 7933.55,-343.027 7934.79,-334.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7938.28,-334.67 7936.23,-324.275 7931.35,-333.68 7938.28,-334.67\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4058276219796939 -->\r\n",
       "<g id=\"node201\" class=\"node\"><title>0.4058276219796939</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8012.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8012.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6032485550052269&#45;&gt;0.4058276219796939 -->\r\n",
       "<g id=\"edge200\" class=\"edge\"><title>0.6032485550052269&#45;&gt;0.4058276219796939</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8012.69,-359.697C8012.69,-351.983 8012.69,-342.712 8012.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8016.19,-334.104 8012.69,-324.104 8009.19,-334.104 8016.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6333266950597162 -->\r\n",
       "<g id=\"node203\" class=\"node\"><title>0.6333266950597162</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8084.69\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8084.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9168065343560666&#45;&gt;0.6333266950597162 -->\r\n",
       "<g id=\"edge202\" class=\"edge\"><title>0.9168065343560666&#45;&gt;0.6333266950597162</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8084.69,-359.697C8084.69,-351.983 8084.69,-342.712 8084.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8088.19,-334.104 8084.69,-324.104 8081.19,-334.104 8088.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.01838012138259948 -->\r\n",
       "<g id=\"node205\" class=\"node\"><title>0.01838012138259948</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-306\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-302.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.39360408117314727&#45;&gt;0.01838012138259948 -->\r\n",
       "<g id=\"edge204\" class=\"edge\"><title>0.39360408117314727&#45;&gt;0.01838012138259948</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8222.69,-359.697C8222.69,-351.983 8222.69,-342.712 8222.69,-334.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8226.19,-334.104 8222.69,-324.104 8219.19,-334.104 8226.19,-334.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.23621004492542763 -->\r\n",
       "<g id=\"node342\" class=\"node\"><title>0.23621004492542763</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-230.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.01838012138259948&#45;&gt;0.23621004492542763 -->\r\n",
       "<g id=\"edge341\" class=\"edge\"><title>0.01838012138259948&#45;&gt;0.23621004492542763</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8222.69,-287.697C8222.69,-279.983 8222.69,-270.712 8222.69,-262.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8226.19,-262.104 8222.69,-252.104 8219.19,-262.104 8226.19,-262.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9018003745696193 -->\r\n",
       "<g id=\"node207\" class=\"node\"><title>0.9018003745696193</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63.6943\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63.6943\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6793962967183612&#45;&gt;0.9018003745696193 -->\r\n",
       "<g id=\"edge206\" class=\"edge\"><title>0.6793962967183612&#45;&gt;0.9018003745696193</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M78.095,-216.055C75.9795,-208.261 73.4174,-198.822 71.0443,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.3807,-189.009 68.3834,-180.275 67.6252,-190.843 74.3807,-189.009\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7910065921860657 -->\r\n",
       "<g id=\"node344\" class=\"node\"><title>0.7910065921860657</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63.6943\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63.6943\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9018003745696193&#45;&gt;0.7910065921860657 -->\r\n",
       "<g id=\"edge343\" class=\"edge\"><title>0.9018003745696193&#45;&gt;0.7910065921860657</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.6943,-143.697C63.6943,-135.983 63.6943,-126.712 63.6943,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.1944,-118.104 63.6943,-108.104 60.1944,-118.104 67.1944,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7535504360162775 -->\r\n",
       "<g id=\"node209\" class=\"node\"><title>0.7535504360162775</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"172.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"172.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6676336004425883&#45;&gt;0.7535504360162775 -->\r\n",
       "<g id=\"edge208\" class=\"edge\"><title>0.6676336004425883&#45;&gt;0.7535504360162775</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.694,-215.697C172.694,-207.983 172.694,-198.712 172.694,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.194,-190.104 172.694,-180.104 169.194,-190.104 176.194,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5765574954710164 -->\r\n",
       "<g id=\"node211\" class=\"node\"><title>0.5765574954710164</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"244.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"244.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3982833292473734&#45;&gt;0.5765574954710164 -->\r\n",
       "<g id=\"edge210\" class=\"edge\"><title>0.3982833292473734&#45;&gt;0.5765574954710164</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.059,-216.411C262.781,-208.216 258.75,-198.14 255.076,-188.955\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.246,-187.455 251.282,-179.47 251.747,-190.055 258.246,-187.455\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8186508283709101 -->\r\n",
       "<g id=\"node213\" class=\"node\"><title>0.8186508283709101</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"353.694\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"353.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.17062656189173098&#45;&gt;0.8186508283709101 -->\r\n",
       "<g id=\"edge212\" class=\"edge\"><title>0.17062656189173098&#45;&gt;0.8186508283709101</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M368.095,-216.055C365.979,-208.261 363.417,-198.822 361.044,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.381,-189.009 358.383,-180.275 357.625,-190.843 364.381,-189.009\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7881390812475115 -->\r\n",
       "<g id=\"node346\" class=\"node\"><title>0.7881390812475115</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"353.694\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"353.694\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8186508283709101&#45;&gt;0.7881390812475115 -->\r\n",
       "<g id=\"edge345\" class=\"edge\"><title>0.8186508283709101&#45;&gt;0.7881390812475115</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.694,-143.697C353.694,-135.983 353.694,-126.712 353.694,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.194,-118.104 353.694,-108.104 350.194,-118.104 357.194,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.25751880436222185 -->\r\n",
       "<g id=\"node215\" class=\"node\"><title>0.25751880436222185</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"462.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"462.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.010937608914960317&#45;&gt;0.25751880436222185 -->\r\n",
       "<g id=\"edge214\" class=\"edge\"><title>0.010937608914960317&#45;&gt;0.25751880436222185</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462.694,-215.697C462.694,-207.983 462.694,-198.712 462.694,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"466.194,-190.104 462.694,-180.104 459.194,-190.104 466.194,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.404081753909281 -->\r\n",
       "<g id=\"node217\" class=\"node\"><title>0.404081753909281</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"571.694\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"571.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7880360180574769&#45;&gt;0.404081753909281 -->\r\n",
       "<g id=\"edge216\" class=\"edge\"><title>0.7880360180574769&#45;&gt;0.404081753909281</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M558.052,-216.055C560.056,-208.261 562.483,-198.822 564.731,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"568.151,-190.832 567.252,-180.275 561.372,-189.089 568.151,-190.832\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0019848925064566147 -->\r\n",
       "<g id=\"node348\" class=\"node\"><title>0.0019848925064566147</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"498.694\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"498.694\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\r\n",
       "</g>\r\n",
       "<!-- 0.404081753909281&#45;&gt;0.0019848925064566147 -->\r\n",
       "<g id=\"edge347\" class=\"edge\"><title>0.404081753909281&#45;&gt;0.0019848925064566147</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M554.394,-144.411C544.352,-134.781 531.598,-122.552 520.83,-112.226\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"523.047,-109.503 513.407,-105.108 518.202,-114.555 523.047,-109.503\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0810641263858708 -->\r\n",
       "<g id=\"node350\" class=\"node\"><title>0.0810641263858708</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"571.694\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"571.694\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.404081753909281&#45;&gt;0.0810641263858708 -->\r\n",
       "<g id=\"edge349\" class=\"edge\"><title>0.404081753909281&#45;&gt;0.0810641263858708</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M571.694,-143.697C571.694,-135.983 571.694,-126.712 571.694,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"575.194,-118.104 571.694,-108.104 568.194,-118.104 575.194,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.18849869367548222 -->\r\n",
       "<g id=\"node352\" class=\"node\"><title>0.18849869367548222</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"643.694\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"643.694\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.404081753909281&#45;&gt;0.18849869367548222 -->\r\n",
       "<g id=\"edge351\" class=\"edge\"><title>0.404081753909281&#45;&gt;0.18849869367548222</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M588.757,-144.411C598.528,-134.911 610.901,-122.882 621.43,-112.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"623.977,-115.051 628.708,-105.57 619.098,-110.032 623.977,-115.051\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9391078462213989 -->\r\n",
       "<g id=\"node219\" class=\"node\"><title>0.9391078462213989</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"680.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"680.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zero</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6499169084921309&#45;&gt;0.9391078462213989 -->\r\n",
       "<g id=\"edge218\" class=\"edge\"><title>0.6499169084921309&#45;&gt;0.9391078462213989</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M680.694,-215.697C680.694,-207.983 680.694,-198.712 680.694,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"684.194,-190.104 680.694,-180.104 677.194,-190.104 684.194,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3666733306598935 -->\r\n",
       "<g id=\"node221\" class=\"node\"><title>0.3666733306598935</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"752.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"752.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7803270503023466&#45;&gt;0.3666733306598935 -->\r\n",
       "<g id=\"edge220\" class=\"edge\"><title>0.7803270503023466&#45;&gt;0.3666733306598935</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M752.694,-215.697C752.694,-207.983 752.694,-198.712 752.694,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"756.194,-190.104 752.694,-180.104 749.194,-190.104 756.194,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4335341979774383 -->\r\n",
       "<g id=\"node223\" class=\"node\"><title>0.4335341979774383</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"824.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"824.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7678746564177727&#45;&gt;0.4335341979774383 -->\r\n",
       "<g id=\"edge222\" class=\"edge\"><title>0.7678746564177727&#45;&gt;0.4335341979774383</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M824.694,-215.697C824.694,-207.983 824.694,-198.712 824.694,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"828.194,-190.104 824.694,-180.104 821.194,-190.104 828.194,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4974177851779029 -->\r\n",
       "<g id=\"node225\" class=\"node\"><title>0.4974177851779029</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"896.694\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"896.694\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4806058890358671&#45;&gt;0.4974177851779029 -->\r\n",
       "<g id=\"edge224\" class=\"edge\"><title>0.4806058890358671&#45;&gt;0.4974177851779029</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M896.694,-215.697C896.694,-207.983 896.694,-198.712 896.694,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"900.194,-190.104 896.694,-180.104 893.194,-190.104 900.194,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7099653848491813 -->\r\n",
       "<g id=\"node227\" class=\"node\"><title>0.7099653848491813</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1005.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1005.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.16154328920106253&#45;&gt;0.7099653848491813 -->\r\n",
       "<g id=\"edge226\" class=\"edge\"><title>0.16154328920106253&#45;&gt;0.7099653848491813</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M992.052,-216.055C994.056,-208.261 996.483,-198.822 998.731,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1002.15,-190.832 1001.25,-180.275 995.372,-189.089 1002.15,-190.832\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.31808427317270205 -->\r\n",
       "<g id=\"node354\" class=\"node\"><title>0.31808427317270205</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"969.694\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"969.694\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7099653848491813&#45;&gt;0.31808427317270205 -->\r\n",
       "<g id=\"edge353\" class=\"edge\"><title>0.7099653848491813&#45;&gt;0.31808427317270205</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M996.98,-144.055C992.717,-135.767 987.498,-125.618 982.77,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"985.767,-114.599 978.081,-107.307 979.542,-117.801 985.767,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8064089529357191 -->\r\n",
       "<g id=\"node356\" class=\"node\"><title>0.8064089529357191</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1041.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1041.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7099653848491813&#45;&gt;0.8064089529357191 -->\r\n",
       "<g id=\"edge355\" class=\"edge\"><title>0.7099653848491813&#45;&gt;0.8064089529357191</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1014.41,-144.055C1018.67,-135.767 1023.89,-125.618 1028.62,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1031.85,-117.801 1033.31,-107.307 1025.62,-114.599 1031.85,-117.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7903193276816416 -->\r\n",
       "<g id=\"node229\" class=\"node\"><title>0.7903193276816416</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1114.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1114.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.13706333104879342&#45;&gt;0.7903193276816416 -->\r\n",
       "<g id=\"edge228\" class=\"edge\"><title>0.13706333104879342&#45;&gt;0.7903193276816416</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1086.28,-216.765C1090.76,-208.283 1096.35,-197.714 1101.38,-188.197\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1104.58,-189.624 1106.16,-179.147 1098.39,-186.353 1104.58,-189.624\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9148946380022931 -->\r\n",
       "<g id=\"node231\" class=\"node\"><title>0.9148946380022931</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1190.69\" cy=\"-162\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1190.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3432875918131765&#45;&gt;0.9148946380022931 -->\r\n",
       "<g id=\"edge230\" class=\"edge\"><title>0.3432875918131765&#45;&gt;0.9148946380022931</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1190.69,-215.697C1190.69,-207.983 1190.69,-198.712 1190.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1194.19,-190.104 1190.69,-180.104 1187.19,-190.104 1194.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5657507339688949 -->\r\n",
       "<g id=\"node233\" class=\"node\"><title>0.5657507339688949</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1266.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1266.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5600210187659853&#45;&gt;0.5657507339688949 -->\r\n",
       "<g id=\"edge232\" class=\"edge\"><title>0.5600210187659853&#45;&gt;0.5657507339688949</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1265.19,-215.697C1265.41,-207.983 1265.67,-198.712 1265.92,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1269.42,-190.2 1266.21,-180.104 1262.42,-190 1269.42,-190.2\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5490867605065756 -->\r\n",
       "<g id=\"node235\" class=\"node\"><title>0.5490867605065756</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1375.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1375.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.11045969728691007&#45;&gt;0.5490867605065756 -->\r\n",
       "<g id=\"edge234\" class=\"edge\"><title>0.11045969728691007&#45;&gt;0.5490867605065756</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1414.6,-217.465C1408.46,-208.867 1400.67,-197.97 1393.69,-188.187\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1396.47,-186.065 1387.81,-179.962 1390.77,-190.133 1396.47,-186.065\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5909444840874958 -->\r\n",
       "<g id=\"node358\" class=\"node\"><title>0.5909444840874958</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1299.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1299.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5490867605065756&#45;&gt;0.5909444840874958 -->\r\n",
       "<g id=\"edge357\" class=\"edge\"><title>0.5490867605065756&#45;&gt;0.5909444840874958</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1357.68,-144.411C1347.13,-134.688 1333.69,-122.314 1322.41,-111.926\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1324.74,-109.308 1315.01,-105.108 1320,-114.457 1324.74,-109.308\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.23850917087597046 -->\r\n",
       "<g id=\"node360\" class=\"node\"><title>0.23850917087597046</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1371.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1371.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5490867605065756&#45;&gt;0.23850917087597046 -->\r\n",
       "<g id=\"edge359\" class=\"edge\"><title>0.5490867605065756&#45;&gt;0.23850917087597046</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1374.71,-143.697C1374.26,-135.983 1373.74,-126.712 1373.24,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1376.74,-117.888 1372.67,-108.104 1369.75,-118.288 1376.74,-117.888\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8374123517579857 -->\r\n",
       "<g id=\"node362\" class=\"node\"><title>0.8374123517579857</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1443.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1443.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5490867605065756&#45;&gt;0.8374123517579857 -->\r\n",
       "<g id=\"edge361\" class=\"edge\"><title>0.5490867605065756&#45;&gt;0.8374123517579857</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1391.81,-144.411C1400.95,-135.004 1412.5,-123.115 1422.38,-112.944\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1425.08,-115.182 1429.54,-105.57 1420.06,-110.305 1425.08,-115.182\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2582822122800311 -->\r\n",
       "<g id=\"node237\" class=\"node\"><title>0.2582822122800311</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1520.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1520.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44720058825849573&#45;&gt;0.2582822122800311 -->\r\n",
       "<g id=\"edge236\" class=\"edge\"><title>0.44720058825849573&#45;&gt;0.2582822122800311</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1542.06,-216.411C1538.83,-208.335 1534.87,-198.431 1531.24,-189.355\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1534.44,-187.941 1527.48,-179.956 1527.94,-190.541 1534.44,-187.941\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7229752900587973 -->\r\n",
       "<g id=\"node364\" class=\"node\"><title>0.7229752900587973</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1519.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1519.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2582822122800311&#45;&gt;0.7229752900587973 -->\r\n",
       "<g id=\"edge363\" class=\"edge\"><title>0.2582822122800311&#45;&gt;0.7229752900587973</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1520.45,-143.697C1520.34,-135.983 1520.2,-126.712 1520.08,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1523.58,-118.053 1519.94,-108.104 1516.58,-118.153 1523.58,-118.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5565851515619594 -->\r\n",
       "<g id=\"node366\" class=\"node\"><title>0.5565851515619594</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1591.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1591.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2582822122800311&#45;&gt;0.5565851515619594 -->\r\n",
       "<g id=\"edge365\" class=\"edge\"><title>0.2582822122800311&#45;&gt;0.5565851515619594</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1537.52,-144.411C1547.16,-134.911 1559.36,-122.882 1569.74,-112.646\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1572.25,-115.084 1576.92,-105.57 1567.34,-110.099 1572.25,-115.084\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.06178115998200573 -->\r\n",
       "<g id=\"node239\" class=\"node\"><title>0.06178115998200573</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1665.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1665.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.660795539797365&#45;&gt;0.06178115998200573 -->\r\n",
       "<g id=\"edge238\" class=\"edge\"><title>0.660795539797365&#45;&gt;0.06178115998200573</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1673.27,-216.055C1672.17,-208.346 1670.84,-199.027 1669.6,-190.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1673.04,-189.68 1668.16,-180.275 1666.11,-190.67 1673.04,-189.68\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3477061322745093 -->\r\n",
       "<g id=\"node368\" class=\"node\"><title>0.3477061322745093</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1666.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1666.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.06178115998200573&#45;&gt;0.3477061322745093 -->\r\n",
       "<g id=\"edge367\" class=\"edge\"><title>0.06178115998200573&#45;&gt;0.3477061322745093</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1665.94,-143.697C1666.05,-135.983 1666.18,-126.712 1666.31,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1669.81,-118.153 1666.45,-108.104 1662.81,-118.053 1669.81,-118.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7587218037786896 -->\r\n",
       "<g id=\"node241\" class=\"node\"><title>0.7587218037786896</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1774.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1774.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7037818392500385&#45;&gt;0.7587218037786896 -->\r\n",
       "<g id=\"edge240\" class=\"edge\"><title>0.7037818392500385&#45;&gt;0.7587218037786896</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1767.87,-216.055C1768.86,-208.346 1770.06,-199.027 1771.18,-190.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1774.67,-190.64 1772.47,-180.275 1767.73,-189.747 1774.67,-190.64\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6573250295180311 -->\r\n",
       "<g id=\"node243\" class=\"node\"><title>0.6573250295180311</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1848.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1848.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9815937077759338&#45;&gt;0.6573250295180311 -->\r\n",
       "<g id=\"edge242\" class=\"edge\"><title>0.9815937077759338&#45;&gt;0.6573250295180311</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1863.85,-216.055C1861.59,-208.145 1858.85,-198.54 1856.32,-189.688\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1859.6,-188.443 1853.49,-179.789 1852.87,-190.366 1859.6,-188.443\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.27559654456181804 -->\r\n",
       "<g id=\"node245\" class=\"node\"><title>0.27559654456181804</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1958.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1958.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8330410674367088&#45;&gt;0.27559654456181804 -->\r\n",
       "<g id=\"edge244\" class=\"edge\"><title>0.8330410674367088&#45;&gt;0.27559654456181804</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1973.85,-216.055C1971.63,-208.261 1968.93,-198.822 1966.43,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1969.74,-188.929 1963.63,-180.275 1963.01,-190.852 1969.74,-188.929\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.011550639027931853 -->\r\n",
       "<g id=\"node370\" class=\"node\"><title>0.011550639027931853</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1922.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1922.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.27559654456181804&#45;&gt;0.011550639027931853 -->\r\n",
       "<g id=\"edge369\" class=\"edge\"><title>0.27559654456181804&#45;&gt;0.011550639027931853</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1949.98,-144.055C1945.72,-135.767 1940.5,-125.618 1935.77,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1938.77,-114.599 1931.08,-107.307 1932.54,-117.801 1938.77,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.507622069224466 -->\r\n",
       "<g id=\"node372\" class=\"node\"><title>0.507622069224466</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1994.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1994.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.27559654456181804&#45;&gt;0.507622069224466 -->\r\n",
       "<g id=\"edge371\" class=\"edge\"><title>0.27559654456181804&#45;&gt;0.507622069224466</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1967.41,-144.055C1971.67,-135.767 1976.89,-125.618 1981.62,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1984.85,-117.801 1986.31,-107.307 1978.62,-114.599 1984.85,-117.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5540787608063638 -->\r\n",
       "<g id=\"node247\" class=\"node\"><title>0.5540787608063638</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2068.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2068.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.41731988881946147&#45;&gt;0.5540787608063638 -->\r\n",
       "<g id=\"edge246\" class=\"edge\"><title>0.41731988881946147&#45;&gt;0.5540787608063638</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2069.45,-215.697C2069.34,-207.983 2069.2,-198.712 2069.08,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2072.58,-190.053 2068.94,-180.104 2065.58,-190.153 2072.58,-190.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.036424609576737876 -->\r\n",
       "<g id=\"node249\" class=\"node\"><title>0.036424609576737876</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2143.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2143.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6589375052403923&#45;&gt;0.036424609576737876 -->\r\n",
       "<g id=\"edge248\" class=\"edge\"><title>0.6589375052403923&#45;&gt;0.036424609576737876</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2142.94,-215.697C2143.05,-207.983 2143.18,-198.712 2143.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2146.81,-190.153 2143.45,-180.104 2139.81,-190.053 2146.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5136002536262376 -->\r\n",
       "<g id=\"node251\" class=\"node\"><title>0.5136002536262376</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2217.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2217.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7425605747809193&#45;&gt;0.5136002536262376 -->\r\n",
       "<g id=\"edge250\" class=\"edge\"><title>0.7425605747809193&#45;&gt;0.5136002536262376</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2216.94,-215.697C2217.05,-207.983 2217.18,-198.712 2217.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2220.81,-190.153 2217.45,-180.104 2213.81,-190.053 2220.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1488861516629021 -->\r\n",
       "<g id=\"node253\" class=\"node\"><title>0.1488861516629021</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2289.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2289.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8667050231079826&#45;&gt;0.1488861516629021 -->\r\n",
       "<g id=\"edge252\" class=\"edge\"><title>0.8667050231079826&#45;&gt;0.1488861516629021</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2291.95,-215.697C2291.62,-207.983 2291.22,-198.712 2290.86,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2294.35,-189.945 2290.43,-180.104 2287.36,-190.245 2294.35,-189.945\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24386456321146888 -->\r\n",
       "<g id=\"node255\" class=\"node\"><title>0.24386456321146888</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2365.69\" cy=\"-162\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2365.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6640136068709913&#45;&gt;0.24386456321146888 -->\r\n",
       "<g id=\"edge254\" class=\"edge\"><title>0.6640136068709913&#45;&gt;0.24386456321146888</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2367.2,-215.697C2366.98,-207.983 2366.71,-198.712 2366.47,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2369.97,-190 2366.18,-180.104 2362.97,-190.2 2369.97,-190\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5041006542612775 -->\r\n",
       "<g id=\"node257\" class=\"node\"><title>0.5041006542612775</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2441.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2441.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4087297087584484&#45;&gt;0.5041006542612775 -->\r\n",
       "<g id=\"edge256\" class=\"edge\"><title>0.4087297087584484&#45;&gt;0.5041006542612775</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2440.94,-215.697C2441.05,-207.983 2441.18,-198.712 2441.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2444.81,-190.153 2441.45,-180.104 2437.81,-190.053 2444.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6245603021401877 -->\r\n",
       "<g id=\"node259\" class=\"node\"><title>0.6245603021401877</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2550.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2550.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.39433255386287647&#45;&gt;0.6245603021401877 -->\r\n",
       "<g id=\"edge258\" class=\"edge\"><title>0.39433255386287647&#45;&gt;0.6245603021401877</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2535.54,-216.055C2537.76,-208.261 2540.46,-198.822 2542.96,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2546.38,-190.852 2545.76,-180.275 2539.65,-188.929 2546.38,-190.852\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5944378539111139 -->\r\n",
       "<g id=\"node374\" class=\"node\"><title>0.5944378539111139</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2514.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2514.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6245603021401877&#45;&gt;0.5944378539111139 -->\r\n",
       "<g id=\"edge373\" class=\"edge\"><title>0.6245603021401877&#45;&gt;0.5944378539111139</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2541.98,-144.055C2537.72,-135.767 2532.5,-125.618 2527.77,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2530.77,-114.599 2523.08,-107.307 2524.54,-117.801 2530.77,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6999692943748069 -->\r\n",
       "<g id=\"node376\" class=\"node\"><title>0.6999692943748069</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2586.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2586.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6245603021401877&#45;&gt;0.6999692943748069 -->\r\n",
       "<g id=\"edge375\" class=\"edge\"><title>0.6245603021401877&#45;&gt;0.6999692943748069</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2559.41,-144.055C2563.67,-135.767 2568.89,-125.618 2573.62,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2576.85,-117.801 2578.31,-107.307 2570.62,-114.599 2576.85,-117.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5860451361889607 -->\r\n",
       "<g id=\"node261\" class=\"node\"><title>0.5860451361889607</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2659.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2659.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8521123338461256&#45;&gt;0.5860451361889607 -->\r\n",
       "<g id=\"edge260\" class=\"edge\"><title>0.8521123338461256&#45;&gt;0.5860451361889607</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2659.69,-215.697C2659.69,-207.983 2659.69,-198.712 2659.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2663.19,-190.104 2659.69,-180.104 2656.19,-190.104 2663.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.829269679008915 -->\r\n",
       "<g id=\"node263\" class=\"node\"><title>0.829269679008915</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2731.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2731.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8769294764034938&#45;&gt;0.829269679008915 -->\r\n",
       "<g id=\"edge262\" class=\"edge\"><title>0.8769294764034938&#45;&gt;0.829269679008915</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2731.69,-215.697C2731.69,-207.983 2731.69,-198.712 2731.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2735.19,-190.104 2731.69,-180.104 2728.19,-190.104 2735.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.27142387466335094 -->\r\n",
       "<g id=\"node265\" class=\"node\"><title>0.27142387466335094</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2805.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2805.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7968775526266042&#45;&gt;0.27142387466335094 -->\r\n",
       "<g id=\"edge264\" class=\"edge\"><title>0.7968775526266042&#45;&gt;0.27142387466335094</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2812.52,-216.055C2811.52,-208.346 2810.33,-199.027 2809.21,-190.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2812.66,-189.747 2807.92,-180.275 2805.72,-190.64 2812.66,-189.747\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6138345512217658 -->\r\n",
       "<g id=\"node267\" class=\"node\"><title>0.6138345512217658</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2915.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2915.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1381350271565699&#45;&gt;0.6138345512217658 -->\r\n",
       "<g id=\"edge266\" class=\"edge\"><title>0.1381350271565699&#45;&gt;0.6138345512217658</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2901.29,-216.055C2903.41,-208.261 2905.97,-198.822 2908.34,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2911.76,-190.843 2911.01,-180.275 2905.01,-189.009 2911.76,-190.843\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4328420583163032 -->\r\n",
       "<g id=\"node378\" class=\"node\"><title>0.4328420583163032</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2879.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2879.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6138345512217658&#45;&gt;0.4328420583163032 -->\r\n",
       "<g id=\"edge377\" class=\"edge\"><title>0.6138345512217658&#45;&gt;0.4328420583163032</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2906.98,-144.055C2902.72,-135.767 2897.5,-125.618 2892.77,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2895.77,-114.599 2888.08,-107.307 2889.54,-117.801 2895.77,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6887553176772824 -->\r\n",
       "<g id=\"node380\" class=\"node\"><title>0.6887553176772824</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2951.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2951.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6138345512217658&#45;&gt;0.6887553176772824 -->\r\n",
       "<g id=\"edge379\" class=\"edge\"><title>0.6138345512217658&#45;&gt;0.6887553176772824</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2924.41,-144.055C2928.67,-135.767 2933.89,-125.618 2938.62,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2941.85,-117.801 2943.31,-107.307 2935.62,-114.599 2941.85,-117.801\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9189488753178451 -->\r\n",
       "<g id=\"node269\" class=\"node\"><title>0.9189488753178451</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3024.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3024.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.42264446244682263&#45;&gt;0.9189488753178451 -->\r\n",
       "<g id=\"edge268\" class=\"edge\"><title>0.42264446244682263&#45;&gt;0.9189488753178451</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3003.33,-216.411C3006.61,-208.216 3010.64,-198.14 3014.31,-188.955\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3017.64,-190.055 3018.11,-179.47 3011.14,-187.455 3017.64,-190.055\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9503986377611082 -->\r\n",
       "<g id=\"node271\" class=\"node\"><title>0.9503986377611082</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3096.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3096.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.30237319061973733&#45;&gt;0.9503986377611082 -->\r\n",
       "<g id=\"edge270\" class=\"edge\"><title>0.30237319061973733&#45;&gt;0.9503986377611082</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3096.69,-215.697C3096.69,-207.983 3096.69,-198.712 3096.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3100.19,-190.104 3096.69,-180.104 3093.19,-190.104 3100.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7535546425424102 -->\r\n",
       "<g id=\"node273\" class=\"node\"><title>0.7535546425424102</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3168.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3168.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.21568019283365125&#45;&gt;0.7535546425424102 -->\r\n",
       "<g id=\"edge272\" class=\"edge\"><title>0.21568019283365125&#45;&gt;0.7535546425424102</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3168.69,-215.697C3168.69,-207.983 3168.69,-198.712 3168.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3172.19,-190.104 3168.69,-180.104 3165.19,-190.104 3172.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8456054259551452 -->\r\n",
       "<g id=\"node275\" class=\"node\"><title>0.8456054259551452</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3240.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3240.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9786072757870522&#45;&gt;0.8456054259551452 -->\r\n",
       "<g id=\"edge274\" class=\"edge\"><title>0.9786072757870522&#45;&gt;0.8456054259551452</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3240.69,-215.697C3240.69,-207.983 3240.69,-198.712 3240.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3244.19,-190.104 3240.69,-180.104 3237.19,-190.104 3244.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9659281057910581 -->\r\n",
       "<g id=\"node277\" class=\"node\"><title>0.9659281057910581</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3312.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3312.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.24095904597997164&#45;&gt;0.9659281057910581 -->\r\n",
       "<g id=\"edge276\" class=\"edge\"><title>0.24095904597997164&#45;&gt;0.9659281057910581</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3313.45,-215.697C3313.34,-207.983 3313.2,-198.712 3313.08,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3316.58,-190.053 3312.94,-180.104 3309.58,-190.153 3316.58,-190.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.55645450931247 -->\r\n",
       "<g id=\"node279\" class=\"node\"><title>0.55645450931247</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3386.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3386.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.25085197028462547&#45;&gt;0.55645450931247 -->\r\n",
       "<g id=\"edge278\" class=\"edge\"><title>0.25085197028462547&#45;&gt;0.55645450931247</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3386.69,-215.697C3386.69,-207.983 3386.69,-198.712 3386.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3390.19,-190.104 3386.69,-180.104 3383.19,-190.104 3390.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9714735480257036 -->\r\n",
       "<g id=\"node281\" class=\"node\"><title>0.9714735480257036</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3460.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3460.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2810484131503791&#45;&gt;0.9714735480257036 -->\r\n",
       "<g id=\"edge280\" class=\"edge\"><title>0.2810484131503791&#45;&gt;0.9714735480257036</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3459.94,-215.697C3460.05,-207.983 3460.18,-198.712 3460.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3463.81,-190.153 3460.45,-180.104 3456.81,-190.053 3463.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4952503602016144 -->\r\n",
       "<g id=\"node283\" class=\"node\"><title>0.4952503602016144</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3532.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3532.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.46616197618207156&#45;&gt;0.4952503602016144 -->\r\n",
       "<g id=\"edge282\" class=\"edge\"><title>0.46616197618207156&#45;&gt;0.4952503602016144</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3532.69,-215.697C3532.69,-207.983 3532.69,-198.712 3532.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3536.19,-190.104 3532.69,-180.104 3529.19,-190.104 3536.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9704430873518489 -->\r\n",
       "<g id=\"node285\" class=\"node\"><title>0.9704430873518489</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3604.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3604.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.23556982151038042&#45;&gt;0.9704430873518489 -->\r\n",
       "<g id=\"edge284\" class=\"edge\"><title>0.23556982151038042&#45;&gt;0.9704430873518489</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3604.69,-215.697C3604.69,-207.983 3604.69,-198.712 3604.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3608.19,-190.104 3604.69,-180.104 3601.19,-190.104 3608.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.932424155403006 -->\r\n",
       "<g id=\"node287\" class=\"node\"><title>0.932424155403006</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3678.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3678.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6142973186856004&#45;&gt;0.932424155403006 -->\r\n",
       "<g id=\"edge286\" class=\"edge\"><title>0.6142973186856004&#45;&gt;0.932424155403006</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3696.13,-216.055C3693.5,-208.059 3690.3,-198.331 3687.37,-189.4\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3690.66,-188.197 3684.21,-179.789 3684.01,-190.382 3690.66,-188.197\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.17893496059118452 -->\r\n",
       "<g id=\"node289\" class=\"node\"><title>0.17893496059118452</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3788.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3788.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.25449535920259625&#45;&gt;0.17893496059118452 -->\r\n",
       "<g id=\"edge288\" class=\"edge\"><title>0.25449535920259625&#45;&gt;0.17893496059118452</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3795.52,-216.055C3794.52,-208.346 3793.33,-199.027 3792.21,-190.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3795.66,-189.747 3790.92,-180.275 3788.72,-190.64 3795.66,-189.747\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1333950365189146 -->\r\n",
       "<g id=\"node382\" class=\"node\"><title>0.1333950365189146</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3788.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3788.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.17893496059118452&#45;&gt;0.1333950365189146 -->\r\n",
       "<g id=\"edge381\" class=\"edge\"><title>0.17893496059118452&#45;&gt;0.1333950365189146</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3788.69,-143.697C3788.69,-135.983 3788.69,-126.712 3788.69,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3792.19,-118.104 3788.69,-108.104 3785.19,-118.104 3792.19,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3205184737843053 -->\r\n",
       "<g id=\"node291\" class=\"node\"><title>0.3205184737843053</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3897.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3897.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9182927983007992&#45;&gt;0.3205184737843053 -->\r\n",
       "<g id=\"edge290\" class=\"edge\"><title>0.9182927983007992&#45;&gt;0.3205184737843053</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3884.05,-216.055C3886.09,-208.145 3888.56,-198.54 3890.83,-189.688\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3894.28,-190.346 3893.38,-179.789 3887.5,-188.602 3894.28,-190.346\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9423821281659954 -->\r\n",
       "<g id=\"node293\" class=\"node\"><title>0.9423821281659954</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4006.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4006.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings1</text>\r\n",
       "</g>\r\n",
       "<!-- 0.32492317609440335&#45;&gt;0.9423821281659954 -->\r\n",
       "<g id=\"edge292\" class=\"edge\"><title>0.32492317609440335&#45;&gt;0.9423821281659954</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4022.61,-216.055C4020.27,-208.261 4017.44,-198.822 4014.82,-190.079\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4018.1,-188.848 4011.88,-180.275 4011.4,-190.859 4018.1,-188.848\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3088605897746505 -->\r\n",
       "<g id=\"node384\" class=\"node\"><title>0.3088605897746505</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3970.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3970.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">h</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9423821281659954&#45;&gt;0.3088605897746505 -->\r\n",
       "<g id=\"edge383\" class=\"edge\"><title>0.9423821281659954&#45;&gt;0.3088605897746505</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3997.98,-144.055C3993.72,-135.767 3988.5,-125.618 3983.77,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3986.77,-114.599 3979.08,-107.307 3980.54,-117.801 3986.77,-114.599\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9494483681429924 -->\r\n",
       "<g id=\"node386\" class=\"node\"><title>0.9494483681429924</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4043.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4043.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9423821281659954&#45;&gt;0.9494483681429924 -->\r\n",
       "<g id=\"edge385\" class=\"edge\"><title>0.9423821281659954&#45;&gt;0.9494483681429924</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4015.65,-144.055C4020.03,-135.767 4025.4,-125.618 4030.26,-116.424\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4033.5,-117.784 4035.07,-107.307 4027.31,-114.512 4033.5,-117.784\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6973225433937442 -->\r\n",
       "<g id=\"node295\" class=\"node\"><title>0.6973225433937442</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4119.69\" cy=\"-162\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4119.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9557055937061032&#45;&gt;0.6973225433937442 -->\r\n",
       "<g id=\"edge294\" class=\"edge\"><title>0.9557055937061032&#45;&gt;0.6973225433937442</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4121.2,-215.697C4120.98,-207.983 4120.71,-198.712 4120.47,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4123.97,-190 4120.18,-180.104 4116.97,-190.2 4123.97,-190\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7534766986867801 -->\r\n",
       "<g id=\"node297\" class=\"node\"><title>0.7534766986867801</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4195.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4195.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4220792418873872&#45;&gt;0.7534766986867801 -->\r\n",
       "<g id=\"edge296\" class=\"edge\"><title>0.4220792418873872&#45;&gt;0.7534766986867801</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4194.94,-215.697C4195.05,-207.983 4195.18,-198.712 4195.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4198.81,-190.153 4195.45,-180.104 4191.81,-190.053 4198.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7653856485290642 -->\r\n",
       "<g id=\"node299\" class=\"node\"><title>0.7653856485290642</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4271.69\" cy=\"-162\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4271.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8824816748847272&#45;&gt;0.7653856485290642 -->\r\n",
       "<g id=\"edge298\" class=\"edge\"><title>0.8824816748847272&#45;&gt;0.7653856485290642</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4271.69,-215.697C4271.69,-207.983 4271.69,-198.712 4271.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4275.19,-190.104 4271.69,-180.104 4268.19,-190.104 4275.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.368140909517788 -->\r\n",
       "<g id=\"node301\" class=\"node\"><title>0.368140909517788</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4347.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4347.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.16025820144932845&#45;&gt;0.368140909517788 -->\r\n",
       "<g id=\"edge300\" class=\"edge\"><title>0.16025820144932845&#45;&gt;0.368140909517788</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4346.19,-215.697C4346.41,-207.983 4346.67,-198.712 4346.92,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4350.42,-190.2 4347.21,-180.104 4343.42,-190 4350.42,-190.2\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.00721042537306027 -->\r\n",
       "<g id=\"node303\" class=\"node\"><title>0.00721042537306027</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4419.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4419.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6731444134173338&#45;&gt;0.00721042537306027 -->\r\n",
       "<g id=\"edge302\" class=\"edge\"><title>0.6731444134173338&#45;&gt;0.00721042537306027</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4418.94,-215.697C4419.05,-207.983 4419.18,-198.712 4419.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4422.81,-190.153 4419.45,-180.104 4415.81,-190.053 4422.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.46002171753366994 -->\r\n",
       "<g id=\"node305\" class=\"node\"><title>0.46002171753366994</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4491.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4491.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4446705263565319&#45;&gt;0.46002171753366994 -->\r\n",
       "<g id=\"edge304\" class=\"edge\"><title>0.4446705263565319&#45;&gt;0.46002171753366994</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4492.45,-215.697C4492.34,-207.983 4492.2,-198.712 4492.08,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4495.58,-190.053 4491.94,-180.104 4488.58,-190.153 4495.58,-190.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5551723044704161 -->\r\n",
       "<g id=\"node307\" class=\"node\"><title>0.5551723044704161</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4565.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4565.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2536574865628032&#45;&gt;0.5551723044704161 -->\r\n",
       "<g id=\"edge306\" class=\"edge\"><title>0.2536574865628032&#45;&gt;0.5551723044704161</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4566.45,-215.697C4566.34,-207.983 4566.2,-198.712 4566.08,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4569.58,-190.053 4565.94,-180.104 4562.58,-190.153 4569.58,-190.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3840384756842604 -->\r\n",
       "<g id=\"node309\" class=\"node\"><title>0.3840384756842604</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4639.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4639.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.11145777283486735&#45;&gt;0.3840384756842604 -->\r\n",
       "<g id=\"edge308\" class=\"edge\"><title>0.11145777283486735&#45;&gt;0.3840384756842604</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4638.94,-215.697C4639.05,-207.983 4639.18,-198.712 4639.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4642.81,-190.153 4639.45,-180.104 4635.81,-190.053 4642.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1473469896596098 -->\r\n",
       "<g id=\"node311\" class=\"node\"><title>0.1473469896596098</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4713.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4713.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.32950187075328785&#45;&gt;0.1473469896596098 -->\r\n",
       "<g id=\"edge310\" class=\"edge\"><title>0.32950187075328785&#45;&gt;0.1473469896596098</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4713.69,-215.697C4713.69,-207.983 4713.69,-198.712 4713.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4717.19,-190.104 4713.69,-180.104 4710.19,-190.104 4717.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.06072085959053908 -->\r\n",
       "<g id=\"node313\" class=\"node\"><title>0.06072085959053908</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4787.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4787.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.20368201692623256&#45;&gt;0.06072085959053908 -->\r\n",
       "<g id=\"edge312\" class=\"edge\"><title>0.20368201692623256&#45;&gt;0.06072085959053908</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4786.94,-215.697C4787.05,-207.983 4787.18,-198.712 4787.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4790.81,-190.153 4787.45,-180.104 4783.81,-190.053 4790.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.1253478349990168 -->\r\n",
       "<g id=\"node315\" class=\"node\"><title>0.1253478349990168</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4859.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4859.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.31068509057140015&#45;&gt;0.1253478349990168 -->\r\n",
       "<g id=\"edge314\" class=\"edge\"><title>0.31068509057140015&#45;&gt;0.1253478349990168</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4858.94,-215.697C4859.05,-207.983 4859.18,-198.712 4859.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4862.81,-190.153 4859.45,-180.104 4855.81,-190.053 4862.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2844399792745168 -->\r\n",
       "<g id=\"node317\" class=\"node\"><title>0.2844399792745168</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4931.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4931.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6625009551009192&#45;&gt;0.2844399792745168 -->\r\n",
       "<g id=\"edge316\" class=\"edge\"><title>0.6625009551009192&#45;&gt;0.2844399792745168</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4930.94,-215.697C4931.05,-207.983 4931.18,-198.712 4931.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4934.81,-190.153 4931.45,-180.104 4927.81,-190.053 4934.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3830134634100748 -->\r\n",
       "<g id=\"node319\" class=\"node\"><title>0.3830134634100748</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5003.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5003.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.44313654468022057&#45;&gt;0.3830134634100748 -->\r\n",
       "<g id=\"edge318\" class=\"edge\"><title>0.44313654468022057&#45;&gt;0.3830134634100748</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5002.94,-215.697C5003.05,-207.983 5003.18,-198.712 5003.31,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5006.81,-190.153 5003.45,-180.104 4999.81,-190.053 5006.81,-190.153\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.158593359627494 -->\r\n",
       "<g id=\"node321\" class=\"node\"><title>0.158593359627494</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5075.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5075.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.21983613269807334&#45;&gt;0.158593359627494 -->\r\n",
       "<g id=\"edge320\" class=\"edge\"><title>0.21983613269807334&#45;&gt;0.158593359627494</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5075.69,-215.697C5075.69,-207.983 5075.69,-198.712 5075.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5079.19,-190.104 5075.69,-180.104 5072.19,-190.104 5079.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.4458987523069665 -->\r\n",
       "<g id=\"node323\" class=\"node\"><title>0.4458987523069665</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5651.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5651.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3809222976402993&#45;&gt;0.4458987523069665 -->\r\n",
       "<g id=\"edge322\" class=\"edge\"><title>0.3809222976402993&#45;&gt;0.4458987523069665</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5662.31,-216.055C5660.76,-208.346 5658.9,-199.027 5657.17,-190.364\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5660.54,-189.395 5655.15,-180.275 5653.68,-190.768 5660.54,-189.395\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8174666176331516 -->\r\n",
       "<g id=\"node325\" class=\"node\"><title>0.8174666176331516</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5752.69\" cy=\"-162\" rx=\"55.7903\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5752.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">VegetationR</text>\r\n",
       "</g>\r\n",
       "<!-- 0.20040879530889555&#45;&gt;0.8174666176331516 -->\r\n",
       "<g id=\"edge324\" class=\"edge\"><title>0.20040879530889555&#45;&gt;0.8174666176331516</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5747.42,-215.697C5748.2,-207.983 5749.12,-198.712 5749.98,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5753.47,-190.403 5750.98,-180.104 5746.51,-189.706 5753.47,-190.403\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.06719812574927997 -->\r\n",
       "<g id=\"node388\" class=\"node\"><title>0.06719812574927997</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5752.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5752.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8174666176331516&#45;&gt;0.06719812574927997 -->\r\n",
       "<g id=\"edge387\" class=\"edge\"><title>0.8174666176331516&#45;&gt;0.06719812574927997</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5752.69,-143.697C5752.69,-135.983 5752.69,-126.712 5752.69,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5756.19,-118.104 5752.69,-108.104 5749.19,-118.104 5756.19,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7078111699012979 -->\r\n",
       "<g id=\"node327\" class=\"node\"><title>0.7078111699012979</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5951.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5951.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5815881942574035&#45;&gt;0.7078111699012979 -->\r\n",
       "<g id=\"edge326\" class=\"edge\"><title>0.5815881942574035&#45;&gt;0.7078111699012979</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5951.69,-215.697C5951.69,-207.983 5951.69,-198.712 5951.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5955.19,-190.104 5951.69,-180.104 5948.19,-190.104 5955.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.39152850349951296 -->\r\n",
       "<g id=\"node329\" class=\"node\"><title>0.39152850349951296</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6023.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6023.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9743843847178872&#45;&gt;0.39152850349951296 -->\r\n",
       "<g id=\"edge328\" class=\"edge\"><title>0.9743843847178872&#45;&gt;0.39152850349951296</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6023.69,-215.697C6023.69,-207.983 6023.69,-198.712 6023.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6027.19,-190.104 6023.69,-180.104 6020.19,-190.104 6027.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.974229461026222 -->\r\n",
       "<g id=\"node331\" class=\"node\"><title>0.974229461026222</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6483.69\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6483.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.317425748234474&#45;&gt;0.974229461026222 -->\r\n",
       "<g id=\"edge330\" class=\"edge\"><title>0.317425748234474&#45;&gt;0.974229461026222</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6484.45,-215.697C6484.34,-207.983 6484.2,-198.712 6484.08,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6487.58,-190.053 6483.94,-180.104 6480.58,-190.153 6487.58,-190.053\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.38644744306479506 -->\r\n",
       "<g id=\"node333\" class=\"node\"><title>0.38644744306479506</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6557.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6557.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7615186875048336&#45;&gt;0.38644744306479506 -->\r\n",
       "<g id=\"edge332\" class=\"edge\"><title>0.7615186875048336&#45;&gt;0.38644744306479506</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6557.69,-215.697C6557.69,-207.983 6557.69,-198.712 6557.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6561.19,-190.104 6557.69,-180.104 6554.19,-190.104 6561.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.13357836562633796 -->\r\n",
       "<g id=\"node335\" class=\"node\"><title>0.13357836562633796</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6629.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6629.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zero</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9250304866711132&#45;&gt;0.13357836562633796 -->\r\n",
       "<g id=\"edge334\" class=\"edge\"><title>0.9250304866711132&#45;&gt;0.13357836562633796</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6629.69,-215.697C6629.69,-207.983 6629.69,-198.712 6629.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6633.19,-190.104 6629.69,-180.104 6626.19,-190.104 6633.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2900008809908192 -->\r\n",
       "<g id=\"node337\" class=\"node\"><title>0.2900008809908192</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2684080686997762&#45;&gt;0.2900008809908192 -->\r\n",
       "<g id=\"edge336\" class=\"edge\"><title>0.2684080686997762&#45;&gt;0.2900008809908192</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6944.69,-215.697C6944.69,-207.983 6944.69,-198.712 6944.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6948.19,-190.104 6944.69,-180.104 6941.19,-190.104 6948.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3299885464433576 -->\r\n",
       "<g id=\"node390\" class=\"node\"><title>0.3299885464433576</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\r\n",
       "</g>\r\n",
       "<!-- 0.2900008809908192&#45;&gt;0.3299885464433576 -->\r\n",
       "<g id=\"edge389\" class=\"edge\"><title>0.2900008809908192&#45;&gt;0.3299885464433576</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6944.69,-143.697C6944.69,-135.983 6944.69,-126.712 6944.69,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6948.19,-118.104 6944.69,-108.104 6941.19,-118.104 6948.19,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.24759520987840977 -->\r\n",
       "<g id=\"node339\" class=\"node\"><title>0.24759520987840977</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7792.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7792.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.025600142969882334&#45;&gt;0.24759520987840977 -->\r\n",
       "<g id=\"edge338\" class=\"edge\"><title>0.025600142969882334&#45;&gt;0.24759520987840977</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7792.69,-215.697C7792.69,-207.983 7792.69,-198.712 7792.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7796.19,-190.104 7792.69,-180.104 7789.19,-190.104 7796.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2732302349536645 -->\r\n",
       "<g id=\"node341\" class=\"node\"><title>0.2732302349536645</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7864.69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"7864.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zero</text>\r\n",
       "</g>\r\n",
       "<!-- 0.11195806396668573&#45;&gt;0.2732302349536645 -->\r\n",
       "<g id=\"edge340\" class=\"edge\"><title>0.11195806396668573&#45;&gt;0.2732302349536645</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7864.69,-215.697C7864.69,-207.983 7864.69,-198.712 7864.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7868.19,-190.104 7864.69,-180.104 7861.19,-190.104 7868.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.320504870082315 -->\r\n",
       "<g id=\"node343\" class=\"node\"><title>0.320504870082315</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-162\" rx=\"63.8893\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Surroundings2</text>\r\n",
       "</g>\r\n",
       "<!-- 0.23621004492542763&#45;&gt;0.320504870082315 -->\r\n",
       "<g id=\"edge342\" class=\"edge\"><title>0.23621004492542763&#45;&gt;0.320504870082315</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8222.69,-215.697C8222.69,-207.983 8222.69,-198.712 8222.69,-190.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8226.19,-190.104 8222.69,-180.104 8219.19,-190.104 8226.19,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6180641213886487 -->\r\n",
       "<g id=\"node392\" class=\"node\"><title>0.6180641213886487</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\r\n",
       "</g>\r\n",
       "<!-- 0.320504870082315&#45;&gt;0.6180641213886487 -->\r\n",
       "<g id=\"edge391\" class=\"edge\"><title>0.320504870082315&#45;&gt;0.6180641213886487</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8222.69,-143.697C8222.69,-135.983 8222.69,-126.712 8222.69,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8226.19,-118.104 8222.69,-108.104 8219.19,-118.104 8226.19,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.13232802451605374 -->\r\n",
       "<g id=\"node345\" class=\"node\"><title>0.13232802451605374</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63.6943\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63.6943\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7910065921860657&#45;&gt;0.13232802451605374 -->\r\n",
       "<g id=\"edge344\" class=\"edge\"><title>0.7910065921860657&#45;&gt;0.13232802451605374</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.6943,-71.6966C63.6943,-63.9827 63.6943,-54.7125 63.6943,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.1944,-46.1043 63.6943,-36.1043 60.1944,-46.1044 67.1944,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7589112931254508 -->\r\n",
       "<g id=\"node347\" class=\"node\"><title>0.7589112931254508</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"353.694\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"353.694\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7881390812475115&#45;&gt;0.7589112931254508 -->\r\n",
       "<g id=\"edge346\" class=\"edge\"><title>0.7881390812475115&#45;&gt;0.7589112931254508</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.694,-71.6966C353.694,-63.9827 353.694,-54.7125 353.694,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.194,-46.1043 353.694,-36.1043 350.194,-46.1044 357.194,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.20265826916681018 -->\r\n",
       "<g id=\"node349\" class=\"node\"><title>0.20265826916681018</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"497.694\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"497.694\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0019848925064566147&#45;&gt;0.20265826916681018 -->\r\n",
       "<g id=\"edge348\" class=\"edge\"><title>0.0019848925064566147&#45;&gt;0.20265826916681018</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M498.447,-71.6966C498.337,-63.9827 498.205,-54.7125 498.082,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"501.581,-46.0533 497.939,-36.1043 494.582,-46.1533 501.581,-46.0533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.308510794389959 -->\r\n",
       "<g id=\"node351\" class=\"node\"><title>0.308510794389959</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"571.694\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"571.694\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.0810641263858708&#45;&gt;0.308510794389959 -->\r\n",
       "<g id=\"edge350\" class=\"edge\"><title>0.0810641263858708&#45;&gt;0.308510794389959</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M571.694,-71.6966C571.694,-63.9827 571.694,-54.7125 571.694,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"575.194,-46.1043 571.694,-36.1043 568.194,-46.1044 575.194,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7178433010283944 -->\r\n",
       "<g id=\"node353\" class=\"node\"><title>0.7178433010283944</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"643.694\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"643.694\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.18849869367548222&#45;&gt;0.7178433010283944 -->\r\n",
       "<g id=\"edge352\" class=\"edge\"><title>0.18849869367548222&#45;&gt;0.7178433010283944</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M643.694,-71.6966C643.694,-63.9827 643.694,-54.7125 643.694,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"647.194,-46.1043 643.694,-36.1043 640.194,-46.1044 647.194,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9835358879385978 -->\r\n",
       "<g id=\"node355\" class=\"node\"><title>0.9835358879385978</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"969.694\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"969.694\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.31808427317270205&#45;&gt;0.9835358879385978 -->\r\n",
       "<g id=\"edge354\" class=\"edge\"><title>0.31808427317270205&#45;&gt;0.9835358879385978</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M969.694,-71.6966C969.694,-63.9827 969.694,-54.7125 969.694,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"973.194,-46.1043 969.694,-36.1043 966.194,-46.1044 973.194,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9478017984625537 -->\r\n",
       "<g id=\"node357\" class=\"node\"><title>0.9478017984625537</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1041.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1041.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8064089529357191&#45;&gt;0.9478017984625537 -->\r\n",
       "<g id=\"edge356\" class=\"edge\"><title>0.8064089529357191&#45;&gt;0.9478017984625537</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1041.69,-71.6966C1041.69,-63.9827 1041.69,-54.7125 1041.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1045.19,-46.1043 1041.69,-36.1043 1038.19,-46.1044 1045.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.11379621663010397 -->\r\n",
       "<g id=\"node359\" class=\"node\"><title>0.11379621663010397</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1299.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1299.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5909444840874958&#45;&gt;0.11379621663010397 -->\r\n",
       "<g id=\"edge358\" class=\"edge\"><title>0.5909444840874958&#45;&gt;0.11379621663010397</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1299.69,-71.6966C1299.69,-63.9827 1299.69,-54.7125 1299.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1303.19,-46.1043 1299.69,-36.1043 1296.19,-46.1044 1303.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5538703237392373 -->\r\n",
       "<g id=\"node361\" class=\"node\"><title>0.5538703237392373</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1371.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1371.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.23850917087597046&#45;&gt;0.5538703237392373 -->\r\n",
       "<g id=\"edge360\" class=\"edge\"><title>0.23850917087597046&#45;&gt;0.5538703237392373</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1371.69,-71.6966C1371.69,-63.9827 1371.69,-54.7125 1371.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1375.19,-46.1043 1371.69,-36.1043 1368.19,-46.1044 1375.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5545982525259292 -->\r\n",
       "<g id=\"node363\" class=\"node\"><title>0.5545982525259292</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1443.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1443.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.8374123517579857&#45;&gt;0.5545982525259292 -->\r\n",
       "<g id=\"edge362\" class=\"edge\"><title>0.8374123517579857&#45;&gt;0.5545982525259292</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1443.69,-71.6966C1443.69,-63.9827 1443.69,-54.7125 1443.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1447.19,-46.1043 1443.69,-36.1043 1440.19,-46.1044 1447.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.3282451581845611 -->\r\n",
       "<g id=\"node365\" class=\"node\"><title>0.3282451581845611</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1519.69\" cy=\"-18\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1519.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.7229752900587973&#45;&gt;0.3282451581845611 -->\r\n",
       "<g id=\"edge364\" class=\"edge\"><title>0.7229752900587973&#45;&gt;0.3282451581845611</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1519.69,-71.6966C1519.69,-63.9827 1519.69,-54.7125 1519.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1523.19,-46.1043 1519.69,-36.1043 1516.19,-46.1044 1523.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8313959262837922 -->\r\n",
       "<g id=\"node367\" class=\"node\"><title>0.8313959262837922</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1595.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1595.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">four</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5565851515619594&#45;&gt;0.8313959262837922 -->\r\n",
       "<g id=\"edge366\" class=\"edge\"><title>0.5565851515619594&#45;&gt;0.8313959262837922</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1592.68,-71.6966C1593.12,-63.9827 1593.65,-54.7125 1594.15,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.64,-46.2878 1594.72,-36.1043 1590.65,-45.8883 1597.64,-46.2878\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9364821382447579 -->\r\n",
       "<g id=\"node369\" class=\"node\"><title>0.9364821382447579</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1667.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1667.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3477061322745093&#45;&gt;0.9364821382447579 -->\r\n",
       "<g id=\"edge368\" class=\"edge\"><title>0.3477061322745093&#45;&gt;0.9364821382447579</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1666.94,-71.6966C1667.05,-63.9827 1667.18,-54.7125 1667.31,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1670.81,-46.1533 1667.45,-36.1043 1663.81,-46.0533 1670.81,-46.1533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.891119911923428 -->\r\n",
       "<g id=\"node371\" class=\"node\"><title>0.891119911923428</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1922.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1922.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.011550639027931853&#45;&gt;0.891119911923428 -->\r\n",
       "<g id=\"edge370\" class=\"edge\"><title>0.011550639027931853&#45;&gt;0.891119911923428</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1922.69,-71.6966C1922.69,-63.9827 1922.69,-54.7125 1922.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1926.19,-46.1043 1922.69,-36.1043 1919.19,-46.1044 1926.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.8223511041985285 -->\r\n",
       "<g id=\"node373\" class=\"node\"><title>0.8223511041985285</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1994.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1994.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.507622069224466&#45;&gt;0.8223511041985285 -->\r\n",
       "<g id=\"edge372\" class=\"edge\"><title>0.507622069224466&#45;&gt;0.8223511041985285</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1994.69,-71.6966C1994.69,-63.9827 1994.69,-54.7125 1994.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1998.19,-46.1043 1994.69,-36.1043 1991.19,-46.1044 1998.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.2765378103064383 -->\r\n",
       "<g id=\"node375\" class=\"node\"><title>0.2765378103064383</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2514.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2514.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.5944378539111139&#45;&gt;0.2765378103064383 -->\r\n",
       "<g id=\"edge374\" class=\"edge\"><title>0.5944378539111139&#45;&gt;0.2765378103064383</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2514.69,-71.6966C2514.69,-63.9827 2514.69,-54.7125 2514.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2518.19,-46.1043 2514.69,-36.1043 2511.19,-46.1044 2518.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9869375650174598 -->\r\n",
       "<g id=\"node377\" class=\"node\"><title>0.9869375650174598</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2586.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2586.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">six</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6999692943748069&#45;&gt;0.9869375650174598 -->\r\n",
       "<g id=\"edge376\" class=\"edge\"><title>0.6999692943748069&#45;&gt;0.9869375650174598</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2586.69,-71.6966C2586.69,-63.9827 2586.69,-54.7125 2586.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2590.19,-46.1043 2586.69,-36.1043 2583.19,-46.1044 2590.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.5116622695021158 -->\r\n",
       "<g id=\"node379\" class=\"node\"><title>0.5116622695021158</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2879.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2879.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.4328420583163032&#45;&gt;0.5116622695021158 -->\r\n",
       "<g id=\"edge378\" class=\"edge\"><title>0.4328420583163032&#45;&gt;0.5116622695021158</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2879.69,-71.6966C2879.69,-63.9827 2879.69,-54.7125 2879.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2883.19,-46.1043 2879.69,-36.1043 2876.19,-46.1044 2883.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.014239224747756074 -->\r\n",
       "<g id=\"node381\" class=\"node\"><title>0.014239224747756074</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2951.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"2951.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">two</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6887553176772824&#45;&gt;0.014239224747756074 -->\r\n",
       "<g id=\"edge380\" class=\"edge\"><title>0.6887553176772824&#45;&gt;0.014239224747756074</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2951.69,-71.6966C2951.69,-63.9827 2951.69,-54.7125 2951.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2955.19,-46.1043 2951.69,-36.1043 2948.19,-46.1044 2955.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7894684542831674 -->\r\n",
       "<g id=\"node383\" class=\"node\"><title>0.7894684542831674</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3788.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3788.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.1333950365189146&#45;&gt;0.7894684542831674 -->\r\n",
       "<g id=\"edge382\" class=\"edge\"><title>0.1333950365189146&#45;&gt;0.7894684542831674</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3788.69,-71.6966C3788.69,-63.9827 3788.69,-54.7125 3788.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3792.19,-46.1043 3788.69,-36.1043 3785.19,-46.1044 3792.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.974212596466 -->\r\n",
       "<g id=\"node385\" class=\"node\"><title>0.974212596466</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3969.69\" cy=\"-18\" rx=\"31.3957\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"3969.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">seven</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3088605897746505&#45;&gt;0.974212596466 -->\r\n",
       "<g id=\"edge384\" class=\"edge\"><title>0.3088605897746505&#45;&gt;0.974212596466</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3970.45,-71.6966C3970.34,-63.9827 3970.2,-54.7125 3970.08,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3973.58,-46.0533 3969.94,-36.1043 3966.58,-46.1533 3973.58,-46.0533\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.0654691918333914 -->\r\n",
       "<g id=\"node387\" class=\"node\"><title>0.0654691918333914</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4045.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"4045.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">five</text>\r\n",
       "</g>\r\n",
       "<!-- 0.9494483681429924&#45;&gt;0.0654691918333914 -->\r\n",
       "<g id=\"edge386\" class=\"edge\"><title>0.9494483681429924&#45;&gt;0.0654691918333914</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4044.19,-71.6966C4044.41,-63.9827 4044.67,-54.7125 4044.92,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4048.42,-46.2002 4045.21,-36.1043 4041.42,-46.0003 4048.42,-46.2002\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.6841879152208593 -->\r\n",
       "<g id=\"node389\" class=\"node\"><title>0.6841879152208593</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5752.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"5752.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.06719812574927997&#45;&gt;0.6841879152208593 -->\r\n",
       "<g id=\"edge388\" class=\"edge\"><title>0.06719812574927997&#45;&gt;0.6841879152208593</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5752.69,-71.6966C5752.69,-63.9827 5752.69,-54.7125 5752.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5756.19,-46.1043 5752.69,-36.1043 5749.19,-46.1044 5756.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.7517136242372804 -->\r\n",
       "<g id=\"node391\" class=\"node\"><title>0.7517136242372804</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6944.69\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"6944.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">three</text>\r\n",
       "</g>\r\n",
       "<!-- 0.3299885464433576&#45;&gt;0.7517136242372804 -->\r\n",
       "<g id=\"edge390\" class=\"edge\"><title>0.3299885464433576&#45;&gt;0.7517136242372804</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6944.69,-71.6966C6944.69,-63.9827 6944.69,-54.7125 6944.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6948.19,-46.1043 6944.69,-36.1043 6941.19,-46.1044 6948.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 0.9603247959923212 -->\r\n",
       "<g id=\"node393\" class=\"node\"><title>0.9603247959923212</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8222.69\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"8222.69\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">one</text>\r\n",
       "</g>\r\n",
       "<!-- 0.6180641213886487&#45;&gt;0.9603247959923212 -->\r\n",
       "<g id=\"edge392\" class=\"edge\"><title>0.6180641213886487&#45;&gt;0.9603247959923212</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8222.69,-71.6966C8222.69,-63.9827 8222.69,-54.7125 8222.69,-46.1124\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8226.19,-46.1043 8222.69,-36.1043 8219.19,-46.1044 8226.19,-46.1043\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x19c1be29408>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System entropy:  2.7780537123291715\n"
     ]
    }
   ],
   "source": [
    "#Calling DecisionTree constructor\n",
    "tree2 = DecisionTree(data_descriptive, descriptive_features, data_label, \"entropy\")\n",
    "\n",
    "#Passing pruning features for tree1\n",
    "tree2.id3(0,1)\n",
    "\n",
    "#Visualizing decision tree by Graphviz\n",
    "dot2 = tree2.print_visualTree( render=True )\n",
    "display(dot2)\n",
    "\n",
    "print(\"System entropy: \", format(tree2.entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Consider tree1. What is the best attribute (based on entropy) for splitting the tree in the second round of ID3 regarding the value of the attribute chosen in the first round of ID3?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: <br>\n",
    "The best attribute for splitting the tree in the second round of ID3 is *Surroundings3*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) Compare tree1 and tree2 in terms of the possibility of overfitting and the complexity of the decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:<br>\n",
    "Tree2 has significantly higher chance of overfitting. <br>\n",
    "Since the minimum number of samples for this tree is set to 1, it will create decision rules for even 1 element subsets. <br>\n",
    "The tree is too complex, it reduces its ability to generalize well on the unseen data.\n",
    "On the other hand Tree1 has minimum number of samples set to 15, which means that decision rules will be created only for cases when certain rule appeared at least 15 times in the dataset. It ensures that we reflect actual rules, and not ones that could be generated based on some data errors. This tree is less complex, and should be better at generalizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Regression (14 points):\n",
    "\n",
    "For this question (Q3), create and use a restricted dataset by removing the columns \"ID\", \"NumberR\", \"Surrounding1\", \"Surrounding2\", \"Surrounding3\", \"Common toad\", \"Fire-bellied toad\", \"Tree frog\", \"Common newt\", \"Great crested newt\" from the sampled_data.\n",
    "\n",
    "In this question, we consider \"Green frogs\" and \"Brown frogs\" to be potential target features, while all other features are potential descriptive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of the columns to drop\n",
    "cols_to_drop = [\"ID\", \"NumberR\", \"Surroundings1\", \"Surroundings2\", \"Surroundings3\", \"Common toad\", \"Fire-bellied toad\", \"Tree frog\", \"Common newt\", \"Great crested newt\"]\n",
    "#Copying sampled data\n",
    "regression_sample_data = sampled_data.copy()\n",
    "#Removing columns\n",
    "regression_sample_data.drop(columns=cols_to_drop, inplace=True)\n",
    "#saving the dataset\n",
    "#regression_sample_data.to_csv('regression_sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurfaceR</th>\n",
       "      <th>TypeR</th>\n",
       "      <th>VegetationR</th>\n",
       "      <th>UseR</th>\n",
       "      <th>FishingR</th>\n",
       "      <th>AcessR</th>\n",
       "      <th>RoadDistanceR</th>\n",
       "      <th>BuildingR</th>\n",
       "      <th>PollutionR</th>\n",
       "      <th>ShoreR</th>\n",
       "      <th>Green frogs</th>\n",
       "      <th>Brown frogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2400</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>300</td>\n",
       "      <td>h</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>22000</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>8000</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1100</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SurfaceR TypeR  VegetationR  UseR  FishingR  AcessR  RoadDistanceR  \\\n",
       "134      2400     a            0     3         4      75              1   \n",
       "16        300     h            4     0         0     100              5   \n",
       "167     22000     a            4     0         0     100              0   \n",
       "104      8000     a            2     3         2     100              0   \n",
       "35       1100     a            0     3         4     100              2   \n",
       "\n",
       "     BuildingR  PollutionR   ShoreR  Green frogs  Brown frogs  \n",
       "134          1           0  natural            1            0  \n",
       "16          10           0  natural            0            1  \n",
       "167          0           0  natural            1            1  \n",
       "104          2           0  natural            1            1  \n",
       "35           2           0  natural            0            1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Which features are suitable as input for logistic regression? Which would need to be modified first? Explain your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurfaceR          int64\n",
       "TypeR            object\n",
       "VegetationR       int64\n",
       "UseR              int64\n",
       "FishingR          int64\n",
       "AcessR            int64\n",
       "RoadDistanceR     int64\n",
       "BuildingR         int64\n",
       "PollutionR        int64\n",
       "ShoreR           object\n",
       "Green frogs       int64\n",
       "Brown frogs       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_sample_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:<br>\n",
    "Logistic regression requires all features to be numeric. We need to change features \"TypeR\" and \"ShoreR\" into numerical values.<br>\n",
    "To do so, we will use one-hot-encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) Implement and briefly motivate an adequate modification. Print the resulting data set limited to the first two data rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**:<br>\n",
    "We implemented one-hot-encoding using get_dummies from the pandas library.<br>\n",
    "This method works by creating a column for each unique value in a feature column that we want to transform. It then assigns 0 or 1 to the new columns. It is 1 if the given value that was in transformed feature and 0 to all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurfaceR</th>\n",
       "      <th>VegetationR</th>\n",
       "      <th>UseR</th>\n",
       "      <th>FishingR</th>\n",
       "      <th>AcessR</th>\n",
       "      <th>RoadDistanceR</th>\n",
       "      <th>BuildingR</th>\n",
       "      <th>PollutionR</th>\n",
       "      <th>Green frogs</th>\n",
       "      <th>Brown frogs</th>\n",
       "      <th>TypeR_a</th>\n",
       "      <th>TypeR_b</th>\n",
       "      <th>TypeR_d</th>\n",
       "      <th>TypeR_e</th>\n",
       "      <th>TypeR_g</th>\n",
       "      <th>TypeR_h</th>\n",
       "      <th>TypeR_i</th>\n",
       "      <th>TypeR_j</th>\n",
       "      <th>ShoreR_concrete</th>\n",
       "      <th>ShoreR_natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SurfaceR  VegetationR  UseR  FishingR  AcessR  RoadDistanceR  BuildingR  \\\n",
       "134      2400            0     3         4      75              1          1   \n",
       "16        300            4     0         0     100              5         10   \n",
       "\n",
       "     PollutionR  Green frogs  Brown frogs  TypeR_a  TypeR_b  TypeR_d  TypeR_e  \\\n",
       "134           0            1            0        1        0        0        0   \n",
       "16            0            0            1        0        0        0        0   \n",
       "\n",
       "     TypeR_g  TypeR_h  TypeR_i  TypeR_j  ShoreR_concrete  ShoreR_natural  \n",
       "134        0        0        0        0                0               1  \n",
       "16         0        1        0        0                0               1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting dummy variables for TypeR and ShoreR\n",
    "regression_sample_data_ohc = pd.get_dummies(regression_sample_data, columns=['TypeR', 'ShoreR'])\n",
    "#Printing first two records\n",
    "regression_sample_data_ohc.head(2)\n",
    "\n",
    "#saving the dataset\n",
    "#regression_sample_data_ohc.to_csv('regression_sample_data_ohc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) We want to predict the presence of green frogs and brown frogs in the habitat, using a distinct logistic regression classifier for each frog type. \n",
    "\n",
    "Consider the set of features available in this question's unmodified data set (that is before Q3b). To get an overview of the data, choose and present some basic visualization as discussed in the lectures (e.g.  scatter matrix, scatter plots, charts, etc.). Based on this visualization, for each frog type choose the 4 most promising descriptive features to predict the presence of that frog type in the habitat. \n",
    "\n",
    "Explain your strategy and choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Heatmap of the correlation between features')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get correlations of each features in dataset\n",
    "corrmat = regression_sample_data_ohc.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(regression_sample_data_ohc[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "plt.title(\"Heatmap of the correlation between features\")\n",
    "#saving the plot\n",
    "#plt.savefig('correlation_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: <br>\n",
    "To select features for the regression, we decided to count the correlation between features and then plot them using heatmap to easily identify features with higly correlated to our target features. <br><br>\n",
    "For *Green frogs*, four most promising features are: <br>\n",
    "- *UseR*, *FishingR*, *SurfaceR* are easy to identify as features with the highest individual corellation to the target feature <br>\n",
    "- *TypeR*, shows high positive and negative correlation on some of the dummy features, which we believe might have positive impact on the performance of the regression <br>\n",
    "\n",
    "For *Brown frogs*, we can that the level of correlation is lower, when compared to *Green frogs*. We decided to choose following features: <br>\n",
    "- *AcessR*, as the feature with highest positive correlation <br>\n",
    "- *PollutionR*, as the feature with the highest negative correlation <br>\n",
    "- *TypeR*, since other features show low correlation values, TypeR has some promising correlations for certain categories of *TypeR* <br>\n",
    "- *VegetationR*, was chosen over *ShoreR* even tough it has lower correlation to the target feature, since *ShoreR* values has symmetric correlations. We also checked that empirically and found out that *VegetationR* returns slightly better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) For both frog types, train a logistic regression classifier to predict the presence of that frog type in the habitat. Use the descriptive features as chosen in Q3c. Apply the modification from Q3b if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 4.89581021e-01 -1.88360755e-01  1.09850480e-04  6.09450814e-01\n",
      "   4.36566844e-01 -7.06075288e-01  4.69368226e-01  6.77514580e-01\n",
      "  -6.94617541e-01 -5.24134918e-02 -1.11394444e+00]]\n",
      "Intercept: \n",
      " [-0.3741503]\n"
     ]
    }
   ],
   "source": [
    "#List of the chosen features for green frog regression\n",
    "chosen_features_green = ['UseR', 'FishingR','SurfaceR', 'TypeR_a', 'TypeR_b', 'TypeR_d', 'TypeR_e', 'TypeR_g',\n",
    "       'TypeR_h', 'TypeR_i', 'TypeR_j']\n",
    "\n",
    "#defining the descriptive and target features\n",
    "descriptiveFeatures_green = regression_sample_data_ohc[chosen_features_green] \n",
    "targetFeature_green = regression_sample_data_ohc['Green frogs'] \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver = 'liblinear', multi_class = 'ovr')\n",
    "classifier.fit(descriptiveFeatures_green, targetFeature_green)\n",
    "\n",
    "targetFeature_green_pred = classifier.predict(descriptiveFeatures_green)\n",
    "\n",
    "print('Coefficients: \\n', classifier.coef_)\n",
    "print('Intercept: \\n', classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 0.01422716 -0.71175507  0.14455841 -0.52162653 -0.61282397  0.16366441\n",
      "  -0.15351186  0.33450149  0.94738161 -0.41411717  0.04552893]]\n",
      "Intercept: \n",
      " [-0.11197361]\n"
     ]
    }
   ],
   "source": [
    "#List of the chosen features for green frog regression\n",
    "chosen_features_brown = ['AcessR', 'PollutionR', 'TypeR_a', 'TypeR_b', 'TypeR_d', 'TypeR_e', 'TypeR_g',\n",
    "       'TypeR_h', 'TypeR_i', 'TypeR_j', 'VegetationR']\n",
    "\n",
    "#defining the descriptive and target features\n",
    "descriptiveFeatures_brown = regression_sample_data_ohc[chosen_features_brown] \n",
    "targetFeature_brown = regression_sample_data_ohc['Brown frogs']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver = 'liblinear', multi_class = 'ovr')\n",
    "classifier.fit(descriptiveFeatures_brown, targetFeature_brown)\n",
    "\n",
    "targetFeature_brown_pred = classifier.predict(descriptiveFeatures_brown)\n",
    "\n",
    "print('Coefficients: \\n', classifier.coef_)\n",
    "print('Intercept: \\n', classifier.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) For each of the two trained classifiers compute and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for green frogs:\n",
      "[[42 31]\n",
      " [12 85]]\n",
      "Confusion matrix for brown frogs:\n",
      "[[  1  37]\n",
      " [  0 132]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#green\n",
    "print(\"Confusion matrix for green frogs:\")\n",
    "print(confusion_matrix(y_true=targetFeature_green, y_pred=targetFeature_green_pred))\n",
    "\n",
    "#brown\n",
    "print(\"Confusion matrix for brown frogs:\")\n",
    "print(confusion_matrix(y_true=targetFeature_brown, y_pred=targetFeature_brown_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Based on the information computed in Q3 so far, interpret and evaluate the two models and compare them. Why are they similar/different? Would you recommend the models and why (not)? How do you think the applied methods could be improved to get better results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: <br>\n",
    "Accuracy of the green frog regression is equal to around 74.7%, while the brown regression is around 78.24% <br>\n",
    "Even tough brown regression had higher accuracy, it can be result of the data distribution. Confusion matrix shows, that 169 times out of 170, regression predicted the same value, which means that it does not generalize well, and in 99.4% of cases chose the same category.<br>\n",
    "That being said we think that the green frog regression classifier is better, as it appears that in generalizes well, even tough overall accuracy is lower. <br><br>\n",
    "To get better results we could:\n",
    "- Try to use more features\n",
    "- Get more data, that will describe target features better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Support Vector Machines (8 points):\n",
    "\n",
    "For this question (Q4), restrict your data set to the same features as in Q3. Similar to Q3, we want to train two distinct classifiers predicting the presence of green frogs and brown frogs in the habitat. \n",
    "\n",
    "In this question, we will use SVMs instead of logistic regression. In the following, consider *Green frogs* and *Brown frogs* to be potential target features, while all other features are potential descriptive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of the columns to drop\n",
    "cols_to_drop = [\"ID\", \"NumberR\", \"Surroundings1\", \"Surroundings2\", \"Surroundings3\", \"Common toad\", \"Fire-bellied toad\", \"Tree frog\", \"Common newt\", \"Great crested newt\"]\n",
    "#Copying sampled data\n",
    "svm_sample_data = sampled_data.copy()\n",
    "#Removing columns\n",
    "svm_sample_data.drop(columns=cols_to_drop, inplace=True)\n",
    "#saving the dataset\n",
    "#svm_sample_data.to_csv('svm_sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Which of the potential descriptive features are suitable as an input for SVMs and which need to be modified first? Modify the data as needed and provide a brief explanation. Print the first two data rows of the modified data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurfaceR</th>\n",
       "      <th>VegetationR</th>\n",
       "      <th>UseR</th>\n",
       "      <th>FishingR</th>\n",
       "      <th>AcessR</th>\n",
       "      <th>RoadDistanceR</th>\n",
       "      <th>BuildingR</th>\n",
       "      <th>PollutionR</th>\n",
       "      <th>Green frogs</th>\n",
       "      <th>Brown frogs</th>\n",
       "      <th>TypeR_a</th>\n",
       "      <th>TypeR_b</th>\n",
       "      <th>TypeR_d</th>\n",
       "      <th>TypeR_e</th>\n",
       "      <th>TypeR_g</th>\n",
       "      <th>TypeR_h</th>\n",
       "      <th>TypeR_i</th>\n",
       "      <th>TypeR_j</th>\n",
       "      <th>ShoreR_concrete</th>\n",
       "      <th>ShoreR_natural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SurfaceR  VegetationR  UseR  FishingR  AcessR  RoadDistanceR  BuildingR  \\\n",
       "134      2400            0     3         4      75              1          1   \n",
       "16        300            4     0         0     100              5         10   \n",
       "\n",
       "     PollutionR  Green frogs  Brown frogs  TypeR_a  TypeR_b  TypeR_d  TypeR_e  \\\n",
       "134           0            1            0        1        0        0        0   \n",
       "16            0            0            1        0        0        0        0   \n",
       "\n",
       "     TypeR_g  TypeR_h  TypeR_i  TypeR_j  ShoreR_concrete  ShoreR_natural  \n",
       "134        0        0        0        0                0               1  \n",
       "16         0        1        0        0                0               1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting dummy variables for TypeR and ShoreR\n",
    "svm_sample_data_ohc = pd.get_dummies(svm_sample_data, columns=['TypeR', 'ShoreR'])\n",
    "#Printing first two records\n",
    "svm_sample_data_ohc.head(2)\n",
    "#saving the dataset\n",
    "#svm_sample_data_ohc.to_csv('svm_sample_data_ohc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**<br>\n",
    "SVM requires features to be numerical, in order to change categorical features into numerical, we use one hot encoding. <br>\n",
    "We need to one hot encode features: *TypeR* and *ShoreR*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) For each frog type, consider the same set of 4 descriptive features as chosen in Q3 c). Generate for both target features a training and test set based on all data rows (for example, consider the sampling strategies as explained in the lecture) of the restricted data set. Briefly explain and motivate the choice of the sampling strategy as well as the size of the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     UseR  FishingR  SurfaceR  TypeR_a  TypeR_b  TypeR_d  TypeR_e  TypeR_g  \\\n",
      "63      0         0       100        1        0        0        0        0   \n",
      "40      0         0     80000        0        0        0        0        0   \n",
      "21      0         1      2500        1        0        0        0        0   \n",
      "82      0         0      2000        1        0        0        0        0   \n",
      "154     3         3       350        1        0        0        0        0   \n",
      "\n",
      "     TypeR_h  TypeR_i  TypeR_j  \n",
      "63         0        0        0  \n",
      "40         1        0        0  \n",
      "21         0        0        0  \n",
      "82         0        0        0  \n",
      "154        0        0        0  \n",
      "     UseR  FishingR  SurfaceR  TypeR_a  TypeR_b  TypeR_d  TypeR_e  TypeR_g  \\\n",
      "134     3         4      2400        1        0        0        0        0   \n",
      "112     0         0       500        1        0        0        0        0   \n",
      "106     0         0       300        0        0        0        0        0   \n",
      "58      3         2     28300        1        0        0        0        0   \n",
      "45      0         0       500        0        0        0        0        0   \n",
      "\n",
      "     TypeR_h  TypeR_i  TypeR_j  \n",
      "134        0        0        0  \n",
      "112        0        0        0  \n",
      "106        0        0        1  \n",
      "58         0        0        0  \n",
      "45         1        0        0  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#List of the chosen features for green frog regression\n",
    "chosen_features_green = ['UseR', 'FishingR','SurfaceR', 'TypeR_a', 'TypeR_b', 'TypeR_d', 'TypeR_e', 'TypeR_g',\n",
    "       'TypeR_h', 'TypeR_i', 'TypeR_j']\n",
    "\n",
    "#List of the chosen features for green frog regression\n",
    "chosen_features_brown = ['AcessR', 'PollutionR', 'TypeR_a', 'TypeR_b', 'TypeR_d', 'TypeR_e', 'TypeR_g',\n",
    "       'TypeR_h', 'TypeR_i', 'TypeR_j', 'VegetationR']\n",
    "\n",
    "X_train_green, X_test_green, y_train_green, y_test_green = train_test_split(svm_sample_data_ohc[chosen_features_green], svm_sample_data_ohc[\"Green frogs\"], test_size=0.2, random_state=414760)\n",
    "X_train_brown, X_test_brown, y_train_brown, y_test_brown = train_test_split(svm_sample_data_ohc[chosen_features_brown], svm_sample_data_ohc[\"Brown frogs\"], test_size=0.2, random_state=414760)\n",
    "\n",
    "print(X_train_green.head())\n",
    "\n",
    "print(X_test_green.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** <br>\n",
    "We decided to use random sampling, because our data sample is quite small, and by using other methods (top, stratified or under-sampling) we could remove significant type of data items.<br>\n",
    "We used 80% of data set for training and 20% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Use the training set to train 4 different SVMs (2 per frog type) with different parameter combinations. Use at least two distinct values for the parameters *kernel* and *C*.\n",
    "\n",
    "*Hint: depending on the size of the training data and chosen parameters, training the SVMs may take some time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Training the first model\n",
    "model1 = SVC(C=1, kernel='linear', decision_function_shape ='ovo').fit(X_train_green, y_train_green)\n",
    "\n",
    "#predicting values for the test set\n",
    "targetFeature_green_predict1 = model1.predict(X_test_green)\n",
    "print(targetFeature_green_predict1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Training the second model\n",
    "model2 = SVC(C=3, kernel='sigmoid', gamma = 'scale', decision_function_shape='ovo').fit(X_train_green, y_train_green)\n",
    "\n",
    "#predicting values for the test set\n",
    "targetFeature_green_predict2 = model2.predict(X_test_green)\n",
    "print(targetFeature_green_predict2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Training the third model\n",
    "model3 = SVC(C=2, kernel='poly', gamma = 'auto').fit(X_train_brown, y_train_brown)\n",
    "\n",
    "#predicting values for the test set\n",
    "targetFeature_brown_predict3 = model3.predict(X_test_brown)\n",
    "print(targetFeature_brown_predict3 )#show the first 5 predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Training the fourth model\n",
    "model4 = SVC(C=3, kernel='rbf', gamma = 'auto').fit(X_train_brown, y_train_brown)\n",
    "\n",
    "#predicting values for the test set\n",
    "targetFeature_brown_predict4 = model4.predict(X_test_brown)\n",
    "print(targetFeature_brown_predict4) #show the first 5 predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) Compute and print the mean accuracy and the classification report of the trained SVMs with respect to the test set (see instruction for examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      " 0.6470588235294118\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67        17\n",
      "           1       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.65        34\n",
      "   macro avg       0.65      0.65      0.65        34\n",
      "weighted avg       0.65      0.65      0.65        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy and classification report for the first model\n",
    "print('Accuracy: \\n', model1.score(X_test_green,y_test_green))\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(y_test_green, targetFeature_green_predict1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      " 0.7058823529411765\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75        17\n",
      "           1       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.71        34\n",
      "   macro avg       0.74      0.71      0.70        34\n",
      "weighted avg       0.74      0.71      0.70        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy and classification report for the second model\n",
    "print('Accuracy: \\n', model2.score(X_test_green,y_test_green))\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(y_test_green, targetFeature_green_predict2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      " 0.7058823529411765\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17         9\n",
      "           1       0.74      0.92      0.82        25\n",
      "\n",
      "    accuracy                           0.71        34\n",
      "   macro avg       0.54      0.52      0.49        34\n",
      "weighted avg       0.63      0.71      0.65        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy and classification report for the third model\n",
    "print('Accuracy: \\n', model3.score(X_test_brown,y_test_brown))\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(y_test_brown, targetFeature_brown_predict3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      " 0.7352941176470589\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.18         9\n",
      "           1       0.75      0.96      0.84        25\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.62      0.54      0.51        34\n",
      "weighted avg       0.68      0.74      0.67        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy and classification report for the fourth model\n",
    "print('Accuracy: \\n', model4.score(X_test_brown,y_test_brown))\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(y_test_brown, targetFeature_brown_predict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Based on the information computed in Q4 so far, interpret and evaluate the 4 SVMs and compare them. Why are they similar/different? Would you recommend using these SVMs and why (not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** <br>\n",
    "Using different parameters for SVM, we can see that the results are very similar to each other. The accuracy varies insignificantly between cases. All models do much better classifing category 1, while doing (depending on the model) much worse on the category 0. This may indicate that, the feature selected in the earlier phase does not explain category 0 well enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Neural Networks (15 points)\n",
    "In this question consider the sampled_data, which is the dataset that you have created in the *Preprocessing of Dataset* section. The target features are the *different frogs*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) What are the possible inputs of your network?\n",
    "   \n",
    "     - Give the number of possible values of the different categorical inputs.\n",
    "     - Give the number of possible input patterns for the categorical data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of the feautres in the cleaned data:\n",
      " ID                     int64\n",
      "SurfaceR               int64\n",
      "NumberR                int64\n",
      "TypeR                 object\n",
      "VegetationR            int64\n",
      "Surroundings1         object\n",
      "Surroundings2         object\n",
      "Surroundings3         object\n",
      "UseR                   int64\n",
      "FishingR               int64\n",
      "AcessR                 int64\n",
      "RoadDistanceR          int64\n",
      "BuildingR              int64\n",
      "PollutionR             int64\n",
      "ShoreR                object\n",
      "Green frogs            int64\n",
      "Brown frogs            int64\n",
      "Common toad            int64\n",
      "Fire-bellied toad      int64\n",
      "Tree frog              int64\n",
      "Common newt            int64\n",
      "Great crested newt     int64\n",
      "dtype: object\n",
      "Number of different categorical input in Surroundings1:  7\n",
      "Number of different categorical input in Surroundings2:  7\n",
      "Number of different categorical input in Surroundings3:  8\n",
      "Number of different categorical input in TypeR:  8\n",
      "Number of different categorical input in ShoreR:  2\n",
      "Number of different categorical input in VegetationR:  5\n",
      "Number of different categorical input in UseR:  3\n",
      "Number of different categorical input in FishingR:  5\n",
      "Number of different categorical input in PollutionR:  3\n",
      "\n",
      "Number of possible input patterns is:  1411200\n"
     ]
    }
   ],
   "source": [
    "#Showing datatypes of the features\n",
    "print(\"Types of the feautres in the cleaned data:\\n\",cleaned_data.dtypes)\n",
    "\n",
    "#Showing number of unique categories for a given feature\n",
    "print(\"Number of different categorical input in Surroundings1: \",cleaned_data[\"Surroundings1\"].nunique())\n",
    "print(\"Number of different categorical input in Surroundings2: \",cleaned_data[\"Surroundings2\"].nunique())\n",
    "print(\"Number of different categorical input in Surroundings3: \",cleaned_data[\"Surroundings3\"].nunique())\n",
    "print(\"Number of different categorical input in TypeR: \",cleaned_data[\"TypeR\"].nunique())\n",
    "print(\"Number of different categorical input in ShoreR: \",cleaned_data[\"ShoreR\"].nunique())\n",
    "\n",
    "print(\"Number of different categorical input in VegetationR: \",cleaned_data[\"VegetationR\"].nunique())\n",
    "print(\"Number of different categorical input in UseR: \",cleaned_data[\"UseR\"].nunique())\n",
    "print(\"Number of different categorical input in FishingR: \",cleaned_data[\"FishingR\"].nunique())\n",
    "print(\"Number of different categorical input in PollutionR: \",cleaned_data[\"PollutionR\"].nunique())\n",
    "\n",
    "#Calculating number of possible input patterns\n",
    "print(\"\\nNumber of possible input patterns is: \",7*7*8*8*2*5*3*5*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**<br>\n",
    "In the dataset we have 5 different categorical-nominal features:\n",
    "- Surroundings1 (7 unique values)\n",
    "- Surroundings2 (7 unique values)\n",
    "- Surroundings3 (8 unique values)\n",
    "- TypeR (8 unique values)\n",
    "- ShoreR (2 unique values)<br>\n",
    "\n",
    "On top of that we have 4 different categorical-ordinal features:\n",
    "- VegetationR (5 unique values)\n",
    "- UseR (3 unique values)\n",
    "- FishingR (5 unique values)\n",
    "- PollutionR (3 unique values)\n",
    "\n",
    "That means that there are 1411200 possible input patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) Choose one categorical feature and two non-categorical features as input features. Create a data set with those features and the target columns (different frogs). Name this data set *NN_data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NumberR TypeR  BuildingR  Green frogs  Brown frogs  Common toad  \\\n",
      "134        2     a          1            1            0            0   \n",
      "16         1     h         10            0            1            1   \n",
      "167        1     a          0            1            1            1   \n",
      "104        1     a          2            1            1            0   \n",
      "35         1     a          2            0            1            1   \n",
      "\n",
      "     Fire-bellied toad  Tree frog  Common newt  Great crested newt  \n",
      "134                  0          0            0                   0  \n",
      "16                   0          1            0                   0  \n",
      "167                  1          1            0                   0  \n",
      "104                  0          0            0                   0  \n",
      "35                   0          0            0                   0  \n"
     ]
    }
   ],
   "source": [
    "#Selecting features\n",
    "NN_data = sampled_data.loc[:, df.columns.isin(['NumberR', 'BuildingR', 'TypeR', 'Green frogs', 'Brown frogs', 'Common toad', 'Fire-bellied toad', 'Tree frog', 'Common newt', 'Great crested newt'])]\n",
    "print(NN_data.head())\n",
    "\n",
    "#saving the dataset\n",
    "#NN_data.to_csv('NN_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Convert the features that need to be converted using One-Hot-Encoding. Explain why you need (not) to convert these features. Name the data set *NN_data_encoded*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NumberR  BuildingR  Green frogs  Brown frogs  Common toad  \\\n",
      "134        2          1            1            0            0   \n",
      "16         1         10            0            1            1   \n",
      "167        1          0            1            1            1   \n",
      "104        1          2            1            1            0   \n",
      "35         1          2            0            1            1   \n",
      "\n",
      "     Fire-bellied toad  Tree frog  Common newt  Great crested newt  TypeR_a  \\\n",
      "134                  0          0            0                   0        1   \n",
      "16                   0          1            0                   0        0   \n",
      "167                  1          1            0                   0        1   \n",
      "104                  0          0            0                   0        1   \n",
      "35                   0          0            0                   0        1   \n",
      "\n",
      "     TypeR_b  TypeR_d  TypeR_e  TypeR_g  TypeR_h  TypeR_i  TypeR_j  \n",
      "134        0        0        0        0        0        0        0  \n",
      "16         0        0        0        0        1        0        0  \n",
      "167        0        0        0        0        0        0        0  \n",
      "104        0        0        0        0        0        0        0  \n",
      "35         0        0        0        0        0        0        0  \n"
     ]
    }
   ],
   "source": [
    "#Encoding categorical features\n",
    "NN_data_encoded = pd.get_dummies(NN_data, columns=['TypeR'])\n",
    "print(NN_data_encoded.head())\n",
    "\n",
    "#saving the dataset\n",
    "#NN_data_encoded.to_csv('NN_data_encoded.csv')\n",
    "\n",
    "data = NN_data_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**<br> \n",
    "We needed to convert the feature \"TypeR\" because it contains categorical values.We sued Pandas' method get_dummies to convert categorical data into numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) Create a training and test set with 90% of the rows of your *NN_data_encoded* data set for training and 10% as test data set. Name them *train_NN* and *test_NN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NumberR  BuildingR  TypeR_a  TypeR_b  TypeR_d  TypeR_e  TypeR_g  TypeR_h  \\\n",
      "34         1          2        1        0        0        0        0        0   \n",
      "135        5          1        1        0        0        0        0        0   \n",
      "76         1          1        1        0        0        0        0        0   \n",
      "49         1          1        1        0        0        0        0        0   \n",
      "137        1          0        1        0        0        0        0        0   \n",
      "\n",
      "     TypeR_i  TypeR_j  \n",
      "34         0        0  \n",
      "135        0        0  \n",
      "76         0        0  \n",
      "49         0        0  \n",
      "137        0        0  \n",
      "     NumberR  BuildingR  TypeR_a  TypeR_b  TypeR_d  TypeR_e  TypeR_g  TypeR_h  \\\n",
      "116        1          1        0        0        0        0        0        0   \n",
      "41         1          5        0        0        0        0        0        1   \n",
      "173        2          0        1        0        0        0        0        0   \n",
      "52         1          2        1        0        0        0        0        0   \n",
      "112        1          1        1        0        0        0        0        0   \n",
      "\n",
      "     TypeR_i  TypeR_j  \n",
      "116        0        1  \n",
      "41         0        0  \n",
      "173        0        0  \n",
      "52         0        0  \n",
      "112        0        0  \n"
     ]
    }
   ],
   "source": [
    "#Listing of the used features and target features\n",
    "X_NN = ['NumberR', 'BuildingR', 'TypeR_a' ,'TypeR_b', 'TypeR_d', 'TypeR_e', 'TypeR_g', 'TypeR_h', 'TypeR_i', 'TypeR_j']\n",
    "y_NN = ['Green frogs', 'Brown frogs', 'Common toad', 'Fire-bellied toad', 'Tree frog', 'Common newt', 'Great crested newt']\n",
    "\n",
    "#Data selection\n",
    "X_data = NN_data_encoded[X_NN]\n",
    "y_data = NN_data_encoded[y_NN]\n",
    "\n",
    "#Creating training and testing sets\n",
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN = train_test_split(X_data, y_data, test_size = 0.1, random_state=414759)\n",
    "\n",
    "\n",
    "print(X_train_NN.head())\n",
    "print(X_test_NN.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Train two different Neural Networks, one with a linear activation function and one with a non-linear activation function. All other settings stay default. Give the accuracy of each Neural Network for the training and test set (*train_NN* and *test_NN*. Which activation function seems to be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.52847133\n",
      "Iteration 2, loss = 4.50204723\n",
      "Iteration 3, loss = 4.47685872\n",
      "Iteration 4, loss = 4.45290554\n",
      "Iteration 5, loss = 4.43028480\n",
      "Iteration 6, loss = 4.40870936\n",
      "Iteration 7, loss = 4.38817213\n",
      "Iteration 8, loss = 4.36863953\n",
      "Iteration 9, loss = 4.35006673\n",
      "Iteration 10, loss = 4.33234095\n",
      "Iteration 11, loss = 4.31546932\n",
      "Iteration 12, loss = 4.29944335\n",
      "Iteration 13, loss = 4.28420497\n",
      "Iteration 14, loss = 4.26973515\n",
      "Iteration 15, loss = 4.25598224\n",
      "Iteration 16, loss = 4.24290091\n",
      "Iteration 17, loss = 4.23045235\n",
      "Iteration 18, loss = 4.21863911\n",
      "Iteration 19, loss = 4.20744295\n",
      "Iteration 20, loss = 4.19680962\n",
      "Iteration 21, loss = 4.18669304\n",
      "Iteration 22, loss = 4.17709234\n",
      "Iteration 23, loss = 4.16791048\n",
      "Iteration 24, loss = 4.15911692\n",
      "Iteration 25, loss = 4.15075992\n",
      "Iteration 26, loss = 4.14269592\n",
      "Iteration 27, loss = 4.13495350\n",
      "Iteration 28, loss = 4.12747986\n",
      "Iteration 29, loss = 4.12025605\n",
      "Iteration 30, loss = 4.11327323\n",
      "Iteration 31, loss = 4.10647841\n",
      "Iteration 32, loss = 4.09985595\n",
      "Iteration 33, loss = 4.09334132\n",
      "Iteration 34, loss = 4.08690186\n",
      "Iteration 35, loss = 4.08053459\n",
      "Iteration 36, loss = 4.07425975\n",
      "Iteration 37, loss = 4.06805598\n",
      "Iteration 38, loss = 4.06189416\n",
      "Iteration 39, loss = 4.05579548\n",
      "Iteration 40, loss = 4.04972276\n",
      "Iteration 41, loss = 4.04365022\n",
      "Iteration 42, loss = 4.03759792\n",
      "Iteration 43, loss = 4.03157114\n",
      "Iteration 44, loss = 4.02558752\n",
      "Iteration 45, loss = 4.01961183\n",
      "Iteration 46, loss = 4.01368861\n",
      "Iteration 47, loss = 4.00780491\n",
      "Iteration 48, loss = 4.00193883\n",
      "Iteration 49, loss = 3.99609172\n",
      "Iteration 50, loss = 3.99031570\n",
      "Iteration 51, loss = 3.98455658\n",
      "Iteration 52, loss = 3.97882047\n",
      "Iteration 53, loss = 3.97313468\n",
      "Iteration 54, loss = 3.96747582\n",
      "Iteration 55, loss = 3.96187305\n",
      "Iteration 56, loss = 3.95632084\n",
      "Iteration 57, loss = 3.95079968\n",
      "Iteration 58, loss = 3.94532662\n",
      "Iteration 59, loss = 3.93990096\n",
      "Iteration 60, loss = 3.93451119\n",
      "Iteration 61, loss = 3.92915617\n",
      "Iteration 62, loss = 3.92385962\n",
      "Iteration 63, loss = 3.91864970\n",
      "Iteration 64, loss = 3.91345015\n",
      "Iteration 65, loss = 3.90825939\n",
      "Iteration 66, loss = 3.90308246\n",
      "Iteration 67, loss = 3.89798479\n",
      "Iteration 68, loss = 3.89296693\n",
      "Iteration 69, loss = 3.88802373\n",
      "Iteration 70, loss = 3.88310800\n",
      "Iteration 71, loss = 3.87821954\n",
      "Iteration 72, loss = 3.87342609\n",
      "Iteration 73, loss = 3.86865986\n",
      "Iteration 74, loss = 3.86392002\n",
      "Iteration 75, loss = 3.85918477\n",
      "Iteration 76, loss = 3.85451589\n",
      "Iteration 77, loss = 3.84983973\n",
      "Iteration 78, loss = 3.84516776\n",
      "Iteration 79, loss = 3.84053159\n",
      "Iteration 80, loss = 3.83594437\n",
      "Iteration 81, loss = 3.83138345\n",
      "Iteration 82, loss = 3.82692060\n",
      "Iteration 83, loss = 3.82257659\n",
      "Iteration 84, loss = 3.81827763\n",
      "Iteration 85, loss = 3.81404833\n",
      "Iteration 86, loss = 3.80994720\n",
      "Iteration 87, loss = 3.80592215\n",
      "Iteration 88, loss = 3.80193666\n",
      "Iteration 89, loss = 3.79797569\n",
      "Iteration 90, loss = 3.79405214\n",
      "Iteration 91, loss = 3.79019584\n",
      "Iteration 92, loss = 3.78639925\n",
      "Iteration 93, loss = 3.78260845\n",
      "Iteration 94, loss = 3.77884302\n",
      "Iteration 95, loss = 3.77512210\n",
      "Iteration 96, loss = 3.77145182\n",
      "Iteration 97, loss = 3.76783310\n",
      "Iteration 98, loss = 3.76429087\n",
      "Iteration 99, loss = 3.76079922\n",
      "Iteration 100, loss = 3.75736998\n",
      "Iteration 101, loss = 3.75398490\n",
      "Iteration 102, loss = 3.75070559\n",
      "Iteration 103, loss = 3.74748080\n",
      "Iteration 104, loss = 3.74431083\n",
      "Iteration 105, loss = 3.74119718\n",
      "Iteration 106, loss = 3.73811128\n",
      "Iteration 107, loss = 3.73508077\n",
      "Iteration 108, loss = 3.73210713\n",
      "Iteration 109, loss = 3.72916865\n",
      "Iteration 110, loss = 3.72627269\n",
      "Iteration 111, loss = 3.72341325\n",
      "Iteration 112, loss = 3.72064008\n",
      "Iteration 113, loss = 3.71792079\n",
      "Iteration 114, loss = 3.71522844\n",
      "Iteration 115, loss = 3.71257488\n",
      "Iteration 116, loss = 3.70995923\n",
      "Iteration 117, loss = 3.70736699\n",
      "Iteration 118, loss = 3.70483822\n",
      "Iteration 119, loss = 3.70239824\n",
      "Iteration 120, loss = 3.69997500\n",
      "Iteration 121, loss = 3.69756842\n",
      "Iteration 122, loss = 3.69516565\n",
      "Iteration 123, loss = 3.69280382\n",
      "Iteration 124, loss = 3.69046560\n",
      "Iteration 125, loss = 3.68817767\n",
      "Iteration 126, loss = 3.68592270\n",
      "Iteration 127, loss = 3.68368454\n",
      "Iteration 128, loss = 3.68147194\n",
      "Iteration 129, loss = 3.67926082\n",
      "Iteration 130, loss = 3.67706453\n",
      "Iteration 131, loss = 3.67494576\n",
      "Iteration 132, loss = 3.67285148\n",
      "Iteration 133, loss = 3.67076397\n",
      "Iteration 134, loss = 3.66870081\n",
      "Iteration 135, loss = 3.66664569\n",
      "Iteration 136, loss = 3.66461853\n",
      "Iteration 137, loss = 3.66260490\n",
      "Iteration 138, loss = 3.66060051\n",
      "Iteration 139, loss = 3.65860990\n",
      "Iteration 140, loss = 3.65664591\n",
      "Iteration 141, loss = 3.65470064\n",
      "Iteration 142, loss = 3.65278213\n",
      "Iteration 143, loss = 3.65087038\n",
      "Iteration 144, loss = 3.64896366\n",
      "Iteration 145, loss = 3.64708846\n",
      "Iteration 146, loss = 3.64521966\n",
      "Iteration 147, loss = 3.64335941\n",
      "Iteration 148, loss = 3.64149315\n",
      "Iteration 149, loss = 3.63964204\n",
      "Iteration 150, loss = 3.63785589\n",
      "Iteration 151, loss = 3.63612763\n",
      "Iteration 152, loss = 3.63438637\n",
      "Iteration 153, loss = 3.63264760\n",
      "Iteration 154, loss = 3.63089023\n",
      "Iteration 155, loss = 3.62917126\n",
      "Iteration 156, loss = 3.62749419\n",
      "Iteration 157, loss = 3.62584080\n",
      "Iteration 158, loss = 3.62418103\n",
      "Iteration 159, loss = 3.62254049\n",
      "Iteration 160, loss = 3.62090822\n",
      "Iteration 161, loss = 3.61931324\n",
      "Iteration 162, loss = 3.61770358\n",
      "Iteration 163, loss = 3.61609293\n",
      "Iteration 164, loss = 3.61451734\n",
      "Iteration 165, loss = 3.61294131\n",
      "Iteration 166, loss = 3.61139009\n",
      "Iteration 167, loss = 3.60989191\n",
      "Iteration 168, loss = 3.60837880\n",
      "Iteration 169, loss = 3.60685333\n",
      "Iteration 170, loss = 3.60533737\n",
      "Iteration 171, loss = 3.60381689\n",
      "Iteration 172, loss = 3.60232182\n",
      "Iteration 173, loss = 3.60084983\n",
      "Iteration 174, loss = 3.59937321\n",
      "Iteration 175, loss = 3.59791740\n",
      "Iteration 176, loss = 3.59644812\n",
      "Iteration 177, loss = 3.59498421\n",
      "Iteration 178, loss = 3.59355281\n",
      "Iteration 179, loss = 3.59212374\n",
      "Iteration 180, loss = 3.59072525\n",
      "Iteration 181, loss = 3.58935094\n",
      "Iteration 182, loss = 3.58796021\n",
      "Iteration 183, loss = 3.58659124\n",
      "Iteration 184, loss = 3.58524482\n",
      "Iteration 185, loss = 3.58389229\n",
      "Iteration 186, loss = 3.58253357\n",
      "Iteration 187, loss = 3.58118289\n",
      "Iteration 188, loss = 3.57985035\n",
      "Iteration 189, loss = 3.57851556\n",
      "Iteration 190, loss = 3.57718784\n",
      "Iteration 191, loss = 3.57588132\n",
      "Iteration 192, loss = 3.57458371\n",
      "Iteration 193, loss = 3.57328185\n",
      "Iteration 194, loss = 3.57199692\n",
      "Iteration 195, loss = 3.57073034\n",
      "Iteration 196, loss = 3.56945580\n",
      "Iteration 197, loss = 3.56818419\n",
      "Iteration 198, loss = 3.56691814\n",
      "Iteration 199, loss = 3.56565648\n",
      "Iteration 200, loss = 3.56439933\n"
     ]
    }
   ],
   "source": [
    "#Creating classifier with non-linear activation function and default parameters\n",
    "clf1 = MLPClassifier(activation='relu', hidden_layer_sizes=(100,), max_iter=200, alpha=0.0001,\n",
    "                     solver='adam', verbose=True,  random_state=414759,tol=1e-4)\n",
    "\n",
    "#Fitting classifier into the training data\n",
    "clf1.fit(X_train_NN, y_train_NN)\n",
    "\n",
    "#Predicting values for the testing set\n",
    "y_pred1 = clf1.predict(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Multi-layer Perceptron is: 0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "#Printing accuracy of the model\n",
    "print('The accuracy of the Multi-layer Perceptron is:', accuracy_score(y_test_NN, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.67575576\n",
      "Iteration 2, loss = 4.61359895\n",
      "Iteration 3, loss = 4.55603753\n",
      "Iteration 4, loss = 4.50315275\n",
      "Iteration 5, loss = 4.45497789\n",
      "Iteration 6, loss = 4.41148768\n",
      "Iteration 7, loss = 4.37259119\n",
      "Iteration 8, loss = 4.33812894\n",
      "Iteration 9, loss = 4.30787012\n",
      "Iteration 10, loss = 4.28151336\n",
      "Iteration 11, loss = 4.25869517\n",
      "Iteration 12, loss = 4.23900670\n",
      "Iteration 13, loss = 4.22201518\n",
      "Iteration 14, loss = 4.20728620\n",
      "Iteration 15, loss = 4.19440385\n",
      "Iteration 16, loss = 4.18298681\n",
      "Iteration 17, loss = 4.17269948\n",
      "Iteration 18, loss = 4.16325782\n",
      "Iteration 19, loss = 4.15443066\n",
      "Iteration 20, loss = 4.14603734\n",
      "Iteration 21, loss = 4.13794270\n",
      "Iteration 22, loss = 4.13005052\n",
      "Iteration 23, loss = 4.12229635\n",
      "Iteration 24, loss = 4.11464034\n",
      "Iteration 25, loss = 4.10706074\n",
      "Iteration 26, loss = 4.09954814\n",
      "Iteration 27, loss = 4.09210075\n",
      "Iteration 28, loss = 4.08472060\n",
      "Iteration 29, loss = 4.07741094\n",
      "Iteration 30, loss = 4.07017487\n",
      "Iteration 31, loss = 4.06301471\n",
      "Iteration 32, loss = 4.05593208\n",
      "Iteration 33, loss = 4.04892811\n",
      "Iteration 34, loss = 4.04200371\n",
      "Iteration 35, loss = 4.03515980\n",
      "Iteration 36, loss = 4.02839742\n",
      "Iteration 37, loss = 4.02171771\n",
      "Iteration 38, loss = 4.01512176\n",
      "Iteration 39, loss = 4.00861046\n",
      "Iteration 40, loss = 4.00218445\n",
      "Iteration 41, loss = 3.99584418\n",
      "Iteration 42, loss = 3.98959006\n",
      "Iteration 43, loss = 3.98342269\n",
      "Iteration 44, loss = 3.97734298\n",
      "Iteration 45, loss = 3.97135230\n",
      "Iteration 46, loss = 3.96545255\n",
      "Iteration 47, loss = 3.95964610\n",
      "Iteration 48, loss = 3.95393570\n",
      "Iteration 49, loss = 3.94832424\n",
      "Iteration 50, loss = 3.94281450\n",
      "Iteration 51, loss = 3.93740874\n",
      "Iteration 52, loss = 3.93210843\n",
      "Iteration 53, loss = 3.92691394\n",
      "Iteration 54, loss = 3.92182434\n",
      "Iteration 55, loss = 3.91683739\n",
      "Iteration 56, loss = 3.91194959\n",
      "Iteration 57, loss = 3.90715640\n",
      "Iteration 58, loss = 3.90245256\n",
      "Iteration 59, loss = 3.89783254\n",
      "Iteration 60, loss = 3.89329091\n",
      "Iteration 61, loss = 3.88882276\n",
      "Iteration 62, loss = 3.88442404\n",
      "Iteration 63, loss = 3.88009179\n",
      "Iteration 64, loss = 3.87582417\n",
      "Iteration 65, loss = 3.87162051\n",
      "Iteration 66, loss = 3.86748108\n",
      "Iteration 67, loss = 3.86340688\n",
      "Iteration 68, loss = 3.85939939\n",
      "Iteration 69, loss = 3.85546019\n",
      "Iteration 70, loss = 3.85159082\n",
      "Iteration 71, loss = 3.84779247\n",
      "Iteration 72, loss = 3.84406593\n",
      "Iteration 73, loss = 3.84041151\n",
      "Iteration 74, loss = 3.83682906\n",
      "Iteration 75, loss = 3.83331803\n",
      "Iteration 76, loss = 3.82987755\n",
      "Iteration 77, loss = 3.82650655\n",
      "Iteration 78, loss = 3.82320382\n",
      "Iteration 79, loss = 3.81996811\n",
      "Iteration 80, loss = 3.81679815\n",
      "Iteration 81, loss = 3.81369272\n",
      "Iteration 82, loss = 3.81065063\n",
      "Iteration 83, loss = 3.80767077\n",
      "Iteration 84, loss = 3.80475206\n",
      "Iteration 85, loss = 3.80189350\n",
      "Iteration 86, loss = 3.79909414\n",
      "Iteration 87, loss = 3.79635308\n",
      "Iteration 88, loss = 3.79366948\n",
      "Iteration 89, loss = 3.79104252\n",
      "Iteration 90, loss = 3.78847142\n",
      "Iteration 91, loss = 3.78595538\n",
      "Iteration 92, loss = 3.78349359\n",
      "Iteration 93, loss = 3.78108521\n",
      "Iteration 94, loss = 3.77872936\n",
      "Iteration 95, loss = 3.77642511\n",
      "Iteration 96, loss = 3.77417150\n",
      "Iteration 97, loss = 3.77196755\n",
      "Iteration 98, loss = 3.76981226\n",
      "Iteration 99, loss = 3.76770463\n",
      "Iteration 100, loss = 3.76564368\n",
      "Iteration 101, loss = 3.76362844\n",
      "Iteration 102, loss = 3.76165797\n",
      "Iteration 103, loss = 3.75973133\n",
      "Iteration 104, loss = 3.75784762\n",
      "Iteration 105, loss = 3.75600591\n",
      "Iteration 106, loss = 3.75420531\n",
      "Iteration 107, loss = 3.75244490\n",
      "Iteration 108, loss = 3.75072378\n",
      "Iteration 109, loss = 3.74904105\n",
      "Iteration 110, loss = 3.74739579\n",
      "Iteration 111, loss = 3.74578713\n",
      "Iteration 112, loss = 3.74421420\n",
      "Iteration 113, loss = 3.74267613\n",
      "Iteration 114, loss = 3.74117210\n",
      "Iteration 115, loss = 3.73970129\n",
      "Iteration 116, loss = 3.73826293\n",
      "Iteration 117, loss = 3.73685625\n",
      "Iteration 118, loss = 3.73548050\n",
      "Iteration 119, loss = 3.73413494\n",
      "Iteration 120, loss = 3.73281886\n",
      "Iteration 121, loss = 3.73153155\n",
      "Iteration 122, loss = 3.73027232\n",
      "Iteration 123, loss = 3.72904049\n",
      "Iteration 124, loss = 3.72783539\n",
      "Iteration 125, loss = 3.72665636\n",
      "Iteration 126, loss = 3.72550276\n",
      "Iteration 127, loss = 3.72437395\n",
      "Iteration 128, loss = 3.72326933\n",
      "Iteration 129, loss = 3.72218830\n",
      "Iteration 130, loss = 3.72113026\n",
      "Iteration 131, loss = 3.72009464\n",
      "Iteration 132, loss = 3.71908089\n",
      "Iteration 133, loss = 3.71808847\n",
      "Iteration 134, loss = 3.71711684\n",
      "Iteration 135, loss = 3.71616549\n",
      "Iteration 136, loss = 3.71523393\n",
      "Iteration 137, loss = 3.71432166\n",
      "Iteration 138, loss = 3.71342821\n",
      "Iteration 139, loss = 3.71255313\n",
      "Iteration 140, loss = 3.71169595\n",
      "Iteration 141, loss = 3.71085624\n",
      "Iteration 142, loss = 3.71003356\n",
      "Iteration 143, loss = 3.70922751\n",
      "Iteration 144, loss = 3.70843767\n",
      "Iteration 145, loss = 3.70766363\n",
      "Iteration 146, loss = 3.70690502\n",
      "Iteration 147, loss = 3.70616146\n",
      "Iteration 148, loss = 3.70543257\n",
      "Iteration 149, loss = 3.70471800\n",
      "Iteration 150, loss = 3.70401741\n",
      "Iteration 151, loss = 3.70333044\n",
      "Iteration 152, loss = 3.70265676\n",
      "Iteration 153, loss = 3.70199606\n",
      "Iteration 154, loss = 3.70134802\n",
      "Iteration 155, loss = 3.70071233\n",
      "Iteration 156, loss = 3.70008869\n",
      "Iteration 157, loss = 3.69947681\n",
      "Iteration 158, loss = 3.69887640\n",
      "Iteration 159, loss = 3.69828720\n",
      "Iteration 160, loss = 3.69770893\n",
      "Iteration 161, loss = 3.69714132\n",
      "Iteration 162, loss = 3.69658413\n",
      "Iteration 163, loss = 3.69603711\n",
      "Iteration 164, loss = 3.69550000\n",
      "Iteration 165, loss = 3.69497259\n",
      "Iteration 166, loss = 3.69445463\n",
      "Iteration 167, loss = 3.69394590\n",
      "Iteration 168, loss = 3.69344619\n",
      "Iteration 169, loss = 3.69295529\n",
      "Iteration 170, loss = 3.69247298\n",
      "Iteration 171, loss = 3.69199907\n",
      "Iteration 172, loss = 3.69153337\n",
      "Iteration 173, loss = 3.69107567\n",
      "Iteration 174, loss = 3.69062580\n",
      "Iteration 175, loss = 3.69018357\n",
      "Iteration 176, loss = 3.68974881\n",
      "Iteration 177, loss = 3.68932135\n",
      "Iteration 178, loss = 3.68890102\n",
      "Iteration 179, loss = 3.68848767\n",
      "Iteration 180, loss = 3.68808112\n",
      "Iteration 181, loss = 3.68768123\n",
      "Iteration 182, loss = 3.68728785\n",
      "Iteration 183, loss = 3.68690084\n",
      "Iteration 184, loss = 3.68652005\n",
      "Iteration 185, loss = 3.68614534\n",
      "Iteration 186, loss = 3.68577659\n",
      "Iteration 187, loss = 3.68541365\n",
      "Iteration 188, loss = 3.68505641\n",
      "Iteration 189, loss = 3.68470474\n",
      "Iteration 190, loss = 3.68435852\n",
      "Iteration 191, loss = 3.68401763\n",
      "Iteration 192, loss = 3.68368195\n",
      "Iteration 193, loss = 3.68335138\n",
      "Iteration 194, loss = 3.68302582\n",
      "Iteration 195, loss = 3.68270514\n",
      "Iteration 196, loss = 3.68238926\n",
      "Iteration 197, loss = 3.68207806\n",
      "Iteration 198, loss = 3.68177146\n",
      "Iteration 199, loss = 3.68146935\n",
      "Iteration 200, loss = 3.68117166\n"
     ]
    }
   ],
   "source": [
    "#Creating classifier with linear activation function and default parameters\n",
    "clf2 = MLPClassifier(activation='identity', hidden_layer_sizes=(100,), max_iter=200, alpha=0.0001,\n",
    "                     solver='adam', verbose=True,  random_state=414759,tol=1e-4)\n",
    "\n",
    "#Fitting classifier into the training data\n",
    "clf2.fit(X_train_NN, y_train_NN)\n",
    "\n",
    "#Predicting values for the testing set\n",
    "y_pred2 = clf2.predict(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Multi-layer Perceptron is: 0.29411764705882354\n"
     ]
    }
   ],
   "source": [
    "#Printing accuracy of the model\n",
    "print('The accuracy of the Multi-layer Perceptron is:', accuracy_score(y_test_NN, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**<br>\n",
    "Model with *identity* function as activation function turned out to have better accuracy of around 29.41%. In comparison the other model, which had *relu* as activation function had accuracy of around 23.53%. *Identity* model seems to be better, when comparing their loss functions during training, *relu* model has slightly lower values, even thoug it does not show increased accuracy on the test data, this may indicate that this model overfits the training data. In this scenario *Identity* model seems to be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (f) Based on your result of (e) train 2 more Neural Networks with different settings (change at least 4 parameters (2 each)). Explain your parameters and the choice of the activation function. Evaluate the different Neural Networks with your test set by giving the accuracy. Try to increase the accuracy and analyse the factors that prohibit better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.94505095\n",
      "Iteration 2, loss = 4.92408843\n",
      "Iteration 3, loss = 4.89494011\n",
      "Iteration 4, loss = 4.85917418\n",
      "Iteration 5, loss = 4.81832329\n",
      "Iteration 6, loss = 4.77384489\n",
      "Iteration 7, loss = 4.72708879\n",
      "Iteration 8, loss = 4.67927124\n",
      "Iteration 9, loss = 4.63145581\n",
      "Iteration 10, loss = 4.58454116\n",
      "Iteration 11, loss = 4.53925610\n",
      "Iteration 12, loss = 4.49616175\n",
      "Iteration 13, loss = 4.45566027\n",
      "Iteration 14, loss = 4.41800897\n",
      "Iteration 15, loss = 4.38333847\n",
      "Iteration 16, loss = 4.35167317\n",
      "Iteration 17, loss = 4.32295259\n",
      "Iteration 18, loss = 4.29705189\n",
      "Iteration 19, loss = 4.27380089\n",
      "Iteration 20, loss = 4.25300047\n",
      "Iteration 21, loss = 4.23443639\n",
      "Iteration 22, loss = 4.21789017\n",
      "Iteration 23, loss = 4.20314736\n",
      "Iteration 24, loss = 4.19000351\n",
      "Iteration 25, loss = 4.17826802\n",
      "Iteration 26, loss = 4.16776652\n",
      "Iteration 27, loss = 4.15834188\n",
      "Iteration 28, loss = 4.14985431\n",
      "Iteration 29, loss = 4.14218083\n",
      "Iteration 30, loss = 4.13521422\n",
      "Iteration 31, loss = 4.12886174\n",
      "Iteration 32, loss = 4.12304367\n",
      "Iteration 33, loss = 4.11769182\n",
      "Iteration 34, loss = 4.11274809\n",
      "Iteration 35, loss = 4.10816305\n",
      "Iteration 36, loss = 4.10389469\n",
      "Iteration 37, loss = 4.09990724\n",
      "Iteration 38, loss = 4.09617016\n",
      "Iteration 39, loss = 4.09265724\n",
      "Iteration 40, loss = 4.08934586\n",
      "Iteration 41, loss = 4.08621632\n",
      "Iteration 42, loss = 4.08325135\n",
      "Iteration 43, loss = 4.08043563\n",
      "Iteration 44, loss = 4.07775551\n",
      "Iteration 45, loss = 4.07519866\n",
      "Iteration 46, loss = 4.07275390\n",
      "Iteration 47, loss = 4.07041103\n",
      "Iteration 48, loss = 4.06816071\n",
      "Iteration 49, loss = 4.06599433\n",
      "Iteration 50, loss = 4.06390398\n",
      "Iteration 51, loss = 4.06188238\n",
      "Iteration 52, loss = 4.05992283\n",
      "Iteration 53, loss = 4.05801918\n",
      "Iteration 54, loss = 4.05616579\n",
      "Iteration 55, loss = 4.05435752\n",
      "Iteration 56, loss = 4.05258970\n",
      "Iteration 57, loss = 4.05085806\n",
      "Iteration 58, loss = 4.04915877\n",
      "Iteration 59, loss = 4.04748837\n",
      "Iteration 60, loss = 4.04584375\n",
      "Iteration 61, loss = 4.04422213\n",
      "Iteration 62, loss = 4.04262100\n",
      "Iteration 63, loss = 4.04103816\n",
      "Iteration 64, loss = 4.03947162\n",
      "Iteration 65, loss = 4.03791962\n",
      "Iteration 66, loss = 4.03638060\n",
      "Iteration 67, loss = 4.03485316\n",
      "Iteration 68, loss = 4.03333606\n",
      "Iteration 69, loss = 4.03182821\n",
      "Iteration 70, loss = 4.03032863\n",
      "Iteration 71, loss = 4.02883643\n",
      "Iteration 72, loss = 4.02735086\n",
      "Iteration 73, loss = 4.02587120\n",
      "Iteration 74, loss = 4.02439685\n",
      "Iteration 75, loss = 4.02292724\n",
      "Iteration 76, loss = 4.02146189\n",
      "Iteration 77, loss = 4.02000035\n",
      "Iteration 78, loss = 4.01854222\n",
      "Iteration 79, loss = 4.01708714\n",
      "Iteration 80, loss = 4.01563481\n",
      "Iteration 81, loss = 4.01418493\n",
      "Iteration 82, loss = 4.01273725\n",
      "Iteration 83, loss = 4.01129154\n",
      "Iteration 84, loss = 4.00984760\n",
      "Iteration 85, loss = 4.00840523\n",
      "Iteration 86, loss = 4.00696427\n",
      "Iteration 87, loss = 4.00552457\n",
      "Iteration 88, loss = 4.00408599\n",
      "Iteration 89, loss = 4.00264841\n",
      "Iteration 90, loss = 4.00121171\n",
      "Iteration 91, loss = 3.99977578\n",
      "Iteration 92, loss = 3.99834052\n",
      "Iteration 93, loss = 3.99690586\n",
      "Iteration 94, loss = 3.99547169\n",
      "Iteration 95, loss = 3.99403795\n",
      "Iteration 96, loss = 3.99260455\n",
      "Iteration 97, loss = 3.99117144\n",
      "Iteration 98, loss = 3.98973853\n",
      "Iteration 99, loss = 3.98830578\n",
      "Iteration 100, loss = 3.98687312\n",
      "Iteration 101, loss = 3.98544050\n",
      "Iteration 102, loss = 3.98400787\n",
      "Iteration 103, loss = 3.98257518\n",
      "Iteration 104, loss = 3.98114239\n",
      "Iteration 105, loss = 3.97970947\n",
      "Iteration 106, loss = 3.97827637\n",
      "Iteration 107, loss = 3.97684306\n",
      "Iteration 108, loss = 3.97540952\n",
      "Iteration 109, loss = 3.97397573\n",
      "Iteration 110, loss = 3.97254166\n",
      "Iteration 111, loss = 3.97110729\n",
      "Iteration 112, loss = 3.96967263\n",
      "Iteration 113, loss = 3.96823765\n",
      "Iteration 114, loss = 3.96680237\n",
      "Iteration 115, loss = 3.96536677\n",
      "Iteration 116, loss = 3.96393086\n",
      "Iteration 117, loss = 3.96249466\n",
      "Iteration 118, loss = 3.96105817\n",
      "Iteration 119, loss = 3.95962141\n",
      "Iteration 120, loss = 3.95818440\n",
      "Iteration 121, loss = 3.95674717\n",
      "Iteration 122, loss = 3.95530973\n",
      "Iteration 123, loss = 3.95387214\n",
      "Iteration 124, loss = 3.95243441\n",
      "Iteration 125, loss = 3.95099658\n",
      "Iteration 126, loss = 3.94955871\n",
      "Iteration 127, loss = 3.94812082\n",
      "Iteration 128, loss = 3.94668297\n",
      "Iteration 129, loss = 3.94524521\n",
      "Iteration 130, loss = 3.94380760\n",
      "Iteration 131, loss = 3.94237019\n",
      "Iteration 132, loss = 3.94093303\n",
      "Iteration 133, loss = 3.93949620\n",
      "Iteration 134, loss = 3.93805975\n",
      "Iteration 135, loss = 3.93662376\n",
      "Iteration 136, loss = 3.93518830\n",
      "Iteration 137, loss = 3.93375343\n",
      "Iteration 138, loss = 3.93231924\n",
      "Iteration 139, loss = 3.93088579\n",
      "Iteration 140, loss = 3.92945319\n",
      "Iteration 141, loss = 3.92802149\n",
      "Iteration 142, loss = 3.92659080\n",
      "Iteration 143, loss = 3.92516120\n",
      "Iteration 144, loss = 3.92373277\n",
      "Iteration 145, loss = 3.92230561\n",
      "Iteration 146, loss = 3.92087981\n",
      "Iteration 147, loss = 3.91945546\n",
      "Iteration 148, loss = 3.91803267\n",
      "Iteration 149, loss = 3.91661154\n",
      "Iteration 150, loss = 3.91519215\n",
      "Iteration 151, loss = 3.91377462\n",
      "Iteration 152, loss = 3.91235905\n",
      "Iteration 153, loss = 3.91094554\n",
      "Iteration 154, loss = 3.90953420\n",
      "Iteration 155, loss = 3.90812514\n",
      "Iteration 156, loss = 3.90671846\n",
      "Iteration 157, loss = 3.90531429\n",
      "Iteration 158, loss = 3.90391271\n",
      "Iteration 159, loss = 3.90251386\n",
      "Iteration 160, loss = 3.90111784\n",
      "Iteration 161, loss = 3.89972476\n",
      "Iteration 162, loss = 3.89833475\n",
      "Iteration 163, loss = 3.89694790\n",
      "Iteration 164, loss = 3.89556435\n",
      "Iteration 165, loss = 3.89418421\n",
      "Iteration 166, loss = 3.89280758\n",
      "Iteration 167, loss = 3.89143460\n",
      "Iteration 168, loss = 3.89006537\n",
      "Iteration 169, loss = 3.88870001\n",
      "Iteration 170, loss = 3.88733863\n",
      "Iteration 171, loss = 3.88598137\n",
      "Iteration 172, loss = 3.88462832\n",
      "Iteration 173, loss = 3.88327960\n",
      "Iteration 174, loss = 3.88193534\n",
      "Iteration 175, loss = 3.88059565\n",
      "Iteration 176, loss = 3.87926063\n",
      "Iteration 177, loss = 3.87793041\n",
      "Iteration 178, loss = 3.87660510\n",
      "Iteration 179, loss = 3.87528480\n",
      "Iteration 180, loss = 3.87396963\n",
      "Iteration 181, loss = 3.87265970\n",
      "Iteration 182, loss = 3.87135512\n",
      "Iteration 183, loss = 3.87005599\n",
      "Iteration 184, loss = 3.86876243\n",
      "Iteration 185, loss = 3.86747453\n",
      "Iteration 186, loss = 3.86619240\n",
      "Iteration 187, loss = 3.86491613\n",
      "Iteration 188, loss = 3.86364584\n",
      "Iteration 189, loss = 3.86238162\n",
      "Iteration 190, loss = 3.86112356\n",
      "Iteration 191, loss = 3.85987176\n",
      "Iteration 192, loss = 3.85862632\n",
      "Iteration 193, loss = 3.85738732\n",
      "Iteration 194, loss = 3.85615484\n",
      "Iteration 195, loss = 3.85492899\n",
      "Iteration 196, loss = 3.85370984\n",
      "Iteration 197, loss = 3.85249747\n",
      "Iteration 198, loss = 3.85129196\n",
      "Iteration 199, loss = 3.85009339\n",
      "Iteration 200, loss = 3.84890184\n",
      "Iteration 201, loss = 3.84771738\n",
      "Iteration 202, loss = 3.84654008\n",
      "Iteration 203, loss = 3.84537000\n",
      "Iteration 204, loss = 3.84420721\n",
      "Iteration 205, loss = 3.84305177\n",
      "Iteration 206, loss = 3.84190374\n",
      "Iteration 207, loss = 3.84076318\n",
      "Iteration 208, loss = 3.83963015\n",
      "Iteration 209, loss = 3.83850469\n",
      "Iteration 210, loss = 3.83738685\n",
      "Iteration 211, loss = 3.83627667\n",
      "Iteration 212, loss = 3.83517421\n",
      "Iteration 213, loss = 3.83407951\n",
      "Iteration 214, loss = 3.83299259\n",
      "Iteration 215, loss = 3.83191350\n",
      "Iteration 216, loss = 3.83084226\n",
      "Iteration 217, loss = 3.82977891\n",
      "Iteration 218, loss = 3.82872347\n",
      "Iteration 219, loss = 3.82767597\n",
      "Iteration 220, loss = 3.82663643\n",
      "Iteration 221, loss = 3.82560486\n",
      "Iteration 222, loss = 3.82458128\n",
      "Iteration 223, loss = 3.82356571\n",
      "Iteration 224, loss = 3.82255815\n",
      "Iteration 225, loss = 3.82155861\n",
      "Iteration 226, loss = 3.82056710\n",
      "Iteration 227, loss = 3.81958362\n",
      "Iteration 228, loss = 3.81860816\n",
      "Iteration 229, loss = 3.81764073\n",
      "Iteration 230, loss = 3.81668132\n",
      "Iteration 231, loss = 3.81572993\n",
      "Iteration 232, loss = 3.81478653\n",
      "Iteration 233, loss = 3.81385113\n",
      "Iteration 234, loss = 3.81292370\n",
      "Iteration 235, loss = 3.81200422\n",
      "Iteration 236, loss = 3.81109269\n",
      "Iteration 237, loss = 3.81018907\n",
      "Iteration 238, loss = 3.80929334\n",
      "Iteration 239, loss = 3.80840548\n",
      "Iteration 240, loss = 3.80752545\n",
      "Iteration 241, loss = 3.80665323\n",
      "Iteration 242, loss = 3.80578879\n",
      "Iteration 243, loss = 3.80493209\n",
      "Iteration 244, loss = 3.80408309\n",
      "Iteration 245, loss = 3.80324176\n",
      "Iteration 246, loss = 3.80240806\n",
      "Iteration 247, loss = 3.80158195\n",
      "Iteration 248, loss = 3.80076338\n",
      "Iteration 249, loss = 3.79995231\n",
      "Iteration 250, loss = 3.79914869\n",
      "Iteration 251, loss = 3.79835248\n",
      "Iteration 252, loss = 3.79756362\n",
      "Iteration 253, loss = 3.79678208\n",
      "Iteration 254, loss = 3.79600779\n",
      "Iteration 255, loss = 3.79524070\n",
      "Iteration 256, loss = 3.79448077\n",
      "Iteration 257, loss = 3.79372792\n",
      "Iteration 258, loss = 3.79298212\n",
      "Iteration 259, loss = 3.79224329\n",
      "Iteration 260, loss = 3.79151139\n",
      "Iteration 261, loss = 3.79078636\n",
      "Iteration 262, loss = 3.79006812\n",
      "Iteration 263, loss = 3.78935663\n",
      "Iteration 264, loss = 3.78865182\n",
      "Iteration 265, loss = 3.78795364\n",
      "Iteration 266, loss = 3.78726200\n",
      "Iteration 267, loss = 3.78657687\n",
      "Iteration 268, loss = 3.78589816\n",
      "Iteration 269, loss = 3.78522581\n",
      "Iteration 270, loss = 3.78455977\n",
      "Iteration 271, loss = 3.78389996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 272, loss = 3.78324631\n",
      "Iteration 273, loss = 3.78259877\n",
      "Iteration 274, loss = 3.78195727\n",
      "Iteration 275, loss = 3.78132174\n",
      "Iteration 276, loss = 3.78069210\n",
      "Iteration 277, loss = 3.78006831\n",
      "Iteration 278, loss = 3.77945028\n",
      "Iteration 279, loss = 3.77883795\n",
      "Iteration 280, loss = 3.77823126\n",
      "Iteration 281, loss = 3.77763013\n",
      "Iteration 282, loss = 3.77703451\n",
      "Iteration 283, loss = 3.77644431\n",
      "Iteration 284, loss = 3.77585948\n",
      "Iteration 285, loss = 3.77527995\n",
      "Iteration 286, loss = 3.77470565\n",
      "Iteration 287, loss = 3.77413651\n",
      "Iteration 288, loss = 3.77357248\n",
      "Iteration 289, loss = 3.77301347\n",
      "Iteration 290, loss = 3.77245943\n",
      "Iteration 291, loss = 3.77191029\n",
      "Iteration 292, loss = 3.77136598\n",
      "Iteration 293, loss = 3.77082645\n",
      "Iteration 294, loss = 3.77029162\n",
      "Iteration 295, loss = 3.76976143\n",
      "Iteration 296, loss = 3.76923582\n",
      "Iteration 297, loss = 3.76871472\n",
      "Iteration 298, loss = 3.76819807\n",
      "Iteration 299, loss = 3.76768581\n",
      "Iteration 300, loss = 3.76717787\n",
      "Iteration 301, loss = 3.76667420\n",
      "Iteration 302, loss = 3.76617474\n",
      "Iteration 303, loss = 3.76567941\n",
      "Iteration 304, loss = 3.76518817\n",
      "Iteration 305, loss = 3.76470095\n",
      "Iteration 306, loss = 3.76421769\n",
      "Iteration 307, loss = 3.76373834\n",
      "Iteration 308, loss = 3.76326284\n",
      "Iteration 309, loss = 3.76279113\n",
      "Iteration 310, loss = 3.76232315\n",
      "Iteration 311, loss = 3.76185885\n",
      "Iteration 312, loss = 3.76139816\n",
      "Iteration 313, loss = 3.76094105\n",
      "Iteration 314, loss = 3.76048745\n",
      "Iteration 315, loss = 3.76003731\n",
      "Iteration 316, loss = 3.75959058\n",
      "Iteration 317, loss = 3.75914719\n",
      "Iteration 318, loss = 3.75870711\n",
      "Iteration 319, loss = 3.75827029\n",
      "Iteration 320, loss = 3.75783666\n",
      "Iteration 321, loss = 3.75740618\n",
      "Iteration 322, loss = 3.75697880\n",
      "Iteration 323, loss = 3.75655448\n",
      "Iteration 324, loss = 3.75613316\n",
      "Iteration 325, loss = 3.75571480\n",
      "Iteration 326, loss = 3.75529935\n",
      "Iteration 327, loss = 3.75488676\n",
      "Iteration 328, loss = 3.75447699\n",
      "Iteration 329, loss = 3.75407000\n",
      "Iteration 330, loss = 3.75366574\n",
      "Iteration 331, loss = 3.75326416\n",
      "Iteration 332, loss = 3.75286523\n",
      "Iteration 333, loss = 3.75246890\n",
      "Iteration 334, loss = 3.75207513\n",
      "Iteration 335, loss = 3.75168389\n",
      "Iteration 336, loss = 3.75129512\n",
      "Iteration 337, loss = 3.75090878\n",
      "Iteration 338, loss = 3.75052485\n",
      "Iteration 339, loss = 3.75014328\n",
      "Iteration 340, loss = 3.74976404\n",
      "Iteration 341, loss = 3.74938708\n",
      "Iteration 342, loss = 3.74901237\n",
      "Iteration 343, loss = 3.74863987\n",
      "Iteration 344, loss = 3.74826956\n",
      "Iteration 345, loss = 3.74790138\n",
      "Iteration 346, loss = 3.74753531\n",
      "Iteration 347, loss = 3.74717132\n",
      "Iteration 348, loss = 3.74680937\n",
      "Iteration 349, loss = 3.74644942\n",
      "Iteration 350, loss = 3.74609145\n",
      "Iteration 351, loss = 3.74573543\n",
      "Iteration 352, loss = 3.74538132\n",
      "Iteration 353, loss = 3.74502909\n",
      "Iteration 354, loss = 3.74467872\n",
      "Iteration 355, loss = 3.74433016\n",
      "Iteration 356, loss = 3.74398340\n",
      "Iteration 357, loss = 3.74363841\n",
      "Iteration 358, loss = 3.74329515\n",
      "Iteration 359, loss = 3.74295360\n",
      "Iteration 360, loss = 3.74261373\n",
      "Iteration 361, loss = 3.74227552\n",
      "Iteration 362, loss = 3.74193894\n",
      "Iteration 363, loss = 3.74160396\n",
      "Iteration 364, loss = 3.74127056\n",
      "Iteration 365, loss = 3.74093871\n",
      "Iteration 366, loss = 3.74060839\n",
      "Iteration 367, loss = 3.74027958\n",
      "Iteration 368, loss = 3.73995225\n",
      "Iteration 369, loss = 3.73962637\n",
      "Iteration 370, loss = 3.73930193\n",
      "Iteration 371, loss = 3.73897890\n",
      "Iteration 372, loss = 3.73865727\n",
      "Iteration 373, loss = 3.73833700\n",
      "Iteration 374, loss = 3.73801809\n",
      "Iteration 375, loss = 3.73770050\n",
      "Iteration 376, loss = 3.73738421\n",
      "Iteration 377, loss = 3.73706922\n",
      "Iteration 378, loss = 3.73675549\n",
      "Iteration 379, loss = 3.73644301\n",
      "Iteration 380, loss = 3.73613177\n",
      "Iteration 381, loss = 3.73582173\n",
      "Iteration 382, loss = 3.73551288\n",
      "Iteration 383, loss = 3.73520521\n",
      "Iteration 384, loss = 3.73489870\n",
      "Iteration 385, loss = 3.73459333\n",
      "Iteration 386, loss = 3.73428908\n",
      "Iteration 387, loss = 3.73398594\n",
      "Iteration 388, loss = 3.73368389\n",
      "Iteration 389, loss = 3.73338291\n",
      "Iteration 390, loss = 3.73308299\n",
      "Iteration 391, loss = 3.73278412\n",
      "Iteration 392, loss = 3.73248627\n",
      "Iteration 393, loss = 3.73218943\n",
      "Iteration 394, loss = 3.73189360\n",
      "Iteration 395, loss = 3.73159875\n",
      "Iteration 396, loss = 3.73130487\n",
      "Iteration 397, loss = 3.73101194\n",
      "Iteration 398, loss = 3.73071996\n",
      "Iteration 399, loss = 3.73042891\n",
      "Iteration 400, loss = 3.73013878\n",
      "Iteration 401, loss = 3.72984955\n",
      "Iteration 402, loss = 3.72956121\n",
      "Iteration 403, loss = 3.72927375\n",
      "Iteration 404, loss = 3.72898716\n",
      "Iteration 405, loss = 3.72870142\n",
      "Iteration 406, loss = 3.72841653\n",
      "Iteration 407, loss = 3.72813247\n",
      "Iteration 408, loss = 3.72784923\n",
      "Iteration 409, loss = 3.72756680\n",
      "Iteration 410, loss = 3.72728517\n",
      "Iteration 411, loss = 3.72700433\n",
      "Iteration 412, loss = 3.72672427\n",
      "Iteration 413, loss = 3.72644498\n",
      "Iteration 414, loss = 3.72616644\n",
      "Iteration 415, loss = 3.72588866\n",
      "Iteration 416, loss = 3.72561161\n",
      "Iteration 417, loss = 3.72533529\n",
      "Iteration 418, loss = 3.72505969\n",
      "Iteration 419, loss = 3.72478481\n",
      "Iteration 420, loss = 3.72451062\n",
      "Iteration 421, loss = 3.72423713\n",
      "Iteration 422, loss = 3.72396432\n",
      "Iteration 423, loss = 3.72369219\n",
      "Iteration 424, loss = 3.72342073\n",
      "Iteration 425, loss = 3.72314993\n",
      "Iteration 426, loss = 3.72287977\n",
      "Iteration 427, loss = 3.72261027\n",
      "Iteration 428, loss = 3.72234140\n",
      "Iteration 429, loss = 3.72207316\n",
      "Iteration 430, loss = 3.72180553\n",
      "Iteration 431, loss = 3.72153853\n",
      "Iteration 432, loss = 3.72127213\n",
      "Iteration 433, loss = 3.72100633\n",
      "Iteration 434, loss = 3.72074112\n",
      "Iteration 435, loss = 3.72047650\n",
      "Iteration 436, loss = 3.72021246\n",
      "Iteration 437, loss = 3.71994899\n",
      "Iteration 438, loss = 3.71968609\n",
      "Iteration 439, loss = 3.71942375\n",
      "Iteration 440, loss = 3.71916196\n",
      "Iteration 441, loss = 3.71890072\n",
      "Iteration 442, loss = 3.71864003\n",
      "Iteration 443, loss = 3.71837987\n",
      "Iteration 444, loss = 3.71812024\n",
      "Iteration 445, loss = 3.71786113\n",
      "Iteration 446, loss = 3.71760255\n",
      "Iteration 447, loss = 3.71734448\n",
      "Iteration 448, loss = 3.71708691\n",
      "Iteration 449, loss = 3.71682986\n",
      "Iteration 450, loss = 3.71657329\n",
      "Iteration 451, loss = 3.71631723\n",
      "Iteration 452, loss = 3.71606165\n",
      "Iteration 453, loss = 3.71580655\n",
      "Iteration 454, loss = 3.71555193\n",
      "Iteration 455, loss = 3.71529779\n",
      "Iteration 456, loss = 3.71504411\n",
      "Iteration 457, loss = 3.71479090\n",
      "Iteration 458, loss = 3.71453815\n",
      "Iteration 459, loss = 3.71428586\n",
      "Iteration 460, loss = 3.71403402\n",
      "Iteration 461, loss = 3.71378262\n",
      "Iteration 462, loss = 3.71353167\n",
      "Iteration 463, loss = 3.71328115\n",
      "Iteration 464, loss = 3.71303108\n",
      "Iteration 465, loss = 3.71278143\n",
      "Iteration 466, loss = 3.71253221\n",
      "Iteration 467, loss = 3.71228341\n",
      "Iteration 468, loss = 3.71203503\n",
      "Iteration 469, loss = 3.71178707\n",
      "Iteration 470, loss = 3.71153952\n",
      "Iteration 471, loss = 3.71129238\n",
      "Iteration 472, loss = 3.71104564\n",
      "Iteration 473, loss = 3.71079931\n",
      "Iteration 474, loss = 3.71055337\n",
      "Iteration 475, loss = 3.71030783\n",
      "Iteration 476, loss = 3.71006268\n",
      "Iteration 477, loss = 3.70981792\n",
      "Iteration 478, loss = 3.70957355\n",
      "Iteration 479, loss = 3.70932956\n",
      "Iteration 480, loss = 3.70908594\n",
      "Iteration 481, loss = 3.70884271\n",
      "Iteration 482, loss = 3.70859984\n",
      "Iteration 483, loss = 3.70835735\n",
      "Iteration 484, loss = 3.70811522\n",
      "Iteration 485, loss = 3.70787346\n",
      "Iteration 486, loss = 3.70763207\n",
      "Iteration 487, loss = 3.70739103\n",
      "Iteration 488, loss = 3.70715034\n",
      "Iteration 489, loss = 3.70691001\n",
      "Iteration 490, loss = 3.70667004\n",
      "Iteration 491, loss = 3.70643041\n",
      "Iteration 492, loss = 3.70619113\n",
      "Iteration 493, loss = 3.70595219\n",
      "Iteration 494, loss = 3.70571359\n",
      "Iteration 495, loss = 3.70547534\n",
      "Iteration 496, loss = 3.70523742\n",
      "Iteration 497, loss = 3.70499983\n",
      "Iteration 498, loss = 3.70476258\n",
      "Iteration 499, loss = 3.70452566\n",
      "Iteration 500, loss = 3.70428906\n",
      "Iteration 501, loss = 3.70405279\n",
      "Iteration 502, loss = 3.70381685\n",
      "Iteration 503, loss = 3.70358122\n",
      "Iteration 504, loss = 3.70334592\n",
      "Iteration 505, loss = 3.70311093\n",
      "Iteration 506, loss = 3.70287626\n",
      "Iteration 507, loss = 3.70264191\n",
      "Iteration 508, loss = 3.70240786\n",
      "Iteration 509, loss = 3.70217413\n",
      "Iteration 510, loss = 3.70194070\n",
      "Iteration 511, loss = 3.70170758\n",
      "Iteration 512, loss = 3.70147476\n",
      "Iteration 513, loss = 3.70124225\n",
      "Iteration 514, loss = 3.70101003\n",
      "Iteration 515, loss = 3.70077812\n",
      "Iteration 516, loss = 3.70054650\n",
      "Iteration 517, loss = 3.70031518\n",
      "Iteration 518, loss = 3.70008416\n",
      "Iteration 519, loss = 3.69985342\n",
      "Iteration 520, loss = 3.69962298\n",
      "Iteration 521, loss = 3.69939283\n",
      "Iteration 522, loss = 3.69916296\n",
      "Iteration 523, loss = 3.69893339\n",
      "Iteration 524, loss = 3.69870409\n",
      "Iteration 525, loss = 3.69847508\n",
      "Iteration 526, loss = 3.69824636\n",
      "Iteration 527, loss = 3.69801791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 528, loss = 3.69778974\n",
      "Iteration 529, loss = 3.69756185\n",
      "Iteration 530, loss = 3.69733424\n",
      "Iteration 531, loss = 3.69710690\n",
      "Iteration 532, loss = 3.69687984\n",
      "Iteration 533, loss = 3.69665305\n",
      "Iteration 534, loss = 3.69642653\n",
      "Iteration 535, loss = 3.69620028\n",
      "Iteration 536, loss = 3.69597430\n",
      "Iteration 537, loss = 3.69574859\n",
      "Iteration 538, loss = 3.69552315\n",
      "Iteration 539, loss = 3.69529797\n",
      "Iteration 540, loss = 3.69507305\n",
      "Iteration 541, loss = 3.69484840\n",
      "Iteration 542, loss = 3.69462401\n",
      "Iteration 543, loss = 3.69439988\n",
      "Iteration 544, loss = 3.69417601\n",
      "Iteration 545, loss = 3.69395240\n",
      "Iteration 546, loss = 3.69372905\n",
      "Iteration 547, loss = 3.69350596\n",
      "Iteration 548, loss = 3.69328312\n",
      "Iteration 549, loss = 3.69306053\n",
      "Iteration 550, loss = 3.69283820\n",
      "Iteration 551, loss = 3.69261612\n",
      "Iteration 552, loss = 3.69239430\n",
      "Iteration 553, loss = 3.69217272\n",
      "Iteration 554, loss = 3.69195139\n",
      "Iteration 555, loss = 3.69173032\n",
      "Iteration 556, loss = 3.69150949\n",
      "Iteration 557, loss = 3.69128891\n",
      "Iteration 558, loss = 3.69106858\n",
      "Iteration 559, loss = 3.69084849\n",
      "Iteration 560, loss = 3.69062864\n",
      "Iteration 561, loss = 3.69040904\n",
      "Iteration 562, loss = 3.69018969\n",
      "Iteration 563, loss = 3.68997057\n",
      "Iteration 564, loss = 3.68975170\n",
      "Iteration 565, loss = 3.68953307\n",
      "Iteration 566, loss = 3.68931467\n",
      "Iteration 567, loss = 3.68909652\n",
      "Iteration 568, loss = 3.68887861\n",
      "Iteration 569, loss = 3.68866093\n",
      "Iteration 570, loss = 3.68844349\n",
      "Iteration 571, loss = 3.68822629\n",
      "Iteration 572, loss = 3.68800932\n",
      "Iteration 573, loss = 3.68779258\n",
      "Iteration 574, loss = 3.68757608\n",
      "Iteration 575, loss = 3.68735982\n",
      "Iteration 576, loss = 3.68714379\n",
      "Iteration 577, loss = 3.68692798\n",
      "Iteration 578, loss = 3.68671242\n",
      "Iteration 579, loss = 3.68649708\n",
      "Iteration 580, loss = 3.68628197\n",
      "Iteration 581, loss = 3.68606709\n",
      "Iteration 582, loss = 3.68585244\n",
      "Iteration 583, loss = 3.68563802\n",
      "Iteration 584, loss = 3.68542383\n",
      "Iteration 585, loss = 3.68520986\n",
      "Iteration 586, loss = 3.68499612\n",
      "Iteration 587, loss = 3.68478261\n",
      "Iteration 588, loss = 3.68456932\n",
      "Iteration 589, loss = 3.68435626\n",
      "Iteration 590, loss = 3.68414342\n",
      "Iteration 591, loss = 3.68393080\n",
      "Iteration 592, loss = 3.68371841\n",
      "Iteration 593, loss = 3.68350624\n",
      "Iteration 594, loss = 3.68329430\n",
      "Iteration 595, loss = 3.68308257\n",
      "Iteration 596, loss = 3.68287107\n",
      "Iteration 597, loss = 3.68265979\n",
      "Iteration 598, loss = 3.68244872\n",
      "Iteration 599, loss = 3.68223788\n",
      "Iteration 600, loss = 3.68202726\n",
      "Iteration 601, loss = 3.68181685\n",
      "Iteration 602, loss = 3.68160667\n",
      "Iteration 603, loss = 3.68139670\n",
      "Iteration 604, loss = 3.68118695\n",
      "Iteration 605, loss = 3.68097742\n",
      "Iteration 606, loss = 3.68076810\n",
      "Iteration 607, loss = 3.68055900\n",
      "Iteration 608, loss = 3.68035011\n",
      "Iteration 609, loss = 3.68014144\n",
      "Iteration 610, loss = 3.67993299\n",
      "Iteration 611, loss = 3.67972475\n",
      "Iteration 612, loss = 3.67951672\n",
      "Iteration 613, loss = 3.67930891\n",
      "Iteration 614, loss = 3.67910131\n",
      "Iteration 615, loss = 3.67889392\n",
      "Iteration 616, loss = 3.67868675\n",
      "Iteration 617, loss = 3.67847978\n",
      "Iteration 618, loss = 3.67827303\n",
      "Iteration 619, loss = 3.67806649\n",
      "Iteration 620, loss = 3.67786016\n",
      "Iteration 621, loss = 3.67765405\n",
      "Iteration 622, loss = 3.67744814\n",
      "Iteration 623, loss = 3.67724244\n",
      "Iteration 624, loss = 3.67703695\n",
      "Iteration 625, loss = 3.67683167\n",
      "Iteration 626, loss = 3.67662660\n",
      "Iteration 627, loss = 3.67642174\n",
      "Iteration 628, loss = 3.67621708\n",
      "Iteration 629, loss = 3.67601263\n",
      "Iteration 630, loss = 3.67580839\n",
      "Iteration 631, loss = 3.67560436\n",
      "Iteration 632, loss = 3.67540054\n",
      "Iteration 633, loss = 3.67519692\n",
      "Iteration 634, loss = 3.67499350\n",
      "Iteration 635, loss = 3.67479029\n",
      "Iteration 636, loss = 3.67458729\n",
      "Iteration 637, loss = 3.67438449\n",
      "Iteration 638, loss = 3.67418190\n",
      "Iteration 639, loss = 3.67397951\n",
      "Iteration 640, loss = 3.67377732\n",
      "Iteration 641, loss = 3.67357534\n",
      "Iteration 642, loss = 3.67337357\n",
      "Iteration 643, loss = 3.67317199\n",
      "Iteration 644, loss = 3.67297062\n",
      "Iteration 645, loss = 3.67276945\n",
      "Iteration 646, loss = 3.67256849\n",
      "Iteration 647, loss = 3.67236772\n",
      "Iteration 648, loss = 3.67216716\n",
      "Iteration 649, loss = 3.67196680\n",
      "Iteration 650, loss = 3.67176664\n",
      "Iteration 651, loss = 3.67156668\n",
      "Iteration 652, loss = 3.67136692\n",
      "Iteration 653, loss = 3.67116736\n",
      "Iteration 654, loss = 3.67096800\n",
      "Iteration 655, loss = 3.67076884\n",
      "Iteration 656, loss = 3.67056988\n",
      "Iteration 657, loss = 3.67037112\n",
      "Iteration 658, loss = 3.67017256\n",
      "Iteration 659, loss = 3.66997420\n",
      "Iteration 660, loss = 3.66977603\n",
      "Iteration 661, loss = 3.66957806\n",
      "Iteration 662, loss = 3.66938030\n",
      "Iteration 663, loss = 3.66918272\n",
      "Iteration 664, loss = 3.66898535\n",
      "Iteration 665, loss = 3.66878817\n",
      "Iteration 666, loss = 3.66859119\n",
      "Iteration 667, loss = 3.66839441\n",
      "Iteration 668, loss = 3.66819782\n",
      "Iteration 669, loss = 3.66800143\n",
      "Iteration 670, loss = 3.66780524\n",
      "Iteration 671, loss = 3.66760923\n",
      "Iteration 672, loss = 3.66741343\n",
      "Iteration 673, loss = 3.66721782\n",
      "Iteration 674, loss = 3.66702240\n",
      "Iteration 675, loss = 3.66682718\n",
      "Iteration 676, loss = 3.66663216\n",
      "Iteration 677, loss = 3.66643732\n",
      "Iteration 678, loss = 3.66624268\n",
      "Iteration 679, loss = 3.66604824\n",
      "Iteration 680, loss = 3.66585398\n",
      "Iteration 681, loss = 3.66565992\n",
      "Iteration 682, loss = 3.66546606\n",
      "Iteration 683, loss = 3.66527238\n",
      "Iteration 684, loss = 3.66507890\n",
      "Iteration 685, loss = 3.66488561\n",
      "Iteration 686, loss = 3.66469251\n",
      "Iteration 687, loss = 3.66449960\n",
      "Iteration 688, loss = 3.66430689\n",
      "Iteration 689, loss = 3.66411436\n",
      "Iteration 690, loss = 3.66392203\n",
      "Iteration 691, loss = 3.66372988\n",
      "Iteration 692, loss = 3.66353793\n",
      "Iteration 693, loss = 3.66334616\n",
      "Iteration 694, loss = 3.66315459\n",
      "Iteration 695, loss = 3.66296320\n",
      "Iteration 696, loss = 3.66277201\n",
      "Iteration 697, loss = 3.66258100\n",
      "Iteration 698, loss = 3.66239018\n",
      "Iteration 699, loss = 3.66219955\n",
      "Iteration 700, loss = 3.66200911\n",
      "Iteration 701, loss = 3.66181886\n",
      "Iteration 702, loss = 3.66162879\n",
      "Iteration 703, loss = 3.66143891\n",
      "Iteration 704, loss = 3.66124922\n",
      "Iteration 705, loss = 3.66105972\n",
      "Iteration 706, loss = 3.66087040\n",
      "Iteration 707, loss = 3.66068127\n",
      "Iteration 708, loss = 3.66049233\n",
      "Iteration 709, loss = 3.66030357\n",
      "Iteration 710, loss = 3.66011499\n",
      "Iteration 711, loss = 3.65992661\n",
      "Iteration 712, loss = 3.65973840\n",
      "Iteration 713, loss = 3.65955039\n",
      "Iteration 714, loss = 3.65936255\n",
      "Iteration 715, loss = 3.65917491\n",
      "Iteration 716, loss = 3.65898744\n",
      "Iteration 717, loss = 3.65880016\n",
      "Iteration 718, loss = 3.65861307\n",
      "Iteration 719, loss = 3.65842616\n",
      "Iteration 720, loss = 3.65823943\n",
      "Iteration 721, loss = 3.65805288\n",
      "Iteration 722, loss = 3.65786652\n",
      "Iteration 723, loss = 3.65768034\n",
      "Iteration 724, loss = 3.65749434\n",
      "Iteration 725, loss = 3.65730852\n",
      "Iteration 726, loss = 3.65712289\n",
      "Iteration 727, loss = 3.65693744\n",
      "Iteration 728, loss = 3.65675216\n",
      "Iteration 729, loss = 3.65656707\n",
      "Iteration 730, loss = 3.65638216\n",
      "Iteration 731, loss = 3.65619743\n",
      "Iteration 732, loss = 3.65601288\n",
      "Iteration 733, loss = 3.65582852\n",
      "Iteration 734, loss = 3.65564433\n",
      "Iteration 735, loss = 3.65546032\n",
      "Iteration 736, loss = 3.65527648\n",
      "Iteration 737, loss = 3.65509283\n",
      "Iteration 738, loss = 3.65490936\n",
      "Iteration 739, loss = 3.65472606\n",
      "Iteration 740, loss = 3.65454295\n",
      "Iteration 741, loss = 3.65436001\n",
      "Iteration 742, loss = 3.65417725\n",
      "Iteration 743, loss = 3.65399466\n",
      "Iteration 744, loss = 3.65381226\n",
      "Iteration 745, loss = 3.65363003\n",
      "Iteration 746, loss = 3.65344797\n",
      "Iteration 747, loss = 3.65326610\n",
      "Iteration 748, loss = 3.65308440\n",
      "Iteration 749, loss = 3.65290287\n",
      "Iteration 750, loss = 3.65272152\n",
      "Iteration 751, loss = 3.65254035\n",
      "Iteration 752, loss = 3.65235935\n",
      "Iteration 753, loss = 3.65217852\n",
      "Iteration 754, loss = 3.65199787\n",
      "Iteration 755, loss = 3.65181740\n",
      "Iteration 756, loss = 3.65163710\n",
      "Iteration 757, loss = 3.65145697\n",
      "Iteration 758, loss = 3.65127701\n",
      "Iteration 759, loss = 3.65109723\n",
      "Iteration 760, loss = 3.65091762\n",
      "Iteration 761, loss = 3.65073818\n",
      "Iteration 762, loss = 3.65055892\n",
      "Iteration 763, loss = 3.65037983\n",
      "Iteration 764, loss = 3.65020091\n",
      "Iteration 765, loss = 3.65002216\n",
      "Iteration 766, loss = 3.64984358\n",
      "Iteration 767, loss = 3.64966517\n",
      "Iteration 768, loss = 3.64948693\n",
      "Iteration 769, loss = 3.64930887\n",
      "Iteration 770, loss = 3.64913097\n",
      "Iteration 771, loss = 3.64895324\n",
      "Iteration 772, loss = 3.64877569\n",
      "Iteration 773, loss = 3.64859830\n",
      "Iteration 774, loss = 3.64842108\n",
      "Iteration 775, loss = 3.64824403\n",
      "Iteration 776, loss = 3.64806715\n",
      "Iteration 777, loss = 3.64789043\n",
      "Iteration 778, loss = 3.64771388\n",
      "Iteration 779, loss = 3.64753751\n",
      "Iteration 780, loss = 3.64736129\n",
      "Iteration 781, loss = 3.64718525\n",
      "Iteration 782, loss = 3.64700937\n",
      "Iteration 783, loss = 3.64683366\n",
      "Iteration 784, loss = 3.64665811\n",
      "Iteration 785, loss = 3.64648273\n",
      "Iteration 786, loss = 3.64630751\n",
      "Iteration 787, loss = 3.64613246\n",
      "Iteration 788, loss = 3.64595758\n",
      "Iteration 789, loss = 3.64578286\n",
      "Iteration 790, loss = 3.64560830\n",
      "Iteration 791, loss = 3.64543391\n",
      "Iteration 792, loss = 3.64525968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 793, loss = 3.64508561\n",
      "Iteration 794, loss = 3.64491171\n",
      "Iteration 795, loss = 3.64473797\n",
      "Iteration 796, loss = 3.64456439\n",
      "Iteration 797, loss = 3.64439098\n",
      "Iteration 798, loss = 3.64421772\n",
      "Iteration 799, loss = 3.64404463\n",
      "Iteration 800, loss = 3.64387170\n",
      "Iteration 801, loss = 3.64369893\n",
      "Iteration 802, loss = 3.64352632\n",
      "Iteration 803, loss = 3.64335387\n",
      "Iteration 804, loss = 3.64318158\n",
      "Iteration 805, loss = 3.64300945\n",
      "Iteration 806, loss = 3.64283748\n",
      "Iteration 807, loss = 3.64266567\n",
      "Iteration 808, loss = 3.64249402\n",
      "Iteration 809, loss = 3.64232252\n",
      "Iteration 810, loss = 3.64215119\n",
      "Iteration 811, loss = 3.64198001\n",
      "Iteration 812, loss = 3.64180899\n",
      "Iteration 813, loss = 3.64163813\n",
      "Iteration 814, loss = 3.64146742\n",
      "Iteration 815, loss = 3.64129687\n",
      "Iteration 816, loss = 3.64112648\n",
      "Iteration 817, loss = 3.64095624\n",
      "Iteration 818, loss = 3.64078616\n",
      "Iteration 819, loss = 3.64061623\n",
      "Iteration 820, loss = 3.64044646\n",
      "Iteration 821, loss = 3.64027684\n",
      "Iteration 822, loss = 3.64010738\n",
      "Iteration 823, loss = 3.63993807\n",
      "Iteration 824, loss = 3.63976892\n",
      "Iteration 825, loss = 3.63959992\n",
      "Iteration 826, loss = 3.63943107\n",
      "Iteration 827, loss = 3.63926237\n",
      "Iteration 828, loss = 3.63909383\n",
      "Iteration 829, loss = 3.63892544\n",
      "Iteration 830, loss = 3.63875720\n",
      "Iteration 831, loss = 3.63858911\n",
      "Iteration 832, loss = 3.63842118\n",
      "Iteration 833, loss = 3.63825339\n",
      "Iteration 834, loss = 3.63808576\n",
      "Iteration 835, loss = 3.63791827\n",
      "Iteration 836, loss = 3.63775094\n",
      "Iteration 837, loss = 3.63758375\n",
      "Iteration 838, loss = 3.63741672\n",
      "Iteration 839, loss = 3.63724983\n",
      "Iteration 840, loss = 3.63708309\n",
      "Iteration 841, loss = 3.63691650\n",
      "Iteration 842, loss = 3.63675006\n",
      "Iteration 843, loss = 3.63658376\n",
      "Iteration 844, loss = 3.63641762\n",
      "Iteration 845, loss = 3.63625162\n",
      "Iteration 846, loss = 3.63608576\n",
      "Iteration 847, loss = 3.63592006\n",
      "Iteration 848, loss = 3.63575450\n",
      "Iteration 849, loss = 3.63558908\n",
      "Iteration 850, loss = 3.63542381\n",
      "Iteration 851, loss = 3.63525869\n",
      "Iteration 852, loss = 3.63509371\n",
      "Iteration 853, loss = 3.63492887\n",
      "Iteration 854, loss = 3.63476418\n",
      "Iteration 855, loss = 3.63459963\n",
      "Iteration 856, loss = 3.63443523\n",
      "Iteration 857, loss = 3.63427096\n",
      "Iteration 858, loss = 3.63410684\n",
      "Iteration 859, loss = 3.63394287\n",
      "Iteration 860, loss = 3.63377903\n",
      "Iteration 861, loss = 3.63361534\n",
      "Iteration 862, loss = 3.63345179\n",
      "Iteration 863, loss = 3.63328838\n",
      "Iteration 864, loss = 3.63312511\n",
      "Iteration 865, loss = 3.63296198\n",
      "Iteration 866, loss = 3.63279899\n",
      "Iteration 867, loss = 3.63263614\n",
      "Iteration 868, loss = 3.63247343\n",
      "Iteration 869, loss = 3.63231086\n",
      "Iteration 870, loss = 3.63214843\n",
      "Iteration 871, loss = 3.63198614\n",
      "Iteration 872, loss = 3.63182398\n",
      "Iteration 873, loss = 3.63166197\n",
      "Iteration 874, loss = 3.63150009\n",
      "Iteration 875, loss = 3.63133834\n",
      "Iteration 876, loss = 3.63117674\n",
      "Iteration 877, loss = 3.63101527\n",
      "Iteration 878, loss = 3.63085393\n",
      "Iteration 879, loss = 3.63069274\n",
      "Iteration 880, loss = 3.63053167\n",
      "Iteration 881, loss = 3.63037075\n",
      "Iteration 882, loss = 3.63020995\n",
      "Iteration 883, loss = 3.63004930\n",
      "Iteration 884, loss = 3.62988877\n",
      "Iteration 885, loss = 3.62972838\n",
      "Iteration 886, loss = 3.62956813\n",
      "Iteration 887, loss = 3.62940800\n",
      "Iteration 888, loss = 3.62924801\n",
      "Iteration 889, loss = 3.62908815\n",
      "Iteration 890, loss = 3.62892843\n",
      "Iteration 891, loss = 3.62876884\n",
      "Iteration 892, loss = 3.62860937\n",
      "Iteration 893, loss = 3.62845004\n",
      "Iteration 894, loss = 3.62829084\n",
      "Iteration 895, loss = 3.62813177\n",
      "Iteration 896, loss = 3.62797283\n",
      "Iteration 897, loss = 3.62781402\n",
      "Iteration 898, loss = 3.62765534\n",
      "Iteration 899, loss = 3.62749679\n",
      "Iteration 900, loss = 3.62733837\n",
      "Iteration 901, loss = 3.62718007\n",
      "Iteration 902, loss = 3.62702191\n",
      "Iteration 903, loss = 3.62686387\n",
      "Iteration 904, loss = 3.62670596\n",
      "Iteration 905, loss = 3.62654818\n",
      "Iteration 906, loss = 3.62639052\n",
      "Iteration 907, loss = 3.62623299\n",
      "Iteration 908, loss = 3.62607559\n",
      "Iteration 909, loss = 3.62591831\n",
      "Iteration 910, loss = 3.62576116\n",
      "Iteration 911, loss = 3.62560413\n",
      "Iteration 912, loss = 3.62544723\n",
      "Iteration 913, loss = 3.62529045\n",
      "Iteration 914, loss = 3.62513380\n",
      "Iteration 915, loss = 3.62497727\n",
      "Iteration 916, loss = 3.62482086\n",
      "Iteration 917, loss = 3.62466458\n",
      "Iteration 918, loss = 3.62450842\n",
      "Iteration 919, loss = 3.62435238\n",
      "Iteration 920, loss = 3.62419647\n",
      "Iteration 921, loss = 3.62404068\n",
      "Iteration 922, loss = 3.62388501\n",
      "Iteration 923, loss = 3.62372946\n",
      "Iteration 924, loss = 3.62357403\n",
      "Iteration 925, loss = 3.62341872\n",
      "Iteration 926, loss = 3.62326353\n",
      "Iteration 927, loss = 3.62310846\n",
      "Iteration 928, loss = 3.62295352\n",
      "Iteration 929, loss = 3.62279869\n",
      "Iteration 930, loss = 3.62264398\n",
      "Iteration 931, loss = 3.62248939\n",
      "Iteration 932, loss = 3.62233491\n",
      "Iteration 933, loss = 3.62218056\n",
      "Iteration 934, loss = 3.62202632\n",
      "Iteration 935, loss = 3.62187220\n",
      "Iteration 936, loss = 3.62171820\n",
      "Iteration 937, loss = 3.62156432\n",
      "Iteration 938, loss = 3.62141055\n",
      "Iteration 939, loss = 3.62125690\n",
      "Iteration 940, loss = 3.62110336\n",
      "Iteration 941, loss = 3.62094994\n",
      "Iteration 942, loss = 3.62079663\n",
      "Iteration 943, loss = 3.62064344\n",
      "Iteration 944, loss = 3.62049036\n",
      "Iteration 945, loss = 3.62033740\n",
      "Iteration 946, loss = 3.62018455\n",
      "Iteration 947, loss = 3.62003182\n",
      "Iteration 948, loss = 3.61987920\n",
      "Iteration 949, loss = 3.61972669\n",
      "Iteration 950, loss = 3.61957429\n",
      "Iteration 951, loss = 3.61942201\n",
      "Iteration 952, loss = 3.61926984\n",
      "Iteration 953, loss = 3.61911778\n",
      "Iteration 954, loss = 3.61896583\n",
      "Iteration 955, loss = 3.61881399\n",
      "Iteration 956, loss = 3.61866227\n",
      "Iteration 957, loss = 3.61851065\n",
      "Iteration 958, loss = 3.61835915\n",
      "Iteration 959, loss = 3.61820775\n",
      "Iteration 960, loss = 3.61805646\n",
      "Iteration 961, loss = 3.61790529\n",
      "Iteration 962, loss = 3.61775422\n",
      "Iteration 963, loss = 3.61760326\n",
      "Iteration 964, loss = 3.61745241\n",
      "Iteration 965, loss = 3.61730166\n",
      "Iteration 966, loss = 3.61715103\n",
      "Iteration 967, loss = 3.61700050\n",
      "Iteration 968, loss = 3.61685008\n",
      "Iteration 969, loss = 3.61669976\n",
      "Iteration 970, loss = 3.61654956\n",
      "Iteration 971, loss = 3.61639945\n",
      "Iteration 972, loss = 3.61624946\n",
      "Iteration 973, loss = 3.61609957\n",
      "Iteration 974, loss = 3.61594978\n",
      "Iteration 975, loss = 3.61580010\n",
      "Iteration 976, loss = 3.61565053\n",
      "Iteration 977, loss = 3.61550106\n",
      "Iteration 978, loss = 3.61535169\n",
      "Iteration 979, loss = 3.61520243\n",
      "Iteration 980, loss = 3.61505327\n",
      "Iteration 981, loss = 3.61490421\n",
      "Iteration 982, loss = 3.61475526\n",
      "Iteration 983, loss = 3.61460640\n",
      "Iteration 984, loss = 3.61445766\n",
      "Iteration 985, loss = 3.61430901\n",
      "Iteration 986, loss = 3.61416046\n",
      "Iteration 987, loss = 3.61401202\n",
      "Iteration 988, loss = 3.61386368\n",
      "Iteration 989, loss = 3.61371543\n",
      "Iteration 990, loss = 3.61356729\n",
      "Iteration 991, loss = 3.61341925\n",
      "Iteration 992, loss = 3.61327131\n",
      "Iteration 993, loss = 3.61312347\n",
      "Iteration 994, loss = 3.61297572\n",
      "Iteration 995, loss = 3.61282808\n",
      "Iteration 996, loss = 3.61268054\n",
      "Iteration 997, loss = 3.61253309\n",
      "Iteration 998, loss = 3.61238574\n",
      "Iteration 999, loss = 3.61223849\n",
      "Iteration 1000, loss = 3.61209134\n",
      "Iteration 1001, loss = 3.61194428\n",
      "Iteration 1002, loss = 3.61179732\n",
      "Iteration 1003, loss = 3.61165046\n",
      "Iteration 1004, loss = 3.61150369\n",
      "Iteration 1005, loss = 3.61135702\n",
      "Iteration 1006, loss = 3.61121045\n",
      "Iteration 1007, loss = 3.61106397\n",
      "Iteration 1008, loss = 3.61091759\n",
      "Iteration 1009, loss = 3.61077130\n",
      "Iteration 1010, loss = 3.61062511\n",
      "Iteration 1011, loss = 3.61047901\n",
      "Iteration 1012, loss = 3.61033301\n",
      "Iteration 1013, loss = 3.61018710\n",
      "Iteration 1014, loss = 3.61004128\n",
      "Iteration 1015, loss = 3.60989556\n",
      "Iteration 1016, loss = 3.60974992\n",
      "Iteration 1017, loss = 3.60960439\n",
      "Iteration 1018, loss = 3.60945894\n",
      "Iteration 1019, loss = 3.60931359\n",
      "Iteration 1020, loss = 3.60916833\n",
      "Iteration 1021, loss = 3.60902316\n",
      "Iteration 1022, loss = 3.60887808\n",
      "Iteration 1023, loss = 3.60873309\n",
      "Iteration 1024, loss = 3.60858820\n",
      "Iteration 1025, loss = 3.60844339\n",
      "Iteration 1026, loss = 3.60829867\n",
      "Iteration 1027, loss = 3.60815405\n",
      "Iteration 1028, loss = 3.60800951\n",
      "Iteration 1029, loss = 3.60786507\n",
      "Iteration 1030, loss = 3.60772071\n",
      "Iteration 1031, loss = 3.60757644\n",
      "Iteration 1032, loss = 3.60743226\n",
      "Iteration 1033, loss = 3.60728817\n",
      "Iteration 1034, loss = 3.60714417\n",
      "Iteration 1035, loss = 3.60700025\n",
      "Iteration 1036, loss = 3.60685643\n",
      "Iteration 1037, loss = 3.60671269\n",
      "Iteration 1038, loss = 3.60656903\n",
      "Iteration 1039, loss = 3.60642547\n",
      "Iteration 1040, loss = 3.60628199\n",
      "Iteration 1041, loss = 3.60613859\n",
      "Iteration 1042, loss = 3.60599529\n",
      "Iteration 1043, loss = 3.60585207\n",
      "Iteration 1044, loss = 3.60570893\n",
      "Iteration 1045, loss = 3.60556588\n",
      "Iteration 1046, loss = 3.60542291\n",
      "Iteration 1047, loss = 3.60528003\n",
      "Iteration 1048, loss = 3.60513724\n",
      "Iteration 1049, loss = 3.60499452\n",
      "Iteration 1050, loss = 3.60485189\n",
      "Iteration 1051, loss = 3.60470935\n",
      "Iteration 1052, loss = 3.60456689\n",
      "Iteration 1053, loss = 3.60442451\n",
      "Iteration 1054, loss = 3.60428221\n",
      "Iteration 1055, loss = 3.60414000\n",
      "Iteration 1056, loss = 3.60399787\n",
      "Iteration 1057, loss = 3.60385582\n",
      "Iteration 1058, loss = 3.60371386\n",
      "Iteration 1059, loss = 3.60357197\n",
      "Iteration 1060, loss = 3.60343017\n",
      "Iteration 1061, loss = 3.60328845\n",
      "Iteration 1062, loss = 3.60314681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1063, loss = 3.60300525\n",
      "Iteration 1064, loss = 3.60286377\n",
      "Iteration 1065, loss = 3.60272237\n",
      "Iteration 1066, loss = 3.60258105\n",
      "Iteration 1067, loss = 3.60243981\n",
      "Iteration 1068, loss = 3.60229865\n",
      "Iteration 1069, loss = 3.60215757\n",
      "Iteration 1070, loss = 3.60201656\n",
      "Iteration 1071, loss = 3.60187564\n",
      "Iteration 1072, loss = 3.60173480\n",
      "Iteration 1073, loss = 3.60159403\n",
      "Iteration 1074, loss = 3.60145334\n",
      "Iteration 1075, loss = 3.60131273\n",
      "Iteration 1076, loss = 3.60117219\n",
      "Iteration 1077, loss = 3.60103174\n",
      "Iteration 1078, loss = 3.60089136\n",
      "Iteration 1079, loss = 3.60075106\n",
      "Iteration 1080, loss = 3.60061083\n",
      "Iteration 1081, loss = 3.60047068\n",
      "Iteration 1082, loss = 3.60033061\n",
      "Iteration 1083, loss = 3.60019061\n",
      "Iteration 1084, loss = 3.60005069\n",
      "Iteration 1085, loss = 3.59991084\n",
      "Iteration 1086, loss = 3.59977107\n",
      "Iteration 1087, loss = 3.59963137\n",
      "Iteration 1088, loss = 3.59949175\n",
      "Iteration 1089, loss = 3.59935220\n",
      "Iteration 1090, loss = 3.59921273\n",
      "Iteration 1091, loss = 3.59907333\n",
      "Iteration 1092, loss = 3.59893400\n",
      "Iteration 1093, loss = 3.59879475\n",
      "Iteration 1094, loss = 3.59865557\n",
      "Iteration 1095, loss = 3.59851646\n",
      "Iteration 1096, loss = 3.59837743\n",
      "Iteration 1097, loss = 3.59823847\n",
      "Iteration 1098, loss = 3.59809958\n",
      "Iteration 1099, loss = 3.59796077\n",
      "Iteration 1100, loss = 3.59782202\n",
      "Iteration 1101, loss = 3.59768335\n",
      "Iteration 1102, loss = 3.59754475\n",
      "Iteration 1103, loss = 3.59740622\n",
      "Iteration 1104, loss = 3.59726776\n",
      "Iteration 1105, loss = 3.59712937\n",
      "Iteration 1106, loss = 3.59699106\n",
      "Iteration 1107, loss = 3.59685281\n",
      "Iteration 1108, loss = 3.59671463\n",
      "Iteration 1109, loss = 3.59657653\n",
      "Iteration 1110, loss = 3.59643849\n",
      "Iteration 1111, loss = 3.59630052\n",
      "Iteration 1112, loss = 3.59616262\n",
      "Iteration 1113, loss = 3.59602479\n",
      "Iteration 1114, loss = 3.59588703\n",
      "Iteration 1115, loss = 3.59574934\n",
      "Iteration 1116, loss = 3.59561172\n",
      "Iteration 1117, loss = 3.59547416\n",
      "Iteration 1118, loss = 3.59533668\n",
      "Iteration 1119, loss = 3.59519926\n",
      "Iteration 1120, loss = 3.59506191\n",
      "Iteration 1121, loss = 3.59492462\n",
      "Iteration 1122, loss = 3.59478740\n",
      "Iteration 1123, loss = 3.59465025\n",
      "Iteration 1124, loss = 3.59451317\n",
      "Iteration 1125, loss = 3.59437615\n",
      "Iteration 1126, loss = 3.59423920\n",
      "Iteration 1127, loss = 3.59410232\n",
      "Iteration 1128, loss = 3.59396550\n",
      "Iteration 1129, loss = 3.59382875\n",
      "Iteration 1130, loss = 3.59369206\n",
      "Iteration 1131, loss = 3.59355544\n",
      "Iteration 1132, loss = 3.59341888\n",
      "Iteration 1133, loss = 3.59328239\n",
      "Iteration 1134, loss = 3.59314596\n",
      "Iteration 1135, loss = 3.59300959\n",
      "Iteration 1136, loss = 3.59287330\n",
      "Iteration 1137, loss = 3.59273706\n",
      "Iteration 1138, loss = 3.59260089\n",
      "Iteration 1139, loss = 3.59246478\n",
      "Iteration 1140, loss = 3.59232874\n",
      "Iteration 1141, loss = 3.59219276\n",
      "Iteration 1142, loss = 3.59205684\n",
      "Iteration 1143, loss = 3.59192098\n",
      "Iteration 1144, loss = 3.59178519\n",
      "Iteration 1145, loss = 3.59164946\n",
      "Iteration 1146, loss = 3.59151379\n",
      "Iteration 1147, loss = 3.59137819\n",
      "Iteration 1148, loss = 3.59124264\n",
      "Iteration 1149, loss = 3.59110716\n",
      "Iteration 1150, loss = 3.59097174\n",
      "Iteration 1151, loss = 3.59083638\n",
      "Iteration 1152, loss = 3.59070108\n",
      "Iteration 1153, loss = 3.59056585\n",
      "Iteration 1154, loss = 3.59043067\n",
      "Iteration 1155, loss = 3.59029555\n",
      "Iteration 1156, loss = 3.59016050\n",
      "Iteration 1157, loss = 3.59002550\n",
      "Iteration 1158, loss = 3.58989057\n",
      "Iteration 1159, loss = 3.58975569\n",
      "Iteration 1160, loss = 3.58962087\n",
      "Iteration 1161, loss = 3.58948612\n",
      "Iteration 1162, loss = 3.58935142\n",
      "Iteration 1163, loss = 3.58921678\n",
      "Iteration 1164, loss = 3.58908220\n",
      "Iteration 1165, loss = 3.58894768\n",
      "Iteration 1166, loss = 3.58881321\n",
      "Iteration 1167, loss = 3.58867881\n",
      "Iteration 1168, loss = 3.58854446\n",
      "Iteration 1169, loss = 3.58841017\n",
      "Iteration 1170, loss = 3.58827594\n",
      "Iteration 1171, loss = 3.58814177\n",
      "Iteration 1172, loss = 3.58800765\n",
      "Iteration 1173, loss = 3.58787359\n",
      "Iteration 1174, loss = 3.58773959\n",
      "Iteration 1175, loss = 3.58760564\n",
      "Iteration 1176, loss = 3.58747175\n",
      "Iteration 1177, loss = 3.58733792\n",
      "Iteration 1178, loss = 3.58720414\n",
      "Iteration 1179, loss = 3.58707042\n",
      "Iteration 1180, loss = 3.58693676\n",
      "Iteration 1181, loss = 3.58680315\n",
      "Iteration 1182, loss = 3.58666959\n",
      "Iteration 1183, loss = 3.58653610\n",
      "Iteration 1184, loss = 3.58640265\n",
      "Iteration 1185, loss = 3.58626926\n",
      "Iteration 1186, loss = 3.58613593\n",
      "Iteration 1187, loss = 3.58600265\n",
      "Iteration 1188, loss = 3.58586943\n",
      "Iteration 1189, loss = 3.58573626\n",
      "Iteration 1190, loss = 3.58560314\n",
      "Iteration 1191, loss = 3.58547008\n",
      "Iteration 1192, loss = 3.58533707\n",
      "Iteration 1193, loss = 3.58520412\n",
      "Iteration 1194, loss = 3.58507122\n",
      "Iteration 1195, loss = 3.58493837\n",
      "Iteration 1196, loss = 3.58480557\n",
      "Iteration 1197, loss = 3.58467283\n",
      "Iteration 1198, loss = 3.58454014\n",
      "Iteration 1199, loss = 3.58440751\n",
      "Iteration 1200, loss = 3.58427492\n",
      "Iteration 1201, loss = 3.58414239\n",
      "Iteration 1202, loss = 3.58400991\n",
      "Iteration 1203, loss = 3.58387748\n",
      "Iteration 1204, loss = 3.58374511\n",
      "Iteration 1205, loss = 3.58361278\n",
      "Iteration 1206, loss = 3.58348051\n",
      "Iteration 1207, loss = 3.58334829\n",
      "Iteration 1208, loss = 3.58321612\n",
      "Iteration 1209, loss = 3.58308400\n",
      "Iteration 1210, loss = 3.58295193\n",
      "Iteration 1211, loss = 3.58281991\n",
      "Iteration 1212, loss = 3.58268794\n",
      "Iteration 1213, loss = 3.58255602\n",
      "Iteration 1214, loss = 3.58242415\n",
      "Iteration 1215, loss = 3.58229234\n",
      "Iteration 1216, loss = 3.58216057\n",
      "Iteration 1217, loss = 3.58202885\n",
      "Iteration 1218, loss = 3.58189718\n",
      "Iteration 1219, loss = 3.58176556\n",
      "Iteration 1220, loss = 3.58163399\n",
      "Iteration 1221, loss = 3.58150247\n",
      "Iteration 1222, loss = 3.58137100\n",
      "Iteration 1223, loss = 3.58123957\n",
      "Iteration 1224, loss = 3.58110820\n",
      "Iteration 1225, loss = 3.58097687\n",
      "Iteration 1226, loss = 3.58084559\n",
      "Iteration 1227, loss = 3.58071436\n",
      "Iteration 1228, loss = 3.58058318\n",
      "Iteration 1229, loss = 3.58045204\n",
      "Iteration 1230, loss = 3.58032095\n",
      "Iteration 1231, loss = 3.58018991\n",
      "Iteration 1232, loss = 3.58005892\n",
      "Iteration 1233, loss = 3.57992797\n",
      "Iteration 1234, loss = 3.57979708\n",
      "Iteration 1235, loss = 3.57966622\n",
      "Iteration 1236, loss = 3.57953542\n",
      "Iteration 1237, loss = 3.57940466\n",
      "Iteration 1238, loss = 3.57927395\n",
      "Iteration 1239, loss = 3.57914328\n",
      "Iteration 1240, loss = 3.57901266\n",
      "Iteration 1241, loss = 3.57888209\n",
      "Iteration 1242, loss = 3.57875156\n",
      "Iteration 1243, loss = 3.57862108\n",
      "Iteration 1244, loss = 3.57849064\n",
      "Iteration 1245, loss = 3.57836025\n",
      "Iteration 1246, loss = 3.57822990\n",
      "Iteration 1247, loss = 3.57809960\n",
      "Iteration 1248, loss = 3.57796934\n",
      "Iteration 1249, loss = 3.57783913\n",
      "Iteration 1250, loss = 3.57770896\n",
      "Iteration 1251, loss = 3.57757884\n",
      "Iteration 1252, loss = 3.57744876\n",
      "Iteration 1253, loss = 3.57731873\n",
      "Iteration 1254, loss = 3.57718874\n",
      "Iteration 1255, loss = 3.57705879\n",
      "Iteration 1256, loss = 3.57692889\n",
      "Iteration 1257, loss = 3.57679903\n",
      "Iteration 1258, loss = 3.57666921\n",
      "Iteration 1259, loss = 3.57653944\n",
      "Iteration 1260, loss = 3.57640971\n",
      "Iteration 1261, loss = 3.57628003\n",
      "Iteration 1262, loss = 3.57615038\n",
      "Iteration 1263, loss = 3.57602078\n",
      "Iteration 1264, loss = 3.57589123\n",
      "Iteration 1265, loss = 3.57576171\n",
      "Iteration 1266, loss = 3.57563224\n",
      "Iteration 1267, loss = 3.57550281\n",
      "Iteration 1268, loss = 3.57537342\n",
      "Iteration 1269, loss = 3.57524407\n",
      "Iteration 1270, loss = 3.57511477\n",
      "Iteration 1271, loss = 3.57498551\n",
      "Iteration 1272, loss = 3.57485629\n",
      "Iteration 1273, loss = 3.57472711\n",
      "Iteration 1274, loss = 3.57459797\n",
      "Iteration 1275, loss = 3.57446887\n",
      "Iteration 1276, loss = 3.57433981\n",
      "Iteration 1277, loss = 3.57421080\n",
      "Iteration 1278, loss = 3.57408182\n",
      "Iteration 1279, loss = 3.57395289\n",
      "Iteration 1280, loss = 3.57382400\n",
      "Iteration 1281, loss = 3.57369514\n",
      "Iteration 1282, loss = 3.57356633\n",
      "Iteration 1283, loss = 3.57343756\n",
      "Iteration 1284, loss = 3.57330883\n",
      "Iteration 1285, loss = 3.57318014\n",
      "Iteration 1286, loss = 3.57305148\n",
      "Iteration 1287, loss = 3.57292287\n",
      "Iteration 1288, loss = 3.57279430\n",
      "Iteration 1289, loss = 3.57266576\n",
      "Iteration 1290, loss = 3.57253727\n",
      "Iteration 1291, loss = 3.57240881\n",
      "Iteration 1292, loss = 3.57228039\n",
      "Iteration 1293, loss = 3.57215202\n",
      "Iteration 1294, loss = 3.57202368\n",
      "Iteration 1295, loss = 3.57189537\n",
      "Iteration 1296, loss = 3.57176711\n",
      "Iteration 1297, loss = 3.57163889\n",
      "Iteration 1298, loss = 3.57151070\n",
      "Iteration 1299, loss = 3.57138256\n",
      "Iteration 1300, loss = 3.57125445\n",
      "Iteration 1301, loss = 3.57112637\n",
      "Iteration 1302, loss = 3.57099834\n",
      "Iteration 1303, loss = 3.57087034\n",
      "Iteration 1304, loss = 3.57074239\n",
      "Iteration 1305, loss = 3.57061446\n",
      "Iteration 1306, loss = 3.57048658\n",
      "Iteration 1307, loss = 3.57035873\n",
      "Iteration 1308, loss = 3.57023092\n",
      "Iteration 1309, loss = 3.57010315\n",
      "Iteration 1310, loss = 3.56997542\n",
      "Iteration 1311, loss = 3.56984772\n",
      "Iteration 1312, loss = 3.56972005\n",
      "Iteration 1313, loss = 3.56959243\n",
      "Iteration 1314, loss = 3.56946484\n",
      "Iteration 1315, loss = 3.56933728\n",
      "Iteration 1316, loss = 3.56920977\n",
      "Iteration 1317, loss = 3.56908228\n",
      "Iteration 1318, loss = 3.56895484\n",
      "Iteration 1319, loss = 3.56882743\n",
      "Iteration 1320, loss = 3.56870006\n",
      "Iteration 1321, loss = 3.56857272\n",
      "Iteration 1322, loss = 3.56844541\n",
      "Iteration 1323, loss = 3.56831815\n",
      "Iteration 1324, loss = 3.56819091\n",
      "Iteration 1325, loss = 3.56806372\n",
      "Iteration 1326, loss = 3.56793655\n",
      "Iteration 1327, loss = 3.56780943\n",
      "Iteration 1328, loss = 3.56768233\n",
      "Iteration 1329, loss = 3.56755527\n",
      "Iteration 1330, loss = 3.56742825\n",
      "Iteration 1331, loss = 3.56730126\n",
      "Iteration 1332, loss = 3.56717431\n",
      "Iteration 1333, loss = 3.56704739\n",
      "Iteration 1334, loss = 3.56692050\n",
      "Iteration 1335, loss = 3.56679365\n",
      "Iteration 1336, loss = 3.56666683\n",
      "Iteration 1337, loss = 3.56654004\n",
      "Iteration 1338, loss = 3.56641329\n",
      "Iteration 1339, loss = 3.56628658\n",
      "Iteration 1340, loss = 3.56615989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1341, loss = 3.56603324\n",
      "Iteration 1342, loss = 3.56590662\n",
      "Iteration 1343, loss = 3.56578004\n",
      "Iteration 1344, loss = 3.56565349\n",
      "Iteration 1345, loss = 3.56552697\n",
      "Iteration 1346, loss = 3.56540049\n",
      "Iteration 1347, loss = 3.56527403\n",
      "Iteration 1348, loss = 3.56514761\n",
      "Iteration 1349, loss = 3.56502123\n",
      "Iteration 1350, loss = 3.56489487\n",
      "Iteration 1351, loss = 3.56476855\n",
      "Iteration 1352, loss = 3.56464226\n",
      "Iteration 1353, loss = 3.56451600\n",
      "Iteration 1354, loss = 3.56438978\n",
      "Iteration 1355, loss = 3.56426358\n",
      "Iteration 1356, loss = 3.56413742\n",
      "Iteration 1357, loss = 3.56401129\n",
      "Iteration 1358, loss = 3.56388519\n",
      "Iteration 1359, loss = 3.56375913\n",
      "Iteration 1360, loss = 3.56363309\n",
      "Iteration 1361, loss = 3.56350709\n",
      "Iteration 1362, loss = 3.56338111\n",
      "Iteration 1363, loss = 3.56325517\n",
      "Iteration 1364, loss = 3.56312926\n",
      "Iteration 1365, loss = 3.56300338\n",
      "Iteration 1366, loss = 3.56287753\n",
      "Iteration 1367, loss = 3.56275172\n",
      "Iteration 1368, loss = 3.56262593\n",
      "Iteration 1369, loss = 3.56250017\n",
      "Iteration 1370, loss = 3.56237445\n",
      "Iteration 1371, loss = 3.56224875\n",
      "Iteration 1372, loss = 3.56212309\n",
      "Iteration 1373, loss = 3.56199745\n",
      "Iteration 1374, loss = 3.56187185\n",
      "Iteration 1375, loss = 3.56174627\n",
      "Iteration 1376, loss = 3.56162073\n",
      "Iteration 1377, loss = 3.56149522\n",
      "Iteration 1378, loss = 3.56136973\n",
      "Iteration 1379, loss = 3.56124428\n",
      "Iteration 1380, loss = 3.56111885\n",
      "Iteration 1381, loss = 3.56099346\n",
      "Iteration 1382, loss = 3.56086809\n",
      "Iteration 1383, loss = 3.56074275\n",
      "Iteration 1384, loss = 3.56061745\n",
      "Iteration 1385, loss = 3.56049217\n",
      "Iteration 1386, loss = 3.56036692\n",
      "Iteration 1387, loss = 3.56024170\n",
      "Iteration 1388, loss = 3.56011651\n",
      "Iteration 1389, loss = 3.55999134\n",
      "Iteration 1390, loss = 3.55986621\n",
      "Iteration 1391, loss = 3.55974111\n",
      "Iteration 1392, loss = 3.55961603\n",
      "Iteration 1393, loss = 3.55949098\n",
      "Iteration 1394, loss = 3.55936596\n",
      "Iteration 1395, loss = 3.55924097\n",
      "Iteration 1396, loss = 3.55911601\n",
      "Iteration 1397, loss = 3.55899108\n",
      "Iteration 1398, loss = 3.55886617\n",
      "Iteration 1399, loss = 3.55874129\n",
      "Iteration 1400, loss = 3.55861644\n",
      "Iteration 1401, loss = 3.55849162\n",
      "Iteration 1402, loss = 3.55836682\n",
      "Iteration 1403, loss = 3.55824206\n",
      "Iteration 1404, loss = 3.55811732\n",
      "Iteration 1405, loss = 3.55799261\n",
      "Iteration 1406, loss = 3.55786792\n",
      "Iteration 1407, loss = 3.55774327\n",
      "Iteration 1408, loss = 3.55761864\n",
      "Iteration 1409, loss = 3.55749403\n",
      "Iteration 1410, loss = 3.55736946\n",
      "Iteration 1411, loss = 3.55724491\n",
      "Iteration 1412, loss = 3.55712039\n",
      "Iteration 1413, loss = 3.55699590\n",
      "Iteration 1414, loss = 3.55687143\n",
      "Iteration 1415, loss = 3.55674699\n",
      "Iteration 1416, loss = 3.55662258\n",
      "Iteration 1417, loss = 3.55649819\n",
      "Iteration 1418, loss = 3.55637383\n",
      "Iteration 1419, loss = 3.55624949\n",
      "Iteration 1420, loss = 3.55612519\n",
      "Iteration 1421, loss = 3.55600091\n",
      "Iteration 1422, loss = 3.55587665\n",
      "Iteration 1423, loss = 3.55575242\n",
      "Iteration 1424, loss = 3.55562822\n",
      "Iteration 1425, loss = 3.55550405\n",
      "Iteration 1426, loss = 3.55537989\n",
      "Iteration 1427, loss = 3.55525577\n",
      "Iteration 1428, loss = 3.55513167\n",
      "Iteration 1429, loss = 3.55500760\n",
      "Iteration 1430, loss = 3.55488355\n",
      "Iteration 1431, loss = 3.55475953\n",
      "Iteration 1432, loss = 3.55463554\n",
      "Iteration 1433, loss = 3.55451157\n",
      "Iteration 1434, loss = 3.55438762\n",
      "Iteration 1435, loss = 3.55426370\n",
      "Iteration 1436, loss = 3.55413981\n",
      "Iteration 1437, loss = 3.55401594\n",
      "Iteration 1438, loss = 3.55389210\n",
      "Iteration 1439, loss = 3.55376828\n",
      "Iteration 1440, loss = 3.55364448\n",
      "Iteration 1441, loss = 3.55352072\n",
      "Iteration 1442, loss = 3.55339697\n",
      "Iteration 1443, loss = 3.55327325\n",
      "Iteration 1444, loss = 3.55314956\n",
      "Iteration 1445, loss = 3.55302589\n",
      "Iteration 1446, loss = 3.55290225\n",
      "Iteration 1447, loss = 3.55277863\n",
      "Iteration 1448, loss = 3.55265503\n",
      "Iteration 1449, loss = 3.55253146\n",
      "Iteration 1450, loss = 3.55240791\n",
      "Iteration 1451, loss = 3.55228439\n",
      "Iteration 1452, loss = 3.55216090\n",
      "Iteration 1453, loss = 3.55203742\n",
      "Iteration 1454, loss = 3.55191397\n",
      "Iteration 1455, loss = 3.55179055\n",
      "Iteration 1456, loss = 3.55166715\n",
      "Iteration 1457, loss = 3.55154377\n",
      "Iteration 1458, loss = 3.55142042\n",
      "Iteration 1459, loss = 3.55129709\n",
      "Iteration 1460, loss = 3.55117378\n",
      "Iteration 1461, loss = 3.55105050\n",
      "Iteration 1462, loss = 3.55092724\n",
      "Iteration 1463, loss = 3.55080401\n",
      "Iteration 1464, loss = 3.55068080\n",
      "Iteration 1465, loss = 3.55055761\n",
      "Iteration 1466, loss = 3.55043445\n",
      "Iteration 1467, loss = 3.55031131\n",
      "Iteration 1468, loss = 3.55018819\n",
      "Iteration 1469, loss = 3.55006510\n",
      "Iteration 1470, loss = 3.54994203\n",
      "Iteration 1471, loss = 3.54981898\n",
      "Iteration 1472, loss = 3.54969596\n",
      "Iteration 1473, loss = 3.54957296\n",
      "Iteration 1474, loss = 3.54944998\n",
      "Iteration 1475, loss = 3.54932702\n",
      "Iteration 1476, loss = 3.54920409\n",
      "Iteration 1477, loss = 3.54908118\n",
      "Iteration 1478, loss = 3.54895830\n",
      "Iteration 1479, loss = 3.54883543\n",
      "Iteration 1480, loss = 3.54871259\n",
      "Iteration 1481, loss = 3.54858978\n",
      "Iteration 1482, loss = 3.54846698\n",
      "Iteration 1483, loss = 3.54834421\n",
      "Iteration 1484, loss = 3.54822146\n",
      "Iteration 1485, loss = 3.54809873\n",
      "Iteration 1486, loss = 3.54797603\n",
      "Iteration 1487, loss = 3.54785335\n",
      "Iteration 1488, loss = 3.54773069\n",
      "Iteration 1489, loss = 3.54760805\n",
      "Iteration 1490, loss = 3.54748543\n",
      "Iteration 1491, loss = 3.54736284\n",
      "Iteration 1492, loss = 3.54724027\n",
      "Iteration 1493, loss = 3.54711772\n",
      "Iteration 1494, loss = 3.54699519\n",
      "Iteration 1495, loss = 3.54687269\n",
      "Iteration 1496, loss = 3.54675020\n",
      "Iteration 1497, loss = 3.54662774\n",
      "Iteration 1498, loss = 3.54650530\n",
      "Iteration 1499, loss = 3.54638289\n",
      "Iteration 1500, loss = 3.54626049\n",
      "Iteration 1501, loss = 3.54613812\n",
      "Iteration 1502, loss = 3.54601577\n",
      "Iteration 1503, loss = 3.54589344\n",
      "Iteration 1504, loss = 3.54577113\n",
      "Iteration 1505, loss = 3.54564884\n",
      "Iteration 1506, loss = 3.54552657\n",
      "Iteration 1507, loss = 3.54540433\n",
      "Iteration 1508, loss = 3.54528211\n",
      "Iteration 1509, loss = 3.54515991\n",
      "Iteration 1510, loss = 3.54503773\n",
      "Iteration 1511, loss = 3.54491557\n",
      "Iteration 1512, loss = 3.54479343\n",
      "Iteration 1513, loss = 3.54467132\n",
      "Iteration 1514, loss = 3.54454922\n",
      "Iteration 1515, loss = 3.54442715\n",
      "Iteration 1516, loss = 3.54430510\n",
      "Iteration 1517, loss = 3.54418307\n",
      "Iteration 1518, loss = 3.54406106\n",
      "Iteration 1519, loss = 3.54393907\n",
      "Iteration 1520, loss = 3.54381710\n",
      "Iteration 1521, loss = 3.54369515\n",
      "Iteration 1522, loss = 3.54357323\n",
      "Iteration 1523, loss = 3.54345132\n",
      "Iteration 1524, loss = 3.54332944\n",
      "Iteration 1525, loss = 3.54320757\n",
      "Iteration 1526, loss = 3.54308573\n",
      "Iteration 1527, loss = 3.54296391\n",
      "Iteration 1528, loss = 3.54284211\n",
      "Iteration 1529, loss = 3.54272033\n",
      "Iteration 1530, loss = 3.54259857\n",
      "Iteration 1531, loss = 3.54247683\n",
      "Iteration 1532, loss = 3.54235511\n",
      "Iteration 1533, loss = 3.54223341\n",
      "Iteration 1534, loss = 3.54211173\n",
      "Iteration 1535, loss = 3.54199008\n",
      "Iteration 1536, loss = 3.54186844\n",
      "Iteration 1537, loss = 3.54174683\n",
      "Iteration 1538, loss = 3.54162523\n",
      "Iteration 1539, loss = 3.54150365\n",
      "Iteration 1540, loss = 3.54138210\n",
      "Iteration 1541, loss = 3.54126056\n",
      "Iteration 1542, loss = 3.54113905\n",
      "Iteration 1543, loss = 3.54101756\n",
      "Iteration 1544, loss = 3.54089608\n",
      "Iteration 1545, loss = 3.54077463\n",
      "Iteration 1546, loss = 3.54065319\n",
      "Iteration 1547, loss = 3.54053178\n",
      "Iteration 1548, loss = 3.54041039\n",
      "Iteration 1549, loss = 3.54028901\n",
      "Iteration 1550, loss = 3.54016766\n",
      "Iteration 1551, loss = 3.54004633\n",
      "Iteration 1552, loss = 3.53992501\n",
      "Iteration 1553, loss = 3.53980372\n",
      "Iteration 1554, loss = 3.53968245\n",
      "Iteration 1555, loss = 3.53956119\n",
      "Iteration 1556, loss = 3.53943996\n",
      "Iteration 1557, loss = 3.53931875\n",
      "Iteration 1558, loss = 3.53919755\n",
      "Iteration 1559, loss = 3.53907638\n",
      "Iteration 1560, loss = 3.53895522\n",
      "Iteration 1561, loss = 3.53883409\n",
      "Iteration 1562, loss = 3.53871297\n",
      "Iteration 1563, loss = 3.53859188\n",
      "Iteration 1564, loss = 3.53847080\n",
      "Iteration 1565, loss = 3.53834975\n",
      "Iteration 1566, loss = 3.53822871\n",
      "Iteration 1567, loss = 3.53810769\n",
      "Iteration 1568, loss = 3.53798670\n",
      "Iteration 1569, loss = 3.53786572\n",
      "Iteration 1570, loss = 3.53774476\n",
      "Iteration 1571, loss = 3.53762382\n",
      "Iteration 1572, loss = 3.53750290\n",
      "Iteration 1573, loss = 3.53738200\n",
      "Iteration 1574, loss = 3.53726112\n",
      "Iteration 1575, loss = 3.53714026\n",
      "Iteration 1576, loss = 3.53701942\n",
      "Iteration 1577, loss = 3.53689860\n",
      "Iteration 1578, loss = 3.53677780\n",
      "Iteration 1579, loss = 3.53665701\n",
      "Iteration 1580, loss = 3.53653625\n",
      "Iteration 1581, loss = 3.53641551\n",
      "Iteration 1582, loss = 3.53629478\n",
      "Iteration 1583, loss = 3.53617408\n",
      "Iteration 1584, loss = 3.53605339\n",
      "Iteration 1585, loss = 3.53593272\n",
      "Iteration 1586, loss = 3.53581207\n",
      "Iteration 1587, loss = 3.53569145\n",
      "Iteration 1588, loss = 3.53557084\n",
      "Iteration 1589, loss = 3.53545025\n",
      "Iteration 1590, loss = 3.53532967\n",
      "Iteration 1591, loss = 3.53520912\n",
      "Iteration 1592, loss = 3.53508859\n",
      "Iteration 1593, loss = 3.53496808\n",
      "Iteration 1594, loss = 3.53484758\n",
      "Iteration 1595, loss = 3.53472711\n",
      "Iteration 1596, loss = 3.53460665\n",
      "Iteration 1597, loss = 3.53448621\n",
      "Iteration 1598, loss = 3.53436579\n",
      "Iteration 1599, loss = 3.53424539\n",
      "Iteration 1600, loss = 3.53412501\n",
      "Iteration 1601, loss = 3.53400465\n",
      "Iteration 1602, loss = 3.53388431\n",
      "Iteration 1603, loss = 3.53376399\n",
      "Iteration 1604, loss = 3.53364368\n",
      "Iteration 1605, loss = 3.53352340\n",
      "Iteration 1606, loss = 3.53340313\n",
      "Iteration 1607, loss = 3.53328288\n",
      "Iteration 1608, loss = 3.53316265\n",
      "Iteration 1609, loss = 3.53304244\n",
      "Iteration 1610, loss = 3.53292225\n",
      "Iteration 1611, loss = 3.53280208\n",
      "Iteration 1612, loss = 3.53268193\n",
      "Iteration 1613, loss = 3.53256179\n",
      "Iteration 1614, loss = 3.53244168\n",
      "Iteration 1615, loss = 3.53232158\n",
      "Iteration 1616, loss = 3.53220150\n",
      "Iteration 1617, loss = 3.53208145\n",
      "Iteration 1618, loss = 3.53196141\n",
      "Iteration 1619, loss = 3.53184138\n",
      "Iteration 1620, loss = 3.53172138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1621, loss = 3.53160140\n",
      "Iteration 1622, loss = 3.53148143\n",
      "Iteration 1623, loss = 3.53136149\n",
      "Iteration 1624, loss = 3.53124156\n",
      "Iteration 1625, loss = 3.53112165\n",
      "Iteration 1626, loss = 3.53100176\n",
      "Iteration 1627, loss = 3.53088189\n",
      "Iteration 1628, loss = 3.53076204\n",
      "Iteration 1629, loss = 3.53064220\n",
      "Iteration 1630, loss = 3.53052239\n",
      "Iteration 1631, loss = 3.53040259\n",
      "Iteration 1632, loss = 3.53028282\n",
      "Iteration 1633, loss = 3.53016306\n",
      "Iteration 1634, loss = 3.53004332\n",
      "Iteration 1635, loss = 3.52992359\n",
      "Iteration 1636, loss = 3.52980389\n",
      "Iteration 1637, loss = 3.52968421\n",
      "Iteration 1638, loss = 3.52956454\n",
      "Iteration 1639, loss = 3.52944490\n",
      "Iteration 1640, loss = 3.52932527\n",
      "Iteration 1641, loss = 3.52920566\n",
      "Iteration 1642, loss = 3.52908607\n",
      "Iteration 1643, loss = 3.52896650\n",
      "Iteration 1644, loss = 3.52884694\n",
      "Iteration 1645, loss = 3.52872741\n",
      "Iteration 1646, loss = 3.52860789\n",
      "Iteration 1647, loss = 3.52848839\n",
      "Iteration 1648, loss = 3.52836892\n",
      "Iteration 1649, loss = 3.52824946\n",
      "Iteration 1650, loss = 3.52813001\n",
      "Iteration 1651, loss = 3.52801059\n",
      "Iteration 1652, loss = 3.52789119\n",
      "Iteration 1653, loss = 3.52777180\n",
      "Iteration 1654, loss = 3.52765243\n",
      "Iteration 1655, loss = 3.52753309\n",
      "Iteration 1656, loss = 3.52741376\n",
      "Iteration 1657, loss = 3.52729444\n",
      "Iteration 1658, loss = 3.52717515\n",
      "Iteration 1659, loss = 3.52705588\n",
      "Iteration 1660, loss = 3.52693662\n",
      "Iteration 1661, loss = 3.52681739\n",
      "Iteration 1662, loss = 3.52669817\n",
      "Iteration 1663, loss = 3.52657897\n",
      "Iteration 1664, loss = 3.52645979\n",
      "Iteration 1665, loss = 3.52634063\n",
      "Iteration 1666, loss = 3.52622148\n",
      "Iteration 1667, loss = 3.52610236\n",
      "Iteration 1668, loss = 3.52598325\n",
      "Iteration 1669, loss = 3.52586417\n",
      "Iteration 1670, loss = 3.52574510\n",
      "Iteration 1671, loss = 3.52562605\n",
      "Iteration 1672, loss = 3.52550701\n",
      "Iteration 1673, loss = 3.52538800\n",
      "Iteration 1674, loss = 3.52526901\n",
      "Iteration 1675, loss = 3.52515003\n",
      "Iteration 1676, loss = 3.52503107\n",
      "Iteration 1677, loss = 3.52491214\n",
      "Iteration 1678, loss = 3.52479322\n",
      "Iteration 1679, loss = 3.52467432\n",
      "Iteration 1680, loss = 3.52455543\n",
      "Iteration 1681, loss = 3.52443657\n",
      "Iteration 1682, loss = 3.52431772\n",
      "Iteration 1683, loss = 3.52419890\n",
      "Iteration 1684, loss = 3.52408009\n",
      "Iteration 1685, loss = 3.52396130\n",
      "Iteration 1686, loss = 3.52384253\n",
      "Iteration 1687, loss = 3.52372378\n",
      "Iteration 1688, loss = 3.52360505\n",
      "Iteration 1689, loss = 3.52348633\n",
      "Iteration 1690, loss = 3.52336764\n",
      "Iteration 1691, loss = 3.52324896\n",
      "Iteration 1692, loss = 3.52313030\n",
      "Iteration 1693, loss = 3.52301166\n",
      "Iteration 1694, loss = 3.52289304\n",
      "Iteration 1695, loss = 3.52277444\n",
      "Iteration 1696, loss = 3.52265586\n",
      "Iteration 1697, loss = 3.52253729\n",
      "Iteration 1698, loss = 3.52241875\n",
      "Iteration 1699, loss = 3.52230022\n",
      "Iteration 1700, loss = 3.52218171\n",
      "Iteration 1701, loss = 3.52206322\n",
      "Iteration 1702, loss = 3.52194475\n",
      "Iteration 1703, loss = 3.52182630\n",
      "Iteration 1704, loss = 3.52170787\n",
      "Iteration 1705, loss = 3.52158946\n",
      "Iteration 1706, loss = 3.52147106\n",
      "Iteration 1707, loss = 3.52135268\n",
      "Iteration 1708, loss = 3.52123433\n",
      "Iteration 1709, loss = 3.52111599\n",
      "Iteration 1710, loss = 3.52099767\n",
      "Iteration 1711, loss = 3.52087937\n",
      "Iteration 1712, loss = 3.52076108\n",
      "Iteration 1713, loss = 3.52064282\n",
      "Iteration 1714, loss = 3.52052458\n",
      "Iteration 1715, loss = 3.52040635\n",
      "Iteration 1716, loss = 3.52028815\n",
      "Iteration 1717, loss = 3.52016996\n",
      "Iteration 1718, loss = 3.52005179\n",
      "Iteration 1719, loss = 3.51993364\n",
      "Iteration 1720, loss = 3.51981551\n",
      "Iteration 1721, loss = 3.51969740\n",
      "Iteration 1722, loss = 3.51957930\n",
      "Iteration 1723, loss = 3.51946123\n",
      "Iteration 1724, loss = 3.51934318\n",
      "Iteration 1725, loss = 3.51922514\n",
      "Iteration 1726, loss = 3.51910712\n",
      "Iteration 1727, loss = 3.51898912\n",
      "Iteration 1728, loss = 3.51887115\n",
      "Iteration 1729, loss = 3.51875319\n",
      "Iteration 1730, loss = 3.51863525\n",
      "Iteration 1731, loss = 3.51851732\n",
      "Iteration 1732, loss = 3.51839942\n",
      "Iteration 1733, loss = 3.51828154\n",
      "Iteration 1734, loss = 3.51816367\n",
      "Iteration 1735, loss = 3.51804583\n",
      "Iteration 1736, loss = 3.51792800\n",
      "Iteration 1737, loss = 3.51781019\n",
      "Iteration 1738, loss = 3.51769241\n",
      "Iteration 1739, loss = 3.51757464\n",
      "Iteration 1740, loss = 3.51745689\n",
      "Iteration 1741, loss = 3.51733916\n",
      "Iteration 1742, loss = 3.51722145\n",
      "Iteration 1743, loss = 3.51710376\n",
      "Iteration 1744, loss = 3.51698608\n",
      "Iteration 1745, loss = 3.51686843\n",
      "Iteration 1746, loss = 3.51675079\n",
      "Iteration 1747, loss = 3.51663318\n",
      "Iteration 1748, loss = 3.51651558\n",
      "Iteration 1749, loss = 3.51639801\n",
      "Iteration 1750, loss = 3.51628045\n",
      "Iteration 1751, loss = 3.51616291\n",
      "Iteration 1752, loss = 3.51604539\n",
      "Iteration 1753, loss = 3.51592790\n",
      "Iteration 1754, loss = 3.51581042\n",
      "Iteration 1755, loss = 3.51569296\n",
      "Iteration 1756, loss = 3.51557551\n",
      "Iteration 1757, loss = 3.51545809\n",
      "Iteration 1758, loss = 3.51534069\n",
      "Iteration 1759, loss = 3.51522331\n",
      "Iteration 1760, loss = 3.51510594\n",
      "Iteration 1761, loss = 3.51498860\n",
      "Iteration 1762, loss = 3.51487128\n",
      "Iteration 1763, loss = 3.51475397\n",
      "Iteration 1764, loss = 3.51463669\n",
      "Iteration 1765, loss = 3.51451942\n",
      "Iteration 1766, loss = 3.51440217\n",
      "Iteration 1767, loss = 3.51428495\n",
      "Iteration 1768, loss = 3.51416774\n",
      "Iteration 1769, loss = 3.51405055\n",
      "Iteration 1770, loss = 3.51393338\n",
      "Iteration 1771, loss = 3.51381624\n",
      "Iteration 1772, loss = 3.51369911\n",
      "Iteration 1773, loss = 3.51358200\n",
      "Iteration 1774, loss = 3.51346491\n",
      "Iteration 1775, loss = 3.51334784\n",
      "Iteration 1776, loss = 3.51323079\n",
      "Iteration 1777, loss = 3.51311376\n",
      "Iteration 1778, loss = 3.51299675\n",
      "Iteration 1779, loss = 3.51287976\n",
      "Iteration 1780, loss = 3.51276279\n",
      "Iteration 1781, loss = 3.51264583\n",
      "Iteration 1782, loss = 3.51252890\n",
      "Iteration 1783, loss = 3.51241199\n",
      "Iteration 1784, loss = 3.51229510\n",
      "Iteration 1785, loss = 3.51217823\n",
      "Iteration 1786, loss = 3.51206138\n",
      "Iteration 1787, loss = 3.51194454\n",
      "Iteration 1788, loss = 3.51182773\n",
      "Iteration 1789, loss = 3.51171094\n",
      "Iteration 1790, loss = 3.51159417\n",
      "Iteration 1791, loss = 3.51147741\n",
      "Iteration 1792, loss = 3.51136068\n",
      "Iteration 1793, loss = 3.51124397\n",
      "Iteration 1794, loss = 3.51112727\n",
      "Iteration 1795, loss = 3.51101060\n",
      "Iteration 1796, loss = 3.51089395\n",
      "Iteration 1797, loss = 3.51077732\n",
      "Iteration 1798, loss = 3.51066070\n",
      "Iteration 1799, loss = 3.51054411\n",
      "Iteration 1800, loss = 3.51042754\n",
      "Iteration 1801, loss = 3.51031099\n",
      "Iteration 1802, loss = 3.51019446\n",
      "Iteration 1803, loss = 3.51007794\n",
      "Iteration 1804, loss = 3.50996145\n",
      "Iteration 1805, loss = 3.50984498\n",
      "Iteration 1806, loss = 3.50972853\n",
      "Iteration 1807, loss = 3.50961210\n",
      "Iteration 1808, loss = 3.50949569\n",
      "Iteration 1809, loss = 3.50937930\n",
      "Iteration 1810, loss = 3.50926293\n",
      "Iteration 1811, loss = 3.50914658\n",
      "Iteration 1812, loss = 3.50903025\n",
      "Iteration 1813, loss = 3.50891394\n",
      "Iteration 1814, loss = 3.50879765\n",
      "Iteration 1815, loss = 3.50868138\n",
      "Iteration 1816, loss = 3.50856513\n",
      "Iteration 1817, loss = 3.50844890\n",
      "Iteration 1818, loss = 3.50833270\n",
      "Iteration 1819, loss = 3.50821651\n",
      "Iteration 1820, loss = 3.50810034\n",
      "Iteration 1821, loss = 3.50798420\n",
      "Iteration 1822, loss = 3.50786807\n",
      "Iteration 1823, loss = 3.50775197\n",
      "Iteration 1824, loss = 3.50763588\n",
      "Iteration 1825, loss = 3.50751982\n",
      "Iteration 1826, loss = 3.50740378\n",
      "Iteration 1827, loss = 3.50728775\n",
      "Iteration 1828, loss = 3.50717175\n",
      "Iteration 1829, loss = 3.50705577\n",
      "Iteration 1830, loss = 3.50693981\n",
      "Iteration 1831, loss = 3.50682387\n",
      "Iteration 1832, loss = 3.50670795\n",
      "Iteration 1833, loss = 3.50659205\n",
      "Iteration 1834, loss = 3.50647618\n",
      "Iteration 1835, loss = 3.50636032\n",
      "Iteration 1836, loss = 3.50624448\n",
      "Iteration 1837, loss = 3.50612867\n",
      "Iteration 1838, loss = 3.50601287\n",
      "Iteration 1839, loss = 3.50589710\n",
      "Iteration 1840, loss = 3.50578135\n",
      "Iteration 1841, loss = 3.50566562\n",
      "Iteration 1842, loss = 3.50554991\n",
      "Iteration 1843, loss = 3.50543422\n",
      "Iteration 1844, loss = 3.50531855\n",
      "Iteration 1845, loss = 3.50520290\n",
      "Iteration 1846, loss = 3.50508727\n",
      "Iteration 1847, loss = 3.50497167\n",
      "Iteration 1848, loss = 3.50485608\n",
      "Iteration 1849, loss = 3.50474052\n",
      "Iteration 1850, loss = 3.50462497\n",
      "Iteration 1851, loss = 3.50450945\n",
      "Iteration 1852, loss = 3.50439395\n",
      "Iteration 1853, loss = 3.50427847\n",
      "Iteration 1854, loss = 3.50416301\n",
      "Iteration 1855, loss = 3.50404758\n",
      "Iteration 1856, loss = 3.50393216\n",
      "Iteration 1857, loss = 3.50381677\n",
      "Iteration 1858, loss = 3.50370139\n",
      "Iteration 1859, loss = 3.50358604\n",
      "Iteration 1860, loss = 3.50347071\n",
      "Iteration 1861, loss = 3.50335540\n",
      "Iteration 1862, loss = 3.50324011\n",
      "Iteration 1863, loss = 3.50312484\n",
      "Iteration 1864, loss = 3.50300960\n",
      "Iteration 1865, loss = 3.50289437\n",
      "Iteration 1866, loss = 3.50277917\n",
      "Iteration 1867, loss = 3.50266399\n",
      "Iteration 1868, loss = 3.50254883\n",
      "Iteration 1869, loss = 3.50243369\n",
      "Iteration 1870, loss = 3.50231857\n",
      "Iteration 1871, loss = 3.50220348\n",
      "Iteration 1872, loss = 3.50208841\n",
      "Iteration 1873, loss = 3.50197335\n",
      "Iteration 1874, loss = 3.50185832\n",
      "Iteration 1875, loss = 3.50174331\n",
      "Iteration 1876, loss = 3.50162833\n",
      "Iteration 1877, loss = 3.50151336\n",
      "Iteration 1878, loss = 3.50139841\n",
      "Iteration 1879, loss = 3.50128349\n",
      "Iteration 1880, loss = 3.50116859\n",
      "Iteration 1881, loss = 3.50105371\n",
      "Iteration 1882, loss = 3.50093885\n",
      "Iteration 1883, loss = 3.50082402\n",
      "Iteration 1884, loss = 3.50070920\n",
      "Iteration 1885, loss = 3.50059441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1886, loss = 3.50047964\n",
      "Iteration 1887, loss = 3.50036489\n",
      "Iteration 1888, loss = 3.50025017\n",
      "Iteration 1889, loss = 3.50013546\n",
      "Iteration 1890, loss = 3.50002078\n",
      "Iteration 1891, loss = 3.49990612\n",
      "Iteration 1892, loss = 3.49979148\n",
      "Iteration 1893, loss = 3.49967686\n",
      "Iteration 1894, loss = 3.49956227\n",
      "Iteration 1895, loss = 3.49944769\n",
      "Iteration 1896, loss = 3.49933314\n",
      "Iteration 1897, loss = 3.49921861\n",
      "Iteration 1898, loss = 3.49910411\n",
      "Iteration 1899, loss = 3.49898962\n",
      "Iteration 1900, loss = 3.49887516\n",
      "Iteration 1901, loss = 3.49876072\n",
      "Iteration 1902, loss = 3.49864630\n",
      "Iteration 1903, loss = 3.49853190\n",
      "Iteration 1904, loss = 3.49841753\n",
      "Iteration 1905, loss = 3.49830318\n",
      "Iteration 1906, loss = 3.49818885\n",
      "Iteration 1907, loss = 3.49807454\n",
      "Iteration 1908, loss = 3.49796026\n",
      "Iteration 1909, loss = 3.49784599\n",
      "Iteration 1910, loss = 3.49773175\n",
      "Iteration 1911, loss = 3.49761753\n",
      "Iteration 1912, loss = 3.49750334\n",
      "Iteration 1913, loss = 3.49738917\n",
      "Iteration 1914, loss = 3.49727501\n",
      "Iteration 1915, loss = 3.49716089\n",
      "Iteration 1916, loss = 3.49704678\n",
      "Iteration 1917, loss = 3.49693270\n",
      "Iteration 1918, loss = 3.49681864\n",
      "Iteration 1919, loss = 3.49670460\n",
      "Iteration 1920, loss = 3.49659058\n",
      "Iteration 1921, loss = 3.49647659\n",
      "Iteration 1922, loss = 3.49636262\n",
      "Iteration 1923, loss = 3.49624867\n",
      "Iteration 1924, loss = 3.49613474\n",
      "Iteration 1925, loss = 3.49602084\n",
      "Iteration 1926, loss = 3.49590696\n",
      "Iteration 1927, loss = 3.49579310\n",
      "Iteration 1928, loss = 3.49567927\n",
      "Iteration 1929, loss = 3.49556545\n",
      "Iteration 1930, loss = 3.49545167\n",
      "Iteration 1931, loss = 3.49533790\n",
      "Iteration 1932, loss = 3.49522415\n",
      "Iteration 1933, loss = 3.49511043\n",
      "Iteration 1934, loss = 3.49499674\n",
      "Iteration 1935, loss = 3.49488306\n",
      "Iteration 1936, loss = 3.49476941\n",
      "Iteration 1937, loss = 3.49465578\n",
      "Iteration 1938, loss = 3.49454217\n",
      "Iteration 1939, loss = 3.49442859\n",
      "Iteration 1940, loss = 3.49431503\n",
      "Iteration 1941, loss = 3.49420149\n",
      "Iteration 1942, loss = 3.49408797\n",
      "Iteration 1943, loss = 3.49397448\n",
      "Iteration 1944, loss = 3.49386101\n",
      "Iteration 1945, loss = 3.49374757\n",
      "Iteration 1946, loss = 3.49363414\n",
      "Iteration 1947, loss = 3.49352074\n",
      "Iteration 1948, loss = 3.49340737\n",
      "Iteration 1949, loss = 3.49329401\n",
      "Iteration 1950, loss = 3.49318068\n",
      "Iteration 1951, loss = 3.49306738\n",
      "Iteration 1952, loss = 3.49295409\n",
      "Iteration 1953, loss = 3.49284083\n",
      "Iteration 1954, loss = 3.49272759\n",
      "Iteration 1955, loss = 3.49261438\n",
      "Iteration 1956, loss = 3.49250119\n",
      "Iteration 1957, loss = 3.49238802\n",
      "Iteration 1958, loss = 3.49227488\n",
      "Iteration 1959, loss = 3.49216176\n",
      "Iteration 1960, loss = 3.49204866\n",
      "Iteration 1961, loss = 3.49193558\n",
      "Iteration 1962, loss = 3.49182253\n",
      "Iteration 1963, loss = 3.49170951\n",
      "Iteration 1964, loss = 3.49159650\n",
      "Iteration 1965, loss = 3.49148352\n",
      "Iteration 1966, loss = 3.49137056\n",
      "Iteration 1967, loss = 3.49125763\n",
      "Iteration 1968, loss = 3.49114472\n",
      "Iteration 1969, loss = 3.49103183\n",
      "Iteration 1970, loss = 3.49091897\n",
      "Iteration 1971, loss = 3.49080613\n",
      "Iteration 1972, loss = 3.49069332\n",
      "Iteration 1973, loss = 3.49058052\n",
      "Iteration 1974, loss = 3.49046775\n",
      "Iteration 1975, loss = 3.49035501\n",
      "Iteration 1976, loss = 3.49024229\n",
      "Iteration 1977, loss = 3.49012959\n",
      "Iteration 1978, loss = 3.49001692\n",
      "Iteration 1979, loss = 3.48990427\n",
      "Iteration 1980, loss = 3.48979164\n",
      "Iteration 1981, loss = 3.48967904\n",
      "Iteration 1982, loss = 3.48956646\n",
      "Iteration 1983, loss = 3.48945390\n",
      "Iteration 1984, loss = 3.48934137\n",
      "Iteration 1985, loss = 3.48922887\n",
      "Iteration 1986, loss = 3.48911638\n",
      "Iteration 1987, loss = 3.48900392\n",
      "Iteration 1988, loss = 3.48889149\n",
      "Iteration 1989, loss = 3.48877908\n",
      "Iteration 1990, loss = 3.48866669\n",
      "Iteration 1991, loss = 3.48855432\n",
      "Iteration 1992, loss = 3.48844198\n",
      "Iteration 1993, loss = 3.48832967\n",
      "Iteration 1994, loss = 3.48821738\n",
      "Iteration 1995, loss = 3.48810511\n",
      "Iteration 1996, loss = 3.48799287\n",
      "Iteration 1997, loss = 3.48788065\n",
      "Iteration 1998, loss = 3.48776845\n",
      "Iteration 1999, loss = 3.48765628\n",
      "Iteration 2000, loss = 3.48754413\n"
     ]
    }
   ],
   "source": [
    "#Creating classifier with changed parameters\n",
    "clf3 = MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 150, 50), max_iter=2000, alpha=0.0001,\n",
    "                     solver='sgd', verbose=True, random_state=414759, tol=1e-4)\n",
    "\n",
    "#Fitting classifier into the training data\n",
    "clf3.fit(X_train_NN, y_train_NN)\n",
    "\n",
    "#Predicting values for the testing set\n",
    "y_pred3 = clf3.predict(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Multi-layer Perceptron is: 0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "#Printing accuracy of the model\n",
    "print('The accuracy of the Multi-layer Perceptron is:', accuracy_score(y_test_NN, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.38817394\n",
      "Iteration 2, loss = 4.89958065\n",
      "Iteration 3, loss = 4.56455104\n",
      "Iteration 4, loss = 4.35198351\n",
      "Iteration 5, loss = 4.22973589\n",
      "Iteration 6, loss = 4.17250566\n",
      "Iteration 7, loss = 4.15203567\n",
      "Iteration 8, loss = 4.14549778\n",
      "Iteration 9, loss = 4.13977673\n",
      "Iteration 10, loss = 4.12985752\n",
      "Iteration 11, loss = 4.11488436\n",
      "Iteration 12, loss = 4.09463554\n",
      "Iteration 13, loss = 4.06880824\n",
      "Iteration 14, loss = 4.03814963\n",
      "Iteration 15, loss = 4.00494428\n",
      "Iteration 16, loss = 3.97214817\n",
      "Iteration 17, loss = 3.94210808\n",
      "Iteration 18, loss = 3.91598520\n",
      "Iteration 19, loss = 3.89416398\n",
      "Iteration 20, loss = 3.87684942\n",
      "Iteration 21, loss = 3.86397058\n",
      "Iteration 22, loss = 3.85465748\n",
      "Iteration 23, loss = 3.84729935\n",
      "Iteration 24, loss = 3.84037469\n",
      "Iteration 25, loss = 3.83313412\n",
      "Iteration 26, loss = 3.82545138\n",
      "Iteration 27, loss = 3.81726675\n",
      "Iteration 28, loss = 3.80847060\n",
      "Iteration 29, loss = 3.79927740\n",
      "Iteration 30, loss = 3.79035045\n",
      "Iteration 31, loss = 3.78239970\n",
      "Iteration 32, loss = 3.77575465\n",
      "Iteration 33, loss = 3.77032605\n",
      "Iteration 34, loss = 3.76583836\n",
      "Iteration 35, loss = 3.76200046\n",
      "Iteration 36, loss = 3.75848320\n",
      "Iteration 37, loss = 3.75487643\n",
      "Iteration 38, loss = 3.75083234\n",
      "Iteration 39, loss = 3.74629964\n",
      "Iteration 40, loss = 3.74155850\n",
      "Iteration 41, loss = 3.73699523\n",
      "Iteration 42, loss = 3.73286118\n",
      "Iteration 43, loss = 3.72921888\n",
      "Iteration 44, loss = 3.72601725\n",
      "Iteration 45, loss = 3.72314558\n",
      "Iteration 46, loss = 3.72045707\n",
      "Iteration 47, loss = 3.71784172\n",
      "Iteration 48, loss = 3.71531385\n",
      "Iteration 49, loss = 3.71298375\n",
      "Iteration 50, loss = 3.71091344\n",
      "Iteration 51, loss = 3.70902981\n",
      "Iteration 52, loss = 3.70720099\n",
      "Iteration 53, loss = 3.70536440\n",
      "Iteration 54, loss = 3.70354986\n",
      "Iteration 55, loss = 3.70180908\n",
      "Iteration 56, loss = 3.70017048\n",
      "Iteration 57, loss = 3.69865577\n",
      "Iteration 58, loss = 3.69729332\n",
      "Iteration 59, loss = 3.69609516\n",
      "Iteration 60, loss = 3.69503440\n",
      "Iteration 61, loss = 3.69404736\n",
      "Iteration 62, loss = 3.69304860\n",
      "Iteration 63, loss = 3.69195925\n",
      "Iteration 64, loss = 3.69075530\n",
      "Iteration 65, loss = 3.68949822\n",
      "Iteration 66, loss = 3.68829852\n",
      "Iteration 67, loss = 3.68723472\n",
      "Iteration 68, loss = 3.68630828\n",
      "Iteration 69, loss = 3.68546958\n",
      "Iteration 70, loss = 3.68466862\n",
      "Iteration 71, loss = 3.68387767\n",
      "Iteration 72, loss = 3.68308641\n",
      "Iteration 73, loss = 3.68229447\n",
      "Iteration 74, loss = 3.68150905\n",
      "Iteration 75, loss = 3.68074205\n",
      "Iteration 76, loss = 3.68000627\n",
      "Iteration 77, loss = 3.67931053\n",
      "Iteration 78, loss = 3.67865275\n",
      "Iteration 79, loss = 3.67801755\n",
      "Iteration 80, loss = 3.67738675\n",
      "Iteration 81, loss = 3.67675446\n",
      "Iteration 82, loss = 3.67612913\n",
      "Iteration 83, loss = 3.67552156\n",
      "Iteration 84, loss = 3.67493552\n",
      "Iteration 85, loss = 3.67436975\n",
      "Iteration 86, loss = 3.67382344\n",
      "Iteration 87, loss = 3.67329642\n",
      "Iteration 88, loss = 3.67278652\n",
      "Iteration 89, loss = 3.67228894\n",
      "Iteration 90, loss = 3.67179891\n",
      "Iteration 91, loss = 3.67131521\n",
      "Iteration 92, loss = 3.67084134\n",
      "Iteration 93, loss = 3.67038194\n",
      "Iteration 94, loss = 3.66993785\n",
      "Iteration 95, loss = 3.66950612\n",
      "Iteration 96, loss = 3.66908432\n",
      "Iteration 97, loss = 3.66867228\n",
      "Iteration 98, loss = 3.66826973\n",
      "Iteration 99, loss = 3.66787535\n",
      "Iteration 100, loss = 3.66748890\n",
      "Iteration 101, loss = 3.66711214\n",
      "Iteration 102, loss = 3.66674638\n",
      "Iteration 103, loss = 3.66639060\n",
      "Iteration 104, loss = 3.66604262\n",
      "Iteration 105, loss = 3.66570149\n",
      "Iteration 106, loss = 3.66536822\n",
      "Iteration 107, loss = 3.66504448\n",
      "Iteration 108, loss = 3.66473076\n",
      "Iteration 109, loss = 3.66442596\n",
      "Iteration 110, loss = 3.66412860\n",
      "Iteration 111, loss = 3.66383789\n",
      "Iteration 112, loss = 3.66355373\n",
      "Iteration 113, loss = 3.66327632\n",
      "Iteration 114, loss = 3.66300622\n",
      "Iteration 115, loss = 3.66274403\n",
      "Iteration 116, loss = 3.66248961\n",
      "Iteration 117, loss = 3.66224196\n",
      "Iteration 118, loss = 3.66200019\n",
      "Iteration 119, loss = 3.66176418\n",
      "Iteration 120, loss = 3.66153421\n",
      "Iteration 121, loss = 3.66131032\n",
      "Iteration 122, loss = 3.66109222\n",
      "Iteration 123, loss = 3.66087961\n",
      "Iteration 124, loss = 3.66067241\n",
      "Iteration 125, loss = 3.66047061\n",
      "Iteration 126, loss = 3.66027405\n",
      "Iteration 127, loss = 3.66008248\n",
      "Iteration 128, loss = 3.65989573\n",
      "Iteration 129, loss = 3.65971366\n",
      "Iteration 130, loss = 3.65953614\n",
      "Iteration 131, loss = 3.65936309\n",
      "Iteration 132, loss = 3.65919453\n",
      "Iteration 133, loss = 3.65903044\n",
      "Iteration 134, loss = 3.65887057\n",
      "Iteration 135, loss = 3.65871470\n",
      "Iteration 136, loss = 3.65856278\n",
      "Iteration 137, loss = 3.65841484\n",
      "Iteration 138, loss = 3.65827080\n",
      "Iteration 139, loss = 3.65813053\n",
      "Iteration 140, loss = 3.65799387\n",
      "Iteration 141, loss = 3.65786073\n",
      "Iteration 142, loss = 3.65773106\n",
      "Iteration 143, loss = 3.65760478\n",
      "Iteration 144, loss = 3.65748184\n",
      "Iteration 145, loss = 3.65736213\n",
      "Iteration 146, loss = 3.65724553\n",
      "Iteration 147, loss = 3.65713195\n",
      "Iteration 148, loss = 3.65702135\n",
      "Iteration 149, loss = 3.65691369\n",
      "Iteration 150, loss = 3.65680890\n",
      "Iteration 151, loss = 3.65670685\n",
      "Iteration 152, loss = 3.65660743\n",
      "Iteration 153, loss = 3.65651059\n",
      "Iteration 154, loss = 3.65641628\n",
      "Iteration 155, loss = 3.65632444\n",
      "Iteration 156, loss = 3.65623500\n",
      "Iteration 157, loss = 3.65614788\n",
      "Iteration 158, loss = 3.65606299\n",
      "Iteration 159, loss = 3.65598027\n",
      "Iteration 160, loss = 3.65589967\n",
      "Iteration 161, loss = 3.65582112\n",
      "Iteration 162, loss = 3.65574456\n",
      "Iteration 163, loss = 3.65566991\n",
      "Iteration 164, loss = 3.65559713\n",
      "Iteration 165, loss = 3.65552616\n",
      "Iteration 166, loss = 3.65545694\n",
      "Iteration 167, loss = 3.65538941\n",
      "Iteration 168, loss = 3.65532352\n",
      "Iteration 169, loss = 3.65525922\n",
      "Iteration 170, loss = 3.65519646\n",
      "Iteration 171, loss = 3.65513518\n",
      "Iteration 172, loss = 3.65507536\n",
      "Iteration 173, loss = 3.65501693\n",
      "Iteration 174, loss = 3.65495986\n",
      "Iteration 175, loss = 3.65490411\n",
      "Iteration 176, loss = 3.65484963\n",
      "Iteration 177, loss = 3.65479640\n",
      "Iteration 178, loss = 3.65474436\n",
      "Iteration 179, loss = 3.65469349\n",
      "Iteration 180, loss = 3.65464376\n",
      "Iteration 181, loss = 3.65459512\n",
      "Iteration 182, loss = 3.65454756\n",
      "Iteration 183, loss = 3.65450103\n",
      "Iteration 184, loss = 3.65445551\n",
      "Iteration 185, loss = 3.65441097\n",
      "Iteration 186, loss = 3.65436739\n",
      "Iteration 187, loss = 3.65432473\n",
      "Iteration 188, loss = 3.65428297\n",
      "Iteration 189, loss = 3.65424209\n",
      "Iteration 190, loss = 3.65420207\n",
      "Iteration 191, loss = 3.65416287\n",
      "Iteration 192, loss = 3.65412449\n",
      "Iteration 193, loss = 3.65408688\n",
      "Iteration 194, loss = 3.65405005\n",
      "Iteration 195, loss = 3.65401396\n",
      "Iteration 196, loss = 3.65397859\n",
      "Iteration 197, loss = 3.65394393\n",
      "Iteration 198, loss = 3.65390995\n",
      "Iteration 199, loss = 3.65387665\n",
      "Iteration 200, loss = 3.65384400\n",
      "Iteration 201, loss = 3.65381198\n",
      "Iteration 202, loss = 3.65378058\n",
      "Iteration 203, loss = 3.65374978\n",
      "Iteration 204, loss = 3.65371957\n",
      "Iteration 205, loss = 3.65368993\n",
      "Iteration 206, loss = 3.65366085\n",
      "Iteration 207, loss = 3.65363232\n",
      "Iteration 208, loss = 3.65360431\n",
      "Iteration 209, loss = 3.65357682\n",
      "Iteration 210, loss = 3.65354983\n",
      "Iteration 211, loss = 3.65352333\n",
      "Iteration 212, loss = 3.65349731\n",
      "Iteration 213, loss = 3.65347176\n",
      "Iteration 214, loss = 3.65344666\n",
      "Iteration 215, loss = 3.65342201\n",
      "Iteration 216, loss = 3.65339779\n",
      "Iteration 217, loss = 3.65337400\n",
      "Iteration 218, loss = 3.65335062\n",
      "Iteration 219, loss = 3.65332764\n",
      "Iteration 220, loss = 3.65330506\n",
      "Iteration 221, loss = 3.65328286\n",
      "Iteration 222, loss = 3.65326104\n",
      "Iteration 223, loss = 3.65323959\n",
      "Iteration 224, loss = 3.65321849\n",
      "Iteration 225, loss = 3.65319775\n",
      "Iteration 226, loss = 3.65317734\n",
      "Iteration 227, loss = 3.65315727\n",
      "Iteration 228, loss = 3.65313753\n",
      "Iteration 229, loss = 3.65311811\n",
      "Iteration 230, loss = 3.65309901\n",
      "Iteration 231, loss = 3.65308021\n",
      "Iteration 232, loss = 3.65306170\n",
      "Iteration 233, loss = 3.65304349\n",
      "Iteration 234, loss = 3.65302557\n",
      "Iteration 235, loss = 3.65300793\n",
      "Iteration 236, loss = 3.65299056\n",
      "Iteration 237, loss = 3.65297346\n",
      "Iteration 238, loss = 3.65295662\n",
      "Iteration 239, loss = 3.65294004\n",
      "Iteration 240, loss = 3.65292372\n",
      "Iteration 241, loss = 3.65290763\n",
      "Iteration 242, loss = 3.65289179\n",
      "Iteration 243, loss = 3.65287619\n",
      "Iteration 244, loss = 3.65286082\n",
      "Iteration 245, loss = 3.65284567\n",
      "Iteration 246, loss = 3.65283075\n",
      "Iteration 247, loss = 3.65281604\n",
      "Iteration 248, loss = 3.65280155\n",
      "Iteration 249, loss = 3.65278727\n",
      "Iteration 250, loss = 3.65277319\n",
      "Iteration 251, loss = 3.65275931\n",
      "Iteration 252, loss = 3.65274563\n",
      "Iteration 253, loss = 3.65273215\n",
      "Iteration 254, loss = 3.65271885\n",
      "Iteration 255, loss = 3.65270574\n",
      "Iteration 256, loss = 3.65269281\n",
      "Iteration 257, loss = 3.65268006\n",
      "Iteration 258, loss = 3.65266749\n",
      "Iteration 259, loss = 3.65265508\n",
      "Iteration 260, loss = 3.65264285\n",
      "Iteration 261, loss = 3.65263078\n",
      "Iteration 262, loss = 3.65261888\n",
      "Iteration 263, loss = 3.65260713\n",
      "Iteration 264, loss = 3.65259554\n",
      "Iteration 265, loss = 3.65258411\n",
      "Iteration 266, loss = 3.65257282\n",
      "Iteration 267, loss = 3.65256169\n",
      "Iteration 268, loss = 3.65255070\n",
      "Iteration 269, loss = 3.65253985\n",
      "Iteration 270, loss = 3.65252914\n",
      "Iteration 271, loss = 3.65251857\n",
      "Iteration 272, loss = 3.65250814\n",
      "Iteration 273, loss = 3.65249784\n",
      "Iteration 274, loss = 3.65248767\n",
      "Iteration 275, loss = 3.65247763\n",
      "Iteration 276, loss = 3.65246771\n",
      "Iteration 277, loss = 3.65245792\n",
      "Iteration 278, loss = 3.65244826\n",
      "Iteration 279, loss = 3.65243871\n",
      "Iteration 280, loss = 3.65242928\n",
      "Iteration 281, loss = 3.65241996\n",
      "Iteration 282, loss = 3.65241076\n",
      "Iteration 283, loss = 3.65240167\n",
      "Iteration 284, loss = 3.65239269\n",
      "Iteration 285, loss = 3.65238382\n",
      "Iteration 286, loss = 3.65237506\n",
      "Iteration 287, loss = 3.65236640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 288, loss = 3.65235785\n",
      "Iteration 289, loss = 3.65234939\n",
      "Iteration 290, loss = 3.65234104\n",
      "Iteration 291, loss = 3.65233278\n",
      "Iteration 292, loss = 3.65232462\n",
      "Iteration 293, loss = 3.65231656\n",
      "Iteration 294, loss = 3.65230858\n",
      "Iteration 295, loss = 3.65230071\n",
      "Iteration 296, loss = 3.65229292\n",
      "Iteration 297, loss = 3.65228522\n",
      "Iteration 298, loss = 3.65227761\n",
      "Iteration 299, loss = 3.65227008\n",
      "Iteration 300, loss = 3.65226264\n",
      "Iteration 301, loss = 3.65225528\n",
      "Iteration 302, loss = 3.65224801\n",
      "Iteration 303, loss = 3.65224082\n",
      "Iteration 304, loss = 3.65223370\n",
      "Iteration 305, loss = 3.65222667\n",
      "Iteration 306, loss = 3.65221971\n",
      "Iteration 307, loss = 3.65221283\n",
      "Iteration 308, loss = 3.65220603\n",
      "Iteration 309, loss = 3.65219930\n",
      "Iteration 310, loss = 3.65219264\n",
      "Iteration 311, loss = 3.65218605\n",
      "Iteration 312, loss = 3.65217954\n",
      "Iteration 313, loss = 3.65217309\n",
      "Iteration 314, loss = 3.65216672\n",
      "Iteration 315, loss = 3.65216041\n",
      "Iteration 316, loss = 3.65215417\n",
      "Iteration 317, loss = 3.65214799\n",
      "Iteration 318, loss = 3.65214188\n",
      "Iteration 319, loss = 3.65213583\n",
      "Iteration 320, loss = 3.65212985\n",
      "Iteration 321, loss = 3.65212393\n",
      "Iteration 322, loss = 3.65211807\n",
      "Iteration 323, loss = 3.65211227\n",
      "Iteration 324, loss = 3.65210653\n",
      "Iteration 325, loss = 3.65210084\n",
      "Iteration 326, loss = 3.65209522\n",
      "Iteration 327, loss = 3.65208965\n",
      "Iteration 328, loss = 3.65208414\n",
      "Iteration 329, loss = 3.65207869\n",
      "Iteration 330, loss = 3.65207329\n",
      "Iteration 331, loss = 3.65206794\n",
      "Iteration 332, loss = 3.65206265\n",
      "Iteration 333, loss = 3.65205741\n",
      "Iteration 334, loss = 3.65205222\n",
      "Iteration 335, loss = 3.65204709\n",
      "Iteration 336, loss = 3.65204200\n",
      "Iteration 337, loss = 3.65203696\n",
      "Iteration 338, loss = 3.65203198\n",
      "Iteration 339, loss = 3.65202704\n",
      "Iteration 340, loss = 3.65202214\n",
      "Iteration 341, loss = 3.65201730\n",
      "Iteration 342, loss = 3.65201250\n",
      "Iteration 343, loss = 3.65200775\n",
      "Iteration 344, loss = 3.65200305\n",
      "Iteration 345, loss = 3.65199838\n",
      "Iteration 346, loss = 3.65199377\n",
      "Iteration 347, loss = 3.65198919\n",
      "Iteration 348, loss = 3.65198466\n",
      "Iteration 349, loss = 3.65198018\n",
      "Iteration 350, loss = 3.65197573\n",
      "Iteration 351, loss = 3.65197133\n",
      "Iteration 352, loss = 3.65196696\n",
      "Iteration 353, loss = 3.65196264\n",
      "Iteration 354, loss = 3.65195836\n",
      "Iteration 355, loss = 3.65195411\n",
      "Iteration 356, loss = 3.65194991\n",
      "Iteration 357, loss = 3.65194574\n",
      "Iteration 358, loss = 3.65194161\n",
      "Iteration 359, loss = 3.65193752\n",
      "Iteration 360, loss = 3.65193347\n",
      "Iteration 361, loss = 3.65192945\n",
      "Iteration 362, loss = 3.65192547\n",
      "Iteration 363, loss = 3.65192153\n",
      "Iteration 364, loss = 3.65191762\n",
      "Iteration 365, loss = 3.65191374\n",
      "Iteration 366, loss = 3.65190990\n",
      "Iteration 367, loss = 3.65190609\n",
      "Iteration 368, loss = 3.65190232\n",
      "Iteration 369, loss = 3.65189858\n",
      "Iteration 370, loss = 3.65189487\n",
      "Iteration 371, loss = 3.65189119\n",
      "Iteration 372, loss = 3.65188755\n",
      "Iteration 373, loss = 3.65188394\n",
      "Iteration 374, loss = 3.65188036\n",
      "Iteration 375, loss = 3.65187681\n",
      "Iteration 376, loss = 3.65187329\n",
      "Iteration 377, loss = 3.65186980\n",
      "Iteration 378, loss = 3.65186634\n",
      "Iteration 379, loss = 3.65186291\n",
      "Iteration 380, loss = 3.65185951\n",
      "Iteration 381, loss = 3.65185614\n",
      "Iteration 382, loss = 3.65185280\n",
      "Iteration 383, loss = 3.65184948\n",
      "Iteration 384, loss = 3.65184620\n",
      "Iteration 385, loss = 3.65184294\n",
      "Iteration 386, loss = 3.65183970\n",
      "Iteration 387, loss = 3.65183650\n",
      "Iteration 388, loss = 3.65183332\n",
      "Iteration 389, loss = 3.65183017\n",
      "Iteration 390, loss = 3.65182704\n",
      "Iteration 391, loss = 3.65182394\n",
      "Iteration 392, loss = 3.65182086\n",
      "Iteration 393, loss = 3.65181781\n",
      "Iteration 394, loss = 3.65181479\n",
      "Iteration 395, loss = 3.65181178\n",
      "Iteration 396, loss = 3.65180881\n",
      "Iteration 397, loss = 3.65180585\n",
      "Iteration 398, loss = 3.65180292\n",
      "Iteration 399, loss = 3.65180002\n",
      "Iteration 400, loss = 3.65179714\n",
      "Iteration 401, loss = 3.65179428\n",
      "Iteration 402, loss = 3.65179144\n",
      "Iteration 403, loss = 3.65178863\n",
      "Iteration 404, loss = 3.65178583\n",
      "Iteration 405, loss = 3.65178306\n",
      "Iteration 406, loss = 3.65178032\n",
      "Iteration 407, loss = 3.65177759\n",
      "Iteration 408, loss = 3.65177488\n",
      "Iteration 409, loss = 3.65177220\n",
      "Iteration 410, loss = 3.65176954\n",
      "Iteration 411, loss = 3.65176689\n",
      "Iteration 412, loss = 3.65176427\n",
      "Iteration 413, loss = 3.65176167\n",
      "Iteration 414, loss = 3.65175909\n",
      "Iteration 415, loss = 3.65175653\n",
      "Iteration 416, loss = 3.65175398\n",
      "Iteration 417, loss = 3.65175146\n",
      "Iteration 418, loss = 3.65174896\n",
      "Iteration 419, loss = 3.65174647\n",
      "Iteration 420, loss = 3.65174401\n",
      "Iteration 421, loss = 3.65174156\n",
      "Iteration 422, loss = 3.65173913\n",
      "Iteration 423, loss = 3.65173672\n",
      "Iteration 424, loss = 3.65173433\n",
      "Iteration 425, loss = 3.65173195\n",
      "Iteration 426, loss = 3.65172959\n",
      "Iteration 427, loss = 3.65172725\n",
      "Iteration 428, loss = 3.65172493\n",
      "Iteration 429, loss = 3.65172263\n",
      "Iteration 430, loss = 3.65172034\n",
      "Iteration 431, loss = 3.65171807\n",
      "Iteration 432, loss = 3.65171581\n",
      "Iteration 433, loss = 3.65171357\n",
      "Iteration 434, loss = 3.65171135\n",
      "Iteration 435, loss = 3.65170914\n",
      "Iteration 436, loss = 3.65170695\n",
      "Iteration 437, loss = 3.65170478\n",
      "Iteration 438, loss = 3.65170262\n",
      "Iteration 439, loss = 3.65170048\n",
      "Iteration 440, loss = 3.65169835\n",
      "Iteration 441, loss = 3.65169624\n",
      "Iteration 442, loss = 3.65169414\n",
      "Iteration 443, loss = 3.65169206\n",
      "Iteration 444, loss = 3.65168999\n",
      "Iteration 445, loss = 3.65168794\n",
      "Iteration 446, loss = 3.65168590\n",
      "Iteration 447, loss = 3.65168388\n",
      "Iteration 448, loss = 3.65168187\n",
      "Iteration 449, loss = 3.65167987\n",
      "Iteration 450, loss = 3.65167789\n",
      "Iteration 451, loss = 3.65167592\n",
      "Iteration 452, loss = 3.65167397\n",
      "Iteration 453, loss = 3.65167203\n",
      "Iteration 454, loss = 3.65167010\n",
      "Iteration 455, loss = 3.65166819\n",
      "Iteration 456, loss = 3.65166629\n",
      "Iteration 457, loss = 3.65166440\n",
      "Iteration 458, loss = 3.65166253\n",
      "Iteration 459, loss = 3.65166066\n",
      "Iteration 460, loss = 3.65165882\n",
      "Iteration 461, loss = 3.65165698\n",
      "Iteration 462, loss = 3.65165516\n",
      "Iteration 463, loss = 3.65165334\n",
      "Iteration 464, loss = 3.65165155\n",
      "Iteration 465, loss = 3.65164976\n",
      "Iteration 466, loss = 3.65164798\n",
      "Iteration 467, loss = 3.65164622\n",
      "Iteration 468, loss = 3.65164447\n",
      "Iteration 469, loss = 3.65164273\n",
      "Iteration 470, loss = 3.65164100\n",
      "Iteration 471, loss = 3.65163928\n",
      "Iteration 472, loss = 3.65163758\n",
      "Iteration 473, loss = 3.65163589\n",
      "Iteration 474, loss = 3.65163420\n",
      "Iteration 475, loss = 3.65163253\n",
      "Iteration 476, loss = 3.65163087\n",
      "Iteration 477, loss = 3.65162922\n",
      "Iteration 478, loss = 3.65162758\n",
      "Iteration 479, loss = 3.65162595\n",
      "Iteration 480, loss = 3.65162434\n",
      "Iteration 481, loss = 3.65162273\n",
      "Iteration 482, loss = 3.65162113\n",
      "Iteration 483, loss = 3.65161955\n",
      "Iteration 484, loss = 3.65161797\n",
      "Iteration 485, loss = 3.65161640\n",
      "Iteration 486, loss = 3.65161485\n",
      "Iteration 487, loss = 3.65161330\n",
      "Iteration 488, loss = 3.65161177\n",
      "Iteration 489, loss = 3.65161024\n",
      "Iteration 490, loss = 3.65160872\n",
      "Iteration 491, loss = 3.65160722\n",
      "Iteration 492, loss = 3.65160572\n",
      "Iteration 493, loss = 3.65160423\n",
      "Iteration 494, loss = 3.65160275\n",
      "Iteration 495, loss = 3.65160128\n",
      "Iteration 496, loss = 3.65159982\n",
      "Iteration 497, loss = 3.65159837\n",
      "Iteration 498, loss = 3.65159693\n",
      "Iteration 499, loss = 3.65159550\n",
      "Iteration 500, loss = 3.65159408\n",
      "Iteration 501, loss = 3.65159266\n",
      "Iteration 502, loss = 3.65159125\n",
      "Iteration 503, loss = 3.65158986\n",
      "Iteration 504, loss = 3.65158847\n",
      "Iteration 505, loss = 3.65158709\n",
      "Iteration 506, loss = 3.65158572\n",
      "Iteration 507, loss = 3.65158435\n",
      "Iteration 508, loss = 3.65158300\n",
      "Iteration 509, loss = 3.65158165\n",
      "Iteration 510, loss = 3.65158031\n",
      "Iteration 511, loss = 3.65157898\n",
      "Iteration 512, loss = 3.65157766\n",
      "Iteration 513, loss = 3.65157634\n",
      "Iteration 514, loss = 3.65157504\n",
      "Iteration 515, loss = 3.65157374\n",
      "Iteration 516, loss = 3.65157245\n",
      "Iteration 517, loss = 3.65157117\n",
      "Iteration 518, loss = 3.65156989\n",
      "Iteration 519, loss = 3.65156862\n",
      "Iteration 520, loss = 3.65156736\n",
      "Iteration 521, loss = 3.65156611\n",
      "Iteration 522, loss = 3.65156487\n",
      "Iteration 523, loss = 3.65156363\n",
      "Iteration 524, loss = 3.65156240\n",
      "Iteration 525, loss = 3.65156117\n",
      "Iteration 526, loss = 3.65155996\n",
      "Iteration 527, loss = 3.65155875\n",
      "Iteration 528, loss = 3.65155755\n",
      "Iteration 529, loss = 3.65155635\n",
      "Iteration 530, loss = 3.65155516\n",
      "Iteration 531, loss = 3.65155398\n",
      "Iteration 532, loss = 3.65155281\n",
      "Iteration 533, loss = 3.65155164\n",
      "Iteration 534, loss = 3.65155048\n",
      "Iteration 535, loss = 3.65154933\n",
      "Iteration 536, loss = 3.65154818\n",
      "Iteration 537, loss = 3.65154704\n",
      "Iteration 538, loss = 3.65154591\n",
      "Iteration 539, loss = 3.65154478\n",
      "Iteration 540, loss = 3.65154366\n",
      "Iteration 541, loss = 3.65154254\n",
      "Iteration 542, loss = 3.65154144\n",
      "Iteration 543, loss = 3.65154033\n",
      "Iteration 544, loss = 3.65153924\n",
      "Iteration 545, loss = 3.65153815\n",
      "Iteration 546, loss = 3.65153707\n",
      "Iteration 547, loss = 3.65153599\n",
      "Iteration 548, loss = 3.65153492\n",
      "Iteration 549, loss = 3.65153385\n",
      "Iteration 550, loss = 3.65153279\n",
      "Iteration 551, loss = 3.65153174\n",
      "Iteration 552, loss = 3.65153069\n",
      "Iteration 553, loss = 3.65152965\n",
      "Iteration 554, loss = 3.65152862\n",
      "Iteration 555, loss = 3.65152759\n",
      "Iteration 556, loss = 3.65152656\n",
      "Iteration 557, loss = 3.65152554\n",
      "Iteration 558, loss = 3.65152453\n",
      "Iteration 559, loss = 3.65152352\n",
      "Iteration 560, loss = 3.65152252\n",
      "Iteration 561, loss = 3.65152153\n",
      "Iteration 562, loss = 3.65152053\n",
      "Iteration 563, loss = 3.65151955\n",
      "Iteration 564, loss = 3.65151857\n",
      "Iteration 565, loss = 3.65151759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 566, loss = 3.65151663\n",
      "Iteration 567, loss = 3.65151566\n",
      "Iteration 568, loss = 3.65151470\n",
      "Iteration 569, loss = 3.65151375\n",
      "Iteration 570, loss = 3.65151280\n",
      "Iteration 571, loss = 3.65151186\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#Creating classifier with changed parameters\n",
    "clf4 = MLPClassifier(activation='identity', hidden_layer_sizes=(100, 100, 100,), max_iter=20000, alpha=0.0001,\n",
    "                     solver='adam', verbose=True, random_state=414759, tol=1e-6)\n",
    "\n",
    "#Fitting classifier into the training data\n",
    "clf4.fit(X_train_NN, y_train_NN)\n",
    "\n",
    "#Predicting values for the testing set\n",
    "y_pred4 = clf4.predict(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Multi-layer Perceptron is: 0.29411764705882354\n"
     ]
    }
   ],
   "source": [
    "#Printing accuracy of the model\n",
    "print('The accuracy of the Multi-layer Perceptron is:', accuracy_score(y_test_NN, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Based on your result of (e) train 2 more Neural Networks with different settings (change at least 4 parameters (2 each)). Explain your parameters and the choice of the activation function. Evaluate the different Neural Networks with your test set by giving the accuracy. Try to increase the accuracy and analyse the factors that prohibit better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**<br>\n",
    "We experimented with different parameters, and we were not able to improve our accuracy. Even tough we had some interesting observations:\n",
    "- Surprisingly the best accuracy we get with identity activation function\n",
    "- Logistic activation function does not result in good accuracy, it seems that it gets stuck in the local optimum of the loss function, and cannot escape it, even when we decrease tolerance and increase n_iter_no_change\n",
    "- For tanh and relu activation functions at the end we end up with smaller value of loss function, compared to the linear model. It may indicate that models with non-linear activation functions overfit the training data, and do not perform well on the testing dataset.\n",
    "- When we use Adam solver with non-linear activation function, the loss function converges quickly to low values, but accuracy decreases drastically. (data overfitting)\n",
    "- increasing the number of hidden layers and changing the topology of the network has rather positive influance on the accuracy\n",
    "\n",
    "At the end model3 has *tanh* activation function, with additional hidden layers (100, 50, 150, 50). We also increased the number of iteration to 2000, from 200, and changed the optimization solver to stochastic gradient descent (sgd). <br>\n",
    "\n",
    "In model4, we stayed with the *identity* activation function and adam solver, as it showed the best accuracy. Changing the neural network topology did not have an impact on the accuracy. We also tried to change maximum iteration, and tolerance, however in this case the model quickly converges to the optimum of the loss function and stays there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 - Evaluation (10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Consider two models of question 5 of your choice with the respective datasets (training and test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create training and test data for 3-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split the data into a training set and a test set\n",
    "X_NN = ['NumberR', 'BuildingR', 'TypeR_a' ,'TypeR_b', 'TypeR_d', 'TypeR_e', 'TypeR_g', 'TypeR_h', 'TypeR_i', 'TypeR_j']\n",
    "y_NN = ['Green frogs', 'Brown frogs', 'Common toad', 'Fire-bellied toad', 'Tree frog', 'Common newt', 'Great crested newt']\n",
    "\n",
    "X_data = NN_data_encoded[X_NN]\n",
    "y_data = NN_data_encoded[y_NN]\n",
    "\n",
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN = train_test_split(X_data, y_data, test_size = 0.1, random_state=414759)\n",
    "\n",
    "#Creating cross validation sets using KFold method\n",
    "kfold3 = model_selection.KFold(n_splits=3, random_state=414759)\n",
    "kfold4 = model_selection.KFold(n_splits=3, random_state=414759)\n",
    "\n",
    "#Initializing variables\n",
    "model3_data_indexes = []\n",
    "model4_data_indexes = []\n",
    "\n",
    "#creating array that stores indexes of train and test data for each fold of cross validation for model3\n",
    "for train_index, test_index in kfold3.split(X_data):\n",
    "    model3_data_indexes.append((train_index, test_index))\n",
    "#creating array that stores indexes of train and test data for each fold of cross validation for model4\n",
    "for train_index, test_index in kfold4.split(X_data):\n",
    "    model4_data_indexes.append((train_index, test_index))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print confusion matrices on the training data and the cell-by-cell summation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.97430284\n",
      "Iteration 2, loss = 4.94988089\n",
      "Iteration 3, loss = 4.91593219\n",
      "Iteration 4, loss = 4.87429500\n",
      "Iteration 5, loss = 4.82676940\n",
      "Iteration 6, loss = 4.77506967\n",
      "Iteration 7, loss = 4.72078416\n",
      "Iteration 8, loss = 4.66534235\n",
      "Iteration 9, loss = 4.60998984\n",
      "Iteration 10, loss = 4.55577232\n",
      "Iteration 11, loss = 4.50352902\n",
      "Iteration 12, loss = 4.45389585\n",
      "Iteration 13, loss = 4.40731728\n",
      "Iteration 14, loss = 4.36406533\n",
      "Iteration 15, loss = 4.32426360\n",
      "Iteration 16, loss = 4.28791377\n",
      "Iteration 17, loss = 4.25492260\n",
      "Iteration 18, loss = 4.22512733\n",
      "Iteration 19, loss = 4.19831835\n",
      "Iteration 20, loss = 4.17425844\n",
      "Iteration 21, loss = 4.15269814\n",
      "Iteration 22, loss = 4.13338762\n",
      "Iteration 23, loss = 4.11608520\n",
      "Iteration 24, loss = 4.10056323\n",
      "Iteration 25, loss = 4.08661160\n",
      "Iteration 26, loss = 4.07403963\n",
      "Iteration 27, loss = 4.06267652\n",
      "Iteration 28, loss = 4.05237105\n",
      "Iteration 29, loss = 4.04299050\n",
      "Iteration 30, loss = 4.03441928\n",
      "Iteration 31, loss = 4.02655727\n",
      "Iteration 32, loss = 4.01931821\n",
      "Iteration 33, loss = 4.01262791\n",
      "Iteration 34, loss = 4.00642273\n",
      "Iteration 35, loss = 4.00064806\n",
      "Iteration 36, loss = 3.99525695\n",
      "Iteration 37, loss = 3.99020895\n",
      "Iteration 38, loss = 3.98546903\n",
      "Iteration 39, loss = 3.98100672\n",
      "Iteration 40, loss = 3.97679530\n",
      "Iteration 41, loss = 3.97281120\n",
      "Iteration 42, loss = 3.96903347\n",
      "Iteration 43, loss = 3.96544336\n",
      "Iteration 44, loss = 3.96202394\n",
      "Iteration 45, loss = 3.95875988\n",
      "Iteration 46, loss = 3.95563720\n",
      "Iteration 47, loss = 3.95264313\n",
      "Iteration 48, loss = 3.94976594\n",
      "Iteration 49, loss = 3.94699487\n",
      "Iteration 50, loss = 3.94432003\n",
      "Iteration 51, loss = 3.94173234\n",
      "Iteration 52, loss = 3.93922347\n",
      "Iteration 53, loss = 3.93678579\n",
      "Iteration 54, loss = 3.93441231\n",
      "Iteration 55, loss = 3.93209667\n",
      "Iteration 56, loss = 3.92983306\n",
      "Iteration 57, loss = 3.92761621\n",
      "Iteration 58, loss = 3.92544135\n",
      "Iteration 59, loss = 3.92330413\n",
      "Iteration 60, loss = 3.92120065\n",
      "Iteration 61, loss = 3.91912736\n",
      "Iteration 62, loss = 3.91708108\n",
      "Iteration 63, loss = 3.91505894\n",
      "Iteration 64, loss = 3.91305834\n",
      "Iteration 65, loss = 3.91107694\n",
      "Iteration 66, loss = 3.90911263\n",
      "Iteration 67, loss = 3.90716353\n",
      "Iteration 68, loss = 3.90522791\n",
      "Iteration 69, loss = 3.90330424\n",
      "Iteration 70, loss = 3.90139112\n",
      "Iteration 71, loss = 3.89948729\n",
      "Iteration 72, loss = 3.89759163\n",
      "Iteration 73, loss = 3.89570312\n",
      "Iteration 74, loss = 3.89382083\n",
      "Iteration 75, loss = 3.89194393\n",
      "Iteration 76, loss = 3.89007169\n",
      "Iteration 77, loss = 3.88820343\n",
      "Iteration 78, loss = 3.88633856\n",
      "Iteration 79, loss = 3.88447652\n",
      "Iteration 80, loss = 3.88261685\n",
      "Iteration 81, loss = 3.88075910\n",
      "Iteration 82, loss = 3.87890289\n",
      "Iteration 83, loss = 3.87704787\n",
      "Iteration 84, loss = 3.87519373\n",
      "Iteration 85, loss = 3.87334019\n",
      "Iteration 86, loss = 3.87148700\n",
      "Iteration 87, loss = 3.86963393\n",
      "Iteration 88, loss = 3.86778078\n",
      "Iteration 89, loss = 3.86592737\n",
      "Iteration 90, loss = 3.86407353\n",
      "Iteration 91, loss = 3.86221910\n",
      "Iteration 92, loss = 3.86036395\n",
      "Iteration 93, loss = 3.85850795\n",
      "Iteration 94, loss = 3.85665099\n",
      "Iteration 95, loss = 3.85479296\n",
      "Iteration 96, loss = 3.85293375\n",
      "Iteration 97, loss = 3.85107328\n",
      "Iteration 98, loss = 3.84921147\n",
      "Iteration 99, loss = 3.84734823\n",
      "Iteration 100, loss = 3.84548351\n",
      "Iteration 101, loss = 3.84361723\n",
      "Iteration 102, loss = 3.84174933\n",
      "Iteration 103, loss = 3.83987978\n",
      "Iteration 104, loss = 3.83800852\n",
      "Iteration 105, loss = 3.83613551\n",
      "Iteration 106, loss = 3.83426072\n",
      "Iteration 107, loss = 3.83238413\n",
      "Iteration 108, loss = 3.83050571\n",
      "Iteration 109, loss = 3.82862545\n",
      "Iteration 110, loss = 3.82674333\n",
      "Iteration 111, loss = 3.82485936\n",
      "Iteration 112, loss = 3.82297354\n",
      "Iteration 113, loss = 3.82108587\n",
      "Iteration 114, loss = 3.81919636\n",
      "Iteration 115, loss = 3.81730504\n",
      "Iteration 116, loss = 3.81541193\n",
      "Iteration 117, loss = 3.81351706\n",
      "Iteration 118, loss = 3.81162045\n",
      "Iteration 119, loss = 3.80972216\n",
      "Iteration 120, loss = 3.80782222\n",
      "Iteration 121, loss = 3.80592068\n",
      "Iteration 122, loss = 3.80401760\n",
      "Iteration 123, loss = 3.80211304\n",
      "Iteration 124, loss = 3.80020704\n",
      "Iteration 125, loss = 3.79829970\n",
      "Iteration 126, loss = 3.79639106\n",
      "Iteration 127, loss = 3.79448122\n",
      "Iteration 128, loss = 3.79257024\n",
      "Iteration 129, loss = 3.79065822\n",
      "Iteration 130, loss = 3.78874524\n",
      "Iteration 131, loss = 3.78683140\n",
      "Iteration 132, loss = 3.78491678\n",
      "Iteration 133, loss = 3.78300150\n",
      "Iteration 134, loss = 3.78108565\n",
      "Iteration 135, loss = 3.77916935\n",
      "Iteration 136, loss = 3.77725270\n",
      "Iteration 137, loss = 3.77533582\n",
      "Iteration 138, loss = 3.77341883\n",
      "Iteration 139, loss = 3.77150186\n",
      "Iteration 140, loss = 3.76958502\n",
      "Iteration 141, loss = 3.76766845\n",
      "Iteration 142, loss = 3.76575228\n",
      "Iteration 143, loss = 3.76383666\n",
      "Iteration 144, loss = 3.76192171\n",
      "Iteration 145, loss = 3.76000759\n",
      "Iteration 146, loss = 3.75809444\n",
      "Iteration 147, loss = 3.75618241\n",
      "Iteration 148, loss = 3.75427165\n",
      "Iteration 149, loss = 3.75236232\n",
      "Iteration 150, loss = 3.75045458\n",
      "Iteration 151, loss = 3.74854858\n",
      "Iteration 152, loss = 3.74664450\n",
      "Iteration 153, loss = 3.74474250\n",
      "Iteration 154, loss = 3.74284274\n",
      "Iteration 155, loss = 3.74094540\n",
      "Iteration 156, loss = 3.73905066\n",
      "Iteration 157, loss = 3.73715868\n",
      "Iteration 158, loss = 3.73526965\n",
      "Iteration 159, loss = 3.73338374\n",
      "Iteration 160, loss = 3.73150114\n",
      "Iteration 161, loss = 3.72962202\n",
      "Iteration 162, loss = 3.72774658\n",
      "Iteration 163, loss = 3.72587499\n",
      "Iteration 164, loss = 3.72400744\n",
      "Iteration 165, loss = 3.72214412\n",
      "Iteration 166, loss = 3.72028521\n",
      "Iteration 167, loss = 3.71843091\n",
      "Iteration 168, loss = 3.71658140\n",
      "Iteration 169, loss = 3.71473688\n",
      "Iteration 170, loss = 3.71289753\n",
      "Iteration 171, loss = 3.71106353\n",
      "Iteration 172, loss = 3.70923508\n",
      "Iteration 173, loss = 3.70741237\n",
      "Iteration 174, loss = 3.70559559\n",
      "Iteration 175, loss = 3.70378492\n",
      "Iteration 176, loss = 3.70198054\n",
      "Iteration 177, loss = 3.70018264\n",
      "Iteration 178, loss = 3.69839141\n",
      "Iteration 179, loss = 3.69660703\n",
      "Iteration 180, loss = 3.69482968\n",
      "Iteration 181, loss = 3.69305953\n",
      "Iteration 182, loss = 3.69129676\n",
      "Iteration 183, loss = 3.68954156\n",
      "Iteration 184, loss = 3.68779408\n",
      "Iteration 185, loss = 3.68605450\n",
      "Iteration 186, loss = 3.68432299\n",
      "Iteration 187, loss = 3.68259971\n",
      "Iteration 188, loss = 3.68088481\n",
      "Iteration 189, loss = 3.67917847\n",
      "Iteration 190, loss = 3.67748084\n",
      "Iteration 191, loss = 3.67579206\n",
      "Iteration 192, loss = 3.67411228\n",
      "Iteration 193, loss = 3.67244166\n",
      "Iteration 194, loss = 3.67078032\n",
      "Iteration 195, loss = 3.66912841\n",
      "Iteration 196, loss = 3.66748606\n",
      "Iteration 197, loss = 3.66585339\n",
      "Iteration 198, loss = 3.66423054\n",
      "Iteration 199, loss = 3.66261762\n",
      "Iteration 200, loss = 3.66101475\n",
      "Iteration 201, loss = 3.65942204\n",
      "Iteration 202, loss = 3.65783960\n",
      "Iteration 203, loss = 3.65626752\n",
      "Iteration 204, loss = 3.65470592\n",
      "Iteration 205, loss = 3.65315487\n",
      "Iteration 206, loss = 3.65161447\n",
      "Iteration 207, loss = 3.65008480\n",
      "Iteration 208, loss = 3.64856594\n",
      "Iteration 209, loss = 3.64705797\n",
      "Iteration 210, loss = 3.64556095\n",
      "Iteration 211, loss = 3.64407495\n",
      "Iteration 212, loss = 3.64260002\n",
      "Iteration 213, loss = 3.64113622\n",
      "Iteration 214, loss = 3.63968361\n",
      "Iteration 215, loss = 3.63824222\n",
      "Iteration 216, loss = 3.63681209\n",
      "Iteration 217, loss = 3.63539326\n",
      "Iteration 218, loss = 3.63398576\n",
      "Iteration 219, loss = 3.63258962\n",
      "Iteration 220, loss = 3.63120485\n",
      "Iteration 221, loss = 3.62983147\n",
      "Iteration 222, loss = 3.62846949\n",
      "Iteration 223, loss = 3.62711892\n",
      "Iteration 224, loss = 3.62577977\n",
      "Iteration 225, loss = 3.62445202\n",
      "Iteration 226, loss = 3.62313568\n",
      "Iteration 227, loss = 3.62183073\n",
      "Iteration 228, loss = 3.62053715\n",
      "Iteration 229, loss = 3.61925494\n",
      "Iteration 230, loss = 3.61798405\n",
      "Iteration 231, loss = 3.61672448\n",
      "Iteration 232, loss = 3.61547618\n",
      "Iteration 233, loss = 3.61423912\n",
      "Iteration 234, loss = 3.61301327\n",
      "Iteration 235, loss = 3.61179857\n",
      "Iteration 236, loss = 3.61059499\n",
      "Iteration 237, loss = 3.60940248\n",
      "Iteration 238, loss = 3.60822098\n",
      "Iteration 239, loss = 3.60705043\n",
      "Iteration 240, loss = 3.60589079\n",
      "Iteration 241, loss = 3.60474198\n",
      "Iteration 242, loss = 3.60360395\n",
      "Iteration 243, loss = 3.60247662\n",
      "Iteration 244, loss = 3.60135993\n",
      "Iteration 245, loss = 3.60025380\n",
      "Iteration 246, loss = 3.59915816\n",
      "Iteration 247, loss = 3.59807293\n",
      "Iteration 248, loss = 3.59699804\n",
      "Iteration 249, loss = 3.59593339\n",
      "Iteration 250, loss = 3.59487891\n",
      "Iteration 251, loss = 3.59383451\n",
      "Iteration 252, loss = 3.59280010\n",
      "Iteration 253, loss = 3.59177560\n",
      "Iteration 254, loss = 3.59076091\n",
      "Iteration 255, loss = 3.58975594\n",
      "Iteration 256, loss = 3.58876059\n",
      "Iteration 257, loss = 3.58777478\n",
      "Iteration 258, loss = 3.58679841\n",
      "Iteration 259, loss = 3.58583137\n",
      "Iteration 260, loss = 3.58487357\n",
      "Iteration 261, loss = 3.58392491\n",
      "Iteration 262, loss = 3.58298528\n",
      "Iteration 263, loss = 3.58205460\n",
      "Iteration 264, loss = 3.58113275\n",
      "Iteration 265, loss = 3.58021964\n",
      "Iteration 266, loss = 3.57931516\n",
      "Iteration 267, loss = 3.57841920\n",
      "Iteration 268, loss = 3.57753167\n",
      "Iteration 269, loss = 3.57665245\n",
      "Iteration 270, loss = 3.57578145\n",
      "Iteration 271, loss = 3.57491856\n",
      "Iteration 272, loss = 3.57406367\n",
      "Iteration 273, loss = 3.57321668\n",
      "Iteration 274, loss = 3.57237749\n",
      "Iteration 275, loss = 3.57154598\n",
      "Iteration 276, loss = 3.57072206\n",
      "Iteration 277, loss = 3.56990562\n",
      "Iteration 278, loss = 3.56909656\n",
      "Iteration 279, loss = 3.56829477\n",
      "Iteration 280, loss = 3.56750015\n",
      "Iteration 281, loss = 3.56671259\n",
      "Iteration 282, loss = 3.56593200\n",
      "Iteration 283, loss = 3.56515826\n",
      "Iteration 284, loss = 3.56439129\n",
      "Iteration 285, loss = 3.56363097\n",
      "Iteration 286, loss = 3.56287721\n",
      "Iteration 287, loss = 3.56212991\n",
      "Iteration 288, loss = 3.56138896\n",
      "Iteration 289, loss = 3.56065427\n",
      "Iteration 290, loss = 3.55992575\n",
      "Iteration 291, loss = 3.55920328\n",
      "Iteration 292, loss = 3.55848678\n",
      "Iteration 293, loss = 3.55777616\n",
      "Iteration 294, loss = 3.55707131\n",
      "Iteration 295, loss = 3.55637215\n",
      "Iteration 296, loss = 3.55567857\n",
      "Iteration 297, loss = 3.55499049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 298, loss = 3.55430782\n",
      "Iteration 299, loss = 3.55363047\n",
      "Iteration 300, loss = 3.55295834\n",
      "Iteration 301, loss = 3.55229135\n",
      "Iteration 302, loss = 3.55162942\n",
      "Iteration 303, loss = 3.55097245\n",
      "Iteration 304, loss = 3.55032035\n",
      "Iteration 305, loss = 3.54967306\n",
      "Iteration 306, loss = 3.54903047\n",
      "Iteration 307, loss = 3.54839252\n",
      "Iteration 308, loss = 3.54775911\n",
      "Iteration 309, loss = 3.54713017\n",
      "Iteration 310, loss = 3.54650562\n",
      "Iteration 311, loss = 3.54588538\n",
      "Iteration 312, loss = 3.54526937\n",
      "Iteration 313, loss = 3.54465752\n",
      "Iteration 314, loss = 3.54404976\n",
      "Iteration 315, loss = 3.54344599\n",
      "Iteration 316, loss = 3.54284617\n",
      "Iteration 317, loss = 3.54225020\n",
      "Iteration 318, loss = 3.54165803\n",
      "Iteration 319, loss = 3.54106958\n",
      "Iteration 320, loss = 3.54048478\n",
      "Iteration 321, loss = 3.53990356\n",
      "Iteration 322, loss = 3.53932586\n",
      "Iteration 323, loss = 3.53875161\n",
      "Iteration 324, loss = 3.53818075\n",
      "Iteration 325, loss = 3.53761322\n",
      "Iteration 326, loss = 3.53704894\n",
      "Iteration 327, loss = 3.53648785\n",
      "Iteration 328, loss = 3.53592991\n",
      "Iteration 329, loss = 3.53537504\n",
      "Iteration 330, loss = 3.53482319\n",
      "Iteration 331, loss = 3.53427430\n",
      "Iteration 332, loss = 3.53372831\n",
      "Iteration 333, loss = 3.53318516\n",
      "Iteration 334, loss = 3.53264481\n",
      "Iteration 335, loss = 3.53210719\n",
      "Iteration 336, loss = 3.53157225\n",
      "Iteration 337, loss = 3.53103994\n",
      "Iteration 338, loss = 3.53051021\n",
      "Iteration 339, loss = 3.52998301\n",
      "Iteration 340, loss = 3.52945828\n",
      "Iteration 341, loss = 3.52893598\n",
      "Iteration 342, loss = 3.52841606\n",
      "Iteration 343, loss = 3.52789848\n",
      "Iteration 344, loss = 3.52738317\n",
      "Iteration 345, loss = 3.52687011\n",
      "Iteration 346, loss = 3.52635924\n",
      "Iteration 347, loss = 3.52585052\n",
      "Iteration 348, loss = 3.52534391\n",
      "Iteration 349, loss = 3.52483936\n",
      "Iteration 350, loss = 3.52433683\n",
      "Iteration 351, loss = 3.52383628\n",
      "Iteration 352, loss = 3.52333767\n",
      "Iteration 353, loss = 3.52284096\n",
      "Iteration 354, loss = 3.52234611\n",
      "Iteration 355, loss = 3.52185308\n",
      "Iteration 356, loss = 3.52136184\n",
      "Iteration 357, loss = 3.52087235\n",
      "Iteration 358, loss = 3.52038456\n",
      "Iteration 359, loss = 3.51989845\n",
      "Iteration 360, loss = 3.51941398\n",
      "Iteration 361, loss = 3.51893112\n",
      "Iteration 362, loss = 3.51844983\n",
      "Iteration 363, loss = 3.51797008\n",
      "Iteration 364, loss = 3.51749183\n",
      "Iteration 365, loss = 3.51701506\n",
      "Iteration 366, loss = 3.51653973\n",
      "Iteration 367, loss = 3.51606582\n",
      "Iteration 368, loss = 3.51559328\n",
      "Iteration 369, loss = 3.51512210\n",
      "Iteration 370, loss = 3.51465224\n",
      "Iteration 371, loss = 3.51418367\n",
      "Iteration 372, loss = 3.51371637\n",
      "Iteration 373, loss = 3.51325031\n",
      "Iteration 374, loss = 3.51278545\n",
      "Iteration 375, loss = 3.51232179\n",
      "Iteration 376, loss = 3.51185928\n",
      "Iteration 377, loss = 3.51139790\n",
      "Iteration 378, loss = 3.51093764\n",
      "Iteration 379, loss = 3.51047845\n",
      "Iteration 380, loss = 3.51002033\n",
      "Iteration 381, loss = 3.50956324\n",
      "Iteration 382, loss = 3.50910716\n",
      "Iteration 383, loss = 3.50865207\n",
      "Iteration 384, loss = 3.50819795\n",
      "Iteration 385, loss = 3.50774477\n",
      "Iteration 386, loss = 3.50729251\n",
      "Iteration 387, loss = 3.50684116\n",
      "Iteration 388, loss = 3.50639069\n",
      "Iteration 389, loss = 3.50594107\n",
      "Iteration 390, loss = 3.50549230\n",
      "Iteration 391, loss = 3.50504434\n",
      "Iteration 392, loss = 3.50459719\n",
      "Iteration 393, loss = 3.50415082\n",
      "Iteration 394, loss = 3.50370521\n",
      "Iteration 395, loss = 3.50326035\n",
      "Iteration 396, loss = 3.50281621\n",
      "Iteration 397, loss = 3.50237278\n",
      "Iteration 398, loss = 3.50193004\n",
      "Iteration 399, loss = 3.50148798\n",
      "Iteration 400, loss = 3.50104658\n",
      "Iteration 401, loss = 3.50060581\n",
      "Iteration 402, loss = 3.50016568\n",
      "Iteration 403, loss = 3.49972615\n",
      "Iteration 404, loss = 3.49928722\n",
      "Iteration 405, loss = 3.49884886\n",
      "Iteration 406, loss = 3.49841107\n",
      "Iteration 407, loss = 3.49797383\n",
      "Iteration 408, loss = 3.49753712\n",
      "Iteration 409, loss = 3.49710093\n",
      "Iteration 410, loss = 3.49666525\n",
      "Iteration 411, loss = 3.49623006\n",
      "Iteration 412, loss = 3.49579536\n",
      "Iteration 413, loss = 3.49536111\n",
      "Iteration 414, loss = 3.49492732\n",
      "Iteration 415, loss = 3.49449397\n",
      "Iteration 416, loss = 3.49406105\n",
      "Iteration 417, loss = 3.49362855\n",
      "Iteration 418, loss = 3.49319645\n",
      "Iteration 419, loss = 3.49276474\n",
      "Iteration 420, loss = 3.49233340\n",
      "Iteration 421, loss = 3.49190244\n",
      "Iteration 422, loss = 3.49147184\n",
      "Iteration 423, loss = 3.49104158\n",
      "Iteration 424, loss = 3.49061166\n",
      "Iteration 425, loss = 3.49018206\n",
      "Iteration 426, loss = 3.48975278\n",
      "Iteration 427, loss = 3.48932380\n",
      "Iteration 428, loss = 3.48889511\n",
      "Iteration 429, loss = 3.48846671\n",
      "Iteration 430, loss = 3.48803858\n",
      "Iteration 431, loss = 3.48761071\n",
      "Iteration 432, loss = 3.48718311\n",
      "Iteration 433, loss = 3.48675574\n",
      "Iteration 434, loss = 3.48632862\n",
      "Iteration 435, loss = 3.48590172\n",
      "Iteration 436, loss = 3.48547504\n",
      "Iteration 437, loss = 3.48504857\n",
      "Iteration 438, loss = 3.48462230\n",
      "Iteration 439, loss = 3.48419622\n",
      "Iteration 440, loss = 3.48377033\n",
      "Iteration 441, loss = 3.48334462\n",
      "Iteration 442, loss = 3.48291908\n",
      "Iteration 443, loss = 3.48249369\n",
      "Iteration 444, loss = 3.48206846\n",
      "Iteration 445, loss = 3.48164338\n",
      "Iteration 446, loss = 3.48121843\n",
      "Iteration 447, loss = 3.48079362\n",
      "Iteration 448, loss = 3.48036893\n",
      "Iteration 449, loss = 3.47994435\n",
      "Iteration 450, loss = 3.47951989\n",
      "Iteration 451, loss = 3.47909552\n",
      "Iteration 452, loss = 3.47867126\n",
      "Iteration 453, loss = 3.47824708\n",
      "Iteration 454, loss = 3.47782299\n",
      "Iteration 455, loss = 3.47739897\n",
      "Iteration 456, loss = 3.47697502\n",
      "Iteration 457, loss = 3.47655113\n",
      "Iteration 458, loss = 3.47612731\n",
      "Iteration 459, loss = 3.47570353\n",
      "Iteration 460, loss = 3.47527980\n",
      "Iteration 461, loss = 3.47485611\n",
      "Iteration 462, loss = 3.47443246\n",
      "Iteration 463, loss = 3.47400883\n",
      "Iteration 464, loss = 3.47358523\n",
      "Iteration 465, loss = 3.47316164\n",
      "Iteration 466, loss = 3.47273806\n",
      "Iteration 467, loss = 3.47231449\n",
      "Iteration 468, loss = 3.47189093\n",
      "Iteration 469, loss = 3.47146736\n",
      "Iteration 470, loss = 3.47104378\n",
      "Iteration 471, loss = 3.47062018\n",
      "Iteration 472, loss = 3.47019657\n",
      "Iteration 473, loss = 3.46977293\n",
      "Iteration 474, loss = 3.46934927\n",
      "Iteration 475, loss = 3.46892557\n",
      "Iteration 476, loss = 3.46850183\n",
      "Iteration 477, loss = 3.46807805\n",
      "Iteration 478, loss = 3.46765423\n",
      "Iteration 479, loss = 3.46723035\n",
      "Iteration 480, loss = 3.46680641\n",
      "Iteration 481, loss = 3.46638242\n",
      "Iteration 482, loss = 3.46595836\n",
      "Iteration 483, loss = 3.46553424\n",
      "Iteration 484, loss = 3.46511004\n",
      "Iteration 485, loss = 3.46468576\n",
      "Iteration 486, loss = 3.46426141\n",
      "Iteration 487, loss = 3.46383697\n",
      "Iteration 488, loss = 3.46341244\n",
      "Iteration 489, loss = 3.46298782\n",
      "Iteration 490, loss = 3.46256310\n",
      "Iteration 491, loss = 3.46213829\n",
      "Iteration 492, loss = 3.46171337\n",
      "Iteration 493, loss = 3.46128834\n",
      "Iteration 494, loss = 3.46086320\n",
      "Iteration 495, loss = 3.46043795\n",
      "Iteration 496, loss = 3.46001258\n",
      "Iteration 497, loss = 3.45958709\n",
      "Iteration 498, loss = 3.45916148\n",
      "Iteration 499, loss = 3.45873574\n",
      "Iteration 500, loss = 3.45830987\n",
      "Iteration 501, loss = 3.45788386\n",
      "Iteration 502, loss = 3.45745772\n",
      "Iteration 503, loss = 3.45703144\n",
      "Iteration 504, loss = 3.45660501\n",
      "Iteration 505, loss = 3.45617844\n",
      "Iteration 506, loss = 3.45575172\n",
      "Iteration 507, loss = 3.45532485\n",
      "Iteration 508, loss = 3.45489782\n",
      "Iteration 509, loss = 3.45447063\n",
      "Iteration 510, loss = 3.45404329\n",
      "Iteration 511, loss = 3.45361578\n",
      "Iteration 512, loss = 3.45318810\n",
      "Iteration 513, loss = 3.45276026\n",
      "Iteration 514, loss = 3.45233224\n",
      "Iteration 515, loss = 3.45190405\n",
      "Iteration 516, loss = 3.45147568\n",
      "Iteration 517, loss = 3.45104714\n",
      "Iteration 518, loss = 3.45061841\n",
      "Iteration 519, loss = 3.45018950\n",
      "Iteration 520, loss = 3.44976040\n",
      "Iteration 521, loss = 3.44933112\n",
      "Iteration 522, loss = 3.44890164\n",
      "Iteration 523, loss = 3.44847197\n",
      "Iteration 524, loss = 3.44804210\n",
      "Iteration 525, loss = 3.44761204\n",
      "Iteration 526, loss = 3.44718177\n",
      "Iteration 527, loss = 3.44675130\n",
      "Iteration 528, loss = 3.44632063\n",
      "Iteration 529, loss = 3.44588975\n",
      "Iteration 530, loss = 3.44545867\n",
      "Iteration 531, loss = 3.44502737\n",
      "Iteration 532, loss = 3.44459586\n",
      "Iteration 533, loss = 3.44416413\n",
      "Iteration 534, loss = 3.44373219\n",
      "Iteration 535, loss = 3.44330003\n",
      "Iteration 536, loss = 3.44286765\n",
      "Iteration 537, loss = 3.44243504\n",
      "Iteration 538, loss = 3.44200222\n",
      "Iteration 539, loss = 3.44156916\n",
      "Iteration 540, loss = 3.44113588\n",
      "Iteration 541, loss = 3.44070237\n",
      "Iteration 542, loss = 3.44026863\n",
      "Iteration 543, loss = 3.43983465\n",
      "Iteration 544, loss = 3.43940045\n",
      "Iteration 545, loss = 3.43896600\n",
      "Iteration 546, loss = 3.43853132\n",
      "Iteration 547, loss = 3.43809640\n",
      "Iteration 548, loss = 3.43766123\n",
      "Iteration 549, loss = 3.43722583\n",
      "Iteration 550, loss = 3.43679018\n",
      "Iteration 551, loss = 3.43635429\n",
      "Iteration 552, loss = 3.43591815\n",
      "Iteration 553, loss = 3.43548176\n",
      "Iteration 554, loss = 3.43504512\n",
      "Iteration 555, loss = 3.43460823\n",
      "Iteration 556, loss = 3.43417109\n",
      "Iteration 557, loss = 3.43373369\n",
      "Iteration 558, loss = 3.43329604\n",
      "Iteration 559, loss = 3.43285814\n",
      "Iteration 560, loss = 3.43241998\n",
      "Iteration 561, loss = 3.43198156\n",
      "Iteration 562, loss = 3.43154288\n",
      "Iteration 563, loss = 3.43110394\n",
      "Iteration 564, loss = 3.43066473\n",
      "Iteration 565, loss = 3.43022527\n",
      "Iteration 566, loss = 3.42978554\n",
      "Iteration 567, loss = 3.42934554\n",
      "Iteration 568, loss = 3.42890528\n",
      "Iteration 569, loss = 3.42846476\n",
      "Iteration 570, loss = 3.42802396\n",
      "Iteration 571, loss = 3.42758290\n",
      "Iteration 572, loss = 3.42714156\n",
      "Iteration 573, loss = 3.42669996\n",
      "Iteration 574, loss = 3.42625808\n",
      "Iteration 575, loss = 3.42581593\n",
      "Iteration 576, loss = 3.42537351\n",
      "Iteration 577, loss = 3.42493081\n",
      "Iteration 578, loss = 3.42448784\n",
      "Iteration 579, loss = 3.42404459\n",
      "Iteration 580, loss = 3.42360107\n",
      "Iteration 581, loss = 3.42315727\n",
      "Iteration 582, loss = 3.42271319\n",
      "Iteration 583, loss = 3.42226883\n",
      "Iteration 584, loss = 3.42182419\n",
      "Iteration 585, loss = 3.42137928\n",
      "Iteration 586, loss = 3.42093408\n",
      "Iteration 587, loss = 3.42048860\n",
      "Iteration 588, loss = 3.42004284\n",
      "Iteration 589, loss = 3.41959680\n",
      "Iteration 590, loss = 3.41915048\n",
      "Iteration 591, loss = 3.41870387\n",
      "Iteration 592, loss = 3.41825698\n",
      "Iteration 593, loss = 3.41780980\n",
      "Iteration 594, loss = 3.41736234\n",
      "Iteration 595, loss = 3.41691460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 596, loss = 3.41646657\n",
      "Iteration 597, loss = 3.41601825\n",
      "Iteration 598, loss = 3.41556965\n",
      "Iteration 599, loss = 3.41512076\n",
      "Iteration 600, loss = 3.41467159\n",
      "Iteration 601, loss = 3.41422213\n",
      "Iteration 602, loss = 3.41377238\n",
      "Iteration 603, loss = 3.41332234\n",
      "Iteration 604, loss = 3.41287202\n",
      "Iteration 605, loss = 3.41242141\n",
      "Iteration 606, loss = 3.41197051\n",
      "Iteration 607, loss = 3.41151932\n",
      "Iteration 608, loss = 3.41106785\n",
      "Iteration 609, loss = 3.41061609\n",
      "Iteration 610, loss = 3.41016403\n",
      "Iteration 611, loss = 3.40971169\n",
      "Iteration 612, loss = 3.40925907\n",
      "Iteration 613, loss = 3.40880615\n",
      "Iteration 614, loss = 3.40835294\n",
      "Iteration 615, loss = 3.40789945\n",
      "Iteration 616, loss = 3.40744567\n",
      "Iteration 617, loss = 3.40699160\n",
      "Iteration 618, loss = 3.40653724\n",
      "Iteration 619, loss = 3.40608260\n",
      "Iteration 620, loss = 3.40562766\n",
      "Iteration 621, loss = 3.40517244\n",
      "Iteration 622, loss = 3.40471693\n",
      "Iteration 623, loss = 3.40426113\n",
      "Iteration 624, loss = 3.40380505\n",
      "Iteration 625, loss = 3.40334868\n",
      "Iteration 626, loss = 3.40289202\n",
      "Iteration 627, loss = 3.40243508\n",
      "Iteration 628, loss = 3.40197785\n",
      "Iteration 629, loss = 3.40152033\n",
      "Iteration 630, loss = 3.40106253\n",
      "Iteration 631, loss = 3.40060444\n",
      "Iteration 632, loss = 3.40014607\n",
      "Iteration 633, loss = 3.39968742\n",
      "Iteration 634, loss = 3.39922848\n",
      "Iteration 635, loss = 3.39876925\n",
      "Iteration 636, loss = 3.39830975\n",
      "Iteration 637, loss = 3.39784996\n",
      "Iteration 638, loss = 3.39738989\n",
      "Iteration 639, loss = 3.39692954\n",
      "Iteration 640, loss = 3.39646891\n",
      "Iteration 641, loss = 3.39600800\n",
      "Iteration 642, loss = 3.39554680\n",
      "Iteration 643, loss = 3.39508533\n",
      "Iteration 644, loss = 3.39462358\n",
      "Iteration 645, loss = 3.39416155\n",
      "Iteration 646, loss = 3.39369925\n",
      "Iteration 647, loss = 3.39323667\n",
      "Iteration 648, loss = 3.39277381\n",
      "Iteration 649, loss = 3.39231068\n",
      "Iteration 650, loss = 3.39184727\n",
      "Iteration 651, loss = 3.39138359\n",
      "Iteration 652, loss = 3.39091964\n",
      "Iteration 653, loss = 3.39045542\n",
      "Iteration 654, loss = 3.38999092\n",
      "Iteration 655, loss = 3.38952615\n",
      "Iteration 656, loss = 3.38906112\n",
      "Iteration 657, loss = 3.38859581\n",
      "Iteration 658, loss = 3.38813024\n",
      "Iteration 659, loss = 3.38766441\n",
      "Iteration 660, loss = 3.38719830\n",
      "Iteration 661, loss = 3.38673193\n",
      "Iteration 662, loss = 3.38626530\n",
      "Iteration 663, loss = 3.38579841\n",
      "Iteration 664, loss = 3.38533125\n",
      "Iteration 665, loss = 3.38486383\n",
      "Iteration 666, loss = 3.38439615\n",
      "Iteration 667, loss = 3.38392822\n",
      "Iteration 668, loss = 3.38346003\n",
      "Iteration 669, loss = 3.38299158\n",
      "Iteration 670, loss = 3.38252287\n",
      "Iteration 671, loss = 3.38205391\n",
      "Iteration 672, loss = 3.38158470\n",
      "Iteration 673, loss = 3.38111524\n",
      "Iteration 674, loss = 3.38064552\n",
      "Iteration 675, loss = 3.38017556\n",
      "Iteration 676, loss = 3.37970535\n",
      "Iteration 677, loss = 3.37923489\n",
      "Iteration 678, loss = 3.37876419\n",
      "Iteration 679, loss = 3.37829324\n",
      "Iteration 680, loss = 3.37782205\n",
      "Iteration 681, loss = 3.37735062\n",
      "Iteration 682, loss = 3.37687895\n",
      "Iteration 683, loss = 3.37640704\n",
      "Iteration 684, loss = 3.37593489\n",
      "Iteration 685, loss = 3.37546251\n",
      "Iteration 686, loss = 3.37498989\n",
      "Iteration 687, loss = 3.37451704\n",
      "Iteration 688, loss = 3.37404396\n",
      "Iteration 689, loss = 3.37357064\n",
      "Iteration 690, loss = 3.37309710\n",
      "Iteration 691, loss = 3.37262333\n",
      "Iteration 692, loss = 3.37214934\n",
      "Iteration 693, loss = 3.37167512\n",
      "Iteration 694, loss = 3.37120068\n",
      "Iteration 695, loss = 3.37072602\n",
      "Iteration 696, loss = 3.37025114\n",
      "Iteration 697, loss = 3.36977604\n",
      "Iteration 698, loss = 3.36930073\n",
      "Iteration 699, loss = 3.36882520\n",
      "Iteration 700, loss = 3.36834946\n",
      "Iteration 701, loss = 3.36787351\n",
      "Iteration 702, loss = 3.36739735\n",
      "Iteration 703, loss = 3.36692098\n",
      "Iteration 704, loss = 3.36644441\n",
      "Iteration 705, loss = 3.36596763\n",
      "Iteration 706, loss = 3.36549065\n",
      "Iteration 707, loss = 3.36501347\n",
      "Iteration 708, loss = 3.36453609\n",
      "Iteration 709, loss = 3.36405851\n",
      "Iteration 710, loss = 3.36358074\n",
      "Iteration 711, loss = 3.36310278\n",
      "Iteration 712, loss = 3.36262462\n",
      "Iteration 713, loss = 3.36214628\n",
      "Iteration 714, loss = 3.36166775\n",
      "Iteration 715, loss = 3.36118903\n",
      "Iteration 716, loss = 3.36071013\n",
      "Iteration 717, loss = 3.36023104\n",
      "Iteration 718, loss = 3.35975178\n",
      "Iteration 719, loss = 3.35927234\n",
      "Iteration 720, loss = 3.35879273\n",
      "Iteration 721, loss = 3.35831294\n",
      "Iteration 722, loss = 3.35783298\n",
      "Iteration 723, loss = 3.35735285\n",
      "Iteration 724, loss = 3.35687255\n",
      "Iteration 725, loss = 3.35639209\n",
      "Iteration 726, loss = 3.35591146\n",
      "Iteration 727, loss = 3.35543067\n",
      "Iteration 728, loss = 3.35494972\n",
      "Iteration 729, loss = 3.35446862\n",
      "Iteration 730, loss = 3.35398736\n",
      "Iteration 731, loss = 3.35350595\n",
      "Iteration 732, loss = 3.35302439\n",
      "Iteration 733, loss = 3.35254268\n",
      "Iteration 734, loss = 3.35206082\n",
      "Iteration 735, loss = 3.35157882\n",
      "Iteration 736, loss = 3.35109667\n",
      "Iteration 737, loss = 3.35061439\n",
      "Iteration 738, loss = 3.35013197\n",
      "Iteration 739, loss = 3.34964942\n",
      "Iteration 740, loss = 3.34916673\n",
      "Iteration 741, loss = 3.34868392\n",
      "Iteration 742, loss = 3.34820097\n",
      "Iteration 743, loss = 3.34771790\n",
      "Iteration 744, loss = 3.34723470\n",
      "Iteration 745, loss = 3.34675139\n",
      "Iteration 746, loss = 3.34626796\n",
      "Iteration 747, loss = 3.34578440\n",
      "Iteration 748, loss = 3.34530074\n",
      "Iteration 749, loss = 3.34481696\n",
      "Iteration 750, loss = 3.34433308\n",
      "Iteration 751, loss = 3.34384909\n",
      "Iteration 752, loss = 3.34336499\n",
      "Iteration 753, loss = 3.34288079\n",
      "Iteration 754, loss = 3.34239650\n",
      "Iteration 755, loss = 3.34191210\n",
      "Iteration 756, loss = 3.34142761\n",
      "Iteration 757, loss = 3.34094303\n",
      "Iteration 758, loss = 3.34045836\n",
      "Iteration 759, loss = 3.33997361\n",
      "Iteration 760, loss = 3.33948877\n",
      "Iteration 761, loss = 3.33900384\n",
      "Iteration 762, loss = 3.33851884\n",
      "Iteration 763, loss = 3.33803376\n",
      "Iteration 764, loss = 3.33754861\n",
      "Iteration 765, loss = 3.33706338\n",
      "Iteration 766, loss = 3.33657809\n",
      "Iteration 767, loss = 3.33609273\n",
      "Iteration 768, loss = 3.33560731\n",
      "Iteration 769, loss = 3.33512182\n",
      "Iteration 770, loss = 3.33463628\n",
      "Iteration 771, loss = 3.33415068\n",
      "Iteration 772, loss = 3.33366503\n",
      "Iteration 773, loss = 3.33317932\n",
      "Iteration 774, loss = 3.33269357\n",
      "Iteration 775, loss = 3.33220778\n",
      "Iteration 776, loss = 3.33172194\n",
      "Iteration 777, loss = 3.33123606\n",
      "Iteration 778, loss = 3.33075014\n",
      "Iteration 779, loss = 3.33026419\n",
      "Iteration 780, loss = 3.32977821\n",
      "Iteration 781, loss = 3.32929220\n",
      "Iteration 782, loss = 3.32880616\n",
      "Iteration 783, loss = 3.32832010\n",
      "Iteration 784, loss = 3.32783402\n",
      "Iteration 785, loss = 3.32734792\n",
      "Iteration 786, loss = 3.32686180\n",
      "Iteration 787, loss = 3.32637568\n",
      "Iteration 788, loss = 3.32588954\n",
      "Iteration 789, loss = 3.32540340\n",
      "Iteration 790, loss = 3.32491725\n",
      "Iteration 791, loss = 3.32443110\n",
      "Iteration 792, loss = 3.32394495\n",
      "Iteration 793, loss = 3.32345881\n",
      "Iteration 794, loss = 3.32297267\n",
      "Iteration 795, loss = 3.32248654\n",
      "Iteration 796, loss = 3.32200043\n",
      "Iteration 797, loss = 3.32151433\n",
      "Iteration 798, loss = 3.32102825\n",
      "Iteration 799, loss = 3.32054219\n",
      "Iteration 800, loss = 3.32005616\n",
      "Iteration 801, loss = 3.31957015\n",
      "Iteration 802, loss = 3.31908417\n",
      "Iteration 803, loss = 3.31859823\n",
      "Iteration 804, loss = 3.31811232\n",
      "Iteration 805, loss = 3.31762645\n",
      "Iteration 806, loss = 3.31714062\n",
      "Iteration 807, loss = 3.31665483\n",
      "Iteration 808, loss = 3.31616910\n",
      "Iteration 809, loss = 3.31568341\n",
      "Iteration 810, loss = 3.31519777\n",
      "Iteration 811, loss = 3.31471219\n",
      "Iteration 812, loss = 3.31422667\n",
      "Iteration 813, loss = 3.31374121\n",
      "Iteration 814, loss = 3.31325582\n",
      "Iteration 815, loss = 3.31277049\n",
      "Iteration 816, loss = 3.31228524\n",
      "Iteration 817, loss = 3.31180005\n",
      "Iteration 818, loss = 3.31131495\n",
      "Iteration 819, loss = 3.31082992\n",
      "Iteration 820, loss = 3.31034497\n",
      "Iteration 821, loss = 3.30986011\n",
      "Iteration 822, loss = 3.30937534\n",
      "Iteration 823, loss = 3.30889065\n",
      "Iteration 824, loss = 3.30840606\n",
      "Iteration 825, loss = 3.30792157\n",
      "Iteration 826, loss = 3.30743718\n",
      "Iteration 827, loss = 3.30695289\n",
      "Iteration 828, loss = 3.30646870\n",
      "Iteration 829, loss = 3.30598462\n",
      "Iteration 830, loss = 3.30550066\n",
      "Iteration 831, loss = 3.30501681\n",
      "Iteration 832, loss = 3.30453307\n",
      "Iteration 833, loss = 3.30404946\n",
      "Iteration 834, loss = 3.30356597\n",
      "Iteration 835, loss = 3.30308260\n",
      "Iteration 836, loss = 3.30259936\n",
      "Iteration 837, loss = 3.30211626\n",
      "Iteration 838, loss = 3.30163328\n",
      "Iteration 839, loss = 3.30115045\n",
      "Iteration 840, loss = 3.30066776\n",
      "Iteration 841, loss = 3.30018521\n",
      "Iteration 842, loss = 3.29970280\n",
      "Iteration 843, loss = 3.29922055\n",
      "Iteration 844, loss = 3.29873844\n",
      "Iteration 845, loss = 3.29825649\n",
      "Iteration 846, loss = 3.29777470\n",
      "Iteration 847, loss = 3.29729307\n",
      "Iteration 848, loss = 3.29681161\n",
      "Iteration 849, loss = 3.29633031\n",
      "Iteration 850, loss = 3.29584917\n",
      "Iteration 851, loss = 3.29536821\n",
      "Iteration 852, loss = 3.29488743\n",
      "Iteration 853, loss = 3.29440682\n",
      "Iteration 854, loss = 3.29392640\n",
      "Iteration 855, loss = 3.29344616\n",
      "Iteration 856, loss = 3.29296610\n",
      "Iteration 857, loss = 3.29248623\n",
      "Iteration 858, loss = 3.29200656\n",
      "Iteration 859, loss = 3.29152708\n",
      "Iteration 860, loss = 3.29104780\n",
      "Iteration 861, loss = 3.29056872\n",
      "Iteration 862, loss = 3.29008984\n",
      "Iteration 863, loss = 3.28961117\n",
      "Iteration 864, loss = 3.28913270\n",
      "Iteration 865, loss = 3.28865445\n",
      "Iteration 866, loss = 3.28817642\n",
      "Iteration 867, loss = 3.28769860\n",
      "Iteration 868, loss = 3.28722100\n",
      "Iteration 869, loss = 3.28674362\n",
      "Iteration 870, loss = 3.28626647\n",
      "Iteration 871, loss = 3.28578955\n",
      "Iteration 872, loss = 3.28531286\n",
      "Iteration 873, loss = 3.28483640\n",
      "Iteration 874, loss = 3.28436018\n",
      "Iteration 875, loss = 3.28388420\n",
      "Iteration 876, loss = 3.28340846\n",
      "Iteration 877, loss = 3.28293296\n",
      "Iteration 878, loss = 3.28245771\n",
      "Iteration 879, loss = 3.28198271\n",
      "Iteration 880, loss = 3.28150797\n",
      "Iteration 881, loss = 3.28103348\n",
      "Iteration 882, loss = 3.28055925\n",
      "Iteration 883, loss = 3.28008528\n",
      "Iteration 884, loss = 3.27961157\n",
      "Iteration 885, loss = 3.27913813\n",
      "Iteration 886, loss = 3.27866496\n",
      "Iteration 887, loss = 3.27819205\n",
      "Iteration 888, loss = 3.27771943\n",
      "Iteration 889, loss = 3.27724707\n",
      "Iteration 890, loss = 3.27677500\n",
      "Iteration 891, loss = 3.27630321\n",
      "Iteration 892, loss = 3.27583170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 893, loss = 3.27536048\n",
      "Iteration 894, loss = 3.27488955\n",
      "Iteration 895, loss = 3.27441891\n",
      "Iteration 896, loss = 3.27394856\n",
      "Iteration 897, loss = 3.27347852\n",
      "Iteration 898, loss = 3.27300877\n",
      "Iteration 899, loss = 3.27253932\n",
      "Iteration 900, loss = 3.27207017\n",
      "Iteration 901, loss = 3.27160134\n",
      "Iteration 902, loss = 3.27113281\n",
      "Iteration 903, loss = 3.27066459\n",
      "Iteration 904, loss = 3.27019669\n",
      "Iteration 905, loss = 3.26972910\n",
      "Iteration 906, loss = 3.26926183\n",
      "Iteration 907, loss = 3.26879488\n",
      "Iteration 908, loss = 3.26832826\n",
      "Iteration 909, loss = 3.26786196\n",
      "Iteration 910, loss = 3.26739599\n",
      "Iteration 911, loss = 3.26693035\n",
      "Iteration 912, loss = 3.26646504\n",
      "Iteration 913, loss = 3.26600007\n",
      "Iteration 914, loss = 3.26553544\n",
      "Iteration 915, loss = 3.26507114\n",
      "Iteration 916, loss = 3.26460719\n",
      "Iteration 917, loss = 3.26414358\n",
      "Iteration 918, loss = 3.26368032\n",
      "Iteration 919, loss = 3.26321740\n",
      "Iteration 920, loss = 3.26275484\n",
      "Iteration 921, loss = 3.26229263\n",
      "Iteration 922, loss = 3.26183078\n",
      "Iteration 923, loss = 3.26136928\n",
      "Iteration 924, loss = 3.26090814\n",
      "Iteration 925, loss = 3.26044736\n",
      "Iteration 926, loss = 3.25998695\n",
      "Iteration 927, loss = 3.25952690\n",
      "Iteration 928, loss = 3.25906723\n",
      "Iteration 929, loss = 3.25860792\n",
      "Iteration 930, loss = 3.25814898\n",
      "Iteration 931, loss = 3.25769042\n",
      "Iteration 932, loss = 3.25723223\n",
      "Iteration 933, loss = 3.25677443\n",
      "Iteration 934, loss = 3.25631700\n",
      "Iteration 935, loss = 3.25585995\n",
      "Iteration 936, loss = 3.25540329\n",
      "Iteration 937, loss = 3.25494702\n",
      "Iteration 938, loss = 3.25449113\n",
      "Iteration 939, loss = 3.25403564\n",
      "Iteration 940, loss = 3.25358053\n",
      "Iteration 941, loss = 3.25312582\n",
      "Iteration 942, loss = 3.25267151\n",
      "Iteration 943, loss = 3.25221759\n",
      "Iteration 944, loss = 3.25176408\n",
      "Iteration 945, loss = 3.25131096\n",
      "Iteration 946, loss = 3.25085825\n",
      "Iteration 947, loss = 3.25040594\n",
      "Iteration 948, loss = 3.24995404\n",
      "Iteration 949, loss = 3.24950255\n",
      "Iteration 950, loss = 3.24905147\n",
      "Iteration 951, loss = 3.24860080\n",
      "Iteration 952, loss = 3.24815055\n",
      "Iteration 953, loss = 3.24770071\n",
      "Iteration 954, loss = 3.24725129\n",
      "Iteration 955, loss = 3.24680229\n",
      "Iteration 956, loss = 3.24635371\n",
      "Iteration 957, loss = 3.24590555\n",
      "Iteration 958, loss = 3.24545782\n",
      "Iteration 959, loss = 3.24501051\n",
      "Iteration 960, loss = 3.24456363\n",
      "Iteration 961, loss = 3.24411718\n",
      "Iteration 962, loss = 3.24367116\n",
      "Iteration 963, loss = 3.24322557\n",
      "Iteration 964, loss = 3.24278041\n",
      "Iteration 965, loss = 3.24233569\n",
      "Iteration 966, loss = 3.24189141\n",
      "Iteration 967, loss = 3.24144757\n",
      "Iteration 968, loss = 3.24100416\n",
      "Iteration 969, loss = 3.24056120\n",
      "Iteration 970, loss = 3.24011868\n",
      "Iteration 971, loss = 3.23967660\n",
      "Iteration 972, loss = 3.23923497\n",
      "Iteration 973, loss = 3.23879379\n",
      "Iteration 974, loss = 3.23835305\n",
      "Iteration 975, loss = 3.23791276\n",
      "Iteration 976, loss = 3.23747293\n",
      "Iteration 977, loss = 3.23703355\n",
      "Iteration 978, loss = 3.23659462\n",
      "Iteration 979, loss = 3.23615615\n",
      "Iteration 980, loss = 3.23571813\n",
      "Iteration 981, loss = 3.23528057\n",
      "Iteration 982, loss = 3.23484347\n",
      "Iteration 983, loss = 3.23440683\n",
      "Iteration 984, loss = 3.23397065\n",
      "Iteration 985, loss = 3.23353494\n",
      "Iteration 986, loss = 3.23309969\n",
      "Iteration 987, loss = 3.23266490\n",
      "Iteration 988, loss = 3.23223058\n",
      "Iteration 989, loss = 3.23179673\n",
      "Iteration 990, loss = 3.23136335\n",
      "Iteration 991, loss = 3.23093043\n",
      "Iteration 992, loss = 3.23049799\n",
      "Iteration 993, loss = 3.23006602\n",
      "Iteration 994, loss = 3.22963452\n",
      "Iteration 995, loss = 3.22920350\n",
      "Iteration 996, loss = 3.22877295\n",
      "Iteration 997, loss = 3.22834287\n",
      "Iteration 998, loss = 3.22791328\n",
      "Iteration 999, loss = 3.22748416\n",
      "Iteration 1000, loss = 3.22705552\n",
      "Iteration 1001, loss = 3.22662736\n",
      "Iteration 1002, loss = 3.22619968\n",
      "Iteration 1003, loss = 3.22577249\n",
      "Iteration 1004, loss = 3.22534578\n",
      "Iteration 1005, loss = 3.22491955\n",
      "Iteration 1006, loss = 3.22449380\n",
      "Iteration 1007, loss = 3.22406854\n",
      "Iteration 1008, loss = 3.22364377\n",
      "Iteration 1009, loss = 3.22321949\n",
      "Iteration 1010, loss = 3.22279569\n",
      "Iteration 1011, loss = 3.22237238\n",
      "Iteration 1012, loss = 3.22194956\n",
      "Iteration 1013, loss = 3.22152723\n",
      "Iteration 1014, loss = 3.22110539\n",
      "Iteration 1015, loss = 3.22068405\n",
      "Iteration 1016, loss = 3.22026320\n",
      "Iteration 1017, loss = 3.21984284\n",
      "Iteration 1018, loss = 3.21942297\n",
      "Iteration 1019, loss = 3.21900360\n",
      "Iteration 1020, loss = 3.21858472\n",
      "Iteration 1021, loss = 3.21816634\n",
      "Iteration 1022, loss = 3.21774846\n",
      "Iteration 1023, loss = 3.21733107\n",
      "Iteration 1024, loss = 3.21691418\n",
      "Iteration 1025, loss = 3.21649779\n",
      "Iteration 1026, loss = 3.21608190\n",
      "Iteration 1027, loss = 3.21566651\n",
      "Iteration 1028, loss = 3.21525162\n",
      "Iteration 1029, loss = 3.21483723\n",
      "Iteration 1030, loss = 3.21442334\n",
      "Iteration 1031, loss = 3.21400995\n",
      "Iteration 1032, loss = 3.21359706\n",
      "Iteration 1033, loss = 3.21318468\n",
      "Iteration 1034, loss = 3.21277280\n",
      "Iteration 1035, loss = 3.21236142\n",
      "Iteration 1036, loss = 3.21195055\n",
      "Iteration 1037, loss = 3.21154018\n",
      "Iteration 1038, loss = 3.21113031\n",
      "Iteration 1039, loss = 3.21072095\n",
      "Iteration 1040, loss = 3.21031210\n",
      "Iteration 1041, loss = 3.20990375\n",
      "Iteration 1042, loss = 3.20949590\n",
      "Iteration 1043, loss = 3.20908857\n",
      "Iteration 1044, loss = 3.20868174\n",
      "Iteration 1045, loss = 3.20827541\n",
      "Iteration 1046, loss = 3.20786960\n",
      "Iteration 1047, loss = 3.20746429\n",
      "Iteration 1048, loss = 3.20705949\n",
      "Iteration 1049, loss = 3.20665519\n",
      "Iteration 1050, loss = 3.20625141\n",
      "Iteration 1051, loss = 3.20584813\n",
      "Iteration 1052, loss = 3.20544536\n",
      "Iteration 1053, loss = 3.20504310\n",
      "Iteration 1054, loss = 3.20464135\n",
      "Iteration 1055, loss = 3.20424011\n",
      "Iteration 1056, loss = 3.20383937\n",
      "Iteration 1057, loss = 3.20343915\n",
      "Iteration 1058, loss = 3.20303943\n",
      "Iteration 1059, loss = 3.20264023\n",
      "Iteration 1060, loss = 3.20224153\n",
      "Iteration 1061, loss = 3.20184334\n",
      "Iteration 1062, loss = 3.20144566\n",
      "Iteration 1063, loss = 3.20104849\n",
      "Iteration 1064, loss = 3.20065184\n",
      "Iteration 1065, loss = 3.20025569\n",
      "Iteration 1066, loss = 3.19986005\n",
      "Iteration 1067, loss = 3.19946492\n",
      "Iteration 1068, loss = 3.19907029\n",
      "Iteration 1069, loss = 3.19867618\n",
      "Iteration 1070, loss = 3.19828258\n",
      "Iteration 1071, loss = 3.19788949\n",
      "Iteration 1072, loss = 3.19749690\n",
      "Iteration 1073, loss = 3.19710483\n",
      "Iteration 1074, loss = 3.19671326\n",
      "Iteration 1075, loss = 3.19632221\n",
      "Iteration 1076, loss = 3.19593166\n",
      "Iteration 1077, loss = 3.19554162\n",
      "Iteration 1078, loss = 3.19515209\n",
      "Iteration 1079, loss = 3.19476306\n",
      "Iteration 1080, loss = 3.19437455\n",
      "Iteration 1081, loss = 3.19398654\n",
      "Iteration 1082, loss = 3.19359904\n",
      "Iteration 1083, loss = 3.19321205\n",
      "Iteration 1084, loss = 3.19282556\n",
      "Iteration 1085, loss = 3.19243958\n",
      "Iteration 1086, loss = 3.19205411\n",
      "Iteration 1087, loss = 3.19166915\n",
      "Iteration 1088, loss = 3.19128469\n",
      "Iteration 1089, loss = 3.19090073\n",
      "Iteration 1090, loss = 3.19051728\n",
      "Iteration 1091, loss = 3.19013434\n",
      "Iteration 1092, loss = 3.18975190\n",
      "Iteration 1093, loss = 3.18936997\n",
      "Iteration 1094, loss = 3.18898854\n",
      "Iteration 1095, loss = 3.18860761\n",
      "Iteration 1096, loss = 3.18822719\n",
      "Iteration 1097, loss = 3.18784727\n",
      "Iteration 1098, loss = 3.18746786\n",
      "Iteration 1099, loss = 3.18708894\n",
      "Iteration 1100, loss = 3.18671053\n",
      "Iteration 1101, loss = 3.18633262\n",
      "Iteration 1102, loss = 3.18595521\n",
      "Iteration 1103, loss = 3.18557830\n",
      "Iteration 1104, loss = 3.18520189\n",
      "Iteration 1105, loss = 3.18482598\n",
      "Iteration 1106, loss = 3.18445057\n",
      "Iteration 1107, loss = 3.18407566\n",
      "Iteration 1108, loss = 3.18370125\n",
      "Iteration 1109, loss = 3.18332733\n",
      "Iteration 1110, loss = 3.18295391\n",
      "Iteration 1111, loss = 3.18258099\n",
      "Iteration 1112, loss = 3.18220856\n",
      "Iteration 1113, loss = 3.18183663\n",
      "Iteration 1114, loss = 3.18146520\n",
      "Iteration 1115, loss = 3.18109426\n",
      "Iteration 1116, loss = 3.18072381\n",
      "Iteration 1117, loss = 3.18035386\n",
      "Iteration 1118, loss = 3.17998440\n",
      "Iteration 1119, loss = 3.17961543\n",
      "Iteration 1120, loss = 3.17924695\n",
      "Iteration 1121, loss = 3.17887897\n",
      "Iteration 1122, loss = 3.17851147\n",
      "Iteration 1123, loss = 3.17814447\n",
      "Iteration 1124, loss = 3.17777795\n",
      "Iteration 1125, loss = 3.17741193\n",
      "Iteration 1126, loss = 3.17704639\n",
      "Iteration 1127, loss = 3.17668133\n",
      "Iteration 1128, loss = 3.17631677\n",
      "Iteration 1129, loss = 3.17595269\n",
      "Iteration 1130, loss = 3.17558909\n",
      "Iteration 1131, loss = 3.17522598\n",
      "Iteration 1132, loss = 3.17486336\n",
      "Iteration 1133, loss = 3.17450121\n",
      "Iteration 1134, loss = 3.17413955\n",
      "Iteration 1135, loss = 3.17377837\n",
      "Iteration 1136, loss = 3.17341767\n",
      "Iteration 1137, loss = 3.17305746\n",
      "Iteration 1138, loss = 3.17269772\n",
      "Iteration 1139, loss = 3.17233846\n",
      "Iteration 1140, loss = 3.17197968\n",
      "Iteration 1141, loss = 3.17162137\n",
      "Iteration 1142, loss = 3.17126355\n",
      "Iteration 1143, loss = 3.17090619\n",
      "Iteration 1144, loss = 3.17054932\n",
      "Iteration 1145, loss = 3.17019291\n",
      "Iteration 1146, loss = 3.16983699\n",
      "Iteration 1147, loss = 3.16948153\n",
      "Iteration 1148, loss = 3.16912655\n",
      "Iteration 1149, loss = 3.16877203\n",
      "Iteration 1150, loss = 3.16841799\n",
      "Iteration 1151, loss = 3.16806442\n",
      "Iteration 1152, loss = 3.16771131\n",
      "Iteration 1153, loss = 3.16735868\n",
      "Iteration 1154, loss = 3.16700651\n",
      "Iteration 1155, loss = 3.16665480\n",
      "Iteration 1156, loss = 3.16630356\n",
      "Iteration 1157, loss = 3.16595279\n",
      "Iteration 1158, loss = 3.16560248\n",
      "Iteration 1159, loss = 3.16525263\n",
      "Iteration 1160, loss = 3.16490325\n",
      "Iteration 1161, loss = 3.16455433\n",
      "Iteration 1162, loss = 3.16420586\n",
      "Iteration 1163, loss = 3.16385786\n",
      "Iteration 1164, loss = 3.16351031\n",
      "Iteration 1165, loss = 3.16316323\n",
      "Iteration 1166, loss = 3.16281660\n",
      "Iteration 1167, loss = 3.16247042\n",
      "Iteration 1168, loss = 3.16212470\n",
      "Iteration 1169, loss = 3.16177944\n",
      "Iteration 1170, loss = 3.16143463\n",
      "Iteration 1171, loss = 3.16109027\n",
      "Iteration 1172, loss = 3.16074636\n",
      "Iteration 1173, loss = 3.16040290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1174, loss = 3.16005989\n",
      "Iteration 1175, loss = 3.15971733\n",
      "Iteration 1176, loss = 3.15937522\n",
      "Iteration 1177, loss = 3.15903356\n",
      "Iteration 1178, loss = 3.15869234\n",
      "Iteration 1179, loss = 3.15835157\n",
      "Iteration 1180, loss = 3.15801124\n",
      "Iteration 1181, loss = 3.15767136\n",
      "Iteration 1182, loss = 3.15733191\n",
      "Iteration 1183, loss = 3.15699291\n",
      "Iteration 1184, loss = 3.15665435\n",
      "Iteration 1185, loss = 3.15631623\n",
      "Iteration 1186, loss = 3.15597855\n",
      "Iteration 1187, loss = 3.15564130\n",
      "Iteration 1188, loss = 3.15530450\n",
      "Iteration 1189, loss = 3.15496813\n",
      "Iteration 1190, loss = 3.15463219\n",
      "Iteration 1191, loss = 3.15429669\n",
      "Iteration 1192, loss = 3.15396162\n",
      "Iteration 1193, loss = 3.15362698\n",
      "Iteration 1194, loss = 3.15329277\n",
      "Iteration 1195, loss = 3.15295899\n",
      "Iteration 1196, loss = 3.15262565\n",
      "Iteration 1197, loss = 3.15229273\n",
      "Iteration 1198, loss = 3.15196024\n",
      "Iteration 1199, loss = 3.15162817\n",
      "Iteration 1200, loss = 3.15129653\n",
      "Iteration 1201, loss = 3.15096532\n",
      "Iteration 1202, loss = 3.15063452\n",
      "Iteration 1203, loss = 3.15030416\n",
      "Iteration 1204, loss = 3.14997421\n",
      "Iteration 1205, loss = 3.14964468\n",
      "Iteration 1206, loss = 3.14931557\n",
      "Iteration 1207, loss = 3.14898688\n",
      "Iteration 1208, loss = 3.14865861\n",
      "Iteration 1209, loss = 3.14833076\n",
      "Iteration 1210, loss = 3.14800332\n",
      "Iteration 1211, loss = 3.14767630\n",
      "Iteration 1212, loss = 3.14734969\n",
      "Iteration 1213, loss = 3.14702349\n",
      "Iteration 1214, loss = 3.14669770\n",
      "Iteration 1215, loss = 3.14637233\n",
      "Iteration 1216, loss = 3.14604737\n",
      "Iteration 1217, loss = 3.14572281\n",
      "Iteration 1218, loss = 3.14539866\n",
      "Iteration 1219, loss = 3.14507492\n",
      "Iteration 1220, loss = 3.14475159\n",
      "Iteration 1221, loss = 3.14442866\n",
      "Iteration 1222, loss = 3.14410614\n",
      "Iteration 1223, loss = 3.14378401\n",
      "Iteration 1224, loss = 3.14346230\n",
      "Iteration 1225, loss = 3.14314098\n",
      "Iteration 1226, loss = 3.14282006\n",
      "Iteration 1227, loss = 3.14249954\n",
      "Iteration 1228, loss = 3.14217942\n",
      "Iteration 1229, loss = 3.14185970\n",
      "Iteration 1230, loss = 3.14154037\n",
      "Iteration 1231, loss = 3.14122144\n",
      "Iteration 1232, loss = 3.14090291\n",
      "Iteration 1233, loss = 3.14058476\n",
      "Iteration 1234, loss = 3.14026701\n",
      "Iteration 1235, loss = 3.13994966\n",
      "Iteration 1236, loss = 3.13963269\n",
      "Iteration 1237, loss = 3.13931611\n",
      "Iteration 1238, loss = 3.13899992\n",
      "Iteration 1239, loss = 3.13868412\n",
      "Iteration 1240, loss = 3.13836870\n",
      "Iteration 1241, loss = 3.13805368\n",
      "Iteration 1242, loss = 3.13773903\n",
      "Iteration 1243, loss = 3.13742477\n",
      "Iteration 1244, loss = 3.13711090\n",
      "Iteration 1245, loss = 3.13679740\n",
      "Iteration 1246, loss = 3.13648429\n",
      "Iteration 1247, loss = 3.13617155\n",
      "Iteration 1248, loss = 3.13585920\n",
      "Iteration 1249, loss = 3.13554722\n",
      "Iteration 1250, loss = 3.13523562\n",
      "Iteration 1251, loss = 3.13492440\n",
      "Iteration 1252, loss = 3.13461356\n",
      "Iteration 1253, loss = 3.13430308\n",
      "Iteration 1254, loss = 3.13399298\n",
      "Iteration 1255, loss = 3.13368326\n",
      "Iteration 1256, loss = 3.13337390\n",
      "Iteration 1257, loss = 3.13306492\n",
      "Iteration 1258, loss = 3.13275631\n",
      "Iteration 1259, loss = 3.13244806\n",
      "Iteration 1260, loss = 3.13214018\n",
      "Iteration 1261, loss = 3.13183267\n",
      "Iteration 1262, loss = 3.13152553\n",
      "Iteration 1263, loss = 3.13121875\n",
      "Iteration 1264, loss = 3.13091233\n",
      "Iteration 1265, loss = 3.13060628\n",
      "Iteration 1266, loss = 3.13030059\n",
      "Iteration 1267, loss = 3.12999527\n",
      "Iteration 1268, loss = 3.12969030\n",
      "Iteration 1269, loss = 3.12938569\n",
      "Iteration 1270, loss = 3.12908144\n",
      "Iteration 1271, loss = 3.12877755\n",
      "Iteration 1272, loss = 3.12847402\n",
      "Iteration 1273, loss = 3.12817084\n",
      "Iteration 1274, loss = 3.12786802\n",
      "Iteration 1275, loss = 3.12756555\n",
      "Iteration 1276, loss = 3.12726343\n",
      "Iteration 1277, loss = 3.12696167\n",
      "Iteration 1278, loss = 3.12666026\n",
      "Iteration 1279, loss = 3.12635920\n",
      "Iteration 1280, loss = 3.12605849\n",
      "Iteration 1281, loss = 3.12575813\n",
      "Iteration 1282, loss = 3.12545811\n",
      "Iteration 1283, loss = 3.12515844\n",
      "Iteration 1284, loss = 3.12485912\n",
      "Iteration 1285, loss = 3.12456015\n",
      "Iteration 1286, loss = 3.12426152\n",
      "Iteration 1287, loss = 3.12396323\n",
      "Iteration 1288, loss = 3.12366528\n",
      "Iteration 1289, loss = 3.12336768\n",
      "Iteration 1290, loss = 3.12307042\n",
      "Iteration 1291, loss = 3.12277349\n",
      "Iteration 1292, loss = 3.12247691\n",
      "Iteration 1293, loss = 3.12218067\n",
      "Iteration 1294, loss = 3.12188476\n",
      "Iteration 1295, loss = 3.12158919\n",
      "Iteration 1296, loss = 3.12129395\n",
      "Iteration 1297, loss = 3.12099905\n",
      "Iteration 1298, loss = 3.12070449\n",
      "Iteration 1299, loss = 3.12041025\n",
      "Iteration 1300, loss = 3.12011635\n",
      "Iteration 1301, loss = 3.11982278\n",
      "Iteration 1302, loss = 3.11952954\n",
      "Iteration 1303, loss = 3.11923663\n",
      "Iteration 1304, loss = 3.11894405\n",
      "Iteration 1305, loss = 3.11865180\n",
      "Iteration 1306, loss = 3.11835988\n",
      "Iteration 1307, loss = 3.11806828\n",
      "Iteration 1308, loss = 3.11777701\n",
      "Iteration 1309, loss = 3.11748606\n",
      "Iteration 1310, loss = 3.11719543\n",
      "Iteration 1311, loss = 3.11690513\n",
      "Iteration 1312, loss = 3.11661515\n",
      "Iteration 1313, loss = 3.11632550\n",
      "Iteration 1314, loss = 3.11603616\n",
      "Iteration 1315, loss = 3.11574715\n",
      "Iteration 1316, loss = 3.11545845\n",
      "Iteration 1317, loss = 3.11517007\n",
      "Iteration 1318, loss = 3.11488201\n",
      "Iteration 1319, loss = 3.11459426\n",
      "Iteration 1320, loss = 3.11430683\n",
      "Iteration 1321, loss = 3.11401972\n",
      "Iteration 1322, loss = 3.11373292\n",
      "Iteration 1323, loss = 3.11344643\n",
      "Iteration 1324, loss = 3.11316026\n",
      "Iteration 1325, loss = 3.11287440\n",
      "Iteration 1326, loss = 3.11258885\n",
      "Iteration 1327, loss = 3.11230360\n",
      "Iteration 1328, loss = 3.11201867\n",
      "Iteration 1329, loss = 3.11173405\n",
      "Iteration 1330, loss = 3.11144974\n",
      "Iteration 1331, loss = 3.11116573\n",
      "Iteration 1332, loss = 3.11088203\n",
      "Iteration 1333, loss = 3.11059863\n",
      "Iteration 1334, loss = 3.11031554\n",
      "Iteration 1335, loss = 3.11003276\n",
      "Iteration 1336, loss = 3.10975027\n",
      "Iteration 1337, loss = 3.10946809\n",
      "Iteration 1338, loss = 3.10918622\n",
      "Iteration 1339, loss = 3.10890464\n",
      "Iteration 1340, loss = 3.10862336\n",
      "Iteration 1341, loss = 3.10834238\n",
      "Iteration 1342, loss = 3.10806170\n",
      "Iteration 1343, loss = 3.10778132\n",
      "Iteration 1344, loss = 3.10750124\n",
      "Iteration 1345, loss = 3.10722145\n",
      "Iteration 1346, loss = 3.10694196\n",
      "Iteration 1347, loss = 3.10666277\n",
      "Iteration 1348, loss = 3.10638386\n",
      "Iteration 1349, loss = 3.10610526\n",
      "Iteration 1350, loss = 3.10582694\n",
      "Iteration 1351, loss = 3.10554892\n",
      "Iteration 1352, loss = 3.10527119\n",
      "Iteration 1353, loss = 3.10499375\n",
      "Iteration 1354, loss = 3.10471660\n",
      "Iteration 1355, loss = 3.10443973\n",
      "Iteration 1356, loss = 3.10416316\n",
      "Iteration 1357, loss = 3.10388688\n",
      "Iteration 1358, loss = 3.10361088\n",
      "Iteration 1359, loss = 3.10333517\n",
      "Iteration 1360, loss = 3.10305974\n",
      "Iteration 1361, loss = 3.10278460\n",
      "Iteration 1362, loss = 3.10250974\n",
      "Iteration 1363, loss = 3.10223517\n",
      "Iteration 1364, loss = 3.10196088\n",
      "Iteration 1365, loss = 3.10168687\n",
      "Iteration 1366, loss = 3.10141315\n",
      "Iteration 1367, loss = 3.10113970\n",
      "Iteration 1368, loss = 3.10086653\n",
      "Iteration 1369, loss = 3.10059365\n",
      "Iteration 1370, loss = 3.10032104\n",
      "Iteration 1371, loss = 3.10004871\n",
      "Iteration 1372, loss = 3.09977666\n",
      "Iteration 1373, loss = 3.09950488\n",
      "Iteration 1374, loss = 3.09923338\n",
      "Iteration 1375, loss = 3.09896216\n",
      "Iteration 1376, loss = 3.09869121\n",
      "Iteration 1377, loss = 3.09842054\n",
      "Iteration 1378, loss = 3.09815013\n",
      "Iteration 1379, loss = 3.09788000\n",
      "Iteration 1380, loss = 3.09761015\n",
      "Iteration 1381, loss = 3.09734056\n",
      "Iteration 1382, loss = 3.09707124\n",
      "Iteration 1383, loss = 3.09680220\n",
      "Iteration 1384, loss = 3.09653342\n",
      "Iteration 1385, loss = 3.09626491\n",
      "Iteration 1386, loss = 3.09599667\n",
      "Iteration 1387, loss = 3.09572870\n",
      "Iteration 1388, loss = 3.09546100\n",
      "Iteration 1389, loss = 3.09519356\n",
      "Iteration 1390, loss = 3.09492638\n",
      "Iteration 1391, loss = 3.09465947\n",
      "Iteration 1392, loss = 3.09439283\n",
      "Iteration 1393, loss = 3.09412645\n",
      "Iteration 1394, loss = 3.09386033\n",
      "Iteration 1395, loss = 3.09359447\n",
      "Iteration 1396, loss = 3.09332888\n",
      "Iteration 1397, loss = 3.09306354\n",
      "Iteration 1398, loss = 3.09279847\n",
      "Iteration 1399, loss = 3.09253365\n",
      "Iteration 1400, loss = 3.09226910\n",
      "Iteration 1401, loss = 3.09200480\n",
      "Iteration 1402, loss = 3.09174076\n",
      "Iteration 1403, loss = 3.09147698\n",
      "Iteration 1404, loss = 3.09121345\n",
      "Iteration 1405, loss = 3.09095018\n",
      "Iteration 1406, loss = 3.09068717\n",
      "Iteration 1407, loss = 3.09042441\n",
      "Iteration 1408, loss = 3.09016190\n",
      "Iteration 1409, loss = 3.08989965\n",
      "Iteration 1410, loss = 3.08963765\n",
      "Iteration 1411, loss = 3.08937591\n",
      "Iteration 1412, loss = 3.08911441\n",
      "Iteration 1413, loss = 3.08885317\n",
      "Iteration 1414, loss = 3.08859217\n",
      "Iteration 1415, loss = 3.08833143\n",
      "Iteration 1416, loss = 3.08807093\n",
      "Iteration 1417, loss = 3.08781068\n",
      "Iteration 1418, loss = 3.08755069\n",
      "Iteration 1419, loss = 3.08729094\n",
      "Iteration 1420, loss = 3.08703143\n",
      "Iteration 1421, loss = 3.08677217\n",
      "Iteration 1422, loss = 3.08651316\n",
      "Iteration 1423, loss = 3.08625439\n",
      "Iteration 1424, loss = 3.08599587\n",
      "Iteration 1425, loss = 3.08573759\n",
      "Iteration 1426, loss = 3.08547955\n",
      "Iteration 1427, loss = 3.08522176\n",
      "Iteration 1428, loss = 3.08496421\n",
      "Iteration 1429, loss = 3.08470690\n",
      "Iteration 1430, loss = 3.08444983\n",
      "Iteration 1431, loss = 3.08419300\n",
      "Iteration 1432, loss = 3.08393641\n",
      "Iteration 1433, loss = 3.08368006\n",
      "Iteration 1434, loss = 3.08342395\n",
      "Iteration 1435, loss = 3.08316808\n",
      "Iteration 1436, loss = 3.08291244\n",
      "Iteration 1437, loss = 3.08265704\n",
      "Iteration 1438, loss = 3.08240188\n",
      "Iteration 1439, loss = 3.08214696\n",
      "Iteration 1440, loss = 3.08189226\n",
      "Iteration 1441, loss = 3.08163781\n",
      "Iteration 1442, loss = 3.08138358\n",
      "Iteration 1443, loss = 3.08112960\n",
      "Iteration 1444, loss = 3.08087584\n",
      "Iteration 1445, loss = 3.08062231\n",
      "Iteration 1446, loss = 3.08036902\n",
      "Iteration 1447, loss = 3.08011596\n",
      "Iteration 1448, loss = 3.07986313\n",
      "Iteration 1449, loss = 3.07961053\n",
      "Iteration 1450, loss = 3.07935816\n",
      "Iteration 1451, loss = 3.07910602\n",
      "Iteration 1452, loss = 3.07885411\n",
      "Iteration 1453, loss = 3.07860242\n",
      "Iteration 1454, loss = 3.07835096\n",
      "Iteration 1455, loss = 3.07809973\n",
      "Iteration 1456, loss = 3.07784873\n",
      "Iteration 1457, loss = 3.07759795\n",
      "Iteration 1458, loss = 3.07734740\n",
      "Iteration 1459, loss = 3.07709707\n",
      "Iteration 1460, loss = 3.07684696\n",
      "Iteration 1461, loss = 3.07659708\n",
      "Iteration 1462, loss = 3.07634742\n",
      "Iteration 1463, loss = 3.07609799\n",
      "Iteration 1464, loss = 3.07584877\n",
      "Iteration 1465, loss = 3.07559978\n",
      "Iteration 1466, loss = 3.07535101\n",
      "Iteration 1467, loss = 3.07510246\n",
      "Iteration 1468, loss = 3.07485413\n",
      "Iteration 1469, loss = 3.07460602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1470, loss = 3.07435812\n",
      "Iteration 1471, loss = 3.07411045\n",
      "Iteration 1472, loss = 3.07386299\n",
      "Iteration 1473, loss = 3.07361575\n",
      "Iteration 1474, loss = 3.07336873\n",
      "Iteration 1475, loss = 3.07312192\n",
      "Iteration 1476, loss = 3.07287533\n",
      "Iteration 1477, loss = 3.07262895\n",
      "Iteration 1478, loss = 3.07238279\n",
      "Iteration 1479, loss = 3.07213684\n",
      "Iteration 1480, loss = 3.07189111\n",
      "Iteration 1481, loss = 3.07164559\n",
      "Iteration 1482, loss = 3.07140028\n",
      "Iteration 1483, loss = 3.07115518\n",
      "Iteration 1484, loss = 3.07091030\n",
      "Iteration 1485, loss = 3.07066562\n",
      "Iteration 1486, loss = 3.07042116\n",
      "Iteration 1487, loss = 3.07017690\n",
      "Iteration 1488, loss = 3.06993286\n",
      "Iteration 1489, loss = 3.06968902\n",
      "Iteration 1490, loss = 3.06944540\n",
      "Iteration 1491, loss = 3.06920198\n",
      "Iteration 1492, loss = 3.06895876\n",
      "Iteration 1493, loss = 3.06871576\n",
      "Iteration 1494, loss = 3.06847296\n",
      "Iteration 1495, loss = 3.06823037\n",
      "Iteration 1496, loss = 3.06798798\n",
      "Iteration 1497, loss = 3.06774580\n",
      "Iteration 1498, loss = 3.06750382\n",
      "Iteration 1499, loss = 3.06726204\n",
      "Iteration 1500, loss = 3.06702047\n",
      "Iteration 1501, loss = 3.06677910\n",
      "Iteration 1502, loss = 3.06653794\n",
      "Iteration 1503, loss = 3.06629697\n",
      "Iteration 1504, loss = 3.06605621\n",
      "Iteration 1505, loss = 3.06581565\n",
      "Iteration 1506, loss = 3.06557529\n",
      "Iteration 1507, loss = 3.06533513\n",
      "Iteration 1508, loss = 3.06509516\n",
      "Iteration 1509, loss = 3.06485540\n",
      "Iteration 1510, loss = 3.06461584\n",
      "Iteration 1511, loss = 3.06437647\n",
      "Iteration 1512, loss = 3.06413730\n",
      "Iteration 1513, loss = 3.06389833\n",
      "Iteration 1514, loss = 3.06365955\n",
      "Iteration 1515, loss = 3.06342097\n",
      "Iteration 1516, loss = 3.06318258\n",
      "Iteration 1517, loss = 3.06294439\n",
      "Iteration 1518, loss = 3.06270640\n",
      "Iteration 1519, loss = 3.06246860\n",
      "Iteration 1520, loss = 3.06223099\n",
      "Iteration 1521, loss = 3.06199358\n",
      "Iteration 1522, loss = 3.06175635\n",
      "Iteration 1523, loss = 3.06151933\n",
      "Iteration 1524, loss = 3.06128249\n",
      "Iteration 1525, loss = 3.06104584\n",
      "Iteration 1526, loss = 3.06080938\n",
      "Iteration 1527, loss = 3.06057312\n",
      "Iteration 1528, loss = 3.06033704\n",
      "Iteration 1529, loss = 3.06010116\n",
      "Iteration 1530, loss = 3.05986546\n",
      "Iteration 1531, loss = 3.05962995\n",
      "Iteration 1532, loss = 3.05939463\n",
      "Iteration 1533, loss = 3.05915949\n",
      "Iteration 1534, loss = 3.05892454\n",
      "Iteration 1535, loss = 3.05868978\n",
      "Iteration 1536, loss = 3.05845521\n",
      "Iteration 1537, loss = 3.05822082\n",
      "Iteration 1538, loss = 3.05798661\n",
      "Iteration 1539, loss = 3.05775260\n",
      "Iteration 1540, loss = 3.05751876\n",
      "Iteration 1541, loss = 3.05728511\n",
      "Iteration 1542, loss = 3.05705164\n",
      "Iteration 1543, loss = 3.05681835\n",
      "Iteration 1544, loss = 3.05658525\n",
      "Iteration 1545, loss = 3.05635233\n",
      "Iteration 1546, loss = 3.05611959\n",
      "Iteration 1547, loss = 3.05588703\n",
      "Iteration 1548, loss = 3.05565465\n",
      "Iteration 1549, loss = 3.05542245\n",
      "Iteration 1550, loss = 3.05519043\n",
      "Iteration 1551, loss = 3.05495859\n",
      "Iteration 1552, loss = 3.05472693\n",
      "Iteration 1553, loss = 3.05449545\n",
      "Iteration 1554, loss = 3.05426415\n",
      "Iteration 1555, loss = 3.05403302\n",
      "Iteration 1556, loss = 3.05380207\n",
      "Iteration 1557, loss = 3.05357129\n",
      "Iteration 1558, loss = 3.05334070\n",
      "Iteration 1559, loss = 3.05311027\n",
      "Iteration 1560, loss = 3.05288003\n",
      "Iteration 1561, loss = 3.05264995\n",
      "Iteration 1562, loss = 3.05242005\n",
      "Iteration 1563, loss = 3.05219033\n",
      "Iteration 1564, loss = 3.05196078\n",
      "Iteration 1565, loss = 3.05173140\n",
      "Iteration 1566, loss = 3.05150219\n",
      "Iteration 1567, loss = 3.05127316\n",
      "Iteration 1568, loss = 3.05104430\n",
      "Iteration 1569, loss = 3.05081561\n",
      "Iteration 1570, loss = 3.05058709\n",
      "Iteration 1571, loss = 3.05035874\n",
      "Iteration 1572, loss = 3.05013056\n",
      "Iteration 1573, loss = 3.04990255\n",
      "Iteration 1574, loss = 3.04967471\n",
      "Iteration 1575, loss = 3.04944704\n",
      "Iteration 1576, loss = 3.04921953\n",
      "Iteration 1577, loss = 3.04899220\n",
      "Iteration 1578, loss = 3.04876503\n",
      "Iteration 1579, loss = 3.04853803\n",
      "Iteration 1580, loss = 3.04831119\n",
      "Iteration 1581, loss = 3.04808452\n",
      "Iteration 1582, loss = 3.04785802\n",
      "Iteration 1583, loss = 3.04763168\n",
      "Iteration 1584, loss = 3.04740551\n",
      "Iteration 1585, loss = 3.04717950\n",
      "Iteration 1586, loss = 3.04695366\n",
      "Iteration 1587, loss = 3.04672798\n",
      "Iteration 1588, loss = 3.04650246\n",
      "Iteration 1589, loss = 3.04627710\n",
      "Iteration 1590, loss = 3.04605191\n",
      "Iteration 1591, loss = 3.04582688\n",
      "Iteration 1592, loss = 3.04560201\n",
      "Iteration 1593, loss = 3.04537731\n",
      "Iteration 1594, loss = 3.04515276\n",
      "Iteration 1595, loss = 3.04492838\n",
      "Iteration 1596, loss = 3.04470415\n",
      "Iteration 1597, loss = 3.04448008\n",
      "Iteration 1598, loss = 3.04425618\n",
      "Iteration 1599, loss = 3.04403243\n",
      "Iteration 1600, loss = 3.04380884\n",
      "Iteration 1601, loss = 3.04358541\n",
      "Iteration 1602, loss = 3.04336214\n",
      "Iteration 1603, loss = 3.04313902\n",
      "Iteration 1604, loss = 3.04291606\n",
      "Iteration 1605, loss = 3.04269326\n",
      "Iteration 1606, loss = 3.04247061\n",
      "Iteration 1607, loss = 3.04224812\n",
      "Iteration 1608, loss = 3.04202579\n",
      "Iteration 1609, loss = 3.04180361\n",
      "Iteration 1610, loss = 3.04158158\n",
      "Iteration 1611, loss = 3.04135971\n",
      "Iteration 1612, loss = 3.04113799\n",
      "Iteration 1613, loss = 3.04091643\n",
      "Iteration 1614, loss = 3.04069502\n",
      "Iteration 1615, loss = 3.04047376\n",
      "Iteration 1616, loss = 3.04025265\n",
      "Iteration 1617, loss = 3.04003170\n",
      "Iteration 1618, loss = 3.03981090\n",
      "Iteration 1619, loss = 3.03959025\n",
      "Iteration 1620, loss = 3.03936975\n",
      "Iteration 1621, loss = 3.03914940\n",
      "Iteration 1622, loss = 3.03892920\n",
      "Iteration 1623, loss = 3.03870915\n",
      "Iteration 1624, loss = 3.03848926\n",
      "Iteration 1625, loss = 3.03826951\n",
      "Iteration 1626, loss = 3.03804991\n",
      "Iteration 1627, loss = 3.03783045\n",
      "Iteration 1628, loss = 3.03761115\n",
      "Iteration 1629, loss = 3.03739199\n",
      "Iteration 1630, loss = 3.03717298\n",
      "Iteration 1631, loss = 3.03695412\n",
      "Iteration 1632, loss = 3.03673541\n",
      "Iteration 1633, loss = 3.03651684\n",
      "Iteration 1634, loss = 3.03629842\n",
      "Iteration 1635, loss = 3.03608014\n",
      "Iteration 1636, loss = 3.03586201\n",
      "Iteration 1637, loss = 3.03564402\n",
      "Iteration 1638, loss = 3.03542618\n",
      "Iteration 1639, loss = 3.03520849\n",
      "Iteration 1640, loss = 3.03499093\n",
      "Iteration 1641, loss = 3.03477352\n",
      "Iteration 1642, loss = 3.03455626\n",
      "Iteration 1643, loss = 3.03433914\n",
      "Iteration 1644, loss = 3.03412216\n",
      "Iteration 1645, loss = 3.03390532\n",
      "Iteration 1646, loss = 3.03368863\n",
      "Iteration 1647, loss = 3.03347207\n",
      "Iteration 1648, loss = 3.03325566\n",
      "Iteration 1649, loss = 3.03303940\n",
      "Iteration 1650, loss = 3.03282327\n",
      "Iteration 1651, loss = 3.03260728\n",
      "Iteration 1652, loss = 3.03239143\n",
      "Iteration 1653, loss = 3.03217573\n",
      "Iteration 1654, loss = 3.03196016\n",
      "Iteration 1655, loss = 3.03174473\n",
      "Iteration 1656, loss = 3.03152944\n",
      "Iteration 1657, loss = 3.03131429\n",
      "Iteration 1658, loss = 3.03109928\n",
      "Iteration 1659, loss = 3.03088441\n",
      "Iteration 1660, loss = 3.03066968\n",
      "Iteration 1661, loss = 3.03045508\n",
      "Iteration 1662, loss = 3.03024062\n",
      "Iteration 1663, loss = 3.03002630\n",
      "Iteration 1664, loss = 3.02981211\n",
      "Iteration 1665, loss = 3.02959807\n",
      "Iteration 1666, loss = 3.02938416\n",
      "Iteration 1667, loss = 3.02917038\n",
      "Iteration 1668, loss = 3.02895674\n",
      "Iteration 1669, loss = 3.02874324\n",
      "Iteration 1670, loss = 3.02852987\n",
      "Iteration 1671, loss = 3.02831664\n",
      "Iteration 1672, loss = 3.02810354\n",
      "Iteration 1673, loss = 3.02789058\n",
      "Iteration 1674, loss = 3.02767775\n",
      "Iteration 1675, loss = 3.02746505\n",
      "Iteration 1676, loss = 3.02725249\n",
      "Iteration 1677, loss = 3.02704007\n",
      "Iteration 1678, loss = 3.02682777\n",
      "Iteration 1679, loss = 3.02661561\n",
      "Iteration 1680, loss = 3.02640358\n",
      "Iteration 1681, loss = 3.02619169\n",
      "Iteration 1682, loss = 3.02597993\n",
      "Iteration 1683, loss = 3.02576830\n",
      "Iteration 1684, loss = 3.02555680\n",
      "Iteration 1685, loss = 3.02534543\n",
      "Iteration 1686, loss = 3.02513420\n",
      "Iteration 1687, loss = 3.02492310\n",
      "Iteration 1688, loss = 3.02471212\n",
      "Iteration 1689, loss = 3.02450128\n",
      "Iteration 1690, loss = 3.02429057\n",
      "Iteration 1691, loss = 3.02407999\n",
      "Iteration 1692, loss = 3.02386954\n",
      "Iteration 1693, loss = 3.02365923\n",
      "Iteration 1694, loss = 3.02344904\n",
      "Iteration 1695, loss = 3.02323898\n",
      "Iteration 1696, loss = 3.02302905\n",
      "Iteration 1697, loss = 3.02281925\n",
      "Iteration 1698, loss = 3.02260957\n",
      "Iteration 1699, loss = 3.02240003\n",
      "Iteration 1700, loss = 3.02219062\n",
      "Iteration 1701, loss = 3.02198133\n",
      "Iteration 1702, loss = 3.02177218\n",
      "Iteration 1703, loss = 3.02156315\n",
      "Iteration 1704, loss = 3.02135425\n",
      "Iteration 1705, loss = 3.02114548\n",
      "Iteration 1706, loss = 3.02093683\n",
      "Iteration 1707, loss = 3.02072832\n",
      "Iteration 1708, loss = 3.02051993\n",
      "Iteration 1709, loss = 3.02031166\n",
      "Iteration 1710, loss = 3.02010353\n",
      "Iteration 1711, loss = 3.01989552\n",
      "Iteration 1712, loss = 3.01968764\n",
      "Iteration 1713, loss = 3.01947988\n",
      "Iteration 1714, loss = 3.01927226\n",
      "Iteration 1715, loss = 3.01906475\n",
      "Iteration 1716, loss = 3.01885738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1717, loss = 3.01865013\n",
      "Iteration 1718, loss = 3.01844300\n",
      "Iteration 1719, loss = 3.01823601\n",
      "Iteration 1720, loss = 3.01802913\n",
      "Iteration 1721, loss = 3.01782239\n",
      "Iteration 1722, loss = 3.01761576\n",
      "Iteration 1723, loss = 3.01740927\n",
      "Iteration 1724, loss = 3.01720290\n",
      "Iteration 1725, loss = 3.01699665\n",
      "Iteration 1726, loss = 3.01679053\n",
      "Iteration 1727, loss = 3.01658453\n",
      "Iteration 1728, loss = 3.01637866\n",
      "Iteration 1729, loss = 3.01617291\n",
      "Iteration 1730, loss = 3.01596729\n",
      "Iteration 1731, loss = 3.01576179\n",
      "Iteration 1732, loss = 3.01555642\n",
      "Iteration 1733, loss = 3.01535117\n",
      "Iteration 1734, loss = 3.01514604\n",
      "Iteration 1735, loss = 3.01494104\n",
      "Iteration 1736, loss = 3.01473616\n",
      "Iteration 1737, loss = 3.01453140\n",
      "Iteration 1738, loss = 3.01432677\n",
      "Iteration 1739, loss = 3.01412226\n",
      "Iteration 1740, loss = 3.01391788\n",
      "Iteration 1741, loss = 3.01371362\n",
      "Iteration 1742, loss = 3.01350948\n",
      "Iteration 1743, loss = 3.01330547\n",
      "Iteration 1744, loss = 3.01310158\n",
      "Iteration 1745, loss = 3.01289781\n",
      "Iteration 1746, loss = 3.01269416\n",
      "Iteration 1747, loss = 3.01249064\n",
      "Iteration 1748, loss = 3.01228724\n",
      "Iteration 1749, loss = 3.01208397\n",
      "Iteration 1750, loss = 3.01188081\n",
      "Iteration 1751, loss = 3.01167778\n",
      "Iteration 1752, loss = 3.01147487\n",
      "Iteration 1753, loss = 3.01127209\n",
      "Iteration 1754, loss = 3.01106942\n",
      "Iteration 1755, loss = 3.01086688\n",
      "Iteration 1756, loss = 3.01066446\n",
      "Iteration 1757, loss = 3.01046217\n",
      "Iteration 1758, loss = 3.01025999\n",
      "Iteration 1759, loss = 3.01005794\n",
      "Iteration 1760, loss = 3.00985601\n",
      "Iteration 1761, loss = 3.00965420\n",
      "Iteration 1762, loss = 3.00945252\n",
      "Iteration 1763, loss = 3.00925096\n",
      "Iteration 1764, loss = 3.00904952\n",
      "Iteration 1765, loss = 3.00884820\n",
      "Iteration 1766, loss = 3.00864700\n",
      "Iteration 1767, loss = 3.00844592\n",
      "Iteration 1768, loss = 3.00824497\n",
      "Iteration 1769, loss = 3.00804414\n",
      "Iteration 1770, loss = 3.00784343\n",
      "Iteration 1771, loss = 3.00764284\n",
      "Iteration 1772, loss = 3.00744238\n",
      "Iteration 1773, loss = 3.00724203\n",
      "Iteration 1774, loss = 3.00704181\n",
      "Iteration 1775, loss = 3.00684171\n",
      "Iteration 1776, loss = 3.00664173\n",
      "Iteration 1777, loss = 3.00644187\n",
      "Iteration 1778, loss = 3.00624214\n",
      "Iteration 1779, loss = 3.00604252\n",
      "Iteration 1780, loss = 3.00584303\n",
      "Iteration 1781, loss = 3.00564366\n",
      "Iteration 1782, loss = 3.00544441\n",
      "Iteration 1783, loss = 3.00524529\n",
      "Iteration 1784, loss = 3.00504628\n",
      "Iteration 1785, loss = 3.00484740\n",
      "Iteration 1786, loss = 3.00464864\n",
      "Iteration 1787, loss = 3.00444999\n",
      "Iteration 1788, loss = 3.00425148\n",
      "Iteration 1789, loss = 3.00405308\n",
      "Iteration 1790, loss = 3.00385480\n",
      "Iteration 1791, loss = 3.00365665\n",
      "Iteration 1792, loss = 3.00345862\n",
      "Iteration 1793, loss = 3.00326071\n",
      "Iteration 1794, loss = 3.00306292\n",
      "Iteration 1795, loss = 3.00286525\n",
      "Iteration 1796, loss = 3.00266770\n",
      "Iteration 1797, loss = 3.00247028\n",
      "Iteration 1798, loss = 3.00227298\n",
      "Iteration 1799, loss = 3.00207579\n",
      "Iteration 1800, loss = 3.00187874\n",
      "Iteration 1801, loss = 3.00168180\n",
      "Iteration 1802, loss = 3.00148498\n",
      "Iteration 1803, loss = 3.00128829\n",
      "Iteration 1804, loss = 3.00109171\n",
      "Iteration 1805, loss = 3.00089526\n",
      "Iteration 1806, loss = 3.00069893\n",
      "Iteration 1807, loss = 3.00050273\n",
      "Iteration 1808, loss = 3.00030664\n",
      "Iteration 1809, loss = 3.00011068\n",
      "Iteration 1810, loss = 2.99991483\n",
      "Iteration 1811, loss = 2.99971911\n",
      "Iteration 1812, loss = 2.99952351\n",
      "Iteration 1813, loss = 2.99932804\n",
      "Iteration 1814, loss = 2.99913268\n",
      "Iteration 1815, loss = 2.99893745\n",
      "Iteration 1816, loss = 2.99874233\n",
      "Iteration 1817, loss = 2.99854734\n",
      "Iteration 1818, loss = 2.99835248\n",
      "Iteration 1819, loss = 2.99815773\n",
      "Iteration 1820, loss = 2.99796310\n",
      "Iteration 1821, loss = 2.99776860\n",
      "Iteration 1822, loss = 2.99757422\n",
      "Iteration 1823, loss = 2.99737996\n",
      "Iteration 1824, loss = 2.99718582\n",
      "Iteration 1825, loss = 2.99699181\n",
      "Iteration 1826, loss = 2.99679792\n",
      "Iteration 1827, loss = 2.99660414\n",
      "Iteration 1828, loss = 2.99641049\n",
      "Iteration 1829, loss = 2.99621697\n",
      "Iteration 1830, loss = 2.99602356\n",
      "Iteration 1831, loss = 2.99583028\n",
      "Iteration 1832, loss = 2.99563712\n",
      "Iteration 1833, loss = 2.99544408\n",
      "Iteration 1834, loss = 2.99525116\n",
      "Iteration 1835, loss = 2.99505836\n",
      "Iteration 1836, loss = 2.99486569\n",
      "Iteration 1837, loss = 2.99467314\n",
      "Iteration 1838, loss = 2.99448071\n",
      "Iteration 1839, loss = 2.99428840\n",
      "Iteration 1840, loss = 2.99409621\n",
      "Iteration 1841, loss = 2.99390415\n",
      "Iteration 1842, loss = 2.99371221\n",
      "Iteration 1843, loss = 2.99352039\n",
      "Iteration 1844, loss = 2.99332869\n",
      "Iteration 1845, loss = 2.99313711\n",
      "Iteration 1846, loss = 2.99294566\n",
      "Iteration 1847, loss = 2.99275433\n",
      "Iteration 1848, loss = 2.99256312\n",
      "Iteration 1849, loss = 2.99237203\n",
      "Iteration 1850, loss = 2.99218106\n",
      "Iteration 1851, loss = 2.99199022\n",
      "Iteration 1852, loss = 2.99179949\n",
      "Iteration 1853, loss = 2.99160889\n",
      "Iteration 1854, loss = 2.99141841\n",
      "Iteration 1855, loss = 2.99122806\n",
      "Iteration 1856, loss = 2.99103782\n",
      "Iteration 1857, loss = 2.99084771\n",
      "Iteration 1858, loss = 2.99065772\n",
      "Iteration 1859, loss = 2.99046785\n",
      "Iteration 1860, loss = 2.99027810\n",
      "Iteration 1861, loss = 2.99008848\n",
      "Iteration 1862, loss = 2.98989897\n",
      "Iteration 1863, loss = 2.98970959\n",
      "Iteration 1864, loss = 2.98952033\n",
      "Iteration 1865, loss = 2.98933119\n",
      "Iteration 1866, loss = 2.98914218\n",
      "Iteration 1867, loss = 2.98895328\n",
      "Iteration 1868, loss = 2.98876451\n",
      "Iteration 1869, loss = 2.98857586\n",
      "Iteration 1870, loss = 2.98838733\n",
      "Iteration 1871, loss = 2.98819892\n",
      "Iteration 1872, loss = 2.98801063\n",
      "Iteration 1873, loss = 2.98782246\n",
      "Iteration 1874, loss = 2.98763442\n",
      "Iteration 1875, loss = 2.98744650\n",
      "Iteration 1876, loss = 2.98725870\n",
      "Iteration 1877, loss = 2.98707102\n",
      "Iteration 1878, loss = 2.98688346\n",
      "Iteration 1879, loss = 2.98669602\n",
      "Iteration 1880, loss = 2.98650870\n",
      "Iteration 1881, loss = 2.98632151\n",
      "Iteration 1882, loss = 2.98613443\n",
      "Iteration 1883, loss = 2.98594748\n",
      "Iteration 1884, loss = 2.98576065\n",
      "Iteration 1885, loss = 2.98557394\n",
      "Iteration 1886, loss = 2.98538735\n",
      "Iteration 1887, loss = 2.98520088\n",
      "Iteration 1888, loss = 2.98501453\n",
      "Iteration 1889, loss = 2.98482830\n",
      "Iteration 1890, loss = 2.98464219\n",
      "Iteration 1891, loss = 2.98445620\n",
      "Iteration 1892, loss = 2.98427034\n",
      "Iteration 1893, loss = 2.98408459\n",
      "Iteration 1894, loss = 2.98389897\n",
      "Iteration 1895, loss = 2.98371346\n",
      "Iteration 1896, loss = 2.98352808\n",
      "Iteration 1897, loss = 2.98334281\n",
      "Iteration 1898, loss = 2.98315767\n",
      "Iteration 1899, loss = 2.98297264\n",
      "Iteration 1900, loss = 2.98278774\n",
      "Iteration 1901, loss = 2.98260295\n",
      "Iteration 1902, loss = 2.98241829\n",
      "Iteration 1903, loss = 2.98223374\n",
      "Iteration 1904, loss = 2.98204931\n",
      "Iteration 1905, loss = 2.98186501\n",
      "Iteration 1906, loss = 2.98168082\n",
      "Iteration 1907, loss = 2.98149675\n",
      "Iteration 1908, loss = 2.98131281\n",
      "Iteration 1909, loss = 2.98112898\n",
      "Iteration 1910, loss = 2.98094527\n",
      "Iteration 1911, loss = 2.98076167\n",
      "Iteration 1912, loss = 2.98057820\n",
      "Iteration 1913, loss = 2.98039485\n",
      "Iteration 1914, loss = 2.98021161\n",
      "Iteration 1915, loss = 2.98002850\n",
      "Iteration 1916, loss = 2.97984550\n",
      "Iteration 1917, loss = 2.97966262\n",
      "Iteration 1918, loss = 2.97947986\n",
      "Iteration 1919, loss = 2.97929722\n",
      "Iteration 1920, loss = 2.97911469\n",
      "Iteration 1921, loss = 2.97893228\n",
      "Iteration 1922, loss = 2.97875000\n",
      "Iteration 1923, loss = 2.97856782\n",
      "Iteration 1924, loss = 2.97838577\n",
      "Iteration 1925, loss = 2.97820383\n",
      "Iteration 1926, loss = 2.97802201\n",
      "Iteration 1927, loss = 2.97784031\n",
      "Iteration 1928, loss = 2.97765873\n",
      "Iteration 1929, loss = 2.97747726\n",
      "Iteration 1930, loss = 2.97729591\n",
      "Iteration 1931, loss = 2.97711467\n",
      "Iteration 1932, loss = 2.97693356\n",
      "Iteration 1933, loss = 2.97675256\n",
      "Iteration 1934, loss = 2.97657167\n",
      "Iteration 1935, loss = 2.97639090\n",
      "Iteration 1936, loss = 2.97621025\n",
      "Iteration 1937, loss = 2.97602971\n",
      "Iteration 1938, loss = 2.97584929\n",
      "Iteration 1939, loss = 2.97566899\n",
      "Iteration 1940, loss = 2.97548880\n",
      "Iteration 1941, loss = 2.97530872\n",
      "Iteration 1942, loss = 2.97512876\n",
      "Iteration 1943, loss = 2.97494892\n",
      "Iteration 1944, loss = 2.97476919\n",
      "Iteration 1945, loss = 2.97458958\n",
      "Iteration 1946, loss = 2.97441008\n",
      "Iteration 1947, loss = 2.97423069\n",
      "Iteration 1948, loss = 2.97405142\n",
      "Iteration 1949, loss = 2.97387227\n",
      "Iteration 1950, loss = 2.97369322\n",
      "Iteration 1951, loss = 2.97351430\n",
      "Iteration 1952, loss = 2.97333548\n",
      "Iteration 1953, loss = 2.97315678\n",
      "Iteration 1954, loss = 2.97297819\n",
      "Iteration 1955, loss = 2.97279972\n",
      "Iteration 1956, loss = 2.97262136\n",
      "Iteration 1957, loss = 2.97244311\n",
      "Iteration 1958, loss = 2.97226497\n",
      "Iteration 1959, loss = 2.97208695\n",
      "Iteration 1960, loss = 2.97190904\n",
      "Iteration 1961, loss = 2.97173124\n",
      "Iteration 1962, loss = 2.97155355\n",
      "Iteration 1963, loss = 2.97137598\n",
      "Iteration 1964, loss = 2.97119852\n",
      "Iteration 1965, loss = 2.97102117\n",
      "Iteration 1966, loss = 2.97084393\n",
      "Iteration 1967, loss = 2.97066680\n",
      "Iteration 1968, loss = 2.97048978\n",
      "Iteration 1969, loss = 2.97031287\n",
      "Iteration 1970, loss = 2.97013608\n",
      "Iteration 1971, loss = 2.96995939\n",
      "Iteration 1972, loss = 2.96978282\n",
      "Iteration 1973, loss = 2.96960635\n",
      "Iteration 1974, loss = 2.96943000\n",
      "Iteration 1975, loss = 2.96925376\n",
      "Iteration 1976, loss = 2.96907762\n",
      "Iteration 1977, loss = 2.96890160\n",
      "Iteration 1978, loss = 2.96872568\n",
      "Iteration 1979, loss = 2.96854987\n",
      "Iteration 1980, loss = 2.96837417\n",
      "Iteration 1981, loss = 2.96819858\n",
      "Iteration 1982, loss = 2.96802310\n",
      "Iteration 1983, loss = 2.96784773\n",
      "Iteration 1984, loss = 2.96767247\n",
      "Iteration 1985, loss = 2.96749731\n",
      "Iteration 1986, loss = 2.96732226\n",
      "Iteration 1987, loss = 2.96714732\n",
      "Iteration 1988, loss = 2.96697249\n",
      "Iteration 1989, loss = 2.96679776\n",
      "Iteration 1990, loss = 2.96662314\n",
      "Iteration 1991, loss = 2.96644863\n",
      "Iteration 1992, loss = 2.96627422\n",
      "Iteration 1993, loss = 2.96609992\n",
      "Iteration 1994, loss = 2.96592573\n",
      "Iteration 1995, loss = 2.96575164\n",
      "Iteration 1996, loss = 2.96557766\n",
      "Iteration 1997, loss = 2.96540378\n",
      "Iteration 1998, loss = 2.96523001\n",
      "Iteration 1999, loss = 2.96505635\n",
      "Iteration 2000, loss = 2.96488279\n",
      "Iteration 1, loss = 4.93691655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 4.91550823\n",
      "Iteration 3, loss = 4.88578824\n",
      "Iteration 4, loss = 4.84939718\n",
      "Iteration 5, loss = 4.80793722\n",
      "Iteration 6, loss = 4.76292727\n",
      "Iteration 7, loss = 4.71576705\n",
      "Iteration 8, loss = 4.66770928\n",
      "Iteration 9, loss = 4.61984008\n",
      "Iteration 10, loss = 4.57306754\n",
      "Iteration 11, loss = 4.52811847\n",
      "Iteration 12, loss = 4.48554279\n",
      "Iteration 13, loss = 4.44572466\n",
      "Iteration 14, loss = 4.40889894\n",
      "Iteration 15, loss = 4.37517145\n",
      "Iteration 16, loss = 4.34454112\n",
      "Iteration 17, loss = 4.31692258\n",
      "Iteration 18, loss = 4.29216770\n",
      "Iteration 19, loss = 4.27008511\n",
      "Iteration 20, loss = 4.25045703\n",
      "Iteration 21, loss = 4.23305317\n",
      "Iteration 22, loss = 4.21764162\n",
      "Iteration 23, loss = 4.20399710\n",
      "Iteration 24, loss = 4.19190663\n",
      "Iteration 25, loss = 4.18117333\n",
      "Iteration 26, loss = 4.17161844\n",
      "Iteration 27, loss = 4.16308218\n",
      "Iteration 28, loss = 4.15542359\n",
      "Iteration 29, loss = 4.14851975\n",
      "Iteration 30, loss = 4.14226452\n",
      "Iteration 31, loss = 4.13656706\n",
      "Iteration 32, loss = 4.13135019\n",
      "Iteration 33, loss = 4.12654870\n",
      "Iteration 34, loss = 4.12210779\n",
      "Iteration 35, loss = 4.11798149\n",
      "Iteration 36, loss = 4.11413132\n",
      "Iteration 37, loss = 4.11052498\n",
      "Iteration 38, loss = 4.10713532\n",
      "Iteration 39, loss = 4.10393936\n",
      "Iteration 40, loss = 4.10091748\n",
      "Iteration 41, loss = 4.09805280\n",
      "Iteration 42, loss = 4.09533058\n",
      "Iteration 43, loss = 4.09273783\n",
      "Iteration 44, loss = 4.09026295\n",
      "Iteration 45, loss = 4.08789547\n",
      "Iteration 46, loss = 4.08562586\n",
      "Iteration 47, loss = 4.08344538\n",
      "Iteration 48, loss = 4.08134595\n",
      "Iteration 49, loss = 4.07932013\n",
      "Iteration 50, loss = 4.07736102\n",
      "Iteration 51, loss = 4.07546223\n",
      "Iteration 52, loss = 4.07361790\n",
      "Iteration 53, loss = 4.07182260\n",
      "Iteration 54, loss = 4.07007138\n",
      "Iteration 55, loss = 4.06835973\n",
      "Iteration 56, loss = 4.06668352\n",
      "Iteration 57, loss = 4.06503906\n",
      "Iteration 58, loss = 4.06342300\n",
      "Iteration 59, loss = 4.06183236\n",
      "Iteration 60, loss = 4.06026446\n",
      "Iteration 61, loss = 4.05871694\n",
      "Iteration 62, loss = 4.05718769\n",
      "Iteration 63, loss = 4.05567485\n",
      "Iteration 64, loss = 4.05417678\n",
      "Iteration 65, loss = 4.05269202\n",
      "Iteration 66, loss = 4.05121931\n",
      "Iteration 67, loss = 4.04975751\n",
      "Iteration 68, loss = 4.04830563\n",
      "Iteration 69, loss = 4.04686279\n",
      "Iteration 70, loss = 4.04542821\n",
      "Iteration 71, loss = 4.04400122\n",
      "Iteration 72, loss = 4.04258119\n",
      "Iteration 73, loss = 4.04116759\n",
      "Iteration 74, loss = 4.03975993\n",
      "Iteration 75, loss = 4.03835778\n",
      "Iteration 76, loss = 4.03696076\n",
      "Iteration 77, loss = 4.03556854\n",
      "Iteration 78, loss = 4.03418079\n",
      "Iteration 79, loss = 4.03279725\n",
      "Iteration 80, loss = 4.03141768\n",
      "Iteration 81, loss = 4.03004184\n",
      "Iteration 82, loss = 4.02866956\n",
      "Iteration 83, loss = 4.02730063\n",
      "Iteration 84, loss = 4.02593491\n",
      "Iteration 85, loss = 4.02457225\n",
      "Iteration 86, loss = 4.02321251\n",
      "Iteration 87, loss = 4.02185555\n",
      "Iteration 88, loss = 4.02050127\n",
      "Iteration 89, loss = 4.01914956\n",
      "Iteration 90, loss = 4.01780030\n",
      "Iteration 91, loss = 4.01645340\n",
      "Iteration 92, loss = 4.01510875\n",
      "Iteration 93, loss = 4.01376627\n",
      "Iteration 94, loss = 4.01242585\n",
      "Iteration 95, loss = 4.01108742\n",
      "Iteration 96, loss = 4.00975087\n",
      "Iteration 97, loss = 4.00841611\n",
      "Iteration 98, loss = 4.00708307\n",
      "Iteration 99, loss = 4.00575164\n",
      "Iteration 100, loss = 4.00442175\n",
      "Iteration 101, loss = 4.00309331\n",
      "Iteration 102, loss = 4.00176624\n",
      "Iteration 103, loss = 4.00044045\n",
      "Iteration 104, loss = 3.99911588\n",
      "Iteration 105, loss = 3.99779244\n",
      "Iteration 106, loss = 3.99647005\n",
      "Iteration 107, loss = 3.99514866\n",
      "Iteration 108, loss = 3.99382819\n",
      "Iteration 109, loss = 3.99250859\n",
      "Iteration 110, loss = 3.99118978\n",
      "Iteration 111, loss = 3.98987171\n",
      "Iteration 112, loss = 3.98855434\n",
      "Iteration 113, loss = 3.98723762\n",
      "Iteration 114, loss = 3.98592149\n",
      "Iteration 115, loss = 3.98460592\n",
      "Iteration 116, loss = 3.98329087\n",
      "Iteration 117, loss = 3.98197632\n",
      "Iteration 118, loss = 3.98066223\n",
      "Iteration 119, loss = 3.97934857\n",
      "Iteration 120, loss = 3.97803534\n",
      "Iteration 121, loss = 3.97672250\n",
      "Iteration 122, loss = 3.97541005\n",
      "Iteration 123, loss = 3.97409798\n",
      "Iteration 124, loss = 3.97278628\n",
      "Iteration 125, loss = 3.97147496\n",
      "Iteration 126, loss = 3.97016400\n",
      "Iteration 127, loss = 3.96885342\n",
      "Iteration 128, loss = 3.96754323\n",
      "Iteration 129, loss = 3.96623343\n",
      "Iteration 130, loss = 3.96492404\n",
      "Iteration 131, loss = 3.96361508\n",
      "Iteration 132, loss = 3.96230657\n",
      "Iteration 133, loss = 3.96099854\n",
      "Iteration 134, loss = 3.95969100\n",
      "Iteration 135, loss = 3.95838398\n",
      "Iteration 136, loss = 3.95707753\n",
      "Iteration 137, loss = 3.95577168\n",
      "Iteration 138, loss = 3.95446646\n",
      "Iteration 139, loss = 3.95316191\n",
      "Iteration 140, loss = 3.95185808\n",
      "Iteration 141, loss = 3.95055501\n",
      "Iteration 142, loss = 3.94925274\n",
      "Iteration 143, loss = 3.94795134\n",
      "Iteration 144, loss = 3.94665085\n",
      "Iteration 145, loss = 3.94535133\n",
      "Iteration 146, loss = 3.94405282\n",
      "Iteration 147, loss = 3.94275540\n",
      "Iteration 148, loss = 3.94145912\n",
      "Iteration 149, loss = 3.94016405\n",
      "Iteration 150, loss = 3.93887025\n",
      "Iteration 151, loss = 3.93757778\n",
      "Iteration 152, loss = 3.93628672\n",
      "Iteration 153, loss = 3.93499713\n",
      "Iteration 154, loss = 3.93370909\n",
      "Iteration 155, loss = 3.93242267\n",
      "Iteration 156, loss = 3.93113794\n",
      "Iteration 157, loss = 3.92985498\n",
      "Iteration 158, loss = 3.92857387\n",
      "Iteration 159, loss = 3.92729468\n",
      "Iteration 160, loss = 3.92601749\n",
      "Iteration 161, loss = 3.92474239\n",
      "Iteration 162, loss = 3.92346945\n",
      "Iteration 163, loss = 3.92219877\n",
      "Iteration 164, loss = 3.92093041\n",
      "Iteration 165, loss = 3.91966447\n",
      "Iteration 166, loss = 3.91840103\n",
      "Iteration 167, loss = 3.91714017\n",
      "Iteration 168, loss = 3.91588198\n",
      "Iteration 169, loss = 3.91462655\n",
      "Iteration 170, loss = 3.91337396\n",
      "Iteration 171, loss = 3.91212431\n",
      "Iteration 172, loss = 3.91087766\n",
      "Iteration 173, loss = 3.90963412\n",
      "Iteration 174, loss = 3.90839377\n",
      "Iteration 175, loss = 3.90715669\n",
      "Iteration 176, loss = 3.90592298\n",
      "Iteration 177, loss = 3.90469272\n",
      "Iteration 178, loss = 3.90346599\n",
      "Iteration 179, loss = 3.90224288\n",
      "Iteration 180, loss = 3.90102347\n",
      "Iteration 181, loss = 3.89980786\n",
      "Iteration 182, loss = 3.89859612\n",
      "Iteration 183, loss = 3.89738834\n",
      "Iteration 184, loss = 3.89618459\n",
      "Iteration 185, loss = 3.89498497\n",
      "Iteration 186, loss = 3.89378954\n",
      "Iteration 187, loss = 3.89259840\n",
      "Iteration 188, loss = 3.89141162\n",
      "Iteration 189, loss = 3.89022927\n",
      "Iteration 190, loss = 3.88905143\n",
      "Iteration 191, loss = 3.88787819\n",
      "Iteration 192, loss = 3.88670960\n",
      "Iteration 193, loss = 3.88554575\n",
      "Iteration 194, loss = 3.88438669\n",
      "Iteration 195, loss = 3.88323252\n",
      "Iteration 196, loss = 3.88208328\n",
      "Iteration 197, loss = 3.88093905\n",
      "Iteration 198, loss = 3.87979988\n",
      "Iteration 199, loss = 3.87866586\n",
      "Iteration 200, loss = 3.87753702\n",
      "Iteration 201, loss = 3.87641344\n",
      "Iteration 202, loss = 3.87529517\n",
      "Iteration 203, loss = 3.87418226\n",
      "Iteration 204, loss = 3.87307477\n",
      "Iteration 205, loss = 3.87197276\n",
      "Iteration 206, loss = 3.87087626\n",
      "Iteration 207, loss = 3.86978533\n",
      "Iteration 208, loss = 3.86870001\n",
      "Iteration 209, loss = 3.86762035\n",
      "Iteration 210, loss = 3.86654639\n",
      "Iteration 211, loss = 3.86547817\n",
      "Iteration 212, loss = 3.86441572\n",
      "Iteration 213, loss = 3.86335908\n",
      "Iteration 214, loss = 3.86230828\n",
      "Iteration 215, loss = 3.86126335\n",
      "Iteration 216, loss = 3.86022433\n",
      "Iteration 217, loss = 3.85919124\n",
      "Iteration 218, loss = 3.85816409\n",
      "Iteration 219, loss = 3.85714293\n",
      "Iteration 220, loss = 3.85612776\n",
      "Iteration 221, loss = 3.85511860\n",
      "Iteration 222, loss = 3.85411548\n",
      "Iteration 223, loss = 3.85311840\n",
      "Iteration 224, loss = 3.85212737\n",
      "Iteration 225, loss = 3.85114241\n",
      "Iteration 226, loss = 3.85016352\n",
      "Iteration 227, loss = 3.84919071\n",
      "Iteration 228, loss = 3.84822398\n",
      "Iteration 229, loss = 3.84726334\n",
      "Iteration 230, loss = 3.84630878\n",
      "Iteration 231, loss = 3.84536030\n",
      "Iteration 232, loss = 3.84441790\n",
      "Iteration 233, loss = 3.84348156\n",
      "Iteration 234, loss = 3.84255129\n",
      "Iteration 235, loss = 3.84162707\n",
      "Iteration 236, loss = 3.84070889\n",
      "Iteration 237, loss = 3.83979674\n",
      "Iteration 238, loss = 3.83889061\n",
      "Iteration 239, loss = 3.83799046\n",
      "Iteration 240, loss = 3.83709630\n",
      "Iteration 241, loss = 3.83620808\n",
      "Iteration 242, loss = 3.83532581\n",
      "Iteration 243, loss = 3.83444944\n",
      "Iteration 244, loss = 3.83357897\n",
      "Iteration 245, loss = 3.83271435\n",
      "Iteration 246, loss = 3.83185556\n",
      "Iteration 247, loss = 3.83100258\n",
      "Iteration 248, loss = 3.83015537\n",
      "Iteration 249, loss = 3.82931390\n",
      "Iteration 250, loss = 3.82847814\n",
      "Iteration 251, loss = 3.82764806\n",
      "Iteration 252, loss = 3.82682361\n",
      "Iteration 253, loss = 3.82600476\n",
      "Iteration 254, loss = 3.82519148\n",
      "Iteration 255, loss = 3.82438373\n",
      "Iteration 256, loss = 3.82358146\n",
      "Iteration 257, loss = 3.82278463\n",
      "Iteration 258, loss = 3.82199321\n",
      "Iteration 259, loss = 3.82120715\n",
      "Iteration 260, loss = 3.82042641\n",
      "Iteration 261, loss = 3.81965094\n",
      "Iteration 262, loss = 3.81888070\n",
      "Iteration 263, loss = 3.81811565\n",
      "Iteration 264, loss = 3.81735573\n",
      "Iteration 265, loss = 3.81660091\n",
      "Iteration 266, loss = 3.81585113\n",
      "Iteration 267, loss = 3.81510634\n",
      "Iteration 268, loss = 3.81436650\n",
      "Iteration 269, loss = 3.81363156\n",
      "Iteration 270, loss = 3.81290147\n",
      "Iteration 271, loss = 3.81217618\n",
      "Iteration 272, loss = 3.81145564\n",
      "Iteration 273, loss = 3.81073980\n",
      "Iteration 274, loss = 3.81002861\n",
      "Iteration 275, loss = 3.80932201\n",
      "Iteration 276, loss = 3.80861996\n",
      "Iteration 277, loss = 3.80792241\n",
      "Iteration 278, loss = 3.80722931\n",
      "Iteration 279, loss = 3.80654059\n",
      "Iteration 280, loss = 3.80585622\n",
      "Iteration 281, loss = 3.80517613\n",
      "Iteration 282, loss = 3.80450029\n",
      "Iteration 283, loss = 3.80382863\n",
      "Iteration 284, loss = 3.80316110\n",
      "Iteration 285, loss = 3.80249766\n",
      "Iteration 286, loss = 3.80183824\n",
      "Iteration 287, loss = 3.80118281\n",
      "Iteration 288, loss = 3.80053131\n",
      "Iteration 289, loss = 3.79988368\n",
      "Iteration 290, loss = 3.79923988\n",
      "Iteration 291, loss = 3.79859986\n",
      "Iteration 292, loss = 3.79796356\n",
      "Iteration 293, loss = 3.79733093\n",
      "Iteration 294, loss = 3.79670193\n",
      "Iteration 295, loss = 3.79607651\n",
      "Iteration 296, loss = 3.79545461\n",
      "Iteration 297, loss = 3.79483618\n",
      "Iteration 298, loss = 3.79422118\n",
      "Iteration 299, loss = 3.79360956\n",
      "Iteration 300, loss = 3.79300127\n",
      "Iteration 301, loss = 3.79239626\n",
      "Iteration 302, loss = 3.79179449\n",
      "Iteration 303, loss = 3.79119590\n",
      "Iteration 304, loss = 3.79060045\n",
      "Iteration 305, loss = 3.79000810\n",
      "Iteration 306, loss = 3.78941880\n",
      "Iteration 307, loss = 3.78883250\n",
      "Iteration 308, loss = 3.78824915\n",
      "Iteration 309, loss = 3.78766872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310, loss = 3.78709116\n",
      "Iteration 311, loss = 3.78651642\n",
      "Iteration 312, loss = 3.78594446\n",
      "Iteration 313, loss = 3.78537525\n",
      "Iteration 314, loss = 3.78480873\n",
      "Iteration 315, loss = 3.78424486\n",
      "Iteration 316, loss = 3.78368361\n",
      "Iteration 317, loss = 3.78312493\n",
      "Iteration 318, loss = 3.78256878\n",
      "Iteration 319, loss = 3.78201513\n",
      "Iteration 320, loss = 3.78146393\n",
      "Iteration 321, loss = 3.78091514\n",
      "Iteration 322, loss = 3.78036873\n",
      "Iteration 323, loss = 3.77982465\n",
      "Iteration 324, loss = 3.77928288\n",
      "Iteration 325, loss = 3.77874337\n",
      "Iteration 326, loss = 3.77820609\n",
      "Iteration 327, loss = 3.77767100\n",
      "Iteration 328, loss = 3.77713806\n",
      "Iteration 329, loss = 3.77660725\n",
      "Iteration 330, loss = 3.77607852\n",
      "Iteration 331, loss = 3.77555185\n",
      "Iteration 332, loss = 3.77502719\n",
      "Iteration 333, loss = 3.77450452\n",
      "Iteration 334, loss = 3.77398381\n",
      "Iteration 335, loss = 3.77346502\n",
      "Iteration 336, loss = 3.77294812\n",
      "Iteration 337, loss = 3.77243308\n",
      "Iteration 338, loss = 3.77191988\n",
      "Iteration 339, loss = 3.77140847\n",
      "Iteration 340, loss = 3.77089883\n",
      "Iteration 341, loss = 3.77039093\n",
      "Iteration 342, loss = 3.76988475\n",
      "Iteration 343, loss = 3.76938026\n",
      "Iteration 344, loss = 3.76887742\n",
      "Iteration 345, loss = 3.76837621\n",
      "Iteration 346, loss = 3.76787660\n",
      "Iteration 347, loss = 3.76737858\n",
      "Iteration 348, loss = 3.76688210\n",
      "Iteration 349, loss = 3.76638716\n",
      "Iteration 350, loss = 3.76589371\n",
      "Iteration 351, loss = 3.76540175\n",
      "Iteration 352, loss = 3.76491123\n",
      "Iteration 353, loss = 3.76442215\n",
      "Iteration 354, loss = 3.76393447\n",
      "Iteration 355, loss = 3.76344818\n",
      "Iteration 356, loss = 3.76296325\n",
      "Iteration 357, loss = 3.76247966\n",
      "Iteration 358, loss = 3.76199739\n",
      "Iteration 359, loss = 3.76151642\n",
      "Iteration 360, loss = 3.76103673\n",
      "Iteration 361, loss = 3.76055829\n",
      "Iteration 362, loss = 3.76008108\n",
      "Iteration 363, loss = 3.75960510\n",
      "Iteration 364, loss = 3.75913031\n",
      "Iteration 365, loss = 3.75865671\n",
      "Iteration 366, loss = 3.75818426\n",
      "Iteration 367, loss = 3.75771295\n",
      "Iteration 368, loss = 3.75724278\n",
      "Iteration 369, loss = 3.75677370\n",
      "Iteration 370, loss = 3.75630572\n",
      "Iteration 371, loss = 3.75583881\n",
      "Iteration 372, loss = 3.75537296\n",
      "Iteration 373, loss = 3.75490816\n",
      "Iteration 374, loss = 3.75444437\n",
      "Iteration 375, loss = 3.75398160\n",
      "Iteration 376, loss = 3.75351982\n",
      "Iteration 377, loss = 3.75305902\n",
      "Iteration 378, loss = 3.75259919\n",
      "Iteration 379, loss = 3.75214031\n",
      "Iteration 380, loss = 3.75168237\n",
      "Iteration 381, loss = 3.75122535\n",
      "Iteration 382, loss = 3.75076924\n",
      "Iteration 383, loss = 3.75031403\n",
      "Iteration 384, loss = 3.74985970\n",
      "Iteration 385, loss = 3.74940624\n",
      "Iteration 386, loss = 3.74895365\n",
      "Iteration 387, loss = 3.74850190\n",
      "Iteration 388, loss = 3.74805099\n",
      "Iteration 389, loss = 3.74760091\n",
      "Iteration 390, loss = 3.74715163\n",
      "Iteration 391, loss = 3.74670316\n",
      "Iteration 392, loss = 3.74625549\n",
      "Iteration 393, loss = 3.74580859\n",
      "Iteration 394, loss = 3.74536246\n",
      "Iteration 395, loss = 3.74491710\n",
      "Iteration 396, loss = 3.74447248\n",
      "Iteration 397, loss = 3.74402861\n",
      "Iteration 398, loss = 3.74358547\n",
      "Iteration 399, loss = 3.74314305\n",
      "Iteration 400, loss = 3.74270134\n",
      "Iteration 401, loss = 3.74226034\n",
      "Iteration 402, loss = 3.74182004\n",
      "Iteration 403, loss = 3.74138042\n",
      "Iteration 404, loss = 3.74094148\n",
      "Iteration 405, loss = 3.74050322\n",
      "Iteration 406, loss = 3.74006562\n",
      "Iteration 407, loss = 3.73962867\n",
      "Iteration 408, loss = 3.73919237\n",
      "Iteration 409, loss = 3.73875672\n",
      "Iteration 410, loss = 3.73832170\n",
      "Iteration 411, loss = 3.73788730\n",
      "Iteration 412, loss = 3.73745353\n",
      "Iteration 413, loss = 3.73702037\n",
      "Iteration 414, loss = 3.73658782\n",
      "Iteration 415, loss = 3.73615586\n",
      "Iteration 416, loss = 3.73572451\n",
      "Iteration 417, loss = 3.73529374\n",
      "Iteration 418, loss = 3.73486356\n",
      "Iteration 419, loss = 3.73443395\n",
      "Iteration 420, loss = 3.73400491\n",
      "Iteration 421, loss = 3.73357644\n",
      "Iteration 422, loss = 3.73314853\n",
      "Iteration 423, loss = 3.73272118\n",
      "Iteration 424, loss = 3.73229438\n",
      "Iteration 425, loss = 3.73186812\n",
      "Iteration 426, loss = 3.73144241\n",
      "Iteration 427, loss = 3.73101723\n",
      "Iteration 428, loss = 3.73059258\n",
      "Iteration 429, loss = 3.73016846\n",
      "Iteration 430, loss = 3.72974486\n",
      "Iteration 431, loss = 3.72932178\n",
      "Iteration 432, loss = 3.72889922\n",
      "Iteration 433, loss = 3.72847717\n",
      "Iteration 434, loss = 3.72805562\n",
      "Iteration 435, loss = 3.72763458\n",
      "Iteration 436, loss = 3.72721404\n",
      "Iteration 437, loss = 3.72679399\n",
      "Iteration 438, loss = 3.72637443\n",
      "Iteration 439, loss = 3.72595537\n",
      "Iteration 440, loss = 3.72553679\n",
      "Iteration 441, loss = 3.72511869\n",
      "Iteration 442, loss = 3.72470107\n",
      "Iteration 443, loss = 3.72428393\n",
      "Iteration 444, loss = 3.72386726\n",
      "Iteration 445, loss = 3.72345107\n",
      "Iteration 446, loss = 3.72303534\n",
      "Iteration 447, loss = 3.72262007\n",
      "Iteration 448, loss = 3.72220527\n",
      "Iteration 449, loss = 3.72179093\n",
      "Iteration 450, loss = 3.72137705\n",
      "Iteration 451, loss = 3.72096362\n",
      "Iteration 452, loss = 3.72055064\n",
      "Iteration 453, loss = 3.72013812\n",
      "Iteration 454, loss = 3.71972604\n",
      "Iteration 455, loss = 3.71931441\n",
      "Iteration 456, loss = 3.71890323\n",
      "Iteration 457, loss = 3.71849248\n",
      "Iteration 458, loss = 3.71808218\n",
      "Iteration 459, loss = 3.71767232\n",
      "Iteration 460, loss = 3.71726289\n",
      "Iteration 461, loss = 3.71685390\n",
      "Iteration 462, loss = 3.71644535\n",
      "Iteration 463, loss = 3.71603722\n",
      "Iteration 464, loss = 3.71562953\n",
      "Iteration 465, loss = 3.71522226\n",
      "Iteration 466, loss = 3.71481542\n",
      "Iteration 467, loss = 3.71440901\n",
      "Iteration 468, loss = 3.71400302\n",
      "Iteration 469, loss = 3.71359746\n",
      "Iteration 470, loss = 3.71319232\n",
      "Iteration 471, loss = 3.71278760\n",
      "Iteration 472, loss = 3.71238330\n",
      "Iteration 473, loss = 3.71197942\n",
      "Iteration 474, loss = 3.71157595\n",
      "Iteration 475, loss = 3.71117290\n",
      "Iteration 476, loss = 3.71077027\n",
      "Iteration 477, loss = 3.71036805\n",
      "Iteration 478, loss = 3.70996625\n",
      "Iteration 479, loss = 3.70956486\n",
      "Iteration 480, loss = 3.70916388\n",
      "Iteration 481, loss = 3.70876331\n",
      "Iteration 482, loss = 3.70836316\n",
      "Iteration 483, loss = 3.70796341\n",
      "Iteration 484, loss = 3.70756407\n",
      "Iteration 485, loss = 3.70716514\n",
      "Iteration 486, loss = 3.70676662\n",
      "Iteration 487, loss = 3.70636850\n",
      "Iteration 488, loss = 3.70597079\n",
      "Iteration 489, loss = 3.70557349\n",
      "Iteration 490, loss = 3.70517659\n",
      "Iteration 491, loss = 3.70478010\n",
      "Iteration 492, loss = 3.70438401\n",
      "Iteration 493, loss = 3.70398832\n",
      "Iteration 494, loss = 3.70359304\n",
      "Iteration 495, loss = 3.70319816\n",
      "Iteration 496, loss = 3.70280369\n",
      "Iteration 497, loss = 3.70240961\n",
      "Iteration 498, loss = 3.70201594\n",
      "Iteration 499, loss = 3.70162267\n",
      "Iteration 500, loss = 3.70122980\n",
      "Iteration 501, loss = 3.70083733\n",
      "Iteration 502, loss = 3.70044527\n",
      "Iteration 503, loss = 3.70005360\n",
      "Iteration 504, loss = 3.69966233\n",
      "Iteration 505, loss = 3.69927146\n",
      "Iteration 506, loss = 3.69888100\n",
      "Iteration 507, loss = 3.69849093\n",
      "Iteration 508, loss = 3.69810126\n",
      "Iteration 509, loss = 3.69771199\n",
      "Iteration 510, loss = 3.69732312\n",
      "Iteration 511, loss = 3.69693465\n",
      "Iteration 512, loss = 3.69654658\n",
      "Iteration 513, loss = 3.69615891\n",
      "Iteration 514, loss = 3.69577163\n",
      "Iteration 515, loss = 3.69538475\n",
      "Iteration 516, loss = 3.69499828\n",
      "Iteration 517, loss = 3.69461220\n",
      "Iteration 518, loss = 3.69422651\n",
      "Iteration 519, loss = 3.69384123\n",
      "Iteration 520, loss = 3.69345635\n",
      "Iteration 521, loss = 3.69307186\n",
      "Iteration 522, loss = 3.69268777\n",
      "Iteration 523, loss = 3.69230408\n",
      "Iteration 524, loss = 3.69192078\n",
      "Iteration 525, loss = 3.69153789\n",
      "Iteration 526, loss = 3.69115539\n",
      "Iteration 527, loss = 3.69077329\n",
      "Iteration 528, loss = 3.69039159\n",
      "Iteration 529, loss = 3.69001029\n",
      "Iteration 530, loss = 3.68962938\n",
      "Iteration 531, loss = 3.68924888\n",
      "Iteration 532, loss = 3.68886877\n",
      "Iteration 533, loss = 3.68848906\n",
      "Iteration 534, loss = 3.68810974\n",
      "Iteration 535, loss = 3.68773083\n",
      "Iteration 536, loss = 3.68735231\n",
      "Iteration 537, loss = 3.68697419\n",
      "Iteration 538, loss = 3.68659647\n",
      "Iteration 539, loss = 3.68621914\n",
      "Iteration 540, loss = 3.68584222\n",
      "Iteration 541, loss = 3.68546569\n",
      "Iteration 542, loss = 3.68508956\n",
      "Iteration 543, loss = 3.68471383\n",
      "Iteration 544, loss = 3.68433850\n",
      "Iteration 545, loss = 3.68396357\n",
      "Iteration 546, loss = 3.68358903\n",
      "Iteration 547, loss = 3.68321489\n",
      "Iteration 548, loss = 3.68284115\n",
      "Iteration 549, loss = 3.68246781\n",
      "Iteration 550, loss = 3.68209487\n",
      "Iteration 551, loss = 3.68172232\n",
      "Iteration 552, loss = 3.68135018\n",
      "Iteration 553, loss = 3.68097843\n",
      "Iteration 554, loss = 3.68060708\n",
      "Iteration 555, loss = 3.68023613\n",
      "Iteration 556, loss = 3.67986557\n",
      "Iteration 557, loss = 3.67949542\n",
      "Iteration 558, loss = 3.67912566\n",
      "Iteration 559, loss = 3.67875630\n",
      "Iteration 560, loss = 3.67838734\n",
      "Iteration 561, loss = 3.67801877\n",
      "Iteration 562, loss = 3.67765061\n",
      "Iteration 563, loss = 3.67728284\n",
      "Iteration 564, loss = 3.67691547\n",
      "Iteration 565, loss = 3.67654850\n",
      "Iteration 566, loss = 3.67618193\n",
      "Iteration 567, loss = 3.67581575\n",
      "Iteration 568, loss = 3.67544998\n",
      "Iteration 569, loss = 3.67508459\n",
      "Iteration 570, loss = 3.67471961\n",
      "Iteration 571, loss = 3.67435503\n",
      "Iteration 572, loss = 3.67399084\n",
      "Iteration 573, loss = 3.67362705\n",
      "Iteration 574, loss = 3.67326365\n",
      "Iteration 575, loss = 3.67290066\n",
      "Iteration 576, loss = 3.67253806\n",
      "Iteration 577, loss = 3.67217585\n",
      "Iteration 578, loss = 3.67181405\n",
      "Iteration 579, loss = 3.67145264\n",
      "Iteration 580, loss = 3.67109162\n",
      "Iteration 581, loss = 3.67073101\n",
      "Iteration 582, loss = 3.67037079\n",
      "Iteration 583, loss = 3.67001096\n",
      "Iteration 584, loss = 3.66965153\n",
      "Iteration 585, loss = 3.66929250\n",
      "Iteration 586, loss = 3.66893386\n",
      "Iteration 587, loss = 3.66857561\n",
      "Iteration 588, loss = 3.66821776\n",
      "Iteration 589, loss = 3.66786031\n",
      "Iteration 590, loss = 3.66750325\n",
      "Iteration 591, loss = 3.66714658\n",
      "Iteration 592, loss = 3.66679031\n",
      "Iteration 593, loss = 3.66643443\n",
      "Iteration 594, loss = 3.66607895\n",
      "Iteration 595, loss = 3.66572386\n",
      "Iteration 596, loss = 3.66536916\n",
      "Iteration 597, loss = 3.66501485\n",
      "Iteration 598, loss = 3.66466094\n",
      "Iteration 599, loss = 3.66430742\n",
      "Iteration 600, loss = 3.66395429\n",
      "Iteration 601, loss = 3.66360155\n",
      "Iteration 602, loss = 3.66324920\n",
      "Iteration 603, loss = 3.66289725\n",
      "Iteration 604, loss = 3.66254568\n",
      "Iteration 605, loss = 3.66219451\n",
      "Iteration 606, loss = 3.66184372\n",
      "Iteration 607, loss = 3.66149333\n",
      "Iteration 608, loss = 3.66114332\n",
      "Iteration 609, loss = 3.66079370\n",
      "Iteration 610, loss = 3.66044447\n",
      "Iteration 611, loss = 3.66009563\n",
      "Iteration 612, loss = 3.65974718\n",
      "Iteration 613, loss = 3.65939911\n",
      "Iteration 614, loss = 3.65905143\n",
      "Iteration 615, loss = 3.65870414\n",
      "Iteration 616, loss = 3.65835723\n",
      "Iteration 617, loss = 3.65801071\n",
      "Iteration 618, loss = 3.65766457\n",
      "Iteration 619, loss = 3.65731882\n",
      "Iteration 620, loss = 3.65697345\n",
      "Iteration 621, loss = 3.65662847\n",
      "Iteration 622, loss = 3.65628387\n",
      "Iteration 623, loss = 3.65593965\n",
      "Iteration 624, loss = 3.65559582\n",
      "Iteration 625, loss = 3.65525236\n",
      "Iteration 626, loss = 3.65490929\n",
      "Iteration 627, loss = 3.65456660\n",
      "Iteration 628, loss = 3.65422429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 629, loss = 3.65388236\n",
      "Iteration 630, loss = 3.65354081\n",
      "Iteration 631, loss = 3.65319964\n",
      "Iteration 632, loss = 3.65285885\n",
      "Iteration 633, loss = 3.65251844\n",
      "Iteration 634, loss = 3.65217840\n",
      "Iteration 635, loss = 3.65183874\n",
      "Iteration 636, loss = 3.65149945\n",
      "Iteration 637, loss = 3.65116055\n",
      "Iteration 638, loss = 3.65082201\n",
      "Iteration 639, loss = 3.65048385\n",
      "Iteration 640, loss = 3.65014607\n",
      "Iteration 641, loss = 3.64980866\n",
      "Iteration 642, loss = 3.64947162\n",
      "Iteration 643, loss = 3.64913496\n",
      "Iteration 644, loss = 3.64879866\n",
      "Iteration 645, loss = 3.64846274\n",
      "Iteration 646, loss = 3.64812719\n",
      "Iteration 647, loss = 3.64779201\n",
      "Iteration 648, loss = 3.64745719\n",
      "Iteration 649, loss = 3.64712275\n",
      "Iteration 650, loss = 3.64678867\n",
      "Iteration 651, loss = 3.64645497\n",
      "Iteration 652, loss = 3.64612162\n",
      "Iteration 653, loss = 3.64578865\n",
      "Iteration 654, loss = 3.64545604\n",
      "Iteration 655, loss = 3.64512379\n",
      "Iteration 656, loss = 3.64479191\n",
      "Iteration 657, loss = 3.64446040\n",
      "Iteration 658, loss = 3.64412924\n",
      "Iteration 659, loss = 3.64379845\n",
      "Iteration 660, loss = 3.64346802\n",
      "Iteration 661, loss = 3.64313796\n",
      "Iteration 662, loss = 3.64280825\n",
      "Iteration 663, loss = 3.64247890\n",
      "Iteration 664, loss = 3.64214991\n",
      "Iteration 665, loss = 3.64182128\n",
      "Iteration 666, loss = 3.64149301\n",
      "Iteration 667, loss = 3.64116509\n",
      "Iteration 668, loss = 3.64083753\n",
      "Iteration 669, loss = 3.64051033\n",
      "Iteration 670, loss = 3.64018348\n",
      "Iteration 671, loss = 3.63985698\n",
      "Iteration 672, loss = 3.63953084\n",
      "Iteration 673, loss = 3.63920505\n",
      "Iteration 674, loss = 3.63887962\n",
      "Iteration 675, loss = 3.63855453\n",
      "Iteration 676, loss = 3.63822980\n",
      "Iteration 677, loss = 3.63790542\n",
      "Iteration 678, loss = 3.63758138\n",
      "Iteration 679, loss = 3.63725770\n",
      "Iteration 680, loss = 3.63693436\n",
      "Iteration 681, loss = 3.63661137\n",
      "Iteration 682, loss = 3.63628872\n",
      "Iteration 683, loss = 3.63596642\n",
      "Iteration 684, loss = 3.63564447\n",
      "Iteration 685, loss = 3.63532286\n",
      "Iteration 686, loss = 3.63500160\n",
      "Iteration 687, loss = 3.63468067\n",
      "Iteration 688, loss = 3.63436009\n",
      "Iteration 689, loss = 3.63403986\n",
      "Iteration 690, loss = 3.63371996\n",
      "Iteration 691, loss = 3.63340040\n",
      "Iteration 692, loss = 3.63308118\n",
      "Iteration 693, loss = 3.63276230\n",
      "Iteration 694, loss = 3.63244376\n",
      "Iteration 695, loss = 3.63212555\n",
      "Iteration 696, loss = 3.63180768\n",
      "Iteration 697, loss = 3.63149015\n",
      "Iteration 698, loss = 3.63117295\n",
      "Iteration 699, loss = 3.63085609\n",
      "Iteration 700, loss = 3.63053956\n",
      "Iteration 701, loss = 3.63022336\n",
      "Iteration 702, loss = 3.62990749\n",
      "Iteration 703, loss = 3.62959196\n",
      "Iteration 704, loss = 3.62927675\n",
      "Iteration 705, loss = 3.62896188\n",
      "Iteration 706, loss = 3.62864733\n",
      "Iteration 707, loss = 3.62833312\n",
      "Iteration 708, loss = 3.62801923\n",
      "Iteration 709, loss = 3.62770566\n",
      "Iteration 710, loss = 3.62739243\n",
      "Iteration 711, loss = 3.62707952\n",
      "Iteration 712, loss = 3.62676693\n",
      "Iteration 713, loss = 3.62645467\n",
      "Iteration 714, loss = 3.62614273\n",
      "Iteration 715, loss = 3.62583111\n",
      "Iteration 716, loss = 3.62551982\n",
      "Iteration 717, loss = 3.62520884\n",
      "Iteration 718, loss = 3.62489819\n",
      "Iteration 719, loss = 3.62458786\n",
      "Iteration 720, loss = 3.62427784\n",
      "Iteration 721, loss = 3.62396814\n",
      "Iteration 722, loss = 3.62365876\n",
      "Iteration 723, loss = 3.62334970\n",
      "Iteration 724, loss = 3.62304096\n",
      "Iteration 725, loss = 3.62273253\n",
      "Iteration 726, loss = 3.62242441\n",
      "Iteration 727, loss = 3.62211661\n",
      "Iteration 728, loss = 3.62180912\n",
      "Iteration 729, loss = 3.62150194\n",
      "Iteration 730, loss = 3.62119508\n",
      "Iteration 731, loss = 3.62088852\n",
      "Iteration 732, loss = 3.62058228\n",
      "Iteration 733, loss = 3.62027634\n",
      "Iteration 734, loss = 3.61997072\n",
      "Iteration 735, loss = 3.61966540\n",
      "Iteration 736, loss = 3.61936039\n",
      "Iteration 737, loss = 3.61905569\n",
      "Iteration 738, loss = 3.61875130\n",
      "Iteration 739, loss = 3.61844721\n",
      "Iteration 740, loss = 3.61814342\n",
      "Iteration 741, loss = 3.61783994\n",
      "Iteration 742, loss = 3.61753676\n",
      "Iteration 743, loss = 3.61723389\n",
      "Iteration 744, loss = 3.61693132\n",
      "Iteration 745, loss = 3.61662905\n",
      "Iteration 746, loss = 3.61632708\n",
      "Iteration 747, loss = 3.61602541\n",
      "Iteration 748, loss = 3.61572404\n",
      "Iteration 749, loss = 3.61542296\n",
      "Iteration 750, loss = 3.61512219\n",
      "Iteration 751, loss = 3.61482171\n",
      "Iteration 752, loss = 3.61452153\n",
      "Iteration 753, loss = 3.61422165\n",
      "Iteration 754, loss = 3.61392206\n",
      "Iteration 755, loss = 3.61362277\n",
      "Iteration 756, loss = 3.61332377\n",
      "Iteration 757, loss = 3.61302507\n",
      "Iteration 758, loss = 3.61272666\n",
      "Iteration 759, loss = 3.61242854\n",
      "Iteration 760, loss = 3.61213071\n",
      "Iteration 761, loss = 3.61183317\n",
      "Iteration 762, loss = 3.61153593\n",
      "Iteration 763, loss = 3.61123897\n",
      "Iteration 764, loss = 3.61094230\n",
      "Iteration 765, loss = 3.61064592\n",
      "Iteration 766, loss = 3.61034983\n",
      "Iteration 767, loss = 3.61005403\n",
      "Iteration 768, loss = 3.60975851\n",
      "Iteration 769, loss = 3.60946328\n",
      "Iteration 770, loss = 3.60916833\n",
      "Iteration 771, loss = 3.60887367\n",
      "Iteration 772, loss = 3.60857930\n",
      "Iteration 773, loss = 3.60828520\n",
      "Iteration 774, loss = 3.60799139\n",
      "Iteration 775, loss = 3.60769787\n",
      "Iteration 776, loss = 3.60740462\n",
      "Iteration 777, loss = 3.60711166\n",
      "Iteration 778, loss = 3.60681897\n",
      "Iteration 779, loss = 3.60652657\n",
      "Iteration 780, loss = 3.60623445\n",
      "Iteration 781, loss = 3.60594260\n",
      "Iteration 782, loss = 3.60565104\n",
      "Iteration 783, loss = 3.60535975\n",
      "Iteration 784, loss = 3.60506874\n",
      "Iteration 785, loss = 3.60477800\n",
      "Iteration 786, loss = 3.60448754\n",
      "Iteration 787, loss = 3.60419736\n",
      "Iteration 788, loss = 3.60390745\n",
      "Iteration 789, loss = 3.60361782\n",
      "Iteration 790, loss = 3.60332846\n",
      "Iteration 791, loss = 3.60303937\n",
      "Iteration 792, loss = 3.60275056\n",
      "Iteration 793, loss = 3.60246201\n",
      "Iteration 794, loss = 3.60217374\n",
      "Iteration 795, loss = 3.60188575\n",
      "Iteration 796, loss = 3.60159802\n",
      "Iteration 797, loss = 3.60131056\n",
      "Iteration 798, loss = 3.60102337\n",
      "Iteration 799, loss = 3.60073645\n",
      "Iteration 800, loss = 3.60044980\n",
      "Iteration 801, loss = 3.60016342\n",
      "Iteration 802, loss = 3.59987730\n",
      "Iteration 803, loss = 3.59959145\n",
      "Iteration 804, loss = 3.59930587\n",
      "Iteration 805, loss = 3.59902056\n",
      "Iteration 806, loss = 3.59873551\n",
      "Iteration 807, loss = 3.59845072\n",
      "Iteration 808, loss = 3.59816620\n",
      "Iteration 809, loss = 3.59788194\n",
      "Iteration 810, loss = 3.59759795\n",
      "Iteration 811, loss = 3.59731422\n",
      "Iteration 812, loss = 3.59703075\n",
      "Iteration 813, loss = 3.59674754\n",
      "Iteration 814, loss = 3.59646459\n",
      "Iteration 815, loss = 3.59618191\n",
      "Iteration 816, loss = 3.59589949\n",
      "Iteration 817, loss = 3.59561732\n",
      "Iteration 818, loss = 3.59533542\n",
      "Iteration 819, loss = 3.59505377\n",
      "Iteration 820, loss = 3.59477239\n",
      "Iteration 821, loss = 3.59449126\n",
      "Iteration 822, loss = 3.59421039\n",
      "Iteration 823, loss = 3.59392977\n",
      "Iteration 824, loss = 3.59364942\n",
      "Iteration 825, loss = 3.59336931\n",
      "Iteration 826, loss = 3.59308947\n",
      "Iteration 827, loss = 3.59280988\n",
      "Iteration 828, loss = 3.59253055\n",
      "Iteration 829, loss = 3.59225147\n",
      "Iteration 830, loss = 3.59197264\n",
      "Iteration 831, loss = 3.59169407\n",
      "Iteration 832, loss = 3.59141575\n",
      "Iteration 833, loss = 3.59113768\n",
      "Iteration 834, loss = 3.59085987\n",
      "Iteration 835, loss = 3.59058230\n",
      "Iteration 836, loss = 3.59030499\n",
      "Iteration 837, loss = 3.59002793\n",
      "Iteration 838, loss = 3.58975112\n",
      "Iteration 839, loss = 3.58947456\n",
      "Iteration 840, loss = 3.58919825\n",
      "Iteration 841, loss = 3.58892219\n",
      "Iteration 842, loss = 3.58864638\n",
      "Iteration 843, loss = 3.58837082\n",
      "Iteration 844, loss = 3.58809550\n",
      "Iteration 845, loss = 3.58782043\n",
      "Iteration 846, loss = 3.58754561\n",
      "Iteration 847, loss = 3.58727104\n",
      "Iteration 848, loss = 3.58699671\n",
      "Iteration 849, loss = 3.58672263\n",
      "Iteration 850, loss = 3.58644880\n",
      "Iteration 851, loss = 3.58617521\n",
      "Iteration 852, loss = 3.58590186\n",
      "Iteration 853, loss = 3.58562876\n",
      "Iteration 854, loss = 3.58535590\n",
      "Iteration 855, loss = 3.58508329\n",
      "Iteration 856, loss = 3.58481092\n",
      "Iteration 857, loss = 3.58453879\n",
      "Iteration 858, loss = 3.58426690\n",
      "Iteration 859, loss = 3.58399526\n",
      "Iteration 860, loss = 3.58372386\n",
      "Iteration 861, loss = 3.58345270\n",
      "Iteration 862, loss = 3.58318178\n",
      "Iteration 863, loss = 3.58291110\n",
      "Iteration 864, loss = 3.58264066\n",
      "Iteration 865, loss = 3.58237046\n",
      "Iteration 866, loss = 3.58210050\n",
      "Iteration 867, loss = 3.58183078\n",
      "Iteration 868, loss = 3.58156130\n",
      "Iteration 869, loss = 3.58129206\n",
      "Iteration 870, loss = 3.58102305\n",
      "Iteration 871, loss = 3.58075429\n",
      "Iteration 872, loss = 3.58048576\n",
      "Iteration 873, loss = 3.58021746\n",
      "Iteration 874, loss = 3.57994941\n",
      "Iteration 875, loss = 3.57968159\n",
      "Iteration 876, loss = 3.57941400\n",
      "Iteration 877, loss = 3.57914665\n",
      "Iteration 878, loss = 3.57887954\n",
      "Iteration 879, loss = 3.57861266\n",
      "Iteration 880, loss = 3.57834601\n",
      "Iteration 881, loss = 3.57807960\n",
      "Iteration 882, loss = 3.57781342\n",
      "Iteration 883, loss = 3.57754748\n",
      "Iteration 884, loss = 3.57728177\n",
      "Iteration 885, loss = 3.57701629\n",
      "Iteration 886, loss = 3.57675104\n",
      "Iteration 887, loss = 3.57648603\n",
      "Iteration 888, loss = 3.57622125\n",
      "Iteration 889, loss = 3.57595670\n",
      "Iteration 890, loss = 3.57569238\n",
      "Iteration 891, loss = 3.57542829\n",
      "Iteration 892, loss = 3.57516443\n",
      "Iteration 893, loss = 3.57490080\n",
      "Iteration 894, loss = 3.57463740\n",
      "Iteration 895, loss = 3.57437423\n",
      "Iteration 896, loss = 3.57411129\n",
      "Iteration 897, loss = 3.57384858\n",
      "Iteration 898, loss = 3.57358609\n",
      "Iteration 899, loss = 3.57332384\n",
      "Iteration 900, loss = 3.57306181\n",
      "Iteration 901, loss = 3.57280001\n",
      "Iteration 902, loss = 3.57253843\n",
      "Iteration 903, loss = 3.57227709\n",
      "Iteration 904, loss = 3.57201597\n",
      "Iteration 905, loss = 3.57175507\n",
      "Iteration 906, loss = 3.57149440\n",
      "Iteration 907, loss = 3.57123396\n",
      "Iteration 908, loss = 3.57097374\n",
      "Iteration 909, loss = 3.57071375\n",
      "Iteration 910, loss = 3.57045398\n",
      "Iteration 911, loss = 3.57019444\n",
      "Iteration 912, loss = 3.56993512\n",
      "Iteration 913, loss = 3.56967602\n",
      "Iteration 914, loss = 3.56941715\n",
      "Iteration 915, loss = 3.56915850\n",
      "Iteration 916, loss = 3.56890007\n",
      "Iteration 917, loss = 3.56864187\n",
      "Iteration 918, loss = 3.56838389\n",
      "Iteration 919, loss = 3.56812613\n",
      "Iteration 920, loss = 3.56786859\n",
      "Iteration 921, loss = 3.56761127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 922, loss = 3.56735417\n",
      "Iteration 923, loss = 3.56709730\n",
      "Iteration 924, loss = 3.56684064\n",
      "Iteration 925, loss = 3.56658420\n",
      "Iteration 926, loss = 3.56632799\n",
      "Iteration 927, loss = 3.56607199\n",
      "Iteration 928, loss = 3.56581621\n",
      "Iteration 929, loss = 3.56556065\n",
      "Iteration 930, loss = 3.56530531\n",
      "Iteration 931, loss = 3.56505019\n",
      "Iteration 932, loss = 3.56479529\n",
      "Iteration 933, loss = 3.56454060\n",
      "Iteration 934, loss = 3.56428613\n",
      "Iteration 935, loss = 3.56403188\n",
      "Iteration 936, loss = 3.56377785\n",
      "Iteration 937, loss = 3.56352403\n",
      "Iteration 938, loss = 3.56327043\n",
      "Iteration 939, loss = 3.56301704\n",
      "Iteration 940, loss = 3.56276387\n",
      "Iteration 941, loss = 3.56251092\n",
      "Iteration 942, loss = 3.56225818\n",
      "Iteration 943, loss = 3.56200565\n",
      "Iteration 944, loss = 3.56175334\n",
      "Iteration 945, loss = 3.56150124\n",
      "Iteration 946, loss = 3.56124936\n",
      "Iteration 947, loss = 3.56099769\n",
      "Iteration 948, loss = 3.56074624\n",
      "Iteration 949, loss = 3.56049499\n",
      "Iteration 950, loss = 3.56024397\n",
      "Iteration 951, loss = 3.55999315\n",
      "Iteration 952, loss = 3.55974254\n",
      "Iteration 953, loss = 3.55949215\n",
      "Iteration 954, loss = 3.55924197\n",
      "Iteration 955, loss = 3.55899200\n",
      "Iteration 956, loss = 3.55874224\n",
      "Iteration 957, loss = 3.55849270\n",
      "Iteration 958, loss = 3.55824336\n",
      "Iteration 959, loss = 3.55799423\n",
      "Iteration 960, loss = 3.55774532\n",
      "Iteration 961, loss = 3.55749661\n",
      "Iteration 962, loss = 3.55724812\n",
      "Iteration 963, loss = 3.55699983\n",
      "Iteration 964, loss = 3.55675175\n",
      "Iteration 965, loss = 3.55650388\n",
      "Iteration 966, loss = 3.55625622\n",
      "Iteration 967, loss = 3.55600877\n",
      "Iteration 968, loss = 3.55576152\n",
      "Iteration 969, loss = 3.55551448\n",
      "Iteration 970, loss = 3.55526765\n",
      "Iteration 971, loss = 3.55502103\n",
      "Iteration 972, loss = 3.55477461\n",
      "Iteration 973, loss = 3.55452840\n",
      "Iteration 974, loss = 3.55428240\n",
      "Iteration 975, loss = 3.55403660\n",
      "Iteration 976, loss = 3.55379101\n",
      "Iteration 977, loss = 3.55354562\n",
      "Iteration 978, loss = 3.55330044\n",
      "Iteration 979, loss = 3.55305547\n",
      "Iteration 980, loss = 3.55281069\n",
      "Iteration 981, loss = 3.55256613\n",
      "Iteration 982, loss = 3.55232176\n",
      "Iteration 983, loss = 3.55207761\n",
      "Iteration 984, loss = 3.55183365\n",
      "Iteration 985, loss = 3.55158990\n",
      "Iteration 986, loss = 3.55134635\n",
      "Iteration 987, loss = 3.55110300\n",
      "Iteration 988, loss = 3.55085986\n",
      "Iteration 989, loss = 3.55061692\n",
      "Iteration 990, loss = 3.55037418\n",
      "Iteration 991, loss = 3.55013164\n",
      "Iteration 992, loss = 3.54988930\n",
      "Iteration 993, loss = 3.54964717\n",
      "Iteration 994, loss = 3.54940523\n",
      "Iteration 995, loss = 3.54916350\n",
      "Iteration 996, loss = 3.54892197\n",
      "Iteration 997, loss = 3.54868063\n",
      "Iteration 998, loss = 3.54843950\n",
      "Iteration 999, loss = 3.54819857\n",
      "Iteration 1000, loss = 3.54795783\n",
      "Iteration 1001, loss = 3.54771730\n",
      "Iteration 1002, loss = 3.54747696\n",
      "Iteration 1003, loss = 3.54723683\n",
      "Iteration 1004, loss = 3.54699689\n",
      "Iteration 1005, loss = 3.54675715\n",
      "Iteration 1006, loss = 3.54651760\n",
      "Iteration 1007, loss = 3.54627826\n",
      "Iteration 1008, loss = 3.54603911\n",
      "Iteration 1009, loss = 3.54580016\n",
      "Iteration 1010, loss = 3.54556140\n",
      "Iteration 1011, loss = 3.54532285\n",
      "Iteration 1012, loss = 3.54508448\n",
      "Iteration 1013, loss = 3.54484632\n",
      "Iteration 1014, loss = 3.54460835\n",
      "Iteration 1015, loss = 3.54437057\n",
      "Iteration 1016, loss = 3.54413299\n",
      "Iteration 1017, loss = 3.54389561\n",
      "Iteration 1018, loss = 3.54365842\n",
      "Iteration 1019, loss = 3.54342142\n",
      "Iteration 1020, loss = 3.54318462\n",
      "Iteration 1021, loss = 3.54294801\n",
      "Iteration 1022, loss = 3.54271160\n",
      "Iteration 1023, loss = 3.54247538\n",
      "Iteration 1024, loss = 3.54223935\n",
      "Iteration 1025, loss = 3.54200352\n",
      "Iteration 1026, loss = 3.54176788\n",
      "Iteration 1027, loss = 3.54153243\n",
      "Iteration 1028, loss = 3.54129717\n",
      "Iteration 1029, loss = 3.54106211\n",
      "Iteration 1030, loss = 3.54082723\n",
      "Iteration 1031, loss = 3.54059255\n",
      "Iteration 1032, loss = 3.54035806\n",
      "Iteration 1033, loss = 3.54012376\n",
      "Iteration 1034, loss = 3.53988965\n",
      "Iteration 1035, loss = 3.53965573\n",
      "Iteration 1036, loss = 3.53942200\n",
      "Iteration 1037, loss = 3.53918846\n",
      "Iteration 1038, loss = 3.53895511\n",
      "Iteration 1039, loss = 3.53872195\n",
      "Iteration 1040, loss = 3.53848897\n",
      "Iteration 1041, loss = 3.53825619\n",
      "Iteration 1042, loss = 3.53802359\n",
      "Iteration 1043, loss = 3.53779119\n",
      "Iteration 1044, loss = 3.53755897\n",
      "Iteration 1045, loss = 3.53732694\n",
      "Iteration 1046, loss = 3.53709509\n",
      "Iteration 1047, loss = 3.53686344\n",
      "Iteration 1048, loss = 3.53663197\n",
      "Iteration 1049, loss = 3.53640068\n",
      "Iteration 1050, loss = 3.53616959\n",
      "Iteration 1051, loss = 3.53593868\n",
      "Iteration 1052, loss = 3.53570795\n",
      "Iteration 1053, loss = 3.53547741\n",
      "Iteration 1054, loss = 3.53524706\n",
      "Iteration 1055, loss = 3.53501689\n",
      "Iteration 1056, loss = 3.53478691\n",
      "Iteration 1057, loss = 3.53455711\n",
      "Iteration 1058, loss = 3.53432750\n",
      "Iteration 1059, loss = 3.53409807\n",
      "Iteration 1060, loss = 3.53386882\n",
      "Iteration 1061, loss = 3.53363976\n",
      "Iteration 1062, loss = 3.53341088\n",
      "Iteration 1063, loss = 3.53318218\n",
      "Iteration 1064, loss = 3.53295367\n",
      "Iteration 1065, loss = 3.53272534\n",
      "Iteration 1066, loss = 3.53249719\n",
      "Iteration 1067, loss = 3.53226922\n",
      "Iteration 1068, loss = 3.53204144\n",
      "Iteration 1069, loss = 3.53181383\n",
      "Iteration 1070, loss = 3.53158641\n",
      "Iteration 1071, loss = 3.53135917\n",
      "Iteration 1072, loss = 3.53113211\n",
      "Iteration 1073, loss = 3.53090523\n",
      "Iteration 1074, loss = 3.53067853\n",
      "Iteration 1075, loss = 3.53045201\n",
      "Iteration 1076, loss = 3.53022567\n",
      "Iteration 1077, loss = 3.52999951\n",
      "Iteration 1078, loss = 3.52977353\n",
      "Iteration 1079, loss = 3.52954773\n",
      "Iteration 1080, loss = 3.52932211\n",
      "Iteration 1081, loss = 3.52909666\n",
      "Iteration 1082, loss = 3.52887140\n",
      "Iteration 1083, loss = 3.52864631\n",
      "Iteration 1084, loss = 3.52842140\n",
      "Iteration 1085, loss = 3.52819666\n",
      "Iteration 1086, loss = 3.52797211\n",
      "Iteration 1087, loss = 3.52774773\n",
      "Iteration 1088, loss = 3.52752353\n",
      "Iteration 1089, loss = 3.52729950\n",
      "Iteration 1090, loss = 3.52707565\n",
      "Iteration 1091, loss = 3.52685198\n",
      "Iteration 1092, loss = 3.52662848\n",
      "Iteration 1093, loss = 3.52640515\n",
      "Iteration 1094, loss = 3.52618201\n",
      "Iteration 1095, loss = 3.52595903\n",
      "Iteration 1096, loss = 3.52573624\n",
      "Iteration 1097, loss = 3.52551361\n",
      "Iteration 1098, loss = 3.52529116\n",
      "Iteration 1099, loss = 3.52506889\n",
      "Iteration 1100, loss = 3.52484678\n",
      "Iteration 1101, loss = 3.52462485\n",
      "Iteration 1102, loss = 3.52440310\n",
      "Iteration 1103, loss = 3.52418151\n",
      "Iteration 1104, loss = 3.52396010\n",
      "Iteration 1105, loss = 3.52373886\n",
      "Iteration 1106, loss = 3.52351780\n",
      "Iteration 1107, loss = 3.52329690\n",
      "Iteration 1108, loss = 3.52307618\n",
      "Iteration 1109, loss = 3.52285563\n",
      "Iteration 1110, loss = 3.52263525\n",
      "Iteration 1111, loss = 3.52241504\n",
      "Iteration 1112, loss = 3.52219500\n",
      "Iteration 1113, loss = 3.52197513\n",
      "Iteration 1114, loss = 3.52175543\n",
      "Iteration 1115, loss = 3.52153590\n",
      "Iteration 1116, loss = 3.52131654\n",
      "Iteration 1117, loss = 3.52109735\n",
      "Iteration 1118, loss = 3.52087833\n",
      "Iteration 1119, loss = 3.52065947\n",
      "Iteration 1120, loss = 3.52044079\n",
      "Iteration 1121, loss = 3.52022227\n",
      "Iteration 1122, loss = 3.52000392\n",
      "Iteration 1123, loss = 3.51978574\n",
      "Iteration 1124, loss = 3.51956773\n",
      "Iteration 1125, loss = 3.51934988\n",
      "Iteration 1126, loss = 3.51913220\n",
      "Iteration 1127, loss = 3.51891469\n",
      "Iteration 1128, loss = 3.51869734\n",
      "Iteration 1129, loss = 3.51848016\n",
      "Iteration 1130, loss = 3.51826314\n",
      "Iteration 1131, loss = 3.51804630\n",
      "Iteration 1132, loss = 3.51782961\n",
      "Iteration 1133, loss = 3.51761309\n",
      "Iteration 1134, loss = 3.51739674\n",
      "Iteration 1135, loss = 3.51718055\n",
      "Iteration 1136, loss = 3.51696452\n",
      "Iteration 1137, loss = 3.51674866\n",
      "Iteration 1138, loss = 3.51653297\n",
      "Iteration 1139, loss = 3.51631743\n",
      "Iteration 1140, loss = 3.51610206\n",
      "Iteration 1141, loss = 3.51588685\n",
      "Iteration 1142, loss = 3.51567181\n",
      "Iteration 1143, loss = 3.51545693\n",
      "Iteration 1144, loss = 3.51524221\n",
      "Iteration 1145, loss = 3.51502765\n",
      "Iteration 1146, loss = 3.51481325\n",
      "Iteration 1147, loss = 3.51459902\n",
      "Iteration 1148, loss = 3.51438494\n",
      "Iteration 1149, loss = 3.51417103\n",
      "Iteration 1150, loss = 3.51395728\n",
      "Iteration 1151, loss = 3.51374369\n",
      "Iteration 1152, loss = 3.51353026\n",
      "Iteration 1153, loss = 3.51331698\n",
      "Iteration 1154, loss = 3.51310387\n",
      "Iteration 1155, loss = 3.51289092\n",
      "Iteration 1156, loss = 3.51267813\n",
      "Iteration 1157, loss = 3.51246549\n",
      "Iteration 1158, loss = 3.51225302\n",
      "Iteration 1159, loss = 3.51204070\n",
      "Iteration 1160, loss = 3.51182854\n",
      "Iteration 1161, loss = 3.51161654\n",
      "Iteration 1162, loss = 3.51140469\n",
      "Iteration 1163, loss = 3.51119301\n",
      "Iteration 1164, loss = 3.51098148\n",
      "Iteration 1165, loss = 3.51077010\n",
      "Iteration 1166, loss = 3.51055889\n",
      "Iteration 1167, loss = 3.51034783\n",
      "Iteration 1168, loss = 3.51013692\n",
      "Iteration 1169, loss = 3.50992617\n",
      "Iteration 1170, loss = 3.50971558\n",
      "Iteration 1171, loss = 3.50950514\n",
      "Iteration 1172, loss = 3.50929486\n",
      "Iteration 1173, loss = 3.50908473\n",
      "Iteration 1174, loss = 3.50887476\n",
      "Iteration 1175, loss = 3.50866494\n",
      "Iteration 1176, loss = 3.50845527\n",
      "Iteration 1177, loss = 3.50824576\n",
      "Iteration 1178, loss = 3.50803640\n",
      "Iteration 1179, loss = 3.50782720\n",
      "Iteration 1180, loss = 3.50761814\n",
      "Iteration 1181, loss = 3.50740924\n",
      "Iteration 1182, loss = 3.50720050\n",
      "Iteration 1183, loss = 3.50699190\n",
      "Iteration 1184, loss = 3.50678346\n",
      "Iteration 1185, loss = 3.50657516\n",
      "Iteration 1186, loss = 3.50636702\n",
      "Iteration 1187, loss = 3.50615903\n",
      "Iteration 1188, loss = 3.50595119\n",
      "Iteration 1189, loss = 3.50574351\n",
      "Iteration 1190, loss = 3.50553597\n",
      "Iteration 1191, loss = 3.50532858\n",
      "Iteration 1192, loss = 3.50512134\n",
      "Iteration 1193, loss = 3.50491425\n",
      "Iteration 1194, loss = 3.50470731\n",
      "Iteration 1195, loss = 3.50450052\n",
      "Iteration 1196, loss = 3.50429388\n",
      "Iteration 1197, loss = 3.50408738\n",
      "Iteration 1198, loss = 3.50388104\n",
      "Iteration 1199, loss = 3.50367484\n",
      "Iteration 1200, loss = 3.50346879\n",
      "Iteration 1201, loss = 3.50326289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1202, loss = 3.50305713\n",
      "Iteration 1203, loss = 3.50285152\n",
      "Iteration 1204, loss = 3.50264606\n",
      "Iteration 1205, loss = 3.50244075\n",
      "Iteration 1206, loss = 3.50223558\n",
      "Iteration 1207, loss = 3.50203055\n",
      "Iteration 1208, loss = 3.50182567\n",
      "Iteration 1209, loss = 3.50162094\n",
      "Iteration 1210, loss = 3.50141635\n",
      "Iteration 1211, loss = 3.50121191\n",
      "Iteration 1212, loss = 3.50100761\n",
      "Iteration 1213, loss = 3.50080345\n",
      "Iteration 1214, loss = 3.50059944\n",
      "Iteration 1215, loss = 3.50039558\n",
      "Iteration 1216, loss = 3.50019185\n",
      "Iteration 1217, loss = 3.49998827\n",
      "Iteration 1218, loss = 3.49978483\n",
      "Iteration 1219, loss = 3.49958154\n",
      "Iteration 1220, loss = 3.49937839\n",
      "Iteration 1221, loss = 3.49917538\n",
      "Iteration 1222, loss = 3.49897251\n",
      "Iteration 1223, loss = 3.49876978\n",
      "Iteration 1224, loss = 3.49856720\n",
      "Iteration 1225, loss = 3.49836475\n",
      "Iteration 1226, loss = 3.49816245\n",
      "Iteration 1227, loss = 3.49796028\n",
      "Iteration 1228, loss = 3.49775826\n",
      "Iteration 1229, loss = 3.49755638\n",
      "Iteration 1230, loss = 3.49735463\n",
      "Iteration 1231, loss = 3.49715303\n",
      "Iteration 1232, loss = 3.49695157\n",
      "Iteration 1233, loss = 3.49675024\n",
      "Iteration 1234, loss = 3.49654905\n",
      "Iteration 1235, loss = 3.49634801\n",
      "Iteration 1236, loss = 3.49614709\n",
      "Iteration 1237, loss = 3.49594632\n",
      "Iteration 1238, loss = 3.49574569\n",
      "Iteration 1239, loss = 3.49554519\n",
      "Iteration 1240, loss = 3.49534483\n",
      "Iteration 1241, loss = 3.49514461\n",
      "Iteration 1242, loss = 3.49494452\n",
      "Iteration 1243, loss = 3.49474457\n",
      "Iteration 1244, loss = 3.49454475\n",
      "Iteration 1245, loss = 3.49434507\n",
      "Iteration 1246, loss = 3.49414553\n",
      "Iteration 1247, loss = 3.49394612\n",
      "Iteration 1248, loss = 3.49374685\n",
      "Iteration 1249, loss = 3.49354771\n",
      "Iteration 1250, loss = 3.49334871\n",
      "Iteration 1251, loss = 3.49314984\n",
      "Iteration 1252, loss = 3.49295110\n",
      "Iteration 1253, loss = 3.49275250\n",
      "Iteration 1254, loss = 3.49255403\n",
      "Iteration 1255, loss = 3.49235570\n",
      "Iteration 1256, loss = 3.49215749\n",
      "Iteration 1257, loss = 3.49195942\n",
      "Iteration 1258, loss = 3.49176148\n",
      "Iteration 1259, loss = 3.49156368\n",
      "Iteration 1260, loss = 3.49136600\n",
      "Iteration 1261, loss = 3.49116846\n",
      "Iteration 1262, loss = 3.49097105\n",
      "Iteration 1263, loss = 3.49077377\n",
      "Iteration 1264, loss = 3.49057662\n",
      "Iteration 1265, loss = 3.49037960\n",
      "Iteration 1266, loss = 3.49018271\n",
      "Iteration 1267, loss = 3.48998595\n",
      "Iteration 1268, loss = 3.48978932\n",
      "Iteration 1269, loss = 3.48959282\n",
      "Iteration 1270, loss = 3.48939645\n",
      "Iteration 1271, loss = 3.48920021\n",
      "Iteration 1272, loss = 3.48900410\n",
      "Iteration 1273, loss = 3.48880811\n",
      "Iteration 1274, loss = 3.48861226\n",
      "Iteration 1275, loss = 3.48841653\n",
      "Iteration 1276, loss = 3.48822093\n",
      "Iteration 1277, loss = 3.48802545\n",
      "Iteration 1278, loss = 3.48783011\n",
      "Iteration 1279, loss = 3.48763488\n",
      "Iteration 1280, loss = 3.48743979\n",
      "Iteration 1281, loss = 3.48724482\n",
      "Iteration 1282, loss = 3.48704998\n",
      "Iteration 1283, loss = 3.48685526\n",
      "Iteration 1284, loss = 3.48666067\n",
      "Iteration 1285, loss = 3.48646621\n",
      "Iteration 1286, loss = 3.48627187\n",
      "Iteration 1287, loss = 3.48607765\n",
      "Iteration 1288, loss = 3.48588356\n",
      "Iteration 1289, loss = 3.48568959\n",
      "Iteration 1290, loss = 3.48549575\n",
      "Iteration 1291, loss = 3.48530203\n",
      "Iteration 1292, loss = 3.48510843\n",
      "Iteration 1293, loss = 3.48491496\n",
      "Iteration 1294, loss = 3.48472161\n",
      "Iteration 1295, loss = 3.48452838\n",
      "Iteration 1296, loss = 3.48433527\n",
      "Iteration 1297, loss = 3.48414229\n",
      "Iteration 1298, loss = 3.48394942\n",
      "Iteration 1299, loss = 3.48375668\n",
      "Iteration 1300, loss = 3.48356406\n",
      "Iteration 1301, loss = 3.48337156\n",
      "Iteration 1302, loss = 3.48317918\n",
      "Iteration 1303, loss = 3.48298693\n",
      "Iteration 1304, loss = 3.48279479\n",
      "Iteration 1305, loss = 3.48260277\n",
      "Iteration 1306, loss = 3.48241087\n",
      "Iteration 1307, loss = 3.48221909\n",
      "Iteration 1308, loss = 3.48202743\n",
      "Iteration 1309, loss = 3.48183589\n",
      "Iteration 1310, loss = 3.48164446\n",
      "Iteration 1311, loss = 3.48145316\n",
      "Iteration 1312, loss = 3.48126197\n",
      "Iteration 1313, loss = 3.48107090\n",
      "Iteration 1314, loss = 3.48087995\n",
      "Iteration 1315, loss = 3.48068911\n",
      "Iteration 1316, loss = 3.48049840\n",
      "Iteration 1317, loss = 3.48030779\n",
      "Iteration 1318, loss = 3.48011731\n",
      "Iteration 1319, loss = 3.47992694\n",
      "Iteration 1320, loss = 3.47973669\n",
      "Iteration 1321, loss = 3.47954655\n",
      "Iteration 1322, loss = 3.47935653\n",
      "Iteration 1323, loss = 3.47916662\n",
      "Iteration 1324, loss = 3.47897683\n",
      "Iteration 1325, loss = 3.47878715\n",
      "Iteration 1326, loss = 3.47859759\n",
      "Iteration 1327, loss = 3.47840814\n",
      "Iteration 1328, loss = 3.47821880\n",
      "Iteration 1329, loss = 3.47802958\n",
      "Iteration 1330, loss = 3.47784047\n",
      "Iteration 1331, loss = 3.47765147\n",
      "Iteration 1332, loss = 3.47746259\n",
      "Iteration 1333, loss = 3.47727381\n",
      "Iteration 1334, loss = 3.47708515\n",
      "Iteration 1335, loss = 3.47689661\n",
      "Iteration 1336, loss = 3.47670817\n",
      "Iteration 1337, loss = 3.47651985\n",
      "Iteration 1338, loss = 3.47633163\n",
      "Iteration 1339, loss = 3.47614353\n",
      "Iteration 1340, loss = 3.47595554\n",
      "Iteration 1341, loss = 3.47576765\n",
      "Iteration 1342, loss = 3.47557988\n",
      "Iteration 1343, loss = 3.47539222\n",
      "Iteration 1344, loss = 3.47520467\n",
      "Iteration 1345, loss = 3.47501722\n",
      "Iteration 1346, loss = 3.47482989\n",
      "Iteration 1347, loss = 3.47464266\n",
      "Iteration 1348, loss = 3.47445554\n",
      "Iteration 1349, loss = 3.47426853\n",
      "Iteration 1350, loss = 3.47408163\n",
      "Iteration 1351, loss = 3.47389484\n",
      "Iteration 1352, loss = 3.47370815\n",
      "Iteration 1353, loss = 3.47352157\n",
      "Iteration 1354, loss = 3.47333509\n",
      "Iteration 1355, loss = 3.47314873\n",
      "Iteration 1356, loss = 3.47296247\n",
      "Iteration 1357, loss = 3.47277631\n",
      "Iteration 1358, loss = 3.47259026\n",
      "Iteration 1359, loss = 3.47240432\n",
      "Iteration 1360, loss = 3.47221848\n",
      "Iteration 1361, loss = 3.47203275\n",
      "Iteration 1362, loss = 3.47184712\n",
      "Iteration 1363, loss = 3.47166160\n",
      "Iteration 1364, loss = 3.47147618\n",
      "Iteration 1365, loss = 3.47129086\n",
      "Iteration 1366, loss = 3.47110565\n",
      "Iteration 1367, loss = 3.47092054\n",
      "Iteration 1368, loss = 3.47073553\n",
      "Iteration 1369, loss = 3.47055063\n",
      "Iteration 1370, loss = 3.47036583\n",
      "Iteration 1371, loss = 3.47018113\n",
      "Iteration 1372, loss = 3.46999654\n",
      "Iteration 1373, loss = 3.46981204\n",
      "Iteration 1374, loss = 3.46962765\n",
      "Iteration 1375, loss = 3.46944336\n",
      "Iteration 1376, loss = 3.46925917\n",
      "Iteration 1377, loss = 3.46907508\n",
      "Iteration 1378, loss = 3.46889109\n",
      "Iteration 1379, loss = 3.46870720\n",
      "Iteration 1380, loss = 3.46852341\n",
      "Iteration 1381, loss = 3.46833972\n",
      "Iteration 1382, loss = 3.46815613\n",
      "Iteration 1383, loss = 3.46797264\n",
      "Iteration 1384, loss = 3.46778925\n",
      "Iteration 1385, loss = 3.46760595\n",
      "Iteration 1386, loss = 3.46742276\n",
      "Iteration 1387, loss = 3.46723966\n",
      "Iteration 1388, loss = 3.46705666\n",
      "Iteration 1389, loss = 3.46687376\n",
      "Iteration 1390, loss = 3.46669096\n",
      "Iteration 1391, loss = 3.46650825\n",
      "Iteration 1392, loss = 3.46632564\n",
      "Iteration 1393, loss = 3.46614313\n",
      "Iteration 1394, loss = 3.46596071\n",
      "Iteration 1395, loss = 3.46577839\n",
      "Iteration 1396, loss = 3.46559617\n",
      "Iteration 1397, loss = 3.46541404\n",
      "Iteration 1398, loss = 3.46523200\n",
      "Iteration 1399, loss = 3.46505006\n",
      "Iteration 1400, loss = 3.46486822\n",
      "Iteration 1401, loss = 3.46468647\n",
      "Iteration 1402, loss = 3.46450481\n",
      "Iteration 1403, loss = 3.46432325\n",
      "Iteration 1404, loss = 3.46414178\n",
      "Iteration 1405, loss = 3.46396041\n",
      "Iteration 1406, loss = 3.46377912\n",
      "Iteration 1407, loss = 3.46359794\n",
      "Iteration 1408, loss = 3.46341684\n",
      "Iteration 1409, loss = 3.46323584\n",
      "Iteration 1410, loss = 3.46305492\n",
      "Iteration 1411, loss = 3.46287410\n",
      "Iteration 1412, loss = 3.46269338\n",
      "Iteration 1413, loss = 3.46251274\n",
      "Iteration 1414, loss = 3.46233220\n",
      "Iteration 1415, loss = 3.46215174\n",
      "Iteration 1416, loss = 3.46197138\n",
      "Iteration 1417, loss = 3.46179110\n",
      "Iteration 1418, loss = 3.46161092\n",
      "Iteration 1419, loss = 3.46143083\n",
      "Iteration 1420, loss = 3.46125082\n",
      "Iteration 1421, loss = 3.46107091\n",
      "Iteration 1422, loss = 3.46089109\n",
      "Iteration 1423, loss = 3.46071135\n",
      "Iteration 1424, loss = 3.46053170\n",
      "Iteration 1425, loss = 3.46035214\n",
      "Iteration 1426, loss = 3.46017267\n",
      "Iteration 1427, loss = 3.45999329\n",
      "Iteration 1428, loss = 3.45981399\n",
      "Iteration 1429, loss = 3.45963478\n",
      "Iteration 1430, loss = 3.45945566\n",
      "Iteration 1431, loss = 3.45927663\n",
      "Iteration 1432, loss = 3.45909768\n",
      "Iteration 1433, loss = 3.45891882\n",
      "Iteration 1434, loss = 3.45874004\n",
      "Iteration 1435, loss = 3.45856135\n",
      "Iteration 1436, loss = 3.45838275\n",
      "Iteration 1437, loss = 3.45820423\n",
      "Iteration 1438, loss = 3.45802580\n",
      "Iteration 1439, loss = 3.45784745\n",
      "Iteration 1440, loss = 3.45766918\n",
      "Iteration 1441, loss = 3.45749100\n",
      "Iteration 1442, loss = 3.45731291\n",
      "Iteration 1443, loss = 3.45713490\n",
      "Iteration 1444, loss = 3.45695697\n",
      "Iteration 1445, loss = 3.45677912\n",
      "Iteration 1446, loss = 3.45660136\n",
      "Iteration 1447, loss = 3.45642368\n",
      "Iteration 1448, loss = 3.45624608\n",
      "Iteration 1449, loss = 3.45606857\n",
      "Iteration 1450, loss = 3.45589114\n",
      "Iteration 1451, loss = 3.45571379\n",
      "Iteration 1452, loss = 3.45553652\n",
      "Iteration 1453, loss = 3.45535933\n",
      "Iteration 1454, loss = 3.45518223\n",
      "Iteration 1455, loss = 3.45500520\n",
      "Iteration 1456, loss = 3.45482826\n",
      "Iteration 1457, loss = 3.45465139\n",
      "Iteration 1458, loss = 3.45447461\n",
      "Iteration 1459, loss = 3.45429790\n",
      "Iteration 1460, loss = 3.45412128\n",
      "Iteration 1461, loss = 3.45394473\n",
      "Iteration 1462, loss = 3.45376827\n",
      "Iteration 1463, loss = 3.45359188\n",
      "Iteration 1464, loss = 3.45341557\n",
      "Iteration 1465, loss = 3.45323934\n",
      "Iteration 1466, loss = 3.45306319\n",
      "Iteration 1467, loss = 3.45288712\n",
      "Iteration 1468, loss = 3.45271112\n",
      "Iteration 1469, loss = 3.45253520\n",
      "Iteration 1470, loss = 3.45235936\n",
      "Iteration 1471, loss = 3.45218359\n",
      "Iteration 1472, loss = 3.45200791\n",
      "Iteration 1473, loss = 3.45183230\n",
      "Iteration 1474, loss = 3.45165676\n",
      "Iteration 1475, loss = 3.45148130\n",
      "Iteration 1476, loss = 3.45130592\n",
      "Iteration 1477, loss = 3.45113061\n",
      "Iteration 1478, loss = 3.45095538\n",
      "Iteration 1479, loss = 3.45078022\n",
      "Iteration 1480, loss = 3.45060514\n",
      "Iteration 1481, loss = 3.45043013\n",
      "Iteration 1482, loss = 3.45025520\n",
      "Iteration 1483, loss = 3.45008034\n",
      "Iteration 1484, loss = 3.44990555\n",
      "Iteration 1485, loss = 3.44973084\n",
      "Iteration 1486, loss = 3.44955620\n",
      "Iteration 1487, loss = 3.44938163\n",
      "Iteration 1488, loss = 3.44920714\n",
      "Iteration 1489, loss = 3.44903272\n",
      "Iteration 1490, loss = 3.44885838\n",
      "Iteration 1491, loss = 3.44868410\n",
      "Iteration 1492, loss = 3.44850990\n",
      "Iteration 1493, loss = 3.44833577\n",
      "Iteration 1494, loss = 3.44816171\n",
      "Iteration 1495, loss = 3.44798772\n",
      "Iteration 1496, loss = 3.44781380\n",
      "Iteration 1497, loss = 3.44763995\n",
      "Iteration 1498, loss = 3.44746618\n",
      "Iteration 1499, loss = 3.44729247\n",
      "Iteration 1500, loss = 3.44711884\n",
      "Iteration 1501, loss = 3.44694527\n",
      "Iteration 1502, loss = 3.44677178\n",
      "Iteration 1503, loss = 3.44659835\n",
      "Iteration 1504, loss = 3.44642499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1505, loss = 3.44625170\n",
      "Iteration 1506, loss = 3.44607849\n",
      "Iteration 1507, loss = 3.44590533\n",
      "Iteration 1508, loss = 3.44573225\n",
      "Iteration 1509, loss = 3.44555924\n",
      "Iteration 1510, loss = 3.44538629\n",
      "Iteration 1511, loss = 3.44521341\n",
      "Iteration 1512, loss = 3.44504060\n",
      "Iteration 1513, loss = 3.44486786\n",
      "Iteration 1514, loss = 3.44469518\n",
      "Iteration 1515, loss = 3.44452257\n",
      "Iteration 1516, loss = 3.44435002\n",
      "Iteration 1517, loss = 3.44417755\n",
      "Iteration 1518, loss = 3.44400513\n",
      "Iteration 1519, loss = 3.44383279\n",
      "Iteration 1520, loss = 3.44366051\n",
      "Iteration 1521, loss = 3.44348829\n",
      "Iteration 1522, loss = 3.44331614\n",
      "Iteration 1523, loss = 3.44314406\n",
      "Iteration 1524, loss = 3.44297204\n",
      "Iteration 1525, loss = 3.44280008\n",
      "Iteration 1526, loss = 3.44262819\n",
      "Iteration 1527, loss = 3.44245636\n",
      "Iteration 1528, loss = 3.44228460\n",
      "Iteration 1529, loss = 3.44211290\n",
      "Iteration 1530, loss = 3.44194127\n",
      "Iteration 1531, loss = 3.44176969\n",
      "Iteration 1532, loss = 3.44159818\n",
      "Iteration 1533, loss = 3.44142673\n",
      "Iteration 1534, loss = 3.44125535\n",
      "Iteration 1535, loss = 3.44108403\n",
      "Iteration 1536, loss = 3.44091277\n",
      "Iteration 1537, loss = 3.44074157\n",
      "Iteration 1538, loss = 3.44057043\n",
      "Iteration 1539, loss = 3.44039936\n",
      "Iteration 1540, loss = 3.44022834\n",
      "Iteration 1541, loss = 3.44005739\n",
      "Iteration 1542, loss = 3.43988650\n",
      "Iteration 1543, loss = 3.43971566\n",
      "Iteration 1544, loss = 3.43954489\n",
      "Iteration 1545, loss = 3.43937418\n",
      "Iteration 1546, loss = 3.43920353\n",
      "Iteration 1547, loss = 3.43903294\n",
      "Iteration 1548, loss = 3.43886241\n",
      "Iteration 1549, loss = 3.43869193\n",
      "Iteration 1550, loss = 3.43852152\n",
      "Iteration 1551, loss = 3.43835117\n",
      "Iteration 1552, loss = 3.43818087\n",
      "Iteration 1553, loss = 3.43801063\n",
      "Iteration 1554, loss = 3.43784045\n",
      "Iteration 1555, loss = 3.43767033\n",
      "Iteration 1556, loss = 3.43750027\n",
      "Iteration 1557, loss = 3.43733026\n",
      "Iteration 1558, loss = 3.43716032\n",
      "Iteration 1559, loss = 3.43699042\n",
      "Iteration 1560, loss = 3.43682059\n",
      "Iteration 1561, loss = 3.43665081\n",
      "Iteration 1562, loss = 3.43648109\n",
      "Iteration 1563, loss = 3.43631143\n",
      "Iteration 1564, loss = 3.43614182\n",
      "Iteration 1565, loss = 3.43597227\n",
      "Iteration 1566, loss = 3.43580277\n",
      "Iteration 1567, loss = 3.43563333\n",
      "Iteration 1568, loss = 3.43546395\n",
      "Iteration 1569, loss = 3.43529462\n",
      "Iteration 1570, loss = 3.43512534\n",
      "Iteration 1571, loss = 3.43495612\n",
      "Iteration 1572, loss = 3.43478696\n",
      "Iteration 1573, loss = 3.43461785\n",
      "Iteration 1574, loss = 3.43444879\n",
      "Iteration 1575, loss = 3.43427979\n",
      "Iteration 1576, loss = 3.43411084\n",
      "Iteration 1577, loss = 3.43394195\n",
      "Iteration 1578, loss = 3.43377310\n",
      "Iteration 1579, loss = 3.43360431\n",
      "Iteration 1580, loss = 3.43343558\n",
      "Iteration 1581, loss = 3.43326690\n",
      "Iteration 1582, loss = 3.43309827\n",
      "Iteration 1583, loss = 3.43292969\n",
      "Iteration 1584, loss = 3.43276116\n",
      "Iteration 1585, loss = 3.43259269\n",
      "Iteration 1586, loss = 3.43242427\n",
      "Iteration 1587, loss = 3.43225590\n",
      "Iteration 1588, loss = 3.43208758\n",
      "Iteration 1589, loss = 3.43191931\n",
      "Iteration 1590, loss = 3.43175110\n",
      "Iteration 1591, loss = 3.43158293\n",
      "Iteration 1592, loss = 3.43141482\n",
      "Iteration 1593, loss = 3.43124675\n",
      "Iteration 1594, loss = 3.43107874\n",
      "Iteration 1595, loss = 3.43091077\n",
      "Iteration 1596, loss = 3.43074286\n",
      "Iteration 1597, loss = 3.43057500\n",
      "Iteration 1598, loss = 3.43040718\n",
      "Iteration 1599, loss = 3.43023942\n",
      "Iteration 1600, loss = 3.43007170\n",
      "Iteration 1601, loss = 3.42990403\n",
      "Iteration 1602, loss = 3.42973641\n",
      "Iteration 1603, loss = 3.42956884\n",
      "Iteration 1604, loss = 3.42940132\n",
      "Iteration 1605, loss = 3.42923385\n",
      "Iteration 1606, loss = 3.42906643\n",
      "Iteration 1607, loss = 3.42889905\n",
      "Iteration 1608, loss = 3.42873172\n",
      "Iteration 1609, loss = 3.42856444\n",
      "Iteration 1610, loss = 3.42839720\n",
      "Iteration 1611, loss = 3.42823002\n",
      "Iteration 1612, loss = 3.42806287\n",
      "Iteration 1613, loss = 3.42789578\n",
      "Iteration 1614, loss = 3.42772873\n",
      "Iteration 1615, loss = 3.42756173\n",
      "Iteration 1616, loss = 3.42739478\n",
      "Iteration 1617, loss = 3.42722787\n",
      "Iteration 1618, loss = 3.42706101\n",
      "Iteration 1619, loss = 3.42689419\n",
      "Iteration 1620, loss = 3.42672742\n",
      "Iteration 1621, loss = 3.42656069\n",
      "Iteration 1622, loss = 3.42639401\n",
      "Iteration 1623, loss = 3.42622738\n",
      "Iteration 1624, loss = 3.42606079\n",
      "Iteration 1625, loss = 3.42589424\n",
      "Iteration 1626, loss = 3.42572774\n",
      "Iteration 1627, loss = 3.42556128\n",
      "Iteration 1628, loss = 3.42539487\n",
      "Iteration 1629, loss = 3.42522850\n",
      "Iteration 1630, loss = 3.42506217\n",
      "Iteration 1631, loss = 3.42489589\n",
      "Iteration 1632, loss = 3.42472965\n",
      "Iteration 1633, loss = 3.42456345\n",
      "Iteration 1634, loss = 3.42439730\n",
      "Iteration 1635, loss = 3.42423119\n",
      "Iteration 1636, loss = 3.42406512\n",
      "Iteration 1637, loss = 3.42389910\n",
      "Iteration 1638, loss = 3.42373312\n",
      "Iteration 1639, loss = 3.42356718\n",
      "Iteration 1640, loss = 3.42340128\n",
      "Iteration 1641, loss = 3.42323542\n",
      "Iteration 1642, loss = 3.42306961\n",
      "Iteration 1643, loss = 3.42290383\n",
      "Iteration 1644, loss = 3.42273810\n",
      "Iteration 1645, loss = 3.42257241\n",
      "Iteration 1646, loss = 3.42240676\n",
      "Iteration 1647, loss = 3.42224116\n",
      "Iteration 1648, loss = 3.42207559\n",
      "Iteration 1649, loss = 3.42191006\n",
      "Iteration 1650, loss = 3.42174457\n",
      "Iteration 1651, loss = 3.42157913\n",
      "Iteration 1652, loss = 3.42141372\n",
      "Iteration 1653, loss = 3.42124835\n",
      "Iteration 1654, loss = 3.42108303\n",
      "Iteration 1655, loss = 3.42091774\n",
      "Iteration 1656, loss = 3.42075249\n",
      "Iteration 1657, loss = 3.42058728\n",
      "Iteration 1658, loss = 3.42042211\n",
      "Iteration 1659, loss = 3.42025698\n",
      "Iteration 1660, loss = 3.42009189\n",
      "Iteration 1661, loss = 3.41992684\n",
      "Iteration 1662, loss = 3.41976182\n",
      "Iteration 1663, loss = 3.41959685\n",
      "Iteration 1664, loss = 3.41943191\n",
      "Iteration 1665, loss = 3.41926701\n",
      "Iteration 1666, loss = 3.41910215\n",
      "Iteration 1667, loss = 3.41893732\n",
      "Iteration 1668, loss = 3.41877253\n",
      "Iteration 1669, loss = 3.41860778\n",
      "Iteration 1670, loss = 3.41844307\n",
      "Iteration 1671, loss = 3.41827840\n",
      "Iteration 1672, loss = 3.41811376\n",
      "Iteration 1673, loss = 3.41794915\n",
      "Iteration 1674, loss = 3.41778459\n",
      "Iteration 1675, loss = 3.41762006\n",
      "Iteration 1676, loss = 3.41745557\n",
      "Iteration 1677, loss = 3.41729111\n",
      "Iteration 1678, loss = 3.41712669\n",
      "Iteration 1679, loss = 3.41696230\n",
      "Iteration 1680, loss = 3.41679795\n",
      "Iteration 1681, loss = 3.41663364\n",
      "Iteration 1682, loss = 3.41646936\n",
      "Iteration 1683, loss = 3.41630512\n",
      "Iteration 1684, loss = 3.41614091\n",
      "Iteration 1685, loss = 3.41597674\n",
      "Iteration 1686, loss = 3.41581260\n",
      "Iteration 1687, loss = 3.41564850\n",
      "Iteration 1688, loss = 3.41548443\n",
      "Iteration 1689, loss = 3.41532039\n",
      "Iteration 1690, loss = 3.41515639\n",
      "Iteration 1691, loss = 3.41499242\n",
      "Iteration 1692, loss = 3.41482849\n",
      "Iteration 1693, loss = 3.41466459\n",
      "Iteration 1694, loss = 3.41450073\n",
      "Iteration 1695, loss = 3.41433689\n",
      "Iteration 1696, loss = 3.41417310\n",
      "Iteration 1697, loss = 3.41400933\n",
      "Iteration 1698, loss = 3.41384560\n",
      "Iteration 1699, loss = 3.41368190\n",
      "Iteration 1700, loss = 3.41351823\n",
      "Iteration 1701, loss = 3.41335460\n",
      "Iteration 1702, loss = 3.41319100\n",
      "Iteration 1703, loss = 3.41302743\n",
      "Iteration 1704, loss = 3.41286389\n",
      "Iteration 1705, loss = 3.41270038\n",
      "Iteration 1706, loss = 3.41253691\n",
      "Iteration 1707, loss = 3.41237347\n",
      "Iteration 1708, loss = 3.41221006\n",
      "Iteration 1709, loss = 3.41204668\n",
      "Iteration 1710, loss = 3.41188334\n",
      "Iteration 1711, loss = 3.41172002\n",
      "Iteration 1712, loss = 3.41155674\n",
      "Iteration 1713, loss = 3.41139348\n",
      "Iteration 1714, loss = 3.41123026\n",
      "Iteration 1715, loss = 3.41106707\n",
      "Iteration 1716, loss = 3.41090391\n",
      "Iteration 1717, loss = 3.41074078\n",
      "Iteration 1718, loss = 3.41057768\n",
      "Iteration 1719, loss = 3.41041460\n",
      "Iteration 1720, loss = 3.41025156\n",
      "Iteration 1721, loss = 3.41008855\n",
      "Iteration 1722, loss = 3.40992557\n",
      "Iteration 1723, loss = 3.40976262\n",
      "Iteration 1724, loss = 3.40959970\n",
      "Iteration 1725, loss = 3.40943681\n",
      "Iteration 1726, loss = 3.40927395\n",
      "Iteration 1727, loss = 3.40911111\n",
      "Iteration 1728, loss = 3.40894831\n",
      "Iteration 1729, loss = 3.40878553\n",
      "Iteration 1730, loss = 3.40862279\n",
      "Iteration 1731, loss = 3.40846007\n",
      "Iteration 1732, loss = 3.40829738\n",
      "Iteration 1733, loss = 3.40813472\n",
      "Iteration 1734, loss = 3.40797208\n",
      "Iteration 1735, loss = 3.40780948\n",
      "Iteration 1736, loss = 3.40764690\n",
      "Iteration 1737, loss = 3.40748435\n",
      "Iteration 1738, loss = 3.40732183\n",
      "Iteration 1739, loss = 3.40715934\n",
      "Iteration 1740, loss = 3.40699687\n",
      "Iteration 1741, loss = 3.40683443\n",
      "Iteration 1742, loss = 3.40667202\n",
      "Iteration 1743, loss = 3.40650964\n",
      "Iteration 1744, loss = 3.40634728\n",
      "Iteration 1745, loss = 3.40618495\n",
      "Iteration 1746, loss = 3.40602264\n",
      "Iteration 1747, loss = 3.40586037\n",
      "Iteration 1748, loss = 3.40569812\n",
      "Iteration 1749, loss = 3.40553589\n",
      "Iteration 1750, loss = 3.40537369\n",
      "Iteration 1751, loss = 3.40521152\n",
      "Iteration 1752, loss = 3.40504938\n",
      "Iteration 1753, loss = 3.40488726\n",
      "Iteration 1754, loss = 3.40472516\n",
      "Iteration 1755, loss = 3.40456309\n",
      "Iteration 1756, loss = 3.40440105\n",
      "Iteration 1757, loss = 3.40423903\n",
      "Iteration 1758, loss = 3.40407704\n",
      "Iteration 1759, loss = 3.40391508\n",
      "Iteration 1760, loss = 3.40375314\n",
      "Iteration 1761, loss = 3.40359122\n",
      "Iteration 1762, loss = 3.40342933\n",
      "Iteration 1763, loss = 3.40326746\n",
      "Iteration 1764, loss = 3.40310562\n",
      "Iteration 1765, loss = 3.40294380\n",
      "Iteration 1766, loss = 3.40278201\n",
      "Iteration 1767, loss = 3.40262024\n",
      "Iteration 1768, loss = 3.40245850\n",
      "Iteration 1769, loss = 3.40229678\n",
      "Iteration 1770, loss = 3.40213508\n",
      "Iteration 1771, loss = 3.40197341\n",
      "Iteration 1772, loss = 3.40181176\n",
      "Iteration 1773, loss = 3.40165014\n",
      "Iteration 1774, loss = 3.40148853\n",
      "Iteration 1775, loss = 3.40132696\n",
      "Iteration 1776, loss = 3.40116540\n",
      "Iteration 1777, loss = 3.40100387\n",
      "Iteration 1778, loss = 3.40084236\n",
      "Iteration 1779, loss = 3.40068088\n",
      "Iteration 1780, loss = 3.40051942\n",
      "Iteration 1781, loss = 3.40035798\n",
      "Iteration 1782, loss = 3.40019656\n",
      "Iteration 1783, loss = 3.40003517\n",
      "Iteration 1784, loss = 3.39987380\n",
      "Iteration 1785, loss = 3.39971245\n",
      "Iteration 1786, loss = 3.39955112\n",
      "Iteration 1787, loss = 3.39938982\n",
      "Iteration 1788, loss = 3.39922854\n",
      "Iteration 1789, loss = 3.39906728\n",
      "Iteration 1790, loss = 3.39890604\n",
      "Iteration 1791, loss = 3.39874482\n",
      "Iteration 1792, loss = 3.39858363\n",
      "Iteration 1793, loss = 3.39842246\n",
      "Iteration 1794, loss = 3.39826131\n",
      "Iteration 1795, loss = 3.39810018\n",
      "Iteration 1796, loss = 3.39793907\n",
      "Iteration 1797, loss = 3.39777798\n",
      "Iteration 1798, loss = 3.39761691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1799, loss = 3.39745587\n",
      "Iteration 1800, loss = 3.39729484\n",
      "Iteration 1801, loss = 3.39713384\n",
      "Iteration 1802, loss = 3.39697286\n",
      "Iteration 1803, loss = 3.39681190\n",
      "Iteration 1804, loss = 3.39665095\n",
      "Iteration 1805, loss = 3.39649003\n",
      "Iteration 1806, loss = 3.39632913\n",
      "Iteration 1807, loss = 3.39616825\n",
      "Iteration 1808, loss = 3.39600739\n",
      "Iteration 1809, loss = 3.39584655\n",
      "Iteration 1810, loss = 3.39568573\n",
      "Iteration 1811, loss = 3.39552493\n",
      "Iteration 1812, loss = 3.39536415\n",
      "Iteration 1813, loss = 3.39520339\n",
      "Iteration 1814, loss = 3.39504265\n",
      "Iteration 1815, loss = 3.39488193\n",
      "Iteration 1816, loss = 3.39472122\n",
      "Iteration 1817, loss = 3.39456054\n",
      "Iteration 1818, loss = 3.39439988\n",
      "Iteration 1819, loss = 3.39423923\n",
      "Iteration 1820, loss = 3.39407861\n",
      "Iteration 1821, loss = 3.39391800\n",
      "Iteration 1822, loss = 3.39375741\n",
      "Iteration 1823, loss = 3.39359684\n",
      "Iteration 1824, loss = 3.39343629\n",
      "Iteration 1825, loss = 3.39327576\n",
      "Iteration 1826, loss = 3.39311525\n",
      "Iteration 1827, loss = 3.39295475\n",
      "Iteration 1828, loss = 3.39279428\n",
      "Iteration 1829, loss = 3.39263382\n",
      "Iteration 1830, loss = 3.39247338\n",
      "Iteration 1831, loss = 3.39231296\n",
      "Iteration 1832, loss = 3.39215255\n",
      "Iteration 1833, loss = 3.39199217\n",
      "Iteration 1834, loss = 3.39183180\n",
      "Iteration 1835, loss = 3.39167145\n",
      "Iteration 1836, loss = 3.39151112\n",
      "Iteration 1837, loss = 3.39135080\n",
      "Iteration 1838, loss = 3.39119051\n",
      "Iteration 1839, loss = 3.39103023\n",
      "Iteration 1840, loss = 3.39086996\n",
      "Iteration 1841, loss = 3.39070972\n",
      "Iteration 1842, loss = 3.39054949\n",
      "Iteration 1843, loss = 3.39038928\n",
      "Iteration 1844, loss = 3.39022908\n",
      "Iteration 1845, loss = 3.39006891\n",
      "Iteration 1846, loss = 3.38990875\n",
      "Iteration 1847, loss = 3.38974860\n",
      "Iteration 1848, loss = 3.38958848\n",
      "Iteration 1849, loss = 3.38942837\n",
      "Iteration 1850, loss = 3.38926827\n",
      "Iteration 1851, loss = 3.38910820\n",
      "Iteration 1852, loss = 3.38894813\n",
      "Iteration 1853, loss = 3.38878809\n",
      "Iteration 1854, loss = 3.38862806\n",
      "Iteration 1855, loss = 3.38846805\n",
      "Iteration 1856, loss = 3.38830805\n",
      "Iteration 1857, loss = 3.38814807\n",
      "Iteration 1858, loss = 3.38798811\n",
      "Iteration 1859, loss = 3.38782816\n",
      "Iteration 1860, loss = 3.38766823\n",
      "Iteration 1861, loss = 3.38750831\n",
      "Iteration 1862, loss = 3.38734841\n",
      "Iteration 1863, loss = 3.38718853\n",
      "Iteration 1864, loss = 3.38702866\n",
      "Iteration 1865, loss = 3.38686880\n",
      "Iteration 1866, loss = 3.38670896\n",
      "Iteration 1867, loss = 3.38654914\n",
      "Iteration 1868, loss = 3.38638933\n",
      "Iteration 1869, loss = 3.38622954\n",
      "Iteration 1870, loss = 3.38606976\n",
      "Iteration 1871, loss = 3.38590999\n",
      "Iteration 1872, loss = 3.38575025\n",
      "Iteration 1873, loss = 3.38559051\n",
      "Iteration 1874, loss = 3.38543079\n",
      "Iteration 1875, loss = 3.38527109\n",
      "Iteration 1876, loss = 3.38511140\n",
      "Iteration 1877, loss = 3.38495172\n",
      "Iteration 1878, loss = 3.38479206\n",
      "Iteration 1879, loss = 3.38463242\n",
      "Iteration 1880, loss = 3.38447279\n",
      "Iteration 1881, loss = 3.38431317\n",
      "Iteration 1882, loss = 3.38415356\n",
      "Iteration 1883, loss = 3.38399398\n",
      "Iteration 1884, loss = 3.38383440\n",
      "Iteration 1885, loss = 3.38367484\n",
      "Iteration 1886, loss = 3.38351529\n",
      "Iteration 1887, loss = 3.38335576\n",
      "Iteration 1888, loss = 3.38319624\n",
      "Iteration 1889, loss = 3.38303673\n",
      "Iteration 1890, loss = 3.38287724\n",
      "Iteration 1891, loss = 3.38271776\n",
      "Iteration 1892, loss = 3.38255830\n",
      "Iteration 1893, loss = 3.38239885\n",
      "Iteration 1894, loss = 3.38223941\n",
      "Iteration 1895, loss = 3.38207999\n",
      "Iteration 1896, loss = 3.38192058\n",
      "Iteration 1897, loss = 3.38176118\n",
      "Iteration 1898, loss = 3.38160179\n",
      "Iteration 1899, loss = 3.38144242\n",
      "Iteration 1900, loss = 3.38128306\n",
      "Iteration 1901, loss = 3.38112372\n",
      "Iteration 1902, loss = 3.38096439\n",
      "Iteration 1903, loss = 3.38080507\n",
      "Iteration 1904, loss = 3.38064576\n",
      "Iteration 1905, loss = 3.38048647\n",
      "Iteration 1906, loss = 3.38032719\n",
      "Iteration 1907, loss = 3.38016792\n",
      "Iteration 1908, loss = 3.38000866\n",
      "Iteration 1909, loss = 3.37984942\n",
      "Iteration 1910, loss = 3.37969019\n",
      "Iteration 1911, loss = 3.37953097\n",
      "Iteration 1912, loss = 3.37937176\n",
      "Iteration 1913, loss = 3.37921257\n",
      "Iteration 1914, loss = 3.37905339\n",
      "Iteration 1915, loss = 3.37889422\n",
      "Iteration 1916, loss = 3.37873506\n",
      "Iteration 1917, loss = 3.37857592\n",
      "Iteration 1918, loss = 3.37841678\n",
      "Iteration 1919, loss = 3.37825766\n",
      "Iteration 1920, loss = 3.37809855\n",
      "Iteration 1921, loss = 3.37793945\n",
      "Iteration 1922, loss = 3.37778037\n",
      "Iteration 1923, loss = 3.37762130\n",
      "Iteration 1924, loss = 3.37746223\n",
      "Iteration 1925, loss = 3.37730318\n",
      "Iteration 1926, loss = 3.37714414\n",
      "Iteration 1927, loss = 3.37698512\n",
      "Iteration 1928, loss = 3.37682610\n",
      "Iteration 1929, loss = 3.37666710\n",
      "Iteration 1930, loss = 3.37650810\n",
      "Iteration 1931, loss = 3.37634912\n",
      "Iteration 1932, loss = 3.37619015\n",
      "Iteration 1933, loss = 3.37603119\n",
      "Iteration 1934, loss = 3.37587225\n",
      "Iteration 1935, loss = 3.37571331\n",
      "Iteration 1936, loss = 3.37555438\n",
      "Iteration 1937, loss = 3.37539547\n",
      "Iteration 1938, loss = 3.37523656\n",
      "Iteration 1939, loss = 3.37507767\n",
      "Iteration 1940, loss = 3.37491879\n",
      "Iteration 1941, loss = 3.37475992\n",
      "Iteration 1942, loss = 3.37460106\n",
      "Iteration 1943, loss = 3.37444221\n",
      "Iteration 1944, loss = 3.37428337\n",
      "Iteration 1945, loss = 3.37412454\n",
      "Iteration 1946, loss = 3.37396572\n",
      "Iteration 1947, loss = 3.37380692\n",
      "Iteration 1948, loss = 3.37364812\n",
      "Iteration 1949, loss = 3.37348933\n",
      "Iteration 1950, loss = 3.37333056\n",
      "Iteration 1951, loss = 3.37317179\n",
      "Iteration 1952, loss = 3.37301304\n",
      "Iteration 1953, loss = 3.37285429\n",
      "Iteration 1954, loss = 3.37269556\n",
      "Iteration 1955, loss = 3.37253684\n",
      "Iteration 1956, loss = 3.37237812\n",
      "Iteration 1957, loss = 3.37221942\n",
      "Iteration 1958, loss = 3.37206072\n",
      "Iteration 1959, loss = 3.37190204\n",
      "Iteration 1960, loss = 3.37174336\n",
      "Iteration 1961, loss = 3.37158470\n",
      "Iteration 1962, loss = 3.37142605\n",
      "Iteration 1963, loss = 3.37126740\n",
      "Iteration 1964, loss = 3.37110877\n",
      "Iteration 1965, loss = 3.37095014\n",
      "Iteration 1966, loss = 3.37079153\n",
      "Iteration 1967, loss = 3.37063292\n",
      "Iteration 1968, loss = 3.37047432\n",
      "Iteration 1969, loss = 3.37031574\n",
      "Iteration 1970, loss = 3.37015716\n",
      "Iteration 1971, loss = 3.36999859\n",
      "Iteration 1972, loss = 3.36984004\n",
      "Iteration 1973, loss = 3.36968149\n",
      "Iteration 1974, loss = 3.36952295\n",
      "Iteration 1975, loss = 3.36936442\n",
      "Iteration 1976, loss = 3.36920590\n",
      "Iteration 1977, loss = 3.36904739\n",
      "Iteration 1978, loss = 3.36888888\n",
      "Iteration 1979, loss = 3.36873039\n",
      "Iteration 1980, loss = 3.36857191\n",
      "Iteration 1981, loss = 3.36841343\n",
      "Iteration 1982, loss = 3.36825497\n",
      "Iteration 1983, loss = 3.36809651\n",
      "Iteration 1984, loss = 3.36793806\n",
      "Iteration 1985, loss = 3.36777963\n",
      "Iteration 1986, loss = 3.36762120\n",
      "Iteration 1987, loss = 3.36746278\n",
      "Iteration 1988, loss = 3.36730436\n",
      "Iteration 1989, loss = 3.36714596\n",
      "Iteration 1990, loss = 3.36698757\n",
      "Iteration 1991, loss = 3.36682918\n",
      "Iteration 1992, loss = 3.36667080\n",
      "Iteration 1993, loss = 3.36651244\n",
      "Iteration 1994, loss = 3.36635408\n",
      "Iteration 1995, loss = 3.36619572\n",
      "Iteration 1996, loss = 3.36603738\n",
      "Iteration 1997, loss = 3.36587905\n",
      "Iteration 1998, loss = 3.36572072\n",
      "Iteration 1999, loss = 3.36556241\n",
      "Iteration 2000, loss = 3.36540410\n",
      "Iteration 1, loss = 4.92708450\n",
      "Iteration 2, loss = 4.90818501\n",
      "Iteration 3, loss = 4.88191501\n",
      "Iteration 4, loss = 4.84969595\n",
      "Iteration 5, loss = 4.81291643\n",
      "Iteration 6, loss = 4.77289534\n",
      "Iteration 7, loss = 4.73085200\n",
      "Iteration 8, loss = 4.68788254\n",
      "Iteration 9, loss = 4.64494268\n",
      "Iteration 10, loss = 4.60283714\n",
      "Iteration 11, loss = 4.56221586\n",
      "Iteration 12, loss = 4.52357682\n",
      "Iteration 13, loss = 4.48727472\n",
      "Iteration 14, loss = 4.45353462\n",
      "Iteration 15, loss = 4.42246887\n",
      "Iteration 16, loss = 4.39409591\n",
      "Iteration 17, loss = 4.36835949\n",
      "Iteration 18, loss = 4.34514709\n",
      "Iteration 19, loss = 4.32430654\n",
      "Iteration 20, loss = 4.30566050\n",
      "Iteration 21, loss = 4.28901838\n",
      "Iteration 22, loss = 4.27418581\n",
      "Iteration 23, loss = 4.26097179\n",
      "Iteration 24, loss = 4.24919387\n",
      "Iteration 25, loss = 4.23868156\n",
      "Iteration 26, loss = 4.22927839\n",
      "Iteration 27, loss = 4.22084293\n",
      "Iteration 28, loss = 4.21324891\n",
      "Iteration 29, loss = 4.20638485\n",
      "Iteration 30, loss = 4.20015326\n",
      "Iteration 31, loss = 4.19446952\n",
      "Iteration 32, loss = 4.18926075\n",
      "Iteration 33, loss = 4.18446447\n",
      "Iteration 34, loss = 4.18002743\n",
      "Iteration 35, loss = 4.17590433\n",
      "Iteration 36, loss = 4.17205679\n",
      "Iteration 37, loss = 4.16845221\n",
      "Iteration 38, loss = 4.16506297\n",
      "Iteration 39, loss = 4.16186555\n",
      "Iteration 40, loss = 4.15883985\n",
      "Iteration 41, loss = 4.15596857\n",
      "Iteration 42, loss = 4.15323676\n",
      "Iteration 43, loss = 4.15063134\n",
      "Iteration 44, loss = 4.14814079\n",
      "Iteration 45, loss = 4.14575485\n",
      "Iteration 46, loss = 4.14346432\n",
      "Iteration 47, loss = 4.14126087\n",
      "Iteration 48, loss = 4.13913691\n",
      "Iteration 49, loss = 4.13708548\n",
      "Iteration 50, loss = 4.13510017\n",
      "Iteration 51, loss = 4.13317507\n",
      "Iteration 52, loss = 4.13130474\n",
      "Iteration 53, loss = 4.12948411\n",
      "Iteration 54, loss = 4.12770855\n",
      "Iteration 55, loss = 4.12597377\n",
      "Iteration 56, loss = 4.12427582\n",
      "Iteration 57, loss = 4.12261110\n",
      "Iteration 58, loss = 4.12097631\n",
      "Iteration 59, loss = 4.11936846\n",
      "Iteration 60, loss = 4.11778484\n",
      "Iteration 61, loss = 4.11622300\n",
      "Iteration 62, loss = 4.11468073\n",
      "Iteration 63, loss = 4.11315606\n",
      "Iteration 64, loss = 4.11164724\n",
      "Iteration 65, loss = 4.11015269\n",
      "Iteration 66, loss = 4.10867103\n",
      "Iteration 67, loss = 4.10720103\n",
      "Iteration 68, loss = 4.10574160\n",
      "Iteration 69, loss = 4.10429180\n",
      "Iteration 70, loss = 4.10285079\n",
      "Iteration 71, loss = 4.10141783\n",
      "Iteration 72, loss = 4.09999228\n",
      "Iteration 73, loss = 4.09857357\n",
      "Iteration 74, loss = 4.09716121\n",
      "Iteration 75, loss = 4.09575476\n",
      "Iteration 76, loss = 4.09435385\n",
      "Iteration 77, loss = 4.09295814\n",
      "Iteration 78, loss = 4.09156732\n",
      "Iteration 79, loss = 4.09018114\n",
      "Iteration 80, loss = 4.08879936\n",
      "Iteration 81, loss = 4.08742178\n",
      "Iteration 82, loss = 4.08604820\n",
      "Iteration 83, loss = 4.08467846\n",
      "Iteration 84, loss = 4.08331240\n",
      "Iteration 85, loss = 4.08194988\n",
      "Iteration 86, loss = 4.08059078\n",
      "Iteration 87, loss = 4.07923496\n",
      "Iteration 88, loss = 4.07788232\n",
      "Iteration 89, loss = 4.07653276\n",
      "Iteration 90, loss = 4.07518617\n",
      "Iteration 91, loss = 4.07384245\n",
      "Iteration 92, loss = 4.07250153\n",
      "Iteration 93, loss = 4.07116330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 94, loss = 4.06982770\n",
      "Iteration 95, loss = 4.06849464\n",
      "Iteration 96, loss = 4.06716403\n",
      "Iteration 97, loss = 4.06583582\n",
      "Iteration 98, loss = 4.06450993\n",
      "Iteration 99, loss = 4.06318628\n",
      "Iteration 100, loss = 4.06186482\n",
      "Iteration 101, loss = 4.06054548\n",
      "Iteration 102, loss = 4.05922820\n",
      "Iteration 103, loss = 4.05791293\n",
      "Iteration 104, loss = 4.05659960\n",
      "Iteration 105, loss = 4.05528816\n",
      "Iteration 106, loss = 4.05397857\n",
      "Iteration 107, loss = 4.05267078\n",
      "Iteration 108, loss = 4.05136474\n",
      "Iteration 109, loss = 4.05006041\n",
      "Iteration 110, loss = 4.04875776\n",
      "Iteration 111, loss = 4.04745674\n",
      "Iteration 112, loss = 4.04615733\n",
      "Iteration 113, loss = 4.04485950\n",
      "Iteration 114, loss = 4.04356321\n",
      "Iteration 115, loss = 4.04226844\n",
      "Iteration 116, loss = 4.04097517\n",
      "Iteration 117, loss = 4.03968338\n",
      "Iteration 118, loss = 4.03839305\n",
      "Iteration 119, loss = 4.03710417\n",
      "Iteration 120, loss = 4.03581673\n",
      "Iteration 121, loss = 4.03453070\n",
      "Iteration 122, loss = 4.03324609\n",
      "Iteration 123, loss = 4.03196289\n",
      "Iteration 124, loss = 4.03068109\n",
      "Iteration 125, loss = 4.02940070\n",
      "Iteration 126, loss = 4.02812170\n",
      "Iteration 127, loss = 4.02684411\n",
      "Iteration 128, loss = 4.02556793\n",
      "Iteration 129, loss = 4.02429315\n",
      "Iteration 130, loss = 4.02301979\n",
      "Iteration 131, loss = 4.02174785\n",
      "Iteration 132, loss = 4.02047735\n",
      "Iteration 133, loss = 4.01920830\n",
      "Iteration 134, loss = 4.01794070\n",
      "Iteration 135, loss = 4.01667458\n",
      "Iteration 136, loss = 4.01540994\n",
      "Iteration 137, loss = 4.01414681\n",
      "Iteration 138, loss = 4.01288520\n",
      "Iteration 139, loss = 4.01162514\n",
      "Iteration 140, loss = 4.01036663\n",
      "Iteration 141, loss = 4.00910972\n",
      "Iteration 142, loss = 4.00785441\n",
      "Iteration 143, loss = 4.00660073\n",
      "Iteration 144, loss = 4.00534872\n",
      "Iteration 145, loss = 4.00409839\n",
      "Iteration 146, loss = 4.00284977\n",
      "Iteration 147, loss = 4.00160290\n",
      "Iteration 148, loss = 4.00035779\n",
      "Iteration 149, loss = 3.99911449\n",
      "Iteration 150, loss = 3.99787303\n",
      "Iteration 151, loss = 3.99663343\n",
      "Iteration 152, loss = 3.99539573\n",
      "Iteration 153, loss = 3.99415997\n",
      "Iteration 154, loss = 3.99292618\n",
      "Iteration 155, loss = 3.99169439\n",
      "Iteration 156, loss = 3.99046465\n",
      "Iteration 157, loss = 3.98923699\n",
      "Iteration 158, loss = 3.98801145\n",
      "Iteration 159, loss = 3.98678807\n",
      "Iteration 160, loss = 3.98556689\n",
      "Iteration 161, loss = 3.98434795\n",
      "Iteration 162, loss = 3.98313129\n",
      "Iteration 163, loss = 3.98191695\n",
      "Iteration 164, loss = 3.98070497\n",
      "Iteration 165, loss = 3.97949540\n",
      "Iteration 166, loss = 3.97828828\n",
      "Iteration 167, loss = 3.97708366\n",
      "Iteration 168, loss = 3.97588157\n",
      "Iteration 169, loss = 3.97468206\n",
      "Iteration 170, loss = 3.97348518\n",
      "Iteration 171, loss = 3.97229098\n",
      "Iteration 172, loss = 3.97109949\n",
      "Iteration 173, loss = 3.96991076\n",
      "Iteration 174, loss = 3.96872484\n",
      "Iteration 175, loss = 3.96754178\n",
      "Iteration 176, loss = 3.96636161\n",
      "Iteration 177, loss = 3.96518440\n",
      "Iteration 178, loss = 3.96401018\n",
      "Iteration 179, loss = 3.96283899\n",
      "Iteration 180, loss = 3.96167090\n",
      "Iteration 181, loss = 3.96050594\n",
      "Iteration 182, loss = 3.95934416\n",
      "Iteration 183, loss = 3.95818560\n",
      "Iteration 184, loss = 3.95703032\n",
      "Iteration 185, loss = 3.95587836\n",
      "Iteration 186, loss = 3.95472976\n",
      "Iteration 187, loss = 3.95358458\n",
      "Iteration 188, loss = 3.95244285\n",
      "Iteration 189, loss = 3.95130462\n",
      "Iteration 190, loss = 3.95016994\n",
      "Iteration 191, loss = 3.94903886\n",
      "Iteration 192, loss = 3.94791141\n",
      "Iteration 193, loss = 3.94678764\n",
      "Iteration 194, loss = 3.94566760\n",
      "Iteration 195, loss = 3.94455132\n",
      "Iteration 196, loss = 3.94343886\n",
      "Iteration 197, loss = 3.94233025\n",
      "Iteration 198, loss = 3.94122553\n",
      "Iteration 199, loss = 3.94012475\n",
      "Iteration 200, loss = 3.93902795\n",
      "Iteration 201, loss = 3.93793517\n",
      "Iteration 202, loss = 3.93684645\n",
      "Iteration 203, loss = 3.93576182\n",
      "Iteration 204, loss = 3.93468133\n",
      "Iteration 205, loss = 3.93360501\n",
      "Iteration 206, loss = 3.93253289\n",
      "Iteration 207, loss = 3.93146503\n",
      "Iteration 208, loss = 3.93040144\n",
      "Iteration 209, loss = 3.92934217\n",
      "Iteration 210, loss = 3.92828726\n",
      "Iteration 211, loss = 3.92723672\n",
      "Iteration 212, loss = 3.92619060\n",
      "Iteration 213, loss = 3.92514892\n",
      "Iteration 214, loss = 3.92411172\n",
      "Iteration 215, loss = 3.92307903\n",
      "Iteration 216, loss = 3.92205088\n",
      "Iteration 217, loss = 3.92102729\n",
      "Iteration 218, loss = 3.92000829\n",
      "Iteration 219, loss = 3.91899390\n",
      "Iteration 220, loss = 3.91798416\n",
      "Iteration 221, loss = 3.91697908\n",
      "Iteration 222, loss = 3.91597870\n",
      "Iteration 223, loss = 3.91498302\n",
      "Iteration 224, loss = 3.91399208\n",
      "Iteration 225, loss = 3.91300590\n",
      "Iteration 226, loss = 3.91202448\n",
      "Iteration 227, loss = 3.91104786\n",
      "Iteration 228, loss = 3.91007605\n",
      "Iteration 229, loss = 3.90910906\n",
      "Iteration 230, loss = 3.90814691\n",
      "Iteration 231, loss = 3.90718962\n",
      "Iteration 232, loss = 3.90623720\n",
      "Iteration 233, loss = 3.90528966\n",
      "Iteration 234, loss = 3.90434701\n",
      "Iteration 235, loss = 3.90340926\n",
      "Iteration 236, loss = 3.90247643\n",
      "Iteration 237, loss = 3.90154852\n",
      "Iteration 238, loss = 3.90062554\n",
      "Iteration 239, loss = 3.89970749\n",
      "Iteration 240, loss = 3.89879438\n",
      "Iteration 241, loss = 3.89788622\n",
      "Iteration 242, loss = 3.89698300\n",
      "Iteration 243, loss = 3.89608474\n",
      "Iteration 244, loss = 3.89519143\n",
      "Iteration 245, loss = 3.89430307\n",
      "Iteration 246, loss = 3.89341966\n",
      "Iteration 247, loss = 3.89254121\n",
      "Iteration 248, loss = 3.89166770\n",
      "Iteration 249, loss = 3.89079914\n",
      "Iteration 250, loss = 3.88993553\n",
      "Iteration 251, loss = 3.88907685\n",
      "Iteration 252, loss = 3.88822310\n",
      "Iteration 253, loss = 3.88737427\n",
      "Iteration 254, loss = 3.88653037\n",
      "Iteration 255, loss = 3.88569137\n",
      "Iteration 256, loss = 3.88485727\n",
      "Iteration 257, loss = 3.88402805\n",
      "Iteration 258, loss = 3.88320372\n",
      "Iteration 259, loss = 3.88238425\n",
      "Iteration 260, loss = 3.88156964\n",
      "Iteration 261, loss = 3.88075987\n",
      "Iteration 262, loss = 3.87995492\n",
      "Iteration 263, loss = 3.87915479\n",
      "Iteration 264, loss = 3.87835945\n",
      "Iteration 265, loss = 3.87756889\n",
      "Iteration 266, loss = 3.87678310\n",
      "Iteration 267, loss = 3.87600205\n",
      "Iteration 268, loss = 3.87522572\n",
      "Iteration 269, loss = 3.87445411\n",
      "Iteration 270, loss = 3.87368718\n",
      "Iteration 271, loss = 3.87292492\n",
      "Iteration 272, loss = 3.87216731\n",
      "Iteration 273, loss = 3.87141432\n",
      "Iteration 274, loss = 3.87066594\n",
      "Iteration 275, loss = 3.86992214\n",
      "Iteration 276, loss = 3.86918290\n",
      "Iteration 277, loss = 3.86844820\n",
      "Iteration 278, loss = 3.86771800\n",
      "Iteration 279, loss = 3.86699229\n",
      "Iteration 280, loss = 3.86627104\n",
      "Iteration 281, loss = 3.86555423\n",
      "Iteration 282, loss = 3.86484183\n",
      "Iteration 283, loss = 3.86413381\n",
      "Iteration 284, loss = 3.86343015\n",
      "Iteration 285, loss = 3.86273081\n",
      "Iteration 286, loss = 3.86203578\n",
      "Iteration 287, loss = 3.86134503\n",
      "Iteration 288, loss = 3.86065852\n",
      "Iteration 289, loss = 3.85997622\n",
      "Iteration 290, loss = 3.85929812\n",
      "Iteration 291, loss = 3.85862417\n",
      "Iteration 292, loss = 3.85795436\n",
      "Iteration 293, loss = 3.85728864\n",
      "Iteration 294, loss = 3.85662700\n",
      "Iteration 295, loss = 3.85596939\n",
      "Iteration 296, loss = 3.85531580\n",
      "Iteration 297, loss = 3.85466618\n",
      "Iteration 298, loss = 3.85402051\n",
      "Iteration 299, loss = 3.85337876\n",
      "Iteration 300, loss = 3.85274090\n",
      "Iteration 301, loss = 3.85210689\n",
      "Iteration 302, loss = 3.85147670\n",
      "Iteration 303, loss = 3.85085031\n",
      "Iteration 304, loss = 3.85022768\n",
      "Iteration 305, loss = 3.84960877\n",
      "Iteration 306, loss = 3.84899356\n",
      "Iteration 307, loss = 3.84838201\n",
      "Iteration 308, loss = 3.84777410\n",
      "Iteration 309, loss = 3.84716979\n",
      "Iteration 310, loss = 3.84656904\n",
      "Iteration 311, loss = 3.84597184\n",
      "Iteration 312, loss = 3.84537813\n",
      "Iteration 313, loss = 3.84478790\n",
      "Iteration 314, loss = 3.84420111\n",
      "Iteration 315, loss = 3.84361772\n",
      "Iteration 316, loss = 3.84303771\n",
      "Iteration 317, loss = 3.84246104\n",
      "Iteration 318, loss = 3.84188769\n",
      "Iteration 319, loss = 3.84131761\n",
      "Iteration 320, loss = 3.84075078\n",
      "Iteration 321, loss = 3.84018717\n",
      "Iteration 322, loss = 3.83962674\n",
      "Iteration 323, loss = 3.83906946\n",
      "Iteration 324, loss = 3.83851530\n",
      "Iteration 325, loss = 3.83796423\n",
      "Iteration 326, loss = 3.83741621\n",
      "Iteration 327, loss = 3.83687123\n",
      "Iteration 328, loss = 3.83632923\n",
      "Iteration 329, loss = 3.83579020\n",
      "Iteration 330, loss = 3.83525411\n",
      "Iteration 331, loss = 3.83472091\n",
      "Iteration 332, loss = 3.83419058\n",
      "Iteration 333, loss = 3.83366310\n",
      "Iteration 334, loss = 3.83313843\n",
      "Iteration 335, loss = 3.83261653\n",
      "Iteration 336, loss = 3.83209739\n",
      "Iteration 337, loss = 3.83158096\n",
      "Iteration 338, loss = 3.83106723\n",
      "Iteration 339, loss = 3.83055616\n",
      "Iteration 340, loss = 3.83004772\n",
      "Iteration 341, loss = 3.82954188\n",
      "Iteration 342, loss = 3.82903862\n",
      "Iteration 343, loss = 3.82853790\n",
      "Iteration 344, loss = 3.82803969\n",
      "Iteration 345, loss = 3.82754398\n",
      "Iteration 346, loss = 3.82705072\n",
      "Iteration 347, loss = 3.82655990\n",
      "Iteration 348, loss = 3.82607148\n",
      "Iteration 349, loss = 3.82558544\n",
      "Iteration 350, loss = 3.82510175\n",
      "Iteration 351, loss = 3.82462038\n",
      "Iteration 352, loss = 3.82414130\n",
      "Iteration 353, loss = 3.82366450\n",
      "Iteration 354, loss = 3.82318994\n",
      "Iteration 355, loss = 3.82271760\n",
      "Iteration 356, loss = 3.82224744\n",
      "Iteration 357, loss = 3.82177946\n",
      "Iteration 358, loss = 3.82131361\n",
      "Iteration 359, loss = 3.82084988\n",
      "Iteration 360, loss = 3.82038823\n",
      "Iteration 361, loss = 3.81992866\n",
      "Iteration 362, loss = 3.81947112\n",
      "Iteration 363, loss = 3.81901560\n",
      "Iteration 364, loss = 3.81856207\n",
      "Iteration 365, loss = 3.81811051\n",
      "Iteration 366, loss = 3.81766090\n",
      "Iteration 367, loss = 3.81721321\n",
      "Iteration 368, loss = 3.81676742\n",
      "Iteration 369, loss = 3.81632350\n",
      "Iteration 370, loss = 3.81588144\n",
      "Iteration 371, loss = 3.81544121\n",
      "Iteration 372, loss = 3.81500279\n",
      "Iteration 373, loss = 3.81456615\n",
      "Iteration 374, loss = 3.81413128\n",
      "Iteration 375, loss = 3.81369816\n",
      "Iteration 376, loss = 3.81326676\n",
      "Iteration 377, loss = 3.81283706\n",
      "Iteration 378, loss = 3.81240905\n",
      "Iteration 379, loss = 3.81198270\n",
      "Iteration 380, loss = 3.81155798\n",
      "Iteration 381, loss = 3.81113489\n",
      "Iteration 382, loss = 3.81071341\n",
      "Iteration 383, loss = 3.81029350\n",
      "Iteration 384, loss = 3.80987516\n",
      "Iteration 385, loss = 3.80945836\n",
      "Iteration 386, loss = 3.80904309\n",
      "Iteration 387, loss = 3.80862932\n",
      "Iteration 388, loss = 3.80821705\n",
      "Iteration 389, loss = 3.80780624\n",
      "Iteration 390, loss = 3.80739689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 391, loss = 3.80698897\n",
      "Iteration 392, loss = 3.80658247\n",
      "Iteration 393, loss = 3.80617738\n",
      "Iteration 394, loss = 3.80577366\n",
      "Iteration 395, loss = 3.80537131\n",
      "Iteration 396, loss = 3.80497031\n",
      "Iteration 397, loss = 3.80457065\n",
      "Iteration 398, loss = 3.80417231\n",
      "Iteration 399, loss = 3.80377526\n",
      "Iteration 400, loss = 3.80337951\n",
      "Iteration 401, loss = 3.80298502\n",
      "Iteration 402, loss = 3.80259179\n",
      "Iteration 403, loss = 3.80219980\n",
      "Iteration 404, loss = 3.80180904\n",
      "Iteration 405, loss = 3.80141948\n",
      "Iteration 406, loss = 3.80103113\n",
      "Iteration 407, loss = 3.80064395\n",
      "Iteration 408, loss = 3.80025795\n",
      "Iteration 409, loss = 3.79987310\n",
      "Iteration 410, loss = 3.79948939\n",
      "Iteration 411, loss = 3.79910680\n",
      "Iteration 412, loss = 3.79872533\n",
      "Iteration 413, loss = 3.79834496\n",
      "Iteration 414, loss = 3.79796568\n",
      "Iteration 415, loss = 3.79758748\n",
      "Iteration 416, loss = 3.79721033\n",
      "Iteration 417, loss = 3.79683424\n",
      "Iteration 418, loss = 3.79645918\n",
      "Iteration 419, loss = 3.79608515\n",
      "Iteration 420, loss = 3.79571213\n",
      "Iteration 421, loss = 3.79534012\n",
      "Iteration 422, loss = 3.79496909\n",
      "Iteration 423, loss = 3.79459905\n",
      "Iteration 424, loss = 3.79422997\n",
      "Iteration 425, loss = 3.79386185\n",
      "Iteration 426, loss = 3.79349467\n",
      "Iteration 427, loss = 3.79312843\n",
      "Iteration 428, loss = 3.79276311\n",
      "Iteration 429, loss = 3.79239871\n",
      "Iteration 430, loss = 3.79203521\n",
      "Iteration 431, loss = 3.79167260\n",
      "Iteration 432, loss = 3.79131088\n",
      "Iteration 433, loss = 3.79095003\n",
      "Iteration 434, loss = 3.79059004\n",
      "Iteration 435, loss = 3.79023091\n",
      "Iteration 436, loss = 3.78987262\n",
      "Iteration 437, loss = 3.78951517\n",
      "Iteration 438, loss = 3.78915855\n",
      "Iteration 439, loss = 3.78880274\n",
      "Iteration 440, loss = 3.78844774\n",
      "Iteration 441, loss = 3.78809354\n",
      "Iteration 442, loss = 3.78774013\n",
      "Iteration 443, loss = 3.78738751\n",
      "Iteration 444, loss = 3.78703566\n",
      "Iteration 445, loss = 3.78668457\n",
      "Iteration 446, loss = 3.78633424\n",
      "Iteration 447, loss = 3.78598466\n",
      "Iteration 448, loss = 3.78563583\n",
      "Iteration 449, loss = 3.78528772\n",
      "Iteration 450, loss = 3.78494035\n",
      "Iteration 451, loss = 3.78459369\n",
      "Iteration 452, loss = 3.78424775\n",
      "Iteration 453, loss = 3.78390251\n",
      "Iteration 454, loss = 3.78355796\n",
      "Iteration 455, loss = 3.78321411\n",
      "Iteration 456, loss = 3.78287094\n",
      "Iteration 457, loss = 3.78252844\n",
      "Iteration 458, loss = 3.78218662\n",
      "Iteration 459, loss = 3.78184545\n",
      "Iteration 460, loss = 3.78150495\n",
      "Iteration 461, loss = 3.78116509\n",
      "Iteration 462, loss = 3.78082588\n",
      "Iteration 463, loss = 3.78048730\n",
      "Iteration 464, loss = 3.78014935\n",
      "Iteration 465, loss = 3.77981203\n",
      "Iteration 466, loss = 3.77947533\n",
      "Iteration 467, loss = 3.77913924\n",
      "Iteration 468, loss = 3.77880376\n",
      "Iteration 469, loss = 3.77846888\n",
      "Iteration 470, loss = 3.77813459\n",
      "Iteration 471, loss = 3.77780089\n",
      "Iteration 472, loss = 3.77746778\n",
      "Iteration 473, loss = 3.77713525\n",
      "Iteration 474, loss = 3.77680329\n",
      "Iteration 475, loss = 3.77647191\n",
      "Iteration 476, loss = 3.77614108\n",
      "Iteration 477, loss = 3.77581081\n",
      "Iteration 478, loss = 3.77548110\n",
      "Iteration 479, loss = 3.77515194\n",
      "Iteration 480, loss = 3.77482331\n",
      "Iteration 481, loss = 3.77449523\n",
      "Iteration 482, loss = 3.77416769\n",
      "Iteration 483, loss = 3.77384067\n",
      "Iteration 484, loss = 3.77351418\n",
      "Iteration 485, loss = 3.77318821\n",
      "Iteration 486, loss = 3.77286275\n",
      "Iteration 487, loss = 3.77253781\n",
      "Iteration 488, loss = 3.77221337\n",
      "Iteration 489, loss = 3.77188944\n",
      "Iteration 490, loss = 3.77156601\n",
      "Iteration 491, loss = 3.77124307\n",
      "Iteration 492, loss = 3.77092063\n",
      "Iteration 493, loss = 3.77059867\n",
      "Iteration 494, loss = 3.77027720\n",
      "Iteration 495, loss = 3.76995620\n",
      "Iteration 496, loss = 3.76963568\n",
      "Iteration 497, loss = 3.76931564\n",
      "Iteration 498, loss = 3.76899606\n",
      "Iteration 499, loss = 3.76867695\n",
      "Iteration 500, loss = 3.76835830\n",
      "Iteration 501, loss = 3.76804010\n",
      "Iteration 502, loss = 3.76772236\n",
      "Iteration 503, loss = 3.76740508\n",
      "Iteration 504, loss = 3.76708823\n",
      "Iteration 505, loss = 3.76677184\n",
      "Iteration 506, loss = 3.76645588\n",
      "Iteration 507, loss = 3.76614037\n",
      "Iteration 508, loss = 3.76582529\n",
      "Iteration 509, loss = 3.76551064\n",
      "Iteration 510, loss = 3.76519642\n",
      "Iteration 511, loss = 3.76488262\n",
      "Iteration 512, loss = 3.76456925\n",
      "Iteration 513, loss = 3.76425629\n",
      "Iteration 514, loss = 3.76394376\n",
      "Iteration 515, loss = 3.76363164\n",
      "Iteration 516, loss = 3.76331993\n",
      "Iteration 517, loss = 3.76300863\n",
      "Iteration 518, loss = 3.76269773\n",
      "Iteration 519, loss = 3.76238724\n",
      "Iteration 520, loss = 3.76207715\n",
      "Iteration 521, loss = 3.76176746\n",
      "Iteration 522, loss = 3.76145816\n",
      "Iteration 523, loss = 3.76114926\n",
      "Iteration 524, loss = 3.76084074\n",
      "Iteration 525, loss = 3.76053262\n",
      "Iteration 526, loss = 3.76022488\n",
      "Iteration 527, loss = 3.75991752\n",
      "Iteration 528, loss = 3.75961055\n",
      "Iteration 529, loss = 3.75930395\n",
      "Iteration 530, loss = 3.75899774\n",
      "Iteration 531, loss = 3.75869189\n",
      "Iteration 532, loss = 3.75838642\n",
      "Iteration 533, loss = 3.75808132\n",
      "Iteration 534, loss = 3.75777659\n",
      "Iteration 535, loss = 3.75747222\n",
      "Iteration 536, loss = 3.75716822\n",
      "Iteration 537, loss = 3.75686458\n",
      "Iteration 538, loss = 3.75656129\n",
      "Iteration 539, loss = 3.75625837\n",
      "Iteration 540, loss = 3.75595580\n",
      "Iteration 541, loss = 3.75565359\n",
      "Iteration 542, loss = 3.75535173\n",
      "Iteration 543, loss = 3.75505022\n",
      "Iteration 544, loss = 3.75474906\n",
      "Iteration 545, loss = 3.75444824\n",
      "Iteration 546, loss = 3.75414777\n",
      "Iteration 547, loss = 3.75384765\n",
      "Iteration 548, loss = 3.75354786\n",
      "Iteration 549, loss = 3.75324842\n",
      "Iteration 550, loss = 3.75294931\n",
      "Iteration 551, loss = 3.75265054\n",
      "Iteration 552, loss = 3.75235211\n",
      "Iteration 553, loss = 3.75205401\n",
      "Iteration 554, loss = 3.75175624\n",
      "Iteration 555, loss = 3.75145880\n",
      "Iteration 556, loss = 3.75116169\n",
      "Iteration 557, loss = 3.75086490\n",
      "Iteration 558, loss = 3.75056845\n",
      "Iteration 559, loss = 3.75027232\n",
      "Iteration 560, loss = 3.74997651\n",
      "Iteration 561, loss = 3.74968102\n",
      "Iteration 562, loss = 3.74938585\n",
      "Iteration 563, loss = 3.74909100\n",
      "Iteration 564, loss = 3.74879647\n",
      "Iteration 565, loss = 3.74850225\n",
      "Iteration 566, loss = 3.74820835\n",
      "Iteration 567, loss = 3.74791476\n",
      "Iteration 568, loss = 3.74762149\n",
      "Iteration 569, loss = 3.74732852\n",
      "Iteration 570, loss = 3.74703587\n",
      "Iteration 571, loss = 3.74674352\n",
      "Iteration 572, loss = 3.74645148\n",
      "Iteration 573, loss = 3.74615975\n",
      "Iteration 574, loss = 3.74586832\n",
      "Iteration 575, loss = 3.74557719\n",
      "Iteration 576, loss = 3.74528637\n",
      "Iteration 577, loss = 3.74499585\n",
      "Iteration 578, loss = 3.74470563\n",
      "Iteration 579, loss = 3.74441571\n",
      "Iteration 580, loss = 3.74412609\n",
      "Iteration 581, loss = 3.74383676\n",
      "Iteration 582, loss = 3.74354773\n",
      "Iteration 583, loss = 3.74325900\n",
      "Iteration 584, loss = 3.74297055\n",
      "Iteration 585, loss = 3.74268241\n",
      "Iteration 586, loss = 3.74239455\n",
      "Iteration 587, loss = 3.74210698\n",
      "Iteration 588, loss = 3.74181971\n",
      "Iteration 589, loss = 3.74153272\n",
      "Iteration 590, loss = 3.74124603\n",
      "Iteration 591, loss = 3.74095961\n",
      "Iteration 592, loss = 3.74067349\n",
      "Iteration 593, loss = 3.74038765\n",
      "Iteration 594, loss = 3.74010210\n",
      "Iteration 595, loss = 3.73981682\n",
      "Iteration 596, loss = 3.73953183\n",
      "Iteration 597, loss = 3.73924713\n",
      "Iteration 598, loss = 3.73896270\n",
      "Iteration 599, loss = 3.73867856\n",
      "Iteration 600, loss = 3.73839469\n",
      "Iteration 601, loss = 3.73811110\n",
      "Iteration 602, loss = 3.73782779\n",
      "Iteration 603, loss = 3.73754476\n",
      "Iteration 604, loss = 3.73726200\n",
      "Iteration 605, loss = 3.73697952\n",
      "Iteration 606, loss = 3.73669731\n",
      "Iteration 607, loss = 3.73641537\n",
      "Iteration 608, loss = 3.73613371\n",
      "Iteration 609, loss = 3.73585232\n",
      "Iteration 610, loss = 3.73557121\n",
      "Iteration 611, loss = 3.73529036\n",
      "Iteration 612, loss = 3.73500978\n",
      "Iteration 613, loss = 3.73472948\n",
      "Iteration 614, loss = 3.73444944\n",
      "Iteration 615, loss = 3.73416967\n",
      "Iteration 616, loss = 3.73389016\n",
      "Iteration 617, loss = 3.73361093\n",
      "Iteration 618, loss = 3.73333196\n",
      "Iteration 619, loss = 3.73305325\n",
      "Iteration 620, loss = 3.73277481\n",
      "Iteration 621, loss = 3.73249663\n",
      "Iteration 622, loss = 3.73221872\n",
      "Iteration 623, loss = 3.73194107\n",
      "Iteration 624, loss = 3.73166368\n",
      "Iteration 625, loss = 3.73138655\n",
      "Iteration 626, loss = 3.73110968\n",
      "Iteration 627, loss = 3.73083308\n",
      "Iteration 628, loss = 3.73055673\n",
      "Iteration 629, loss = 3.73028064\n",
      "Iteration 630, loss = 3.73000481\n",
      "Iteration 631, loss = 3.72972924\n",
      "Iteration 632, loss = 3.72945392\n",
      "Iteration 633, loss = 3.72917886\n",
      "Iteration 634, loss = 3.72890406\n",
      "Iteration 635, loss = 3.72862951\n",
      "Iteration 636, loss = 3.72835522\n",
      "Iteration 637, loss = 3.72808118\n",
      "Iteration 638, loss = 3.72780739\n",
      "Iteration 639, loss = 3.72753386\n",
      "Iteration 640, loss = 3.72726058\n",
      "Iteration 641, loss = 3.72698755\n",
      "Iteration 642, loss = 3.72671478\n",
      "Iteration 643, loss = 3.72644225\n",
      "Iteration 644, loss = 3.72616998\n",
      "Iteration 645, loss = 3.72589795\n",
      "Iteration 646, loss = 3.72562618\n",
      "Iteration 647, loss = 3.72535465\n",
      "Iteration 648, loss = 3.72508338\n",
      "Iteration 649, loss = 3.72481234\n",
      "Iteration 650, loss = 3.72454156\n",
      "Iteration 651, loss = 3.72427103\n",
      "Iteration 652, loss = 3.72400074\n",
      "Iteration 653, loss = 3.72373069\n",
      "Iteration 654, loss = 3.72346089\n",
      "Iteration 655, loss = 3.72319134\n",
      "Iteration 656, loss = 3.72292203\n",
      "Iteration 657, loss = 3.72265296\n",
      "Iteration 658, loss = 3.72238414\n",
      "Iteration 659, loss = 3.72211556\n",
      "Iteration 660, loss = 3.72184722\n",
      "Iteration 661, loss = 3.72157912\n",
      "Iteration 662, loss = 3.72131127\n",
      "Iteration 663, loss = 3.72104365\n",
      "Iteration 664, loss = 3.72077628\n",
      "Iteration 665, loss = 3.72050914\n",
      "Iteration 666, loss = 3.72024225\n",
      "Iteration 667, loss = 3.71997559\n",
      "Iteration 668, loss = 3.71970918\n",
      "Iteration 669, loss = 3.71944300\n",
      "Iteration 670, loss = 3.71917705\n",
      "Iteration 671, loss = 3.71891135\n",
      "Iteration 672, loss = 3.71864588\n",
      "Iteration 673, loss = 3.71838065\n",
      "Iteration 674, loss = 3.71811565\n",
      "Iteration 675, loss = 3.71785089\n",
      "Iteration 676, loss = 3.71758636\n",
      "Iteration 677, loss = 3.71732206\n",
      "Iteration 678, loss = 3.71705800\n",
      "Iteration 679, loss = 3.71679418\n",
      "Iteration 680, loss = 3.71653058\n",
      "Iteration 681, loss = 3.71626722\n",
      "Iteration 682, loss = 3.71600409\n",
      "Iteration 683, loss = 3.71574119\n",
      "Iteration 684, loss = 3.71547852\n",
      "Iteration 685, loss = 3.71521608\n",
      "Iteration 686, loss = 3.71495388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 687, loss = 3.71469190\n",
      "Iteration 688, loss = 3.71443015\n",
      "Iteration 689, loss = 3.71416863\n",
      "Iteration 690, loss = 3.71390733\n",
      "Iteration 691, loss = 3.71364627\n",
      "Iteration 692, loss = 3.71338543\n",
      "Iteration 693, loss = 3.71312482\n",
      "Iteration 694, loss = 3.71286443\n",
      "Iteration 695, loss = 3.71260427\n",
      "Iteration 696, loss = 3.71234434\n",
      "Iteration 697, loss = 3.71208463\n",
      "Iteration 698, loss = 3.71182514\n",
      "Iteration 699, loss = 3.71156588\n",
      "Iteration 700, loss = 3.71130684\n",
      "Iteration 701, loss = 3.71104802\n",
      "Iteration 702, loss = 3.71078943\n",
      "Iteration 703, loss = 3.71053105\n",
      "Iteration 704, loss = 3.71027290\n",
      "Iteration 705, loss = 3.71001497\n",
      "Iteration 706, loss = 3.70975726\n",
      "Iteration 707, loss = 3.70949977\n",
      "Iteration 708, loss = 3.70924250\n",
      "Iteration 709, loss = 3.70898545\n",
      "Iteration 710, loss = 3.70872862\n",
      "Iteration 711, loss = 3.70847200\n",
      "Iteration 712, loss = 3.70821561\n",
      "Iteration 713, loss = 3.70795943\n",
      "Iteration 714, loss = 3.70770346\n",
      "Iteration 715, loss = 3.70744771\n",
      "Iteration 716, loss = 3.70719218\n",
      "Iteration 717, loss = 3.70693686\n",
      "Iteration 718, loss = 3.70668176\n",
      "Iteration 719, loss = 3.70642687\n",
      "Iteration 720, loss = 3.70617220\n",
      "Iteration 721, loss = 3.70591773\n",
      "Iteration 722, loss = 3.70566348\n",
      "Iteration 723, loss = 3.70540945\n",
      "Iteration 724, loss = 3.70515562\n",
      "Iteration 725, loss = 3.70490200\n",
      "Iteration 726, loss = 3.70464860\n",
      "Iteration 727, loss = 3.70439540\n",
      "Iteration 728, loss = 3.70414242\n",
      "Iteration 729, loss = 3.70388964\n",
      "Iteration 730, loss = 3.70363707\n",
      "Iteration 731, loss = 3.70338471\n",
      "Iteration 732, loss = 3.70313256\n",
      "Iteration 733, loss = 3.70288061\n",
      "Iteration 734, loss = 3.70262887\n",
      "Iteration 735, loss = 3.70237734\n",
      "Iteration 736, loss = 3.70212601\n",
      "Iteration 737, loss = 3.70187488\n",
      "Iteration 738, loss = 3.70162396\n",
      "Iteration 739, loss = 3.70137325\n",
      "Iteration 740, loss = 3.70112273\n",
      "Iteration 741, loss = 3.70087242\n",
      "Iteration 742, loss = 3.70062231\n",
      "Iteration 743, loss = 3.70037240\n",
      "Iteration 744, loss = 3.70012270\n",
      "Iteration 745, loss = 3.69987319\n",
      "Iteration 746, loss = 3.69962388\n",
      "Iteration 747, loss = 3.69937478\n",
      "Iteration 748, loss = 3.69912587\n",
      "Iteration 749, loss = 3.69887716\n",
      "Iteration 750, loss = 3.69862864\n",
      "Iteration 751, loss = 3.69838033\n",
      "Iteration 752, loss = 3.69813221\n",
      "Iteration 753, loss = 3.69788428\n",
      "Iteration 754, loss = 3.69763655\n",
      "Iteration 755, loss = 3.69738902\n",
      "Iteration 756, loss = 3.69714168\n",
      "Iteration 757, loss = 3.69689453\n",
      "Iteration 758, loss = 3.69664758\n",
      "Iteration 759, loss = 3.69640082\n",
      "Iteration 760, loss = 3.69615425\n",
      "Iteration 761, loss = 3.69590787\n",
      "Iteration 762, loss = 3.69566168\n",
      "Iteration 763, loss = 3.69541569\n",
      "Iteration 764, loss = 3.69516988\n",
      "Iteration 765, loss = 3.69492426\n",
      "Iteration 766, loss = 3.69467883\n",
      "Iteration 767, loss = 3.69443359\n",
      "Iteration 768, loss = 3.69418853\n",
      "Iteration 769, loss = 3.69394366\n",
      "Iteration 770, loss = 3.69369898\n",
      "Iteration 771, loss = 3.69345448\n",
      "Iteration 772, loss = 3.69321016\n",
      "Iteration 773, loss = 3.69296603\n",
      "Iteration 774, loss = 3.69272209\n",
      "Iteration 775, loss = 3.69247832\n",
      "Iteration 776, loss = 3.69223474\n",
      "Iteration 777, loss = 3.69199134\n",
      "Iteration 778, loss = 3.69174812\n",
      "Iteration 779, loss = 3.69150508\n",
      "Iteration 780, loss = 3.69126223\n",
      "Iteration 781, loss = 3.69101955\n",
      "Iteration 782, loss = 3.69077704\n",
      "Iteration 783, loss = 3.69053472\n",
      "Iteration 784, loss = 3.69029257\n",
      "Iteration 785, loss = 3.69005060\n",
      "Iteration 786, loss = 3.68980881\n",
      "Iteration 787, loss = 3.68956719\n",
      "Iteration 788, loss = 3.68932575\n",
      "Iteration 789, loss = 3.68908448\n",
      "Iteration 790, loss = 3.68884338\n",
      "Iteration 791, loss = 3.68860246\n",
      "Iteration 792, loss = 3.68836170\n",
      "Iteration 793, loss = 3.68812112\n",
      "Iteration 794, loss = 3.68788071\n",
      "Iteration 795, loss = 3.68764047\n",
      "Iteration 796, loss = 3.68740040\n",
      "Iteration 797, loss = 3.68716050\n",
      "Iteration 798, loss = 3.68692077\n",
      "Iteration 799, loss = 3.68668120\n",
      "Iteration 800, loss = 3.68644180\n",
      "Iteration 801, loss = 3.68620257\n",
      "Iteration 802, loss = 3.68596350\n",
      "Iteration 803, loss = 3.68572460\n",
      "Iteration 804, loss = 3.68548586\n",
      "Iteration 805, loss = 3.68524728\n",
      "Iteration 806, loss = 3.68500887\n",
      "Iteration 807, loss = 3.68477062\n",
      "Iteration 808, loss = 3.68453253\n",
      "Iteration 809, loss = 3.68429461\n",
      "Iteration 810, loss = 3.68405684\n",
      "Iteration 811, loss = 3.68381923\n",
      "Iteration 812, loss = 3.68358178\n",
      "Iteration 813, loss = 3.68334449\n",
      "Iteration 814, loss = 3.68310735\n",
      "Iteration 815, loss = 3.68287038\n",
      "Iteration 816, loss = 3.68263356\n",
      "Iteration 817, loss = 3.68239689\n",
      "Iteration 818, loss = 3.68216038\n",
      "Iteration 819, loss = 3.68192402\n",
      "Iteration 820, loss = 3.68168782\n",
      "Iteration 821, loss = 3.68145177\n",
      "Iteration 822, loss = 3.68121587\n",
      "Iteration 823, loss = 3.68098012\n",
      "Iteration 824, loss = 3.68074452\n",
      "Iteration 825, loss = 3.68050908\n",
      "Iteration 826, loss = 3.68027378\n",
      "Iteration 827, loss = 3.68003863\n",
      "Iteration 828, loss = 3.67980363\n",
      "Iteration 829, loss = 3.67956877\n",
      "Iteration 830, loss = 3.67933406\n",
      "Iteration 831, loss = 3.67909950\n",
      "Iteration 832, loss = 3.67886508\n",
      "Iteration 833, loss = 3.67863081\n",
      "Iteration 834, loss = 3.67839668\n",
      "Iteration 835, loss = 3.67816269\n",
      "Iteration 836, loss = 3.67792885\n",
      "Iteration 837, loss = 3.67769515\n",
      "Iteration 838, loss = 3.67746159\n",
      "Iteration 839, loss = 3.67722817\n",
      "Iteration 840, loss = 3.67699488\n",
      "Iteration 841, loss = 3.67676174\n",
      "Iteration 842, loss = 3.67652874\n",
      "Iteration 843, loss = 3.67629587\n",
      "Iteration 844, loss = 3.67606314\n",
      "Iteration 845, loss = 3.67583054\n",
      "Iteration 846, loss = 3.67559808\n",
      "Iteration 847, loss = 3.67536576\n",
      "Iteration 848, loss = 3.67513357\n",
      "Iteration 849, loss = 3.67490151\n",
      "Iteration 850, loss = 3.67466959\n",
      "Iteration 851, loss = 3.67443780\n",
      "Iteration 852, loss = 3.67420613\n",
      "Iteration 853, loss = 3.67397460\n",
      "Iteration 854, loss = 3.67374320\n",
      "Iteration 855, loss = 3.67351193\n",
      "Iteration 856, loss = 3.67328079\n",
      "Iteration 857, loss = 3.67304977\n",
      "Iteration 858, loss = 3.67281888\n",
      "Iteration 859, loss = 3.67258812\n",
      "Iteration 860, loss = 3.67235748\n",
      "Iteration 861, loss = 3.67212697\n",
      "Iteration 862, loss = 3.67189658\n",
      "Iteration 863, loss = 3.67166632\n",
      "Iteration 864, loss = 3.67143618\n",
      "Iteration 865, loss = 3.67120616\n",
      "Iteration 866, loss = 3.67097626\n",
      "Iteration 867, loss = 3.67074648\n",
      "Iteration 868, loss = 3.67051683\n",
      "Iteration 869, loss = 3.67028729\n",
      "Iteration 870, loss = 3.67005787\n",
      "Iteration 871, loss = 3.66982857\n",
      "Iteration 872, loss = 3.66959939\n",
      "Iteration 873, loss = 3.66937032\n",
      "Iteration 874, loss = 3.66914137\n",
      "Iteration 875, loss = 3.66891254\n",
      "Iteration 876, loss = 3.66868382\n",
      "Iteration 877, loss = 3.66845521\n",
      "Iteration 878, loss = 3.66822672\n",
      "Iteration 879, loss = 3.66799834\n",
      "Iteration 880, loss = 3.66777007\n",
      "Iteration 881, loss = 3.66754192\n",
      "Iteration 882, loss = 3.66731387\n",
      "Iteration 883, loss = 3.66708594\n",
      "Iteration 884, loss = 3.66685811\n",
      "Iteration 885, loss = 3.66663039\n",
      "Iteration 886, loss = 3.66640278\n",
      "Iteration 887, loss = 3.66617528\n",
      "Iteration 888, loss = 3.66594789\n",
      "Iteration 889, loss = 3.66572060\n",
      "Iteration 890, loss = 3.66549341\n",
      "Iteration 891, loss = 3.66526633\n",
      "Iteration 892, loss = 3.66503936\n",
      "Iteration 893, loss = 3.66481249\n",
      "Iteration 894, loss = 3.66458572\n",
      "Iteration 895, loss = 3.66435905\n",
      "Iteration 896, loss = 3.66413249\n",
      "Iteration 897, loss = 3.66390602\n",
      "Iteration 898, loss = 3.66367966\n",
      "Iteration 899, loss = 3.66345339\n",
      "Iteration 900, loss = 3.66322723\n",
      "Iteration 901, loss = 3.66300116\n",
      "Iteration 902, loss = 3.66277519\n",
      "Iteration 903, loss = 3.66254932\n",
      "Iteration 904, loss = 3.66232354\n",
      "Iteration 905, loss = 3.66209786\n",
      "Iteration 906, loss = 3.66187228\n",
      "Iteration 907, loss = 3.66164679\n",
      "Iteration 908, loss = 3.66142139\n",
      "Iteration 909, loss = 3.66119609\n",
      "Iteration 910, loss = 3.66097087\n",
      "Iteration 911, loss = 3.66074576\n",
      "Iteration 912, loss = 3.66052073\n",
      "Iteration 913, loss = 3.66029579\n",
      "Iteration 914, loss = 3.66007094\n",
      "Iteration 915, loss = 3.65984619\n",
      "Iteration 916, loss = 3.65962152\n",
      "Iteration 917, loss = 3.65939694\n",
      "Iteration 918, loss = 3.65917245\n",
      "Iteration 919, loss = 3.65894804\n",
      "Iteration 920, loss = 3.65872373\n",
      "Iteration 921, loss = 3.65849949\n",
      "Iteration 922, loss = 3.65827535\n",
      "Iteration 923, loss = 3.65805129\n",
      "Iteration 924, loss = 3.65782731\n",
      "Iteration 925, loss = 3.65760341\n",
      "Iteration 926, loss = 3.65737960\n",
      "Iteration 927, loss = 3.65715588\n",
      "Iteration 928, loss = 3.65693223\n",
      "Iteration 929, loss = 3.65670867\n",
      "Iteration 930, loss = 3.65648518\n",
      "Iteration 931, loss = 3.65626178\n",
      "Iteration 932, loss = 3.65603845\n",
      "Iteration 933, loss = 3.65581521\n",
      "Iteration 934, loss = 3.65559204\n",
      "Iteration 935, loss = 3.65536895\n",
      "Iteration 936, loss = 3.65514594\n",
      "Iteration 937, loss = 3.65492301\n",
      "Iteration 938, loss = 3.65470015\n",
      "Iteration 939, loss = 3.65447737\n",
      "Iteration 940, loss = 3.65425466\n",
      "Iteration 941, loss = 3.65403203\n",
      "Iteration 942, loss = 3.65380948\n",
      "Iteration 943, loss = 3.65358699\n",
      "Iteration 944, loss = 3.65336458\n",
      "Iteration 945, loss = 3.65314224\n",
      "Iteration 946, loss = 3.65291998\n",
      "Iteration 947, loss = 3.65269778\n",
      "Iteration 948, loss = 3.65247566\n",
      "Iteration 949, loss = 3.65225361\n",
      "Iteration 950, loss = 3.65203163\n",
      "Iteration 951, loss = 3.65180971\n",
      "Iteration 952, loss = 3.65158787\n",
      "Iteration 953, loss = 3.65136610\n",
      "Iteration 954, loss = 3.65114439\n",
      "Iteration 955, loss = 3.65092275\n",
      "Iteration 956, loss = 3.65070118\n",
      "Iteration 957, loss = 3.65047967\n",
      "Iteration 958, loss = 3.65025823\n",
      "Iteration 959, loss = 3.65003686\n",
      "Iteration 960, loss = 3.64981555\n",
      "Iteration 961, loss = 3.64959430\n",
      "Iteration 962, loss = 3.64937312\n",
      "Iteration 963, loss = 3.64915201\n",
      "Iteration 964, loss = 3.64893096\n",
      "Iteration 965, loss = 3.64870997\n",
      "Iteration 966, loss = 3.64848904\n",
      "Iteration 967, loss = 3.64826817\n",
      "Iteration 968, loss = 3.64804737\n",
      "Iteration 969, loss = 3.64782663\n",
      "Iteration 970, loss = 3.64760594\n",
      "Iteration 971, loss = 3.64738532\n",
      "Iteration 972, loss = 3.64716476\n",
      "Iteration 973, loss = 3.64694425\n",
      "Iteration 974, loss = 3.64672381\n",
      "Iteration 975, loss = 3.64650342\n",
      "Iteration 976, loss = 3.64628310\n",
      "Iteration 977, loss = 3.64606283\n",
      "Iteration 978, loss = 3.64584261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 979, loss = 3.64562246\n",
      "Iteration 980, loss = 3.64540236\n",
      "Iteration 981, loss = 3.64518231\n",
      "Iteration 982, loss = 3.64496232\n",
      "Iteration 983, loss = 3.64474239\n",
      "Iteration 984, loss = 3.64452251\n",
      "Iteration 985, loss = 3.64430269\n",
      "Iteration 986, loss = 3.64408292\n",
      "Iteration 987, loss = 3.64386320\n",
      "Iteration 988, loss = 3.64364354\n",
      "Iteration 989, loss = 3.64342392\n",
      "Iteration 990, loss = 3.64320437\n",
      "Iteration 991, loss = 3.64298486\n",
      "Iteration 992, loss = 3.64276541\n",
      "Iteration 993, loss = 3.64254600\n",
      "Iteration 994, loss = 3.64232665\n",
      "Iteration 995, loss = 3.64210735\n",
      "Iteration 996, loss = 3.64188810\n",
      "Iteration 997, loss = 3.64166890\n",
      "Iteration 998, loss = 3.64144974\n",
      "Iteration 999, loss = 3.64123064\n",
      "Iteration 1000, loss = 3.64101159\n",
      "Iteration 1001, loss = 3.64079258\n",
      "Iteration 1002, loss = 3.64057363\n",
      "Iteration 1003, loss = 3.64035472\n",
      "Iteration 1004, loss = 3.64013585\n",
      "Iteration 1005, loss = 3.63991704\n",
      "Iteration 1006, loss = 3.63969827\n",
      "Iteration 1007, loss = 3.63947955\n",
      "Iteration 1008, loss = 3.63926088\n",
      "Iteration 1009, loss = 3.63904225\n",
      "Iteration 1010, loss = 3.63882367\n",
      "Iteration 1011, loss = 3.63860513\n",
      "Iteration 1012, loss = 3.63838664\n",
      "Iteration 1013, loss = 3.63816819\n",
      "Iteration 1014, loss = 3.63794979\n",
      "Iteration 1015, loss = 3.63773143\n",
      "Iteration 1016, loss = 3.63751312\n",
      "Iteration 1017, loss = 3.63729485\n",
      "Iteration 1018, loss = 3.63707662\n",
      "Iteration 1019, loss = 3.63685843\n",
      "Iteration 1020, loss = 3.63664029\n",
      "Iteration 1021, loss = 3.63642220\n",
      "Iteration 1022, loss = 3.63620414\n",
      "Iteration 1023, loss = 3.63598612\n",
      "Iteration 1024, loss = 3.63576815\n",
      "Iteration 1025, loss = 3.63555022\n",
      "Iteration 1026, loss = 3.63533233\n",
      "Iteration 1027, loss = 3.63511448\n",
      "Iteration 1028, loss = 3.63489668\n",
      "Iteration 1029, loss = 3.63467891\n",
      "Iteration 1030, loss = 3.63446118\n",
      "Iteration 1031, loss = 3.63424350\n",
      "Iteration 1032, loss = 3.63402585\n",
      "Iteration 1033, loss = 3.63380824\n",
      "Iteration 1034, loss = 3.63359068\n",
      "Iteration 1035, loss = 3.63337315\n",
      "Iteration 1036, loss = 3.63315566\n",
      "Iteration 1037, loss = 3.63293821\n",
      "Iteration 1038, loss = 3.63272080\n",
      "Iteration 1039, loss = 3.63250343\n",
      "Iteration 1040, loss = 3.63228609\n",
      "Iteration 1041, loss = 3.63206880\n",
      "Iteration 1042, loss = 3.63185154\n",
      "Iteration 1043, loss = 3.63163432\n",
      "Iteration 1044, loss = 3.63141713\n",
      "Iteration 1045, loss = 3.63119999\n",
      "Iteration 1046, loss = 3.63098288\n",
      "Iteration 1047, loss = 3.63076580\n",
      "Iteration 1048, loss = 3.63054877\n",
      "Iteration 1049, loss = 3.63033177\n",
      "Iteration 1050, loss = 3.63011481\n",
      "Iteration 1051, loss = 3.62989788\n",
      "Iteration 1052, loss = 3.62968099\n",
      "Iteration 1053, loss = 3.62946414\n",
      "Iteration 1054, loss = 3.62924732\n",
      "Iteration 1055, loss = 3.62903054\n",
      "Iteration 1056, loss = 3.62881379\n",
      "Iteration 1057, loss = 3.62859708\n",
      "Iteration 1058, loss = 3.62838040\n",
      "Iteration 1059, loss = 3.62816376\n",
      "Iteration 1060, loss = 3.62794716\n",
      "Iteration 1061, loss = 3.62773059\n",
      "Iteration 1062, loss = 3.62751405\n",
      "Iteration 1063, loss = 3.62729755\n",
      "Iteration 1064, loss = 3.62708108\n",
      "Iteration 1065, loss = 3.62686465\n",
      "Iteration 1066, loss = 3.62664825\n",
      "Iteration 1067, loss = 3.62643188\n",
      "Iteration 1068, loss = 3.62621555\n",
      "Iteration 1069, loss = 3.62599926\n",
      "Iteration 1070, loss = 3.62578299\n",
      "Iteration 1071, loss = 3.62556676\n",
      "Iteration 1072, loss = 3.62535057\n",
      "Iteration 1073, loss = 3.62513441\n",
      "Iteration 1074, loss = 3.62491828\n",
      "Iteration 1075, loss = 3.62470218\n",
      "Iteration 1076, loss = 3.62448612\n",
      "Iteration 1077, loss = 3.62427009\n",
      "Iteration 1078, loss = 3.62405410\n",
      "Iteration 1079, loss = 3.62383813\n",
      "Iteration 1080, loss = 3.62362220\n",
      "Iteration 1081, loss = 3.62340631\n",
      "Iteration 1082, loss = 3.62319044\n",
      "Iteration 1083, loss = 3.62297461\n",
      "Iteration 1084, loss = 3.62275882\n",
      "Iteration 1085, loss = 3.62254305\n",
      "Iteration 1086, loss = 3.62232732\n",
      "Iteration 1087, loss = 3.62211162\n",
      "Iteration 1088, loss = 3.62189595\n",
      "Iteration 1089, loss = 3.62168032\n",
      "Iteration 1090, loss = 3.62146471\n",
      "Iteration 1091, loss = 3.62124914\n",
      "Iteration 1092, loss = 3.62103361\n",
      "Iteration 1093, loss = 3.62081810\n",
      "Iteration 1094, loss = 3.62060263\n",
      "Iteration 1095, loss = 3.62038719\n",
      "Iteration 1096, loss = 3.62017178\n",
      "Iteration 1097, loss = 3.61995640\n",
      "Iteration 1098, loss = 3.61974106\n",
      "Iteration 1099, loss = 3.61952575\n",
      "Iteration 1100, loss = 3.61931047\n",
      "Iteration 1101, loss = 3.61909522\n",
      "Iteration 1102, loss = 3.61888001\n",
      "Iteration 1103, loss = 3.61866482\n",
      "Iteration 1104, loss = 3.61844967\n",
      "Iteration 1105, loss = 3.61823456\n",
      "Iteration 1106, loss = 3.61801947\n",
      "Iteration 1107, loss = 3.61780442\n",
      "Iteration 1108, loss = 3.61758939\n",
      "Iteration 1109, loss = 3.61737440\n",
      "Iteration 1110, loss = 3.61715945\n",
      "Iteration 1111, loss = 3.61694452\n",
      "Iteration 1112, loss = 3.61672963\n",
      "Iteration 1113, loss = 3.61651477\n",
      "Iteration 1114, loss = 3.61629994\n",
      "Iteration 1115, loss = 3.61608515\n",
      "Iteration 1116, loss = 3.61587038\n",
      "Iteration 1117, loss = 3.61565565\n",
      "Iteration 1118, loss = 3.61544096\n",
      "Iteration 1119, loss = 3.61522629\n",
      "Iteration 1120, loss = 3.61501166\n",
      "Iteration 1121, loss = 3.61479706\n",
      "Iteration 1122, loss = 3.61458249\n",
      "Iteration 1123, loss = 3.61436795\n",
      "Iteration 1124, loss = 3.61415345\n",
      "Iteration 1125, loss = 3.61393898\n",
      "Iteration 1126, loss = 3.61372455\n",
      "Iteration 1127, loss = 3.61351014\n",
      "Iteration 1128, loss = 3.61329577\n",
      "Iteration 1129, loss = 3.61308143\n",
      "Iteration 1130, loss = 3.61286713\n",
      "Iteration 1131, loss = 3.61265286\n",
      "Iteration 1132, loss = 3.61243862\n",
      "Iteration 1133, loss = 3.61222441\n",
      "Iteration 1134, loss = 3.61201024\n",
      "Iteration 1135, loss = 3.61179610\n",
      "Iteration 1136, loss = 3.61158200\n",
      "Iteration 1137, loss = 3.61136793\n",
      "Iteration 1138, loss = 3.61115389\n",
      "Iteration 1139, loss = 3.61093988\n",
      "Iteration 1140, loss = 3.61072591\n",
      "Iteration 1141, loss = 3.61051198\n",
      "Iteration 1142, loss = 3.61029808\n",
      "Iteration 1143, loss = 3.61008421\n",
      "Iteration 1144, loss = 3.60987038\n",
      "Iteration 1145, loss = 3.60965658\n",
      "Iteration 1146, loss = 3.60944281\n",
      "Iteration 1147, loss = 3.60922908\n",
      "Iteration 1148, loss = 3.60901538\n",
      "Iteration 1149, loss = 3.60880172\n",
      "Iteration 1150, loss = 3.60858810\n",
      "Iteration 1151, loss = 3.60837451\n",
      "Iteration 1152, loss = 3.60816095\n",
      "Iteration 1153, loss = 3.60794743\n",
      "Iteration 1154, loss = 3.60773394\n",
      "Iteration 1155, loss = 3.60752049\n",
      "Iteration 1156, loss = 3.60730708\n",
      "Iteration 1157, loss = 3.60709370\n",
      "Iteration 1158, loss = 3.60688035\n",
      "Iteration 1159, loss = 3.60666705\n",
      "Iteration 1160, loss = 3.60645377\n",
      "Iteration 1161, loss = 3.60624054\n",
      "Iteration 1162, loss = 3.60602734\n",
      "Iteration 1163, loss = 3.60581418\n",
      "Iteration 1164, loss = 3.60560105\n",
      "Iteration 1165, loss = 3.60538796\n",
      "Iteration 1166, loss = 3.60517491\n",
      "Iteration 1167, loss = 3.60496189\n",
      "Iteration 1168, loss = 3.60474891\n",
      "Iteration 1169, loss = 3.60453597\n",
      "Iteration 1170, loss = 3.60432306\n",
      "Iteration 1171, loss = 3.60411020\n",
      "Iteration 1172, loss = 3.60389737\n",
      "Iteration 1173, loss = 3.60368458\n",
      "Iteration 1174, loss = 3.60347182\n",
      "Iteration 1175, loss = 3.60325911\n",
      "Iteration 1176, loss = 3.60304643\n",
      "Iteration 1177, loss = 3.60283379\n",
      "Iteration 1178, loss = 3.60262119\n",
      "Iteration 1179, loss = 3.60240863\n",
      "Iteration 1180, loss = 3.60219610\n",
      "Iteration 1181, loss = 3.60198362\n",
      "Iteration 1182, loss = 3.60177118\n",
      "Iteration 1183, loss = 3.60155877\n",
      "Iteration 1184, loss = 3.60134640\n",
      "Iteration 1185, loss = 3.60113408\n",
      "Iteration 1186, loss = 3.60092179\n",
      "Iteration 1187, loss = 3.60070955\n",
      "Iteration 1188, loss = 3.60049734\n",
      "Iteration 1189, loss = 3.60028517\n",
      "Iteration 1190, loss = 3.60007305\n",
      "Iteration 1191, loss = 3.59986096\n",
      "Iteration 1192, loss = 3.59964892\n",
      "Iteration 1193, loss = 3.59943692\n",
      "Iteration 1194, loss = 3.59922496\n",
      "Iteration 1195, loss = 3.59901304\n",
      "Iteration 1196, loss = 3.59880116\n",
      "Iteration 1197, loss = 3.59858932\n",
      "Iteration 1198, loss = 3.59837753\n",
      "Iteration 1199, loss = 3.59816577\n",
      "Iteration 1200, loss = 3.59795406\n",
      "Iteration 1201, loss = 3.59774240\n",
      "Iteration 1202, loss = 3.59753077\n",
      "Iteration 1203, loss = 3.59731919\n",
      "Iteration 1204, loss = 3.59710765\n",
      "Iteration 1205, loss = 3.59689615\n",
      "Iteration 1206, loss = 3.59668470\n",
      "Iteration 1207, loss = 3.59647329\n",
      "Iteration 1208, loss = 3.59626193\n",
      "Iteration 1209, loss = 3.59605061\n",
      "Iteration 1210, loss = 3.59583933\n",
      "Iteration 1211, loss = 3.59562810\n",
      "Iteration 1212, loss = 3.59541691\n",
      "Iteration 1213, loss = 3.59520577\n",
      "Iteration 1214, loss = 3.59499467\n",
      "Iteration 1215, loss = 3.59478362\n",
      "Iteration 1216, loss = 3.59457261\n",
      "Iteration 1217, loss = 3.59436165\n",
      "Iteration 1218, loss = 3.59415073\n",
      "Iteration 1219, loss = 3.59393986\n",
      "Iteration 1220, loss = 3.59372904\n",
      "Iteration 1221, loss = 3.59351826\n",
      "Iteration 1222, loss = 3.59330753\n",
      "Iteration 1223, loss = 3.59309685\n",
      "Iteration 1224, loss = 3.59288621\n",
      "Iteration 1225, loss = 3.59267563\n",
      "Iteration 1226, loss = 3.59246508\n",
      "Iteration 1227, loss = 3.59225459\n",
      "Iteration 1228, loss = 3.59204414\n",
      "Iteration 1229, loss = 3.59183375\n",
      "Iteration 1230, loss = 3.59162340\n",
      "Iteration 1231, loss = 3.59141310\n",
      "Iteration 1232, loss = 3.59120284\n",
      "Iteration 1233, loss = 3.59099264\n",
      "Iteration 1234, loss = 3.59078249\n",
      "Iteration 1235, loss = 3.59057238\n",
      "Iteration 1236, loss = 3.59036233\n",
      "Iteration 1237, loss = 3.59015232\n",
      "Iteration 1238, loss = 3.58994237\n",
      "Iteration 1239, loss = 3.58973246\n",
      "Iteration 1240, loss = 3.58952261\n",
      "Iteration 1241, loss = 3.58931281\n",
      "Iteration 1242, loss = 3.58910305\n",
      "Iteration 1243, loss = 3.58889335\n",
      "Iteration 1244, loss = 3.58868370\n",
      "Iteration 1245, loss = 3.58847410\n",
      "Iteration 1246, loss = 3.58826456\n",
      "Iteration 1247, loss = 3.58805506\n",
      "Iteration 1248, loss = 3.58784562\n",
      "Iteration 1249, loss = 3.58763623\n",
      "Iteration 1250, loss = 3.58742689\n",
      "Iteration 1251, loss = 3.58721761\n",
      "Iteration 1252, loss = 3.58700838\n",
      "Iteration 1253, loss = 3.58679920\n",
      "Iteration 1254, loss = 3.58659008\n",
      "Iteration 1255, loss = 3.58638101\n",
      "Iteration 1256, loss = 3.58617199\n",
      "Iteration 1257, loss = 3.58596303\n",
      "Iteration 1258, loss = 3.58575412\n",
      "Iteration 1259, loss = 3.58554527\n",
      "Iteration 1260, loss = 3.58533647\n",
      "Iteration 1261, loss = 3.58512773\n",
      "Iteration 1262, loss = 3.58491904\n",
      "Iteration 1263, loss = 3.58471041\n",
      "Iteration 1264, loss = 3.58450183\n",
      "Iteration 1265, loss = 3.58429331\n",
      "Iteration 1266, loss = 3.58408485\n",
      "Iteration 1267, loss = 3.58387644\n",
      "Iteration 1268, loss = 3.58366809\n",
      "Iteration 1269, loss = 3.58345980\n",
      "Iteration 1270, loss = 3.58325156\n",
      "Iteration 1271, loss = 3.58304339\n",
      "Iteration 1272, loss = 3.58283527\n",
      "Iteration 1273, loss = 3.58262720\n",
      "Iteration 1274, loss = 3.58241920\n",
      "Iteration 1275, loss = 3.58221125\n",
      "Iteration 1276, loss = 3.58200336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1277, loss = 3.58179554\n",
      "Iteration 1278, loss = 3.58158777\n",
      "Iteration 1279, loss = 3.58138006\n",
      "Iteration 1280, loss = 3.58117240\n",
      "Iteration 1281, loss = 3.58096481\n",
      "Iteration 1282, loss = 3.58075728\n",
      "Iteration 1283, loss = 3.58054981\n",
      "Iteration 1284, loss = 3.58034240\n",
      "Iteration 1285, loss = 3.58013505\n",
      "Iteration 1286, loss = 3.57992776\n",
      "Iteration 1287, loss = 3.57972053\n",
      "Iteration 1288, loss = 3.57951337\n",
      "Iteration 1289, loss = 3.57930626\n",
      "Iteration 1290, loss = 3.57909922\n",
      "Iteration 1291, loss = 3.57889224\n",
      "Iteration 1292, loss = 3.57868532\n",
      "Iteration 1293, loss = 3.57847846\n",
      "Iteration 1294, loss = 3.57827167\n",
      "Iteration 1295, loss = 3.57806493\n",
      "Iteration 1296, loss = 3.57785827\n",
      "Iteration 1297, loss = 3.57765166\n",
      "Iteration 1298, loss = 3.57744512\n",
      "Iteration 1299, loss = 3.57723864\n",
      "Iteration 1300, loss = 3.57703223\n",
      "Iteration 1301, loss = 3.57682588\n",
      "Iteration 1302, loss = 3.57661959\n",
      "Iteration 1303, loss = 3.57641337\n",
      "Iteration 1304, loss = 3.57620722\n",
      "Iteration 1305, loss = 3.57600113\n",
      "Iteration 1306, loss = 3.57579511\n",
      "Iteration 1307, loss = 3.57558915\n",
      "Iteration 1308, loss = 3.57538325\n",
      "Iteration 1309, loss = 3.57517743\n",
      "Iteration 1310, loss = 3.57497166\n",
      "Iteration 1311, loss = 3.57476597\n",
      "Iteration 1312, loss = 3.57456034\n",
      "Iteration 1313, loss = 3.57435478\n",
      "Iteration 1314, loss = 3.57414929\n",
      "Iteration 1315, loss = 3.57394386\n",
      "Iteration 1316, loss = 3.57373850\n",
      "Iteration 1317, loss = 3.57353321\n",
      "Iteration 1318, loss = 3.57332799\n",
      "Iteration 1319, loss = 3.57312283\n",
      "Iteration 1320, loss = 3.57291774\n",
      "Iteration 1321, loss = 3.57271273\n",
      "Iteration 1322, loss = 3.57250778\n",
      "Iteration 1323, loss = 3.57230290\n",
      "Iteration 1324, loss = 3.57209809\n",
      "Iteration 1325, loss = 3.57189334\n",
      "Iteration 1326, loss = 3.57168867\n",
      "Iteration 1327, loss = 3.57148407\n",
      "Iteration 1328, loss = 3.57127954\n",
      "Iteration 1329, loss = 3.57107508\n",
      "Iteration 1330, loss = 3.57087069\n",
      "Iteration 1331, loss = 3.57066637\n",
      "Iteration 1332, loss = 3.57046212\n",
      "Iteration 1333, loss = 3.57025794\n",
      "Iteration 1334, loss = 3.57005383\n",
      "Iteration 1335, loss = 3.56984980\n",
      "Iteration 1336, loss = 3.56964583\n",
      "Iteration 1337, loss = 3.56944194\n",
      "Iteration 1338, loss = 3.56923812\n",
      "Iteration 1339, loss = 3.56903437\n",
      "Iteration 1340, loss = 3.56883070\n",
      "Iteration 1341, loss = 3.56862710\n",
      "Iteration 1342, loss = 3.56842357\n",
      "Iteration 1343, loss = 3.56822011\n",
      "Iteration 1344, loss = 3.56801673\n",
      "Iteration 1345, loss = 3.56781342\n",
      "Iteration 1346, loss = 3.56761019\n",
      "Iteration 1347, loss = 3.56740702\n",
      "Iteration 1348, loss = 3.56720394\n",
      "Iteration 1349, loss = 3.56700092\n",
      "Iteration 1350, loss = 3.56679799\n",
      "Iteration 1351, loss = 3.56659512\n",
      "Iteration 1352, loss = 3.56639233\n",
      "Iteration 1353, loss = 3.56618962\n",
      "Iteration 1354, loss = 3.56598698\n",
      "Iteration 1355, loss = 3.56578442\n",
      "Iteration 1356, loss = 3.56558193\n",
      "Iteration 1357, loss = 3.56537952\n",
      "Iteration 1358, loss = 3.56517719\n",
      "Iteration 1359, loss = 3.56497493\n",
      "Iteration 1360, loss = 3.56477275\n",
      "Iteration 1361, loss = 3.56457064\n",
      "Iteration 1362, loss = 3.56436861\n",
      "Iteration 1363, loss = 3.56416666\n",
      "Iteration 1364, loss = 3.56396478\n",
      "Iteration 1365, loss = 3.56376298\n",
      "Iteration 1366, loss = 3.56356126\n",
      "Iteration 1367, loss = 3.56335962\n",
      "Iteration 1368, loss = 3.56315806\n",
      "Iteration 1369, loss = 3.56295657\n",
      "Iteration 1370, loss = 3.56275516\n",
      "Iteration 1371, loss = 3.56255383\n",
      "Iteration 1372, loss = 3.56235258\n",
      "Iteration 1373, loss = 3.56215141\n",
      "Iteration 1374, loss = 3.56195031\n",
      "Iteration 1375, loss = 3.56174930\n",
      "Iteration 1376, loss = 3.56154836\n",
      "Iteration 1377, loss = 3.56134750\n",
      "Iteration 1378, loss = 3.56114673\n",
      "Iteration 1379, loss = 3.56094603\n",
      "Iteration 1380, loss = 3.56074541\n",
      "Iteration 1381, loss = 3.56054487\n",
      "Iteration 1382, loss = 3.56034441\n",
      "Iteration 1383, loss = 3.56014404\n",
      "Iteration 1384, loss = 3.55994374\n",
      "Iteration 1385, loss = 3.55974352\n",
      "Iteration 1386, loss = 3.55954339\n",
      "Iteration 1387, loss = 3.55934333\n",
      "Iteration 1388, loss = 3.55914336\n",
      "Iteration 1389, loss = 3.55894347\n",
      "Iteration 1390, loss = 3.55874366\n",
      "Iteration 1391, loss = 3.55854393\n",
      "Iteration 1392, loss = 3.55834428\n",
      "Iteration 1393, loss = 3.55814472\n",
      "Iteration 1394, loss = 3.55794523\n",
      "Iteration 1395, loss = 3.55774583\n",
      "Iteration 1396, loss = 3.55754651\n",
      "Iteration 1397, loss = 3.55734728\n",
      "Iteration 1398, loss = 3.55714812\n",
      "Iteration 1399, loss = 3.55694905\n",
      "Iteration 1400, loss = 3.55675006\n",
      "Iteration 1401, loss = 3.55655116\n",
      "Iteration 1402, loss = 3.55635233\n",
      "Iteration 1403, loss = 3.55615359\n",
      "Iteration 1404, loss = 3.55595494\n",
      "Iteration 1405, loss = 3.55575637\n",
      "Iteration 1406, loss = 3.55555788\n",
      "Iteration 1407, loss = 3.55535947\n",
      "Iteration 1408, loss = 3.55516115\n",
      "Iteration 1409, loss = 3.55496291\n",
      "Iteration 1410, loss = 3.55476476\n",
      "Iteration 1411, loss = 3.55456669\n",
      "Iteration 1412, loss = 3.55436871\n",
      "Iteration 1413, loss = 3.55417081\n",
      "Iteration 1414, loss = 3.55397299\n",
      "Iteration 1415, loss = 3.55377526\n",
      "Iteration 1416, loss = 3.55357762\n",
      "Iteration 1417, loss = 3.55338006\n",
      "Iteration 1418, loss = 3.55318258\n",
      "Iteration 1419, loss = 3.55298519\n",
      "Iteration 1420, loss = 3.55278789\n",
      "Iteration 1421, loss = 3.55259067\n",
      "Iteration 1422, loss = 3.55239353\n",
      "Iteration 1423, loss = 3.55219649\n",
      "Iteration 1424, loss = 3.55199952\n",
      "Iteration 1425, loss = 3.55180265\n",
      "Iteration 1426, loss = 3.55160586\n",
      "Iteration 1427, loss = 3.55140915\n",
      "Iteration 1428, loss = 3.55121253\n",
      "Iteration 1429, loss = 3.55101600\n",
      "Iteration 1430, loss = 3.55081956\n",
      "Iteration 1431, loss = 3.55062320\n",
      "Iteration 1432, loss = 3.55042693\n",
      "Iteration 1433, loss = 3.55023074\n",
      "Iteration 1434, loss = 3.55003464\n",
      "Iteration 1435, loss = 3.54983863\n",
      "Iteration 1436, loss = 3.54964270\n",
      "Iteration 1437, loss = 3.54944686\n",
      "Iteration 1438, loss = 3.54925111\n",
      "Iteration 1439, loss = 3.54905545\n",
      "Iteration 1440, loss = 3.54885987\n",
      "Iteration 1441, loss = 3.54866438\n",
      "Iteration 1442, loss = 3.54846898\n",
      "Iteration 1443, loss = 3.54827367\n",
      "Iteration 1444, loss = 3.54807844\n",
      "Iteration 1445, loss = 3.54788330\n",
      "Iteration 1446, loss = 3.54768825\n",
      "Iteration 1447, loss = 3.54749329\n",
      "Iteration 1448, loss = 3.54729841\n",
      "Iteration 1449, loss = 3.54710362\n",
      "Iteration 1450, loss = 3.54690892\n",
      "Iteration 1451, loss = 3.54671431\n",
      "Iteration 1452, loss = 3.54651979\n",
      "Iteration 1453, loss = 3.54632535\n",
      "Iteration 1454, loss = 3.54613101\n",
      "Iteration 1455, loss = 3.54593675\n",
      "Iteration 1456, loss = 3.54574258\n",
      "Iteration 1457, loss = 3.54554850\n",
      "Iteration 1458, loss = 3.54535451\n",
      "Iteration 1459, loss = 3.54516060\n",
      "Iteration 1460, loss = 3.54496679\n",
      "Iteration 1461, loss = 3.54477306\n",
      "Iteration 1462, loss = 3.54457942\n",
      "Iteration 1463, loss = 3.54438587\n",
      "Iteration 1464, loss = 3.54419241\n",
      "Iteration 1465, loss = 3.54399904\n",
      "Iteration 1466, loss = 3.54380576\n",
      "Iteration 1467, loss = 3.54361257\n",
      "Iteration 1468, loss = 3.54341946\n",
      "Iteration 1469, loss = 3.54322645\n",
      "Iteration 1470, loss = 3.54303352\n",
      "Iteration 1471, loss = 3.54284069\n",
      "Iteration 1472, loss = 3.54264794\n",
      "Iteration 1473, loss = 3.54245528\n",
      "Iteration 1474, loss = 3.54226271\n",
      "Iteration 1475, loss = 3.54207023\n",
      "Iteration 1476, loss = 3.54187784\n",
      "Iteration 1477, loss = 3.54168554\n",
      "Iteration 1478, loss = 3.54149333\n",
      "Iteration 1479, loss = 3.54130121\n",
      "Iteration 1480, loss = 3.54110918\n",
      "Iteration 1481, loss = 3.54091723\n",
      "Iteration 1482, loss = 3.54072538\n",
      "Iteration 1483, loss = 3.54053362\n",
      "Iteration 1484, loss = 3.54034194\n",
      "Iteration 1485, loss = 3.54015036\n",
      "Iteration 1486, loss = 3.53995887\n",
      "Iteration 1487, loss = 3.53976746\n",
      "Iteration 1488, loss = 3.53957614\n",
      "Iteration 1489, loss = 3.53938492\n",
      "Iteration 1490, loss = 3.53919378\n",
      "Iteration 1491, loss = 3.53900274\n",
      "Iteration 1492, loss = 3.53881178\n",
      "Iteration 1493, loss = 3.53862091\n",
      "Iteration 1494, loss = 3.53843014\n",
      "Iteration 1495, loss = 3.53823945\n",
      "Iteration 1496, loss = 3.53804885\n",
      "Iteration 1497, loss = 3.53785835\n",
      "Iteration 1498, loss = 3.53766793\n",
      "Iteration 1499, loss = 3.53747760\n",
      "Iteration 1500, loss = 3.53728736\n",
      "Iteration 1501, loss = 3.53709721\n",
      "Iteration 1502, loss = 3.53690715\n",
      "Iteration 1503, loss = 3.53671719\n",
      "Iteration 1504, loss = 3.53652731\n",
      "Iteration 1505, loss = 3.53633752\n",
      "Iteration 1506, loss = 3.53614782\n",
      "Iteration 1507, loss = 3.53595821\n",
      "Iteration 1508, loss = 3.53576869\n",
      "Iteration 1509, loss = 3.53557926\n",
      "Iteration 1510, loss = 3.53538992\n",
      "Iteration 1511, loss = 3.53520066\n",
      "Iteration 1512, loss = 3.53501150\n",
      "Iteration 1513, loss = 3.53482243\n",
      "Iteration 1514, loss = 3.53463345\n",
      "Iteration 1515, loss = 3.53444456\n",
      "Iteration 1516, loss = 3.53425575\n",
      "Iteration 1517, loss = 3.53406704\n",
      "Iteration 1518, loss = 3.53387842\n",
      "Iteration 1519, loss = 3.53368988\n",
      "Iteration 1520, loss = 3.53350144\n",
      "Iteration 1521, loss = 3.53331308\n",
      "Iteration 1522, loss = 3.53312482\n",
      "Iteration 1523, loss = 3.53293664\n",
      "Iteration 1524, loss = 3.53274855\n",
      "Iteration 1525, loss = 3.53256055\n",
      "Iteration 1526, loss = 3.53237264\n",
      "Iteration 1527, loss = 3.53218483\n",
      "Iteration 1528, loss = 3.53199710\n",
      "Iteration 1529, loss = 3.53180945\n",
      "Iteration 1530, loss = 3.53162190\n",
      "Iteration 1531, loss = 3.53143444\n",
      "Iteration 1532, loss = 3.53124707\n",
      "Iteration 1533, loss = 3.53105978\n",
      "Iteration 1534, loss = 3.53087259\n",
      "Iteration 1535, loss = 3.53068548\n",
      "Iteration 1536, loss = 3.53049846\n",
      "Iteration 1537, loss = 3.53031153\n",
      "Iteration 1538, loss = 3.53012469\n",
      "Iteration 1539, loss = 3.52993794\n",
      "Iteration 1540, loss = 3.52975128\n",
      "Iteration 1541, loss = 3.52956470\n",
      "Iteration 1542, loss = 3.52937822\n",
      "Iteration 1543, loss = 3.52919182\n",
      "Iteration 1544, loss = 3.52900551\n",
      "Iteration 1545, loss = 3.52881929\n",
      "Iteration 1546, loss = 3.52863316\n",
      "Iteration 1547, loss = 3.52844712\n",
      "Iteration 1548, loss = 3.52826116\n",
      "Iteration 1549, loss = 3.52807529\n",
      "Iteration 1550, loss = 3.52788952\n",
      "Iteration 1551, loss = 3.52770382\n",
      "Iteration 1552, loss = 3.52751822\n",
      "Iteration 1553, loss = 3.52733271\n",
      "Iteration 1554, loss = 3.52714728\n",
      "Iteration 1555, loss = 3.52696194\n",
      "Iteration 1556, loss = 3.52677669\n",
      "Iteration 1557, loss = 3.52659152\n",
      "Iteration 1558, loss = 3.52640645\n",
      "Iteration 1559, loss = 3.52622146\n",
      "Iteration 1560, loss = 3.52603656\n",
      "Iteration 1561, loss = 3.52585174\n",
      "Iteration 1562, loss = 3.52566701\n",
      "Iteration 1563, loss = 3.52548237\n",
      "Iteration 1564, loss = 3.52529782\n",
      "Iteration 1565, loss = 3.52511335\n",
      "Iteration 1566, loss = 3.52492898\n",
      "Iteration 1567, loss = 3.52474468\n",
      "Iteration 1568, loss = 3.52456048\n",
      "Iteration 1569, loss = 3.52437636\n",
      "Iteration 1570, loss = 3.52419233\n",
      "Iteration 1571, loss = 3.52400838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1572, loss = 3.52382452\n",
      "Iteration 1573, loss = 3.52364075\n",
      "Iteration 1574, loss = 3.52345706\n",
      "Iteration 1575, loss = 3.52327346\n",
      "Iteration 1576, loss = 3.52308995\n",
      "Iteration 1577, loss = 3.52290652\n",
      "Iteration 1578, loss = 3.52272317\n",
      "Iteration 1579, loss = 3.52253992\n",
      "Iteration 1580, loss = 3.52235675\n",
      "Iteration 1581, loss = 3.52217366\n",
      "Iteration 1582, loss = 3.52199066\n",
      "Iteration 1583, loss = 3.52180774\n",
      "Iteration 1584, loss = 3.52162491\n",
      "Iteration 1585, loss = 3.52144217\n",
      "Iteration 1586, loss = 3.52125951\n",
      "Iteration 1587, loss = 3.52107694\n",
      "Iteration 1588, loss = 3.52089445\n",
      "Iteration 1589, loss = 3.52071204\n",
      "Iteration 1590, loss = 3.52052972\n",
      "Iteration 1591, loss = 3.52034749\n",
      "Iteration 1592, loss = 3.52016533\n",
      "Iteration 1593, loss = 3.51998327\n",
      "Iteration 1594, loss = 3.51980129\n",
      "Iteration 1595, loss = 3.51961939\n",
      "Iteration 1596, loss = 3.51943757\n",
      "Iteration 1597, loss = 3.51925584\n",
      "Iteration 1598, loss = 3.51907419\n",
      "Iteration 1599, loss = 3.51889263\n",
      "Iteration 1600, loss = 3.51871115\n",
      "Iteration 1601, loss = 3.51852976\n",
      "Iteration 1602, loss = 3.51834844\n",
      "Iteration 1603, loss = 3.51816721\n",
      "Iteration 1604, loss = 3.51798607\n",
      "Iteration 1605, loss = 3.51780500\n",
      "Iteration 1606, loss = 3.51762402\n",
      "Iteration 1607, loss = 3.51744312\n",
      "Iteration 1608, loss = 3.51726231\n",
      "Iteration 1609, loss = 3.51708157\n",
      "Iteration 1610, loss = 3.51690092\n",
      "Iteration 1611, loss = 3.51672036\n",
      "Iteration 1612, loss = 3.51653987\n",
      "Iteration 1613, loss = 3.51635946\n",
      "Iteration 1614, loss = 3.51617914\n",
      "Iteration 1615, loss = 3.51599890\n",
      "Iteration 1616, loss = 3.51581874\n",
      "Iteration 1617, loss = 3.51563866\n",
      "Iteration 1618, loss = 3.51545867\n",
      "Iteration 1619, loss = 3.51527875\n",
      "Iteration 1620, loss = 3.51509892\n",
      "Iteration 1621, loss = 3.51491917\n",
      "Iteration 1622, loss = 3.51473949\n",
      "Iteration 1623, loss = 3.51455990\n",
      "Iteration 1624, loss = 3.51438039\n",
      "Iteration 1625, loss = 3.51420096\n",
      "Iteration 1626, loss = 3.51402161\n",
      "Iteration 1627, loss = 3.51384234\n",
      "Iteration 1628, loss = 3.51366315\n",
      "Iteration 1629, loss = 3.51348404\n",
      "Iteration 1630, loss = 3.51330501\n",
      "Iteration 1631, loss = 3.51312606\n",
      "Iteration 1632, loss = 3.51294719\n",
      "Iteration 1633, loss = 3.51276839\n",
      "Iteration 1634, loss = 3.51258968\n",
      "Iteration 1635, loss = 3.51241105\n",
      "Iteration 1636, loss = 3.51223249\n",
      "Iteration 1637, loss = 3.51205402\n",
      "Iteration 1638, loss = 3.51187562\n",
      "Iteration 1639, loss = 3.51169730\n",
      "Iteration 1640, loss = 3.51151906\n",
      "Iteration 1641, loss = 3.51134090\n",
      "Iteration 1642, loss = 3.51116281\n",
      "Iteration 1643, loss = 3.51098481\n",
      "Iteration 1644, loss = 3.51080688\n",
      "Iteration 1645, loss = 3.51062903\n",
      "Iteration 1646, loss = 3.51045125\n",
      "Iteration 1647, loss = 3.51027356\n",
      "Iteration 1648, loss = 3.51009594\n",
      "Iteration 1649, loss = 3.50991839\n",
      "Iteration 1650, loss = 3.50974093\n",
      "Iteration 1651, loss = 3.50956354\n",
      "Iteration 1652, loss = 3.50938623\n",
      "Iteration 1653, loss = 3.50920899\n",
      "Iteration 1654, loss = 3.50903183\n",
      "Iteration 1655, loss = 3.50885475\n",
      "Iteration 1656, loss = 3.50867774\n",
      "Iteration 1657, loss = 3.50850081\n",
      "Iteration 1658, loss = 3.50832396\n",
      "Iteration 1659, loss = 3.50814718\n",
      "Iteration 1660, loss = 3.50797047\n",
      "Iteration 1661, loss = 3.50779384\n",
      "Iteration 1662, loss = 3.50761729\n",
      "Iteration 1663, loss = 3.50744081\n",
      "Iteration 1664, loss = 3.50726440\n",
      "Iteration 1665, loss = 3.50708807\n",
      "Iteration 1666, loss = 3.50691182\n",
      "Iteration 1667, loss = 3.50673564\n",
      "Iteration 1668, loss = 3.50655953\n",
      "Iteration 1669, loss = 3.50638350\n",
      "Iteration 1670, loss = 3.50620754\n",
      "Iteration 1671, loss = 3.50603165\n",
      "Iteration 1672, loss = 3.50585584\n",
      "Iteration 1673, loss = 3.50568010\n",
      "Iteration 1674, loss = 3.50550443\n",
      "Iteration 1675, loss = 3.50532884\n",
      "Iteration 1676, loss = 3.50515332\n",
      "Iteration 1677, loss = 3.50497787\n",
      "Iteration 1678, loss = 3.50480250\n",
      "Iteration 1679, loss = 3.50462720\n",
      "Iteration 1680, loss = 3.50445196\n",
      "Iteration 1681, loss = 3.50427681\n",
      "Iteration 1682, loss = 3.50410172\n",
      "Iteration 1683, loss = 3.50392671\n",
      "Iteration 1684, loss = 3.50375176\n",
      "Iteration 1685, loss = 3.50357689\n",
      "Iteration 1686, loss = 3.50340209\n",
      "Iteration 1687, loss = 3.50322736\n",
      "Iteration 1688, loss = 3.50305270\n",
      "Iteration 1689, loss = 3.50287811\n",
      "Iteration 1690, loss = 3.50270360\n",
      "Iteration 1691, loss = 3.50252915\n",
      "Iteration 1692, loss = 3.50235477\n",
      "Iteration 1693, loss = 3.50218047\n",
      "Iteration 1694, loss = 3.50200623\n",
      "Iteration 1695, loss = 3.50183207\n",
      "Iteration 1696, loss = 3.50165797\n",
      "Iteration 1697, loss = 3.50148394\n",
      "Iteration 1698, loss = 3.50130998\n",
      "Iteration 1699, loss = 3.50113609\n",
      "Iteration 1700, loss = 3.50096227\n",
      "Iteration 1701, loss = 3.50078852\n",
      "Iteration 1702, loss = 3.50061484\n",
      "Iteration 1703, loss = 3.50044122\n",
      "Iteration 1704, loss = 3.50026768\n",
      "Iteration 1705, loss = 3.50009420\n",
      "Iteration 1706, loss = 3.49992079\n",
      "Iteration 1707, loss = 3.49974745\n",
      "Iteration 1708, loss = 3.49957417\n",
      "Iteration 1709, loss = 3.49940096\n",
      "Iteration 1710, loss = 3.49922782\n",
      "Iteration 1711, loss = 3.49905475\n",
      "Iteration 1712, loss = 3.49888174\n",
      "Iteration 1713, loss = 3.49870880\n",
      "Iteration 1714, loss = 3.49853593\n",
      "Iteration 1715, loss = 3.49836312\n",
      "Iteration 1716, loss = 3.49819038\n",
      "Iteration 1717, loss = 3.49801771\n",
      "Iteration 1718, loss = 3.49784510\n",
      "Iteration 1719, loss = 3.49767256\n",
      "Iteration 1720, loss = 3.49750008\n",
      "Iteration 1721, loss = 3.49732767\n",
      "Iteration 1722, loss = 3.49715532\n",
      "Iteration 1723, loss = 3.49698304\n",
      "Iteration 1724, loss = 3.49681082\n",
      "Iteration 1725, loss = 3.49663867\n",
      "Iteration 1726, loss = 3.49646659\n",
      "Iteration 1727, loss = 3.49629456\n",
      "Iteration 1728, loss = 3.49612260\n",
      "Iteration 1729, loss = 3.49595071\n",
      "Iteration 1730, loss = 3.49577888\n",
      "Iteration 1731, loss = 3.49560711\n",
      "Iteration 1732, loss = 3.49543541\n",
      "Iteration 1733, loss = 3.49526377\n",
      "Iteration 1734, loss = 3.49509219\n",
      "Iteration 1735, loss = 3.49492068\n",
      "Iteration 1736, loss = 3.49474922\n",
      "Iteration 1737, loss = 3.49457784\n",
      "Iteration 1738, loss = 3.49440651\n",
      "Iteration 1739, loss = 3.49423525\n",
      "Iteration 1740, loss = 3.49406404\n",
      "Iteration 1741, loss = 3.49389290\n",
      "Iteration 1742, loss = 3.49372183\n",
      "Iteration 1743, loss = 3.49355081\n",
      "Iteration 1744, loss = 3.49337986\n",
      "Iteration 1745, loss = 3.49320896\n",
      "Iteration 1746, loss = 3.49303813\n",
      "Iteration 1747, loss = 3.49286736\n",
      "Iteration 1748, loss = 3.49269665\n",
      "Iteration 1749, loss = 3.49252600\n",
      "Iteration 1750, loss = 3.49235541\n",
      "Iteration 1751, loss = 3.49218488\n",
      "Iteration 1752, loss = 3.49201441\n",
      "Iteration 1753, loss = 3.49184400\n",
      "Iteration 1754, loss = 3.49167365\n",
      "Iteration 1755, loss = 3.49150336\n",
      "Iteration 1756, loss = 3.49133313\n",
      "Iteration 1757, loss = 3.49116296\n",
      "Iteration 1758, loss = 3.49099285\n",
      "Iteration 1759, loss = 3.49082279\n",
      "Iteration 1760, loss = 3.49065280\n",
      "Iteration 1761, loss = 3.49048286\n",
      "Iteration 1762, loss = 3.49031298\n",
      "Iteration 1763, loss = 3.49014316\n",
      "Iteration 1764, loss = 3.48997340\n",
      "Iteration 1765, loss = 3.48980370\n",
      "Iteration 1766, loss = 3.48963405\n",
      "Iteration 1767, loss = 3.48946447\n",
      "Iteration 1768, loss = 3.48929494\n",
      "Iteration 1769, loss = 3.48912546\n",
      "Iteration 1770, loss = 3.48895605\n",
      "Iteration 1771, loss = 3.48878669\n",
      "Iteration 1772, loss = 3.48861738\n",
      "Iteration 1773, loss = 3.48844814\n",
      "Iteration 1774, loss = 3.48827895\n",
      "Iteration 1775, loss = 3.48810981\n",
      "Iteration 1776, loss = 3.48794073\n",
      "Iteration 1777, loss = 3.48777171\n",
      "Iteration 1778, loss = 3.48760275\n",
      "Iteration 1779, loss = 3.48743383\n",
      "Iteration 1780, loss = 3.48726498\n",
      "Iteration 1781, loss = 3.48709618\n",
      "Iteration 1782, loss = 3.48692743\n",
      "Iteration 1783, loss = 3.48675874\n",
      "Iteration 1784, loss = 3.48659011\n",
      "Iteration 1785, loss = 3.48642153\n",
      "Iteration 1786, loss = 3.48625300\n",
      "Iteration 1787, loss = 3.48608453\n",
      "Iteration 1788, loss = 3.48591611\n",
      "Iteration 1789, loss = 3.48574774\n",
      "Iteration 1790, loss = 3.48557943\n",
      "Iteration 1791, loss = 3.48541117\n",
      "Iteration 1792, loss = 3.48524297\n",
      "Iteration 1793, loss = 3.48507482\n",
      "Iteration 1794, loss = 3.48490672\n",
      "Iteration 1795, loss = 3.48473868\n",
      "Iteration 1796, loss = 3.48457068\n",
      "Iteration 1797, loss = 3.48440274\n",
      "Iteration 1798, loss = 3.48423486\n",
      "Iteration 1799, loss = 3.48406702\n",
      "Iteration 1800, loss = 3.48389924\n",
      "Iteration 1801, loss = 3.48373151\n",
      "Iteration 1802, loss = 3.48356383\n",
      "Iteration 1803, loss = 3.48339620\n",
      "Iteration 1804, loss = 3.48322862\n",
      "Iteration 1805, loss = 3.48306109\n",
      "Iteration 1806, loss = 3.48289362\n",
      "Iteration 1807, loss = 3.48272620\n",
      "Iteration 1808, loss = 3.48255882\n",
      "Iteration 1809, loss = 3.48239150\n",
      "Iteration 1810, loss = 3.48222423\n",
      "Iteration 1811, loss = 3.48205701\n",
      "Iteration 1812, loss = 3.48188983\n",
      "Iteration 1813, loss = 3.48172271\n",
      "Iteration 1814, loss = 3.48155564\n",
      "Iteration 1815, loss = 3.48138862\n",
      "Iteration 1816, loss = 3.48122164\n",
      "Iteration 1817, loss = 3.48105472\n",
      "Iteration 1818, loss = 3.48088784\n",
      "Iteration 1819, loss = 3.48072102\n",
      "Iteration 1820, loss = 3.48055424\n",
      "Iteration 1821, loss = 3.48038751\n",
      "Iteration 1822, loss = 3.48022083\n",
      "Iteration 1823, loss = 3.48005420\n",
      "Iteration 1824, loss = 3.47988762\n",
      "Iteration 1825, loss = 3.47972108\n",
      "Iteration 1826, loss = 3.47955459\n",
      "Iteration 1827, loss = 3.47938815\n",
      "Iteration 1828, loss = 3.47922176\n",
      "Iteration 1829, loss = 3.47905541\n",
      "Iteration 1830, loss = 3.47888912\n",
      "Iteration 1831, loss = 3.47872286\n",
      "Iteration 1832, loss = 3.47855666\n",
      "Iteration 1833, loss = 3.47839050\n",
      "Iteration 1834, loss = 3.47822439\n",
      "Iteration 1835, loss = 3.47805833\n",
      "Iteration 1836, loss = 3.47789231\n",
      "Iteration 1837, loss = 3.47772634\n",
      "Iteration 1838, loss = 3.47756041\n",
      "Iteration 1839, loss = 3.47739453\n",
      "Iteration 1840, loss = 3.47722869\n",
      "Iteration 1841, loss = 3.47706290\n",
      "Iteration 1842, loss = 3.47689716\n",
      "Iteration 1843, loss = 3.47673146\n",
      "Iteration 1844, loss = 3.47656581\n",
      "Iteration 1845, loss = 3.47640020\n",
      "Iteration 1846, loss = 3.47623463\n",
      "Iteration 1847, loss = 3.47606911\n",
      "Iteration 1848, loss = 3.47590364\n",
      "Iteration 1849, loss = 3.47573821\n",
      "Iteration 1850, loss = 3.47557282\n",
      "Iteration 1851, loss = 3.47540748\n",
      "Iteration 1852, loss = 3.47524218\n",
      "Iteration 1853, loss = 3.47507692\n",
      "Iteration 1854, loss = 3.47491171\n",
      "Iteration 1855, loss = 3.47474654\n",
      "Iteration 1856, loss = 3.47458141\n",
      "Iteration 1857, loss = 3.47441633\n",
      "Iteration 1858, loss = 3.47425129\n",
      "Iteration 1859, loss = 3.47408629\n",
      "Iteration 1860, loss = 3.47392134\n",
      "Iteration 1861, loss = 3.47375643\n",
      "Iteration 1862, loss = 3.47359156\n",
      "Iteration 1863, loss = 3.47342673\n",
      "Iteration 1864, loss = 3.47326194\n",
      "Iteration 1865, loss = 3.47309720\n",
      "Iteration 1866, loss = 3.47293250\n",
      "Iteration 1867, loss = 3.47276784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1868, loss = 3.47260322\n",
      "Iteration 1869, loss = 3.47243864\n",
      "Iteration 1870, loss = 3.47227410\n",
      "Iteration 1871, loss = 3.47210961\n",
      "Iteration 1872, loss = 3.47194515\n",
      "Iteration 1873, loss = 3.47178074\n",
      "Iteration 1874, loss = 3.47161636\n",
      "Iteration 1875, loss = 3.47145203\n",
      "Iteration 1876, loss = 3.47128773\n",
      "Iteration 1877, loss = 3.47112348\n",
      "Iteration 1878, loss = 3.47095927\n",
      "Iteration 1879, loss = 3.47079509\n",
      "Iteration 1880, loss = 3.47063096\n",
      "Iteration 1881, loss = 3.47046687\n",
      "Iteration 1882, loss = 3.47030281\n",
      "Iteration 1883, loss = 3.47013880\n",
      "Iteration 1884, loss = 3.46997482\n",
      "Iteration 1885, loss = 3.46981088\n",
      "Iteration 1886, loss = 3.46964698\n",
      "Iteration 1887, loss = 3.46948312\n",
      "Iteration 1888, loss = 3.46931930\n",
      "Iteration 1889, loss = 3.46915552\n",
      "Iteration 1890, loss = 3.46899177\n",
      "Iteration 1891, loss = 3.46882806\n",
      "Iteration 1892, loss = 3.46866440\n",
      "Iteration 1893, loss = 3.46850076\n",
      "Iteration 1894, loss = 3.46833717\n",
      "Iteration 1895, loss = 3.46817361\n",
      "Iteration 1896, loss = 3.46801010\n",
      "Iteration 1897, loss = 3.46784661\n",
      "Iteration 1898, loss = 3.46768317\n",
      "Iteration 1899, loss = 3.46751976\n",
      "Iteration 1900, loss = 3.46735639\n",
      "Iteration 1901, loss = 3.46719306\n",
      "Iteration 1902, loss = 3.46702976\n",
      "Iteration 1903, loss = 3.46686650\n",
      "Iteration 1904, loss = 3.46670328\n",
      "Iteration 1905, loss = 3.46654009\n",
      "Iteration 1906, loss = 3.46637694\n",
      "Iteration 1907, loss = 3.46621382\n",
      "Iteration 1908, loss = 3.46605074\n",
      "Iteration 1909, loss = 3.46588770\n",
      "Iteration 1910, loss = 3.46572469\n",
      "Iteration 1911, loss = 3.46556171\n",
      "Iteration 1912, loss = 3.46539878\n",
      "Iteration 1913, loss = 3.46523587\n",
      "Iteration 1914, loss = 3.46507300\n",
      "Iteration 1915, loss = 3.46491017\n",
      "Iteration 1916, loss = 3.46474737\n",
      "Iteration 1917, loss = 3.46458461\n",
      "Iteration 1918, loss = 3.46442188\n",
      "Iteration 1919, loss = 3.46425918\n",
      "Iteration 1920, loss = 3.46409652\n",
      "Iteration 1921, loss = 3.46393389\n",
      "Iteration 1922, loss = 3.46377130\n",
      "Iteration 1923, loss = 3.46360874\n",
      "Iteration 1924, loss = 3.46344622\n",
      "Iteration 1925, loss = 3.46328372\n",
      "Iteration 1926, loss = 3.46312127\n",
      "Iteration 1927, loss = 3.46295884\n",
      "Iteration 1928, loss = 3.46279645\n",
      "Iteration 1929, loss = 3.46263409\n",
      "Iteration 1930, loss = 3.46247176\n",
      "Iteration 1931, loss = 3.46230947\n",
      "Iteration 1932, loss = 3.46214721\n",
      "Iteration 1933, loss = 3.46198498\n",
      "Iteration 1934, loss = 3.46182279\n",
      "Iteration 1935, loss = 3.46166062\n",
      "Iteration 1936, loss = 3.46149849\n",
      "Iteration 1937, loss = 3.46133639\n",
      "Iteration 1938, loss = 3.46117432\n",
      "Iteration 1939, loss = 3.46101229\n",
      "Iteration 1940, loss = 3.46085028\n",
      "Iteration 1941, loss = 3.46068831\n",
      "Iteration 1942, loss = 3.46052637\n",
      "Iteration 1943, loss = 3.46036446\n",
      "Iteration 1944, loss = 3.46020258\n",
      "Iteration 1945, loss = 3.46004074\n",
      "Iteration 1946, loss = 3.45987892\n",
      "Iteration 1947, loss = 3.45971713\n",
      "Iteration 1948, loss = 3.45955538\n",
      "Iteration 1949, loss = 3.45939365\n",
      "Iteration 1950, loss = 3.45923196\n",
      "Iteration 1951, loss = 3.45907030\n",
      "Iteration 1952, loss = 3.45890866\n",
      "Iteration 1953, loss = 3.45874706\n",
      "Iteration 1954, loss = 3.45858549\n",
      "Iteration 1955, loss = 3.45842394\n",
      "Iteration 1956, loss = 3.45826243\n",
      "Iteration 1957, loss = 3.45810094\n",
      "Iteration 1958, loss = 3.45793949\n",
      "Iteration 1959, loss = 3.45777807\n",
      "Iteration 1960, loss = 3.45761667\n",
      "Iteration 1961, loss = 3.45745530\n",
      "Iteration 1962, loss = 3.45729396\n",
      "Iteration 1963, loss = 3.45713266\n",
      "Iteration 1964, loss = 3.45697138\n",
      "Iteration 1965, loss = 3.45681012\n",
      "Iteration 1966, loss = 3.45664890\n",
      "Iteration 1967, loss = 3.45648771\n",
      "Iteration 1968, loss = 3.45632654\n",
      "Iteration 1969, loss = 3.45616540\n",
      "Iteration 1970, loss = 3.45600429\n",
      "Iteration 1971, loss = 3.45584321\n",
      "Iteration 1972, loss = 3.45568216\n",
      "Iteration 1973, loss = 3.45552113\n",
      "Iteration 1974, loss = 3.45536013\n",
      "Iteration 1975, loss = 3.45519916\n",
      "Iteration 1976, loss = 3.45503822\n",
      "Iteration 1977, loss = 3.45487730\n",
      "Iteration 1978, loss = 3.45471641\n",
      "Iteration 1979, loss = 3.45455555\n",
      "Iteration 1980, loss = 3.45439472\n",
      "Iteration 1981, loss = 3.45423391\n",
      "Iteration 1982, loss = 3.45407313\n",
      "Iteration 1983, loss = 3.45391238\n",
      "Iteration 1984, loss = 3.45375165\n",
      "Iteration 1985, loss = 3.45359095\n",
      "Iteration 1986, loss = 3.45343027\n",
      "Iteration 1987, loss = 3.45326962\n",
      "Iteration 1988, loss = 3.45310900\n",
      "Iteration 1989, loss = 3.45294840\n",
      "Iteration 1990, loss = 3.45278783\n",
      "Iteration 1991, loss = 3.45262729\n",
      "Iteration 1992, loss = 3.45246677\n",
      "Iteration 1993, loss = 3.45230627\n",
      "Iteration 1994, loss = 3.45214581\n",
      "Iteration 1995, loss = 3.45198536\n",
      "Iteration 1996, loss = 3.45182494\n",
      "Iteration 1997, loss = 3.45166455\n",
      "Iteration 1998, loss = 3.45150418\n",
      "Iteration 1999, loss = 3.45134384\n",
      "Iteration 2000, loss = 3.45118352\n"
     ]
    }
   ],
   "source": [
    "#setting up variable that will store confusion matrices\n",
    "confusion_matrices_train3 = []\n",
    "\n",
    "#We iterate over datasets for each fold\n",
    "for dataset in model3_data_indexes:\n",
    "    #From the list of all indexes we get only the ones for a given fold\n",
    "    train_indexes=dataset[0]\n",
    "    test_indexes=dataset[1]\n",
    "\n",
    "    #We fit the model using data with indexes for a given fold\n",
    "    clf3.fit(X_data.iloc[train_indexes], y_data.iloc[train_indexes])\n",
    "    #Predict values on the training data\n",
    "    y_pred3 = clf3.predict(X_data.iloc[train_indexes])\n",
    "    \n",
    "    #calculating multilabel_confusion_matrix\n",
    "    cm = multilabel_confusion_matrix(y_data.iloc[train_indexes], y_pred3)\n",
    "    \n",
    "    #setting up variable for cell-by-cell summation\n",
    "    res = np.matrix([[0, 0], [0, 0]])  \n",
    "    \n",
    "    #cell-by-cell summation of the confusion matrices\n",
    "    for item in cm:\n",
    "        single_cm = np.matrix(item)\n",
    "        res += single_cm\n",
    "    \n",
    "    #adding summed confussion_matrix to the variable with the results\n",
    "    confusion_matrices_train3.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold index 0\n",
      "[[383  70]\n",
      " [ 83 255]]\n",
      "Fold index 1\n",
      "[[355  86]\n",
      " [111 239]]\n",
      "Fold index 2\n",
      "[[330 100]\n",
      " [105 263]]\n"
     ]
    }
   ],
   "source": [
    "#printing resulted confusion matrices for the model3\n",
    "for fold, cm in enumerate(confusion_matrices_train3):\n",
    "    print(\"Fold index\", fold)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.36372677\n",
      "Iteration 2, loss = 4.86860399\n",
      "Iteration 3, loss = 4.52668702\n",
      "Iteration 4, loss = 4.30290986\n",
      "Iteration 5, loss = 4.16788263\n",
      "Iteration 6, loss = 4.09707362\n",
      "Iteration 7, loss = 4.06295036\n",
      "Iteration 8, loss = 4.04499828\n",
      "Iteration 9, loss = 4.03121963\n",
      "Iteration 10, loss = 4.01560191\n",
      "Iteration 11, loss = 3.99599952\n",
      "Iteration 12, loss = 3.97183797\n",
      "Iteration 13, loss = 3.94317026\n",
      "Iteration 14, loss = 3.91094879\n",
      "Iteration 15, loss = 3.87704475\n",
      "Iteration 16, loss = 3.84348679\n",
      "Iteration 17, loss = 3.81161691\n",
      "Iteration 18, loss = 3.78205383\n",
      "Iteration 19, loss = 3.75536227\n",
      "Iteration 20, loss = 3.73235646\n",
      "Iteration 21, loss = 3.71343227\n",
      "Iteration 22, loss = 3.69770327\n",
      "Iteration 23, loss = 3.68319498\n",
      "Iteration 24, loss = 3.66815682\n",
      "Iteration 25, loss = 3.65217043\n",
      "Iteration 26, loss = 3.63612433\n",
      "Iteration 27, loss = 3.62141359\n",
      "Iteration 28, loss = 3.60913903\n",
      "Iteration 29, loss = 3.59964384\n",
      "Iteration 30, loss = 3.59232095\n",
      "Iteration 31, loss = 3.58576421\n",
      "Iteration 32, loss = 3.57850757\n",
      "Iteration 33, loss = 3.56996044\n",
      "Iteration 34, loss = 3.56064717\n",
      "Iteration 35, loss = 3.55162960\n",
      "Iteration 36, loss = 3.54379544\n",
      "Iteration 37, loss = 3.53750021\n",
      "Iteration 38, loss = 3.53255133\n",
      "Iteration 39, loss = 3.52837917\n",
      "Iteration 40, loss = 3.52430263\n",
      "Iteration 41, loss = 3.51980533\n",
      "Iteration 42, loss = 3.51472069\n",
      "Iteration 43, loss = 3.50925000\n",
      "Iteration 44, loss = 3.50379748\n",
      "Iteration 45, loss = 3.49871452\n",
      "Iteration 46, loss = 3.49414240\n",
      "Iteration 47, loss = 3.49006581\n",
      "Iteration 48, loss = 3.48646118\n",
      "Iteration 49, loss = 3.48333346\n",
      "Iteration 50, loss = 3.48061433\n",
      "Iteration 51, loss = 3.47809431\n",
      "Iteration 52, loss = 3.47552121\n",
      "Iteration 53, loss = 3.47278288\n",
      "Iteration 54, loss = 3.46997557\n",
      "Iteration 55, loss = 3.46729233\n",
      "Iteration 56, loss = 3.46486556\n",
      "Iteration 57, loss = 3.46270566\n",
      "Iteration 58, loss = 3.46073820\n",
      "Iteration 59, loss = 3.45886454\n",
      "Iteration 60, loss = 3.45700102\n",
      "Iteration 61, loss = 3.45509690\n",
      "Iteration 62, loss = 3.45314186\n",
      "Iteration 63, loss = 3.45116536\n",
      "Iteration 64, loss = 3.44922143\n",
      "Iteration 65, loss = 3.44735648\n",
      "Iteration 66, loss = 3.44557853\n",
      "Iteration 67, loss = 3.44385583\n",
      "Iteration 68, loss = 3.44214830\n",
      "Iteration 69, loss = 3.44044128\n",
      "Iteration 70, loss = 3.43875206\n",
      "Iteration 71, loss = 3.43711259\n",
      "Iteration 72, loss = 3.43554959\n",
      "Iteration 73, loss = 3.43407438\n",
      "Iteration 74, loss = 3.43268054\n",
      "Iteration 75, loss = 3.43134729\n",
      "Iteration 76, loss = 3.43004818\n",
      "Iteration 77, loss = 3.42876161\n",
      "Iteration 78, loss = 3.42747836\n",
      "Iteration 79, loss = 3.42620290\n",
      "Iteration 80, loss = 3.42494740\n",
      "Iteration 81, loss = 3.42372232\n",
      "Iteration 82, loss = 3.42253090\n",
      "Iteration 83, loss = 3.42137051\n",
      "Iteration 84, loss = 3.42023600\n",
      "Iteration 85, loss = 3.41912118\n",
      "Iteration 86, loss = 3.41802058\n",
      "Iteration 87, loss = 3.41693218\n",
      "Iteration 88, loss = 3.41585813\n",
      "Iteration 89, loss = 3.41480240\n",
      "Iteration 90, loss = 3.41376798\n",
      "Iteration 91, loss = 3.41275544\n",
      "Iteration 92, loss = 3.41176301\n",
      "Iteration 93, loss = 3.41078751\n",
      "Iteration 94, loss = 3.40982570\n",
      "Iteration 95, loss = 3.40887585\n",
      "Iteration 96, loss = 3.40793845\n",
      "Iteration 97, loss = 3.40701498\n",
      "Iteration 98, loss = 3.40610568\n",
      "Iteration 99, loss = 3.40520908\n",
      "Iteration 100, loss = 3.40432364\n",
      "Iteration 101, loss = 3.40344895\n",
      "Iteration 102, loss = 3.40258552\n",
      "Iteration 103, loss = 3.40173425\n",
      "Iteration 104, loss = 3.40089599\n",
      "Iteration 105, loss = 3.40007093\n",
      "Iteration 106, loss = 3.39925859\n",
      "Iteration 107, loss = 3.39845852\n",
      "Iteration 108, loss = 3.39767089\n",
      "Iteration 109, loss = 3.39689626\n",
      "Iteration 110, loss = 3.39613480\n",
      "Iteration 111, loss = 3.39538601\n",
      "Iteration 112, loss = 3.39464949\n",
      "Iteration 113, loss = 3.39392536\n",
      "Iteration 114, loss = 3.39321400\n",
      "Iteration 115, loss = 3.39251576\n",
      "Iteration 116, loss = 3.39183098\n",
      "Iteration 117, loss = 3.39115980\n",
      "Iteration 118, loss = 3.39050210\n",
      "Iteration 119, loss = 3.38985769\n",
      "Iteration 120, loss = 3.38922643\n",
      "Iteration 121, loss = 3.38860831\n",
      "Iteration 122, loss = 3.38800338\n",
      "Iteration 123, loss = 3.38741173\n",
      "Iteration 124, loss = 3.38683342\n",
      "Iteration 125, loss = 3.38626836\n",
      "Iteration 126, loss = 3.38571636\n",
      "Iteration 127, loss = 3.38517727\n",
      "Iteration 128, loss = 3.38465098\n",
      "Iteration 129, loss = 3.38413731\n",
      "Iteration 130, loss = 3.38363606\n",
      "Iteration 131, loss = 3.38314706\n",
      "Iteration 132, loss = 3.38267015\n",
      "Iteration 133, loss = 3.38220521\n",
      "Iteration 134, loss = 3.38175216\n",
      "Iteration 135, loss = 3.38131082\n",
      "Iteration 136, loss = 3.38088088\n",
      "Iteration 137, loss = 3.38046198\n",
      "Iteration 138, loss = 3.38005387\n",
      "Iteration 139, loss = 3.37965635\n",
      "Iteration 140, loss = 3.37926925\n",
      "Iteration 141, loss = 3.37889232\n",
      "Iteration 142, loss = 3.37852528\n",
      "Iteration 143, loss = 3.37816786\n",
      "Iteration 144, loss = 3.37781983\n",
      "Iteration 145, loss = 3.37748101\n",
      "Iteration 146, loss = 3.37715117\n",
      "Iteration 147, loss = 3.37683007\n",
      "Iteration 148, loss = 3.37651750\n",
      "Iteration 149, loss = 3.37621324\n",
      "Iteration 150, loss = 3.37591708\n",
      "Iteration 151, loss = 3.37562881\n",
      "Iteration 152, loss = 3.37534820\n",
      "Iteration 153, loss = 3.37507505\n",
      "Iteration 154, loss = 3.37480918\n",
      "Iteration 155, loss = 3.37455042\n",
      "Iteration 156, loss = 3.37429860\n",
      "Iteration 157, loss = 3.37405353\n",
      "Iteration 158, loss = 3.37381501\n",
      "Iteration 159, loss = 3.37358285\n",
      "Iteration 160, loss = 3.37335690\n",
      "Iteration 161, loss = 3.37313700\n",
      "Iteration 162, loss = 3.37292299\n",
      "Iteration 163, loss = 3.37271469\n",
      "Iteration 164, loss = 3.37251194\n",
      "Iteration 165, loss = 3.37231460\n",
      "Iteration 166, loss = 3.37212251\n",
      "Iteration 167, loss = 3.37193551\n",
      "Iteration 168, loss = 3.37175346\n",
      "Iteration 169, loss = 3.37157623\n",
      "Iteration 170, loss = 3.37140368\n",
      "Iteration 171, loss = 3.37123567\n",
      "Iteration 172, loss = 3.37107207\n",
      "Iteration 173, loss = 3.37091274\n",
      "Iteration 174, loss = 3.37075757\n",
      "Iteration 175, loss = 3.37060643\n",
      "Iteration 176, loss = 3.37045920\n",
      "Iteration 177, loss = 3.37031576\n",
      "Iteration 178, loss = 3.37017601\n",
      "Iteration 179, loss = 3.37003984\n",
      "Iteration 180, loss = 3.36990713\n",
      "Iteration 181, loss = 3.36977778\n",
      "Iteration 182, loss = 3.36965170\n",
      "Iteration 183, loss = 3.36952878\n",
      "Iteration 184, loss = 3.36940893\n",
      "Iteration 185, loss = 3.36929207\n",
      "Iteration 186, loss = 3.36917809\n",
      "Iteration 187, loss = 3.36906691\n",
      "Iteration 188, loss = 3.36895845\n",
      "Iteration 189, loss = 3.36885264\n",
      "Iteration 190, loss = 3.36874938\n",
      "Iteration 191, loss = 3.36864860\n",
      "Iteration 192, loss = 3.36855024\n",
      "Iteration 193, loss = 3.36845422\n",
      "Iteration 194, loss = 3.36836046\n",
      "Iteration 195, loss = 3.36826892\n",
      "Iteration 196, loss = 3.36817951\n",
      "Iteration 197, loss = 3.36809219\n",
      "Iteration 198, loss = 3.36800688\n",
      "Iteration 199, loss = 3.36792354\n",
      "Iteration 200, loss = 3.36784210\n",
      "Iteration 201, loss = 3.36776251\n",
      "Iteration 202, loss = 3.36768472\n",
      "Iteration 203, loss = 3.36760867\n",
      "Iteration 204, loss = 3.36753433\n",
      "Iteration 205, loss = 3.36746163\n",
      "Iteration 206, loss = 3.36739053\n",
      "Iteration 207, loss = 3.36732099\n",
      "Iteration 208, loss = 3.36725297\n",
      "Iteration 209, loss = 3.36718642\n",
      "Iteration 210, loss = 3.36712129\n",
      "Iteration 211, loss = 3.36705756\n",
      "Iteration 212, loss = 3.36699517\n",
      "Iteration 213, loss = 3.36693410\n",
      "Iteration 214, loss = 3.36687430\n",
      "Iteration 215, loss = 3.36681575\n",
      "Iteration 216, loss = 3.36675840\n",
      "Iteration 217, loss = 3.36670223\n",
      "Iteration 218, loss = 3.36664720\n",
      "Iteration 219, loss = 3.36659328\n",
      "Iteration 220, loss = 3.36654045\n",
      "Iteration 221, loss = 3.36648866\n",
      "Iteration 222, loss = 3.36643791\n",
      "Iteration 223, loss = 3.36638815\n",
      "Iteration 224, loss = 3.36633936\n",
      "Iteration 225, loss = 3.36629152\n",
      "Iteration 226, loss = 3.36624460\n",
      "Iteration 227, loss = 3.36619858\n",
      "Iteration 228, loss = 3.36615343\n",
      "Iteration 229, loss = 3.36610914\n",
      "Iteration 230, loss = 3.36606568\n",
      "Iteration 231, loss = 3.36602303\n",
      "Iteration 232, loss = 3.36598117\n",
      "Iteration 233, loss = 3.36594009\n",
      "Iteration 234, loss = 3.36589975\n",
      "Iteration 235, loss = 3.36586015\n",
      "Iteration 236, loss = 3.36582126\n",
      "Iteration 237, loss = 3.36578307\n",
      "Iteration 238, loss = 3.36574557\n",
      "Iteration 239, loss = 3.36570873\n",
      "Iteration 240, loss = 3.36567253\n",
      "Iteration 241, loss = 3.36563697\n",
      "Iteration 242, loss = 3.36560203\n",
      "Iteration 243, loss = 3.36556769\n",
      "Iteration 244, loss = 3.36553395\n",
      "Iteration 245, loss = 3.36550077\n",
      "Iteration 246, loss = 3.36546817\n",
      "Iteration 247, loss = 3.36543611\n",
      "Iteration 248, loss = 3.36540459\n",
      "Iteration 249, loss = 3.36537359\n",
      "Iteration 250, loss = 3.36534311\n",
      "Iteration 251, loss = 3.36531313\n",
      "Iteration 252, loss = 3.36528364\n",
      "Iteration 253, loss = 3.36525462\n",
      "Iteration 254, loss = 3.36522608\n",
      "Iteration 255, loss = 3.36519800\n",
      "Iteration 256, loss = 3.36517036\n",
      "Iteration 257, loss = 3.36514317\n",
      "Iteration 258, loss = 3.36511640\n",
      "Iteration 259, loss = 3.36509006\n",
      "Iteration 260, loss = 3.36506412\n",
      "Iteration 261, loss = 3.36503859\n",
      "Iteration 262, loss = 3.36501345\n",
      "Iteration 263, loss = 3.36498870\n",
      "Iteration 264, loss = 3.36496432\n",
      "Iteration 265, loss = 3.36494032\n",
      "Iteration 266, loss = 3.36491668\n",
      "Iteration 267, loss = 3.36489339\n",
      "Iteration 268, loss = 3.36487045\n",
      "Iteration 269, loss = 3.36484785\n",
      "Iteration 270, loss = 3.36482558\n",
      "Iteration 271, loss = 3.36480365\n",
      "Iteration 272, loss = 3.36478203\n",
      "Iteration 273, loss = 3.36476072\n",
      "Iteration 274, loss = 3.36473972\n",
      "Iteration 275, loss = 3.36471903\n",
      "Iteration 276, loss = 3.36469863\n",
      "Iteration 277, loss = 3.36467852\n",
      "Iteration 278, loss = 3.36465870\n",
      "Iteration 279, loss = 3.36463915\n",
      "Iteration 280, loss = 3.36461988\n",
      "Iteration 281, loss = 3.36460087\n",
      "Iteration 282, loss = 3.36458213\n",
      "Iteration 283, loss = 3.36456365\n",
      "Iteration 284, loss = 3.36454542\n",
      "Iteration 285, loss = 3.36452744\n",
      "Iteration 286, loss = 3.36450970\n",
      "Iteration 287, loss = 3.36449221\n",
      "Iteration 288, loss = 3.36447494\n",
      "Iteration 289, loss = 3.36445791\n",
      "Iteration 290, loss = 3.36444111\n",
      "Iteration 291, loss = 3.36442453\n",
      "Iteration 292, loss = 3.36440816\n",
      "Iteration 293, loss = 3.36439202\n",
      "Iteration 294, loss = 3.36437608\n",
      "Iteration 295, loss = 3.36436035\n",
      "Iteration 296, loss = 3.36434482\n",
      "Iteration 297, loss = 3.36432949\n",
      "Iteration 298, loss = 3.36431436\n",
      "Iteration 299, loss = 3.36429942\n",
      "Iteration 300, loss = 3.36428467\n",
      "Iteration 301, loss = 3.36427011\n",
      "Iteration 302, loss = 3.36425573\n",
      "Iteration 303, loss = 3.36424153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 304, loss = 3.36422751\n",
      "Iteration 305, loss = 3.36421366\n",
      "Iteration 306, loss = 3.36419998\n",
      "Iteration 307, loss = 3.36418647\n",
      "Iteration 308, loss = 3.36417312\n",
      "Iteration 309, loss = 3.36415994\n",
      "Iteration 310, loss = 3.36414691\n",
      "Iteration 311, loss = 3.36413405\n",
      "Iteration 312, loss = 3.36412134\n",
      "Iteration 313, loss = 3.36410878\n",
      "Iteration 314, loss = 3.36409637\n",
      "Iteration 315, loss = 3.36408410\n",
      "Iteration 316, loss = 3.36407198\n",
      "Iteration 317, loss = 3.36406001\n",
      "Iteration 318, loss = 3.36404817\n",
      "Iteration 319, loss = 3.36403647\n",
      "Iteration 320, loss = 3.36402491\n",
      "Iteration 321, loss = 3.36401348\n",
      "Iteration 322, loss = 3.36400218\n",
      "Iteration 323, loss = 3.36399101\n",
      "Iteration 324, loss = 3.36397997\n",
      "Iteration 325, loss = 3.36396906\n",
      "Iteration 326, loss = 3.36395827\n",
      "Iteration 327, loss = 3.36394759\n",
      "Iteration 328, loss = 3.36393704\n",
      "Iteration 329, loss = 3.36392661\n",
      "Iteration 330, loss = 3.36391629\n",
      "Iteration 331, loss = 3.36390609\n",
      "Iteration 332, loss = 3.36389600\n",
      "Iteration 333, loss = 3.36388602\n",
      "Iteration 334, loss = 3.36387615\n",
      "Iteration 335, loss = 3.36386639\n",
      "Iteration 336, loss = 3.36385673\n",
      "Iteration 337, loss = 3.36384718\n",
      "Iteration 338, loss = 3.36383773\n",
      "Iteration 339, loss = 3.36382838\n",
      "Iteration 340, loss = 3.36381913\n",
      "Iteration 341, loss = 3.36380998\n",
      "Iteration 342, loss = 3.36380093\n",
      "Iteration 343, loss = 3.36379197\n",
      "Iteration 344, loss = 3.36378311\n",
      "Iteration 345, loss = 3.36377434\n",
      "Iteration 346, loss = 3.36376566\n",
      "Iteration 347, loss = 3.36375708\n",
      "Iteration 348, loss = 3.36374858\n",
      "Iteration 349, loss = 3.36374017\n",
      "Iteration 350, loss = 3.36373184\n",
      "Iteration 351, loss = 3.36372360\n",
      "Iteration 352, loss = 3.36371545\n",
      "Iteration 353, loss = 3.36370737\n",
      "Iteration 354, loss = 3.36369938\n",
      "Iteration 355, loss = 3.36369147\n",
      "Iteration 356, loss = 3.36368364\n",
      "Iteration 357, loss = 3.36367589\n",
      "Iteration 358, loss = 3.36366822\n",
      "Iteration 359, loss = 3.36366062\n",
      "Iteration 360, loss = 3.36365309\n",
      "Iteration 361, loss = 3.36364565\n",
      "Iteration 362, loss = 3.36363827\n",
      "Iteration 363, loss = 3.36363097\n",
      "Iteration 364, loss = 3.36362374\n",
      "Iteration 365, loss = 3.36361657\n",
      "Iteration 366, loss = 3.36360948\n",
      "Iteration 367, loss = 3.36360246\n",
      "Iteration 368, loss = 3.36359550\n",
      "Iteration 369, loss = 3.36358862\n",
      "Iteration 370, loss = 3.36358179\n",
      "Iteration 371, loss = 3.36357503\n",
      "Iteration 372, loss = 3.36356834\n",
      "Iteration 373, loss = 3.36356171\n",
      "Iteration 374, loss = 3.36355514\n",
      "Iteration 375, loss = 3.36354864\n",
      "Iteration 376, loss = 3.36354219\n",
      "Iteration 377, loss = 3.36353581\n",
      "Iteration 378, loss = 3.36352948\n",
      "Iteration 379, loss = 3.36352321\n",
      "Iteration 380, loss = 3.36351701\n",
      "Iteration 381, loss = 3.36351085\n",
      "Iteration 382, loss = 3.36350476\n",
      "Iteration 383, loss = 3.36349872\n",
      "Iteration 384, loss = 3.36349274\n",
      "Iteration 385, loss = 3.36348681\n",
      "Iteration 386, loss = 3.36348093\n",
      "Iteration 387, loss = 3.36347511\n",
      "Iteration 388, loss = 3.36346934\n",
      "Iteration 389, loss = 3.36346362\n",
      "Iteration 390, loss = 3.36345795\n",
      "Iteration 391, loss = 3.36345233\n",
      "Iteration 392, loss = 3.36344676\n",
      "Iteration 393, loss = 3.36344125\n",
      "Iteration 394, loss = 3.36343578\n",
      "Iteration 395, loss = 3.36343036\n",
      "Iteration 396, loss = 3.36342498\n",
      "Iteration 397, loss = 3.36341966\n",
      "Iteration 398, loss = 3.36341438\n",
      "Iteration 399, loss = 3.36340914\n",
      "Iteration 400, loss = 3.36340395\n",
      "Iteration 401, loss = 3.36339881\n",
      "Iteration 402, loss = 3.36339371\n",
      "Iteration 403, loss = 3.36338865\n",
      "Iteration 404, loss = 3.36338364\n",
      "Iteration 405, loss = 3.36337867\n",
      "Iteration 406, loss = 3.36337374\n",
      "Iteration 407, loss = 3.36336886\n",
      "Iteration 408, loss = 3.36336401\n",
      "Iteration 409, loss = 3.36335921\n",
      "Iteration 410, loss = 3.36335445\n",
      "Iteration 411, loss = 3.36334972\n",
      "Iteration 412, loss = 3.36334504\n",
      "Iteration 413, loss = 3.36334039\n",
      "Iteration 414, loss = 3.36333579\n",
      "Iteration 415, loss = 3.36333122\n",
      "Iteration 416, loss = 3.36332669\n",
      "Iteration 417, loss = 3.36332219\n",
      "Iteration 418, loss = 3.36331774\n",
      "Iteration 419, loss = 3.36331332\n",
      "Iteration 420, loss = 3.36330893\n",
      "Iteration 421, loss = 3.36330458\n",
      "Iteration 422, loss = 3.36330027\n",
      "Iteration 423, loss = 3.36329599\n",
      "Iteration 424, loss = 3.36329175\n",
      "Iteration 425, loss = 3.36328754\n",
      "Iteration 426, loss = 3.36328336\n",
      "Iteration 427, loss = 3.36327922\n",
      "Iteration 428, loss = 3.36327511\n",
      "Iteration 429, loss = 3.36327103\n",
      "Iteration 430, loss = 3.36326699\n",
      "Iteration 431, loss = 3.36326298\n",
      "Iteration 432, loss = 3.36325899\n",
      "Iteration 433, loss = 3.36325504\n",
      "Iteration 434, loss = 3.36325112\n",
      "Iteration 435, loss = 3.36324724\n",
      "Iteration 436, loss = 3.36324338\n",
      "Iteration 437, loss = 3.36323955\n",
      "Iteration 438, loss = 3.36323575\n",
      "Iteration 439, loss = 3.36323198\n",
      "Iteration 440, loss = 3.36322824\n",
      "Iteration 441, loss = 3.36322453\n",
      "Iteration 442, loss = 3.36322085\n",
      "Iteration 443, loss = 3.36321719\n",
      "Iteration 444, loss = 3.36321357\n",
      "Iteration 445, loss = 3.36320997\n",
      "Iteration 446, loss = 3.36320639\n",
      "Iteration 447, loss = 3.36320285\n",
      "Iteration 448, loss = 3.36319933\n",
      "Iteration 449, loss = 3.36319584\n",
      "Iteration 450, loss = 3.36319237\n",
      "Iteration 451, loss = 3.36318893\n",
      "Iteration 452, loss = 3.36318552\n",
      "Iteration 453, loss = 3.36318213\n",
      "Iteration 454, loss = 3.36317877\n",
      "Iteration 455, loss = 3.36317543\n",
      "Iteration 456, loss = 3.36317211\n",
      "Iteration 457, loss = 3.36316882\n",
      "Iteration 458, loss = 3.36316556\n",
      "Iteration 459, loss = 3.36316231\n",
      "Iteration 460, loss = 3.36315910\n",
      "Iteration 461, loss = 3.36315590\n",
      "Iteration 462, loss = 3.36315273\n",
      "Iteration 463, loss = 3.36314958\n",
      "Iteration 464, loss = 3.36314646\n",
      "Iteration 465, loss = 3.36314335\n",
      "Iteration 466, loss = 3.36314027\n",
      "Iteration 467, loss = 3.36313721\n",
      "Iteration 468, loss = 3.36313417\n",
      "Iteration 469, loss = 3.36313116\n",
      "Iteration 470, loss = 3.36312816\n",
      "Iteration 471, loss = 3.36312519\n",
      "Iteration 472, loss = 3.36312224\n",
      "Iteration 473, loss = 3.36311931\n",
      "Iteration 474, loss = 3.36311640\n",
      "Iteration 475, loss = 3.36311351\n",
      "Iteration 476, loss = 3.36311065\n",
      "Iteration 477, loss = 3.36310781\n",
      "Iteration 478, loss = 3.36310501\n",
      "Iteration 479, loss = 3.36310232\n",
      "Iteration 480, loss = 3.36309991\n",
      "Iteration 481, loss = 3.36309840\n",
      "Iteration 482, loss = 3.36309992\n",
      "Iteration 483, loss = 3.36311178\n",
      "Iteration 484, loss = 3.36315884\n",
      "Iteration 485, loss = 3.36332510\n",
      "Iteration 486, loss = 3.36384828\n",
      "Iteration 487, loss = 3.36522425\n",
      "Iteration 488, loss = 3.36714665\n",
      "Iteration 489, loss = 3.36741947\n",
      "Iteration 490, loss = 3.36421315\n",
      "Iteration 491, loss = 3.36330489\n",
      "Iteration 492, loss = 3.36550630\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 5.31407369\n",
      "Iteration 2, loss = 4.86067263\n",
      "Iteration 3, loss = 4.55618005\n",
      "Iteration 4, loss = 4.35698962\n",
      "Iteration 5, loss = 4.23636009\n",
      "Iteration 6, loss = 4.17812562\n",
      "Iteration 7, loss = 4.15762286\n",
      "Iteration 8, loss = 4.14777553\n",
      "Iteration 9, loss = 4.13552159\n",
      "Iteration 10, loss = 4.11892962\n",
      "Iteration 11, loss = 4.09872051\n",
      "Iteration 12, loss = 4.07465009\n",
      "Iteration 13, loss = 4.04646270\n",
      "Iteration 14, loss = 4.01553273\n",
      "Iteration 15, loss = 3.98478791\n",
      "Iteration 16, loss = 3.95738508\n",
      "Iteration 17, loss = 3.93548885\n",
      "Iteration 18, loss = 3.91988229\n",
      "Iteration 19, loss = 3.91004738\n",
      "Iteration 20, loss = 3.90415959\n",
      "Iteration 21, loss = 3.89926792\n",
      "Iteration 22, loss = 3.89252895\n",
      "Iteration 23, loss = 3.88282441\n",
      "Iteration 24, loss = 3.87091808\n",
      "Iteration 25, loss = 3.85823515\n",
      "Iteration 26, loss = 3.84574196\n",
      "Iteration 27, loss = 3.83372936\n",
      "Iteration 28, loss = 3.82223582\n",
      "Iteration 29, loss = 3.81144935\n",
      "Iteration 30, loss = 3.80173159\n",
      "Iteration 31, loss = 3.79337271\n",
      "Iteration 32, loss = 3.78635724\n",
      "Iteration 33, loss = 3.78032754\n",
      "Iteration 34, loss = 3.77474027\n",
      "Iteration 35, loss = 3.76907053\n",
      "Iteration 36, loss = 3.76296166\n",
      "Iteration 37, loss = 3.75632585\n",
      "Iteration 38, loss = 3.74937097\n",
      "Iteration 39, loss = 3.74247626\n",
      "Iteration 40, loss = 3.73594274\n",
      "Iteration 41, loss = 3.72980417\n",
      "Iteration 42, loss = 3.72387623\n",
      "Iteration 43, loss = 3.71800429\n",
      "Iteration 44, loss = 3.71225832\n",
      "Iteration 45, loss = 3.70687383\n",
      "Iteration 46, loss = 3.70201095\n",
      "Iteration 47, loss = 3.69759224\n",
      "Iteration 48, loss = 3.69337868\n",
      "Iteration 49, loss = 3.68918131\n",
      "Iteration 50, loss = 3.68498744\n",
      "Iteration 51, loss = 3.68091011\n",
      "Iteration 52, loss = 3.67705286\n",
      "Iteration 53, loss = 3.67342681\n",
      "Iteration 54, loss = 3.66997058\n",
      "Iteration 55, loss = 3.66662546\n",
      "Iteration 56, loss = 3.66338457\n",
      "Iteration 57, loss = 3.66027269\n",
      "Iteration 58, loss = 3.65728754\n",
      "Iteration 59, loss = 3.65437770\n",
      "Iteration 60, loss = 3.65148683\n",
      "Iteration 61, loss = 3.64860728\n",
      "Iteration 62, loss = 3.64577703\n",
      "Iteration 63, loss = 3.64303510\n",
      "Iteration 64, loss = 3.64039553\n",
      "Iteration 65, loss = 3.63785372\n",
      "Iteration 66, loss = 3.63539927\n",
      "Iteration 67, loss = 3.63302389\n",
      "Iteration 68, loss = 3.63072194\n",
      "Iteration 69, loss = 3.62847938\n",
      "Iteration 70, loss = 3.62627062\n",
      "Iteration 71, loss = 3.62408151\n",
      "Iteration 72, loss = 3.62192765\n",
      "Iteration 73, loss = 3.61983686\n",
      "Iteration 74, loss = 3.61782074\n",
      "Iteration 75, loss = 3.61587033\n",
      "Iteration 76, loss = 3.61397195\n",
      "Iteration 77, loss = 3.61212308\n",
      "Iteration 78, loss = 3.61033275\n",
      "Iteration 79, loss = 3.60860510\n",
      "Iteration 80, loss = 3.60693177\n",
      "Iteration 81, loss = 3.60530754\n",
      "Iteration 82, loss = 3.60374095\n",
      "Iteration 83, loss = 3.60224159\n",
      "Iteration 84, loss = 3.60080553\n",
      "Iteration 85, loss = 3.59941704\n",
      "Iteration 86, loss = 3.59806316\n",
      "Iteration 87, loss = 3.59674563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 88, loss = 3.59547342\n",
      "Iteration 89, loss = 3.59424814\n",
      "Iteration 90, loss = 3.59306557\n",
      "Iteration 91, loss = 3.59192432\n",
      "Iteration 92, loss = 3.59082592\n",
      "Iteration 93, loss = 3.58976978\n",
      "Iteration 94, loss = 3.58875046\n",
      "Iteration 95, loss = 3.58776273\n",
      "Iteration 96, loss = 3.58680763\n",
      "Iteration 97, loss = 3.58588830\n",
      "Iteration 98, loss = 3.58500435\n",
      "Iteration 99, loss = 3.58415246\n",
      "Iteration 100, loss = 3.58332956\n",
      "Iteration 101, loss = 3.58253502\n",
      "Iteration 102, loss = 3.58176832\n",
      "Iteration 103, loss = 3.58102749\n",
      "Iteration 104, loss = 3.58031154\n",
      "Iteration 105, loss = 3.57962090\n",
      "Iteration 106, loss = 3.57895596\n",
      "Iteration 107, loss = 3.57831522\n",
      "Iteration 108, loss = 3.57769566\n",
      "Iteration 109, loss = 3.57709521\n",
      "Iteration 110, loss = 3.57651313\n",
      "Iteration 111, loss = 3.57594945\n",
      "Iteration 112, loss = 3.57540423\n",
      "Iteration 113, loss = 3.57487717\n",
      "Iteration 114, loss = 3.57436772\n",
      "Iteration 115, loss = 3.57387467\n",
      "Iteration 116, loss = 3.57339677\n",
      "Iteration 117, loss = 3.57293324\n",
      "Iteration 118, loss = 3.57248397\n",
      "Iteration 119, loss = 3.57204900\n",
      "Iteration 120, loss = 3.57162794\n",
      "Iteration 121, loss = 3.57122011\n",
      "Iteration 122, loss = 3.57082476\n",
      "Iteration 123, loss = 3.57044133\n",
      "Iteration 124, loss = 3.57006947\n",
      "Iteration 125, loss = 3.56970902\n",
      "Iteration 126, loss = 3.56935986\n",
      "Iteration 127, loss = 3.56902176\n",
      "Iteration 128, loss = 3.56869421\n",
      "Iteration 129, loss = 3.56837658\n",
      "Iteration 130, loss = 3.56806842\n",
      "Iteration 131, loss = 3.56776948\n",
      "Iteration 132, loss = 3.56747959\n",
      "Iteration 133, loss = 3.56719851\n",
      "Iteration 134, loss = 3.56692601\n",
      "Iteration 135, loss = 3.56666184\n",
      "Iteration 136, loss = 3.56640565\n",
      "Iteration 137, loss = 3.56615707\n",
      "Iteration 138, loss = 3.56591586\n",
      "Iteration 139, loss = 3.56568179\n",
      "Iteration 140, loss = 3.56545463\n",
      "Iteration 141, loss = 3.56523409\n",
      "Iteration 142, loss = 3.56501997\n",
      "Iteration 143, loss = 3.56481203\n",
      "Iteration 144, loss = 3.56461005\n",
      "Iteration 145, loss = 3.56441384\n",
      "Iteration 146, loss = 3.56422325\n",
      "Iteration 147, loss = 3.56403805\n",
      "Iteration 148, loss = 3.56385800\n",
      "Iteration 149, loss = 3.56368294\n",
      "Iteration 150, loss = 3.56351271\n",
      "Iteration 151, loss = 3.56334715\n",
      "Iteration 152, loss = 3.56318610\n",
      "Iteration 153, loss = 3.56302943\n",
      "Iteration 154, loss = 3.56287698\n",
      "Iteration 155, loss = 3.56272860\n",
      "Iteration 156, loss = 3.56258416\n",
      "Iteration 157, loss = 3.56244353\n",
      "Iteration 158, loss = 3.56230656\n",
      "Iteration 159, loss = 3.56217315\n",
      "Iteration 160, loss = 3.56204320\n",
      "Iteration 161, loss = 3.56191659\n",
      "Iteration 162, loss = 3.56179323\n",
      "Iteration 163, loss = 3.56167299\n",
      "Iteration 164, loss = 3.56155579\n",
      "Iteration 165, loss = 3.56144151\n",
      "Iteration 166, loss = 3.56133007\n",
      "Iteration 167, loss = 3.56122139\n",
      "Iteration 168, loss = 3.56111538\n",
      "Iteration 169, loss = 3.56101195\n",
      "Iteration 170, loss = 3.56091102\n",
      "Iteration 171, loss = 3.56081251\n",
      "Iteration 172, loss = 3.56071635\n",
      "Iteration 173, loss = 3.56062247\n",
      "Iteration 174, loss = 3.56053080\n",
      "Iteration 175, loss = 3.56044126\n",
      "Iteration 176, loss = 3.56035379\n",
      "Iteration 177, loss = 3.56026834\n",
      "Iteration 178, loss = 3.56018484\n",
      "Iteration 179, loss = 3.56010323\n",
      "Iteration 180, loss = 3.56002346\n",
      "Iteration 181, loss = 3.55994548\n",
      "Iteration 182, loss = 3.55986922\n",
      "Iteration 183, loss = 3.55979465\n",
      "Iteration 184, loss = 3.55972171\n",
      "Iteration 185, loss = 3.55965036\n",
      "Iteration 186, loss = 3.55958055\n",
      "Iteration 187, loss = 3.55951224\n",
      "Iteration 188, loss = 3.55944538\n",
      "Iteration 189, loss = 3.55937993\n",
      "Iteration 190, loss = 3.55931586\n",
      "Iteration 191, loss = 3.55925313\n",
      "Iteration 192, loss = 3.55919169\n",
      "Iteration 193, loss = 3.55913152\n",
      "Iteration 194, loss = 3.55907259\n",
      "Iteration 195, loss = 3.55901485\n",
      "Iteration 196, loss = 3.55895827\n",
      "Iteration 197, loss = 3.55890283\n",
      "Iteration 198, loss = 3.55884849\n",
      "Iteration 199, loss = 3.55879522\n",
      "Iteration 200, loss = 3.55874300\n",
      "Iteration 201, loss = 3.55869180\n",
      "Iteration 202, loss = 3.55864159\n",
      "Iteration 203, loss = 3.55859235\n",
      "Iteration 204, loss = 3.55854405\n",
      "Iteration 205, loss = 3.55849667\n",
      "Iteration 206, loss = 3.55845018\n",
      "Iteration 207, loss = 3.55840457\n",
      "Iteration 208, loss = 3.55835980\n",
      "Iteration 209, loss = 3.55831586\n",
      "Iteration 210, loss = 3.55827273\n",
      "Iteration 211, loss = 3.55823039\n",
      "Iteration 212, loss = 3.55818882\n",
      "Iteration 213, loss = 3.55814800\n",
      "Iteration 214, loss = 3.55810791\n",
      "Iteration 215, loss = 3.55806854\n",
      "Iteration 216, loss = 3.55802986\n",
      "Iteration 217, loss = 3.55799186\n",
      "Iteration 218, loss = 3.55795453\n",
      "Iteration 219, loss = 3.55791785\n",
      "Iteration 220, loss = 3.55788180\n",
      "Iteration 221, loss = 3.55784637\n",
      "Iteration 222, loss = 3.55781155\n",
      "Iteration 223, loss = 3.55777732\n",
      "Iteration 224, loss = 3.55774367\n",
      "Iteration 225, loss = 3.55771058\n",
      "Iteration 226, loss = 3.55767804\n",
      "Iteration 227, loss = 3.55764604\n",
      "Iteration 228, loss = 3.55761457\n",
      "Iteration 229, loss = 3.55758362\n",
      "Iteration 230, loss = 3.55755317\n",
      "Iteration 231, loss = 3.55752322\n",
      "Iteration 232, loss = 3.55749374\n",
      "Iteration 233, loss = 3.55746474\n",
      "Iteration 234, loss = 3.55743620\n",
      "Iteration 235, loss = 3.55740812\n",
      "Iteration 236, loss = 3.55738047\n",
      "Iteration 237, loss = 3.55735326\n",
      "Iteration 238, loss = 3.55732648\n",
      "Iteration 239, loss = 3.55730010\n",
      "Iteration 240, loss = 3.55727414\n",
      "Iteration 241, loss = 3.55724857\n",
      "Iteration 242, loss = 3.55722340\n",
      "Iteration 243, loss = 3.55719860\n",
      "Iteration 244, loss = 3.55717418\n",
      "Iteration 245, loss = 3.55715012\n",
      "Iteration 246, loss = 3.55712643\n",
      "Iteration 247, loss = 3.55710308\n",
      "Iteration 248, loss = 3.55708008\n",
      "Iteration 249, loss = 3.55705742\n",
      "Iteration 250, loss = 3.55703509\n",
      "Iteration 251, loss = 3.55701308\n",
      "Iteration 252, loss = 3.55699140\n",
      "Iteration 253, loss = 3.55697002\n",
      "Iteration 254, loss = 3.55694895\n",
      "Iteration 255, loss = 3.55692818\n",
      "Iteration 256, loss = 3.55690771\n",
      "Iteration 257, loss = 3.55688752\n",
      "Iteration 258, loss = 3.55686762\n",
      "Iteration 259, loss = 3.55684799\n",
      "Iteration 260, loss = 3.55682864\n",
      "Iteration 261, loss = 3.55680956\n",
      "Iteration 262, loss = 3.55679073\n",
      "Iteration 263, loss = 3.55677217\n",
      "Iteration 264, loss = 3.55675386\n",
      "Iteration 265, loss = 3.55673580\n",
      "Iteration 266, loss = 3.55671798\n",
      "Iteration 267, loss = 3.55670040\n",
      "Iteration 268, loss = 3.55668305\n",
      "Iteration 269, loss = 3.55666594\n",
      "Iteration 270, loss = 3.55664905\n",
      "Iteration 271, loss = 3.55663238\n",
      "Iteration 272, loss = 3.55661594\n",
      "Iteration 273, loss = 3.55659971\n",
      "Iteration 274, loss = 3.55658369\n",
      "Iteration 275, loss = 3.55656787\n",
      "Iteration 276, loss = 3.55655226\n",
      "Iteration 277, loss = 3.55653685\n",
      "Iteration 278, loss = 3.55652164\n",
      "Iteration 279, loss = 3.55650663\n",
      "Iteration 280, loss = 3.55649182\n",
      "Iteration 281, loss = 3.55647724\n",
      "Iteration 282, loss = 3.55646297\n",
      "Iteration 283, loss = 3.55644930\n",
      "Iteration 284, loss = 3.55643717\n",
      "Iteration 285, loss = 3.55642981\n",
      "Iteration 286, loss = 3.55643821\n",
      "Iteration 287, loss = 3.55650046\n",
      "Iteration 288, loss = 3.55673607\n",
      "Iteration 289, loss = 3.55746986\n",
      "Iteration 290, loss = 3.55898552\n",
      "Iteration 291, loss = 3.56050011\n",
      "Iteration 292, loss = 3.55884578\n",
      "Iteration 293, loss = 3.55645129\n",
      "Iteration 294, loss = 3.55723108\n",
      "Iteration 295, loss = 3.55860304\n",
      "Iteration 296, loss = 3.55730042\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 5.50316831\n",
      "Iteration 2, loss = 4.98355300\n",
      "Iteration 3, loss = 4.62107767\n",
      "Iteration 4, loss = 4.39195933\n",
      "Iteration 5, loss = 4.26256098\n",
      "Iteration 6, loss = 4.20687042\n",
      "Iteration 7, loss = 4.19080588\n",
      "Iteration 8, loss = 4.18718117\n",
      "Iteration 9, loss = 4.18420012\n",
      "Iteration 10, loss = 4.17855109\n",
      "Iteration 11, loss = 4.16901915\n",
      "Iteration 12, loss = 4.15381576\n",
      "Iteration 13, loss = 4.13142390\n",
      "Iteration 14, loss = 4.10245204\n",
      "Iteration 15, loss = 4.06992294\n",
      "Iteration 16, loss = 4.03793580\n",
      "Iteration 17, loss = 4.00977521\n",
      "Iteration 18, loss = 3.98655829\n",
      "Iteration 19, loss = 3.96746255\n",
      "Iteration 20, loss = 3.95137164\n",
      "Iteration 21, loss = 3.93798468\n",
      "Iteration 22, loss = 3.92726796\n",
      "Iteration 23, loss = 3.91851332\n",
      "Iteration 24, loss = 3.91053243\n",
      "Iteration 25, loss = 3.90270953\n",
      "Iteration 26, loss = 3.89544742\n",
      "Iteration 27, loss = 3.88939876\n",
      "Iteration 28, loss = 3.88434997\n",
      "Iteration 29, loss = 3.87910167\n",
      "Iteration 30, loss = 3.87258777\n",
      "Iteration 31, loss = 3.86484511\n",
      "Iteration 32, loss = 3.85677492\n",
      "Iteration 33, loss = 3.84930782\n",
      "Iteration 34, loss = 3.84299013\n",
      "Iteration 35, loss = 3.83809022\n",
      "Iteration 36, loss = 3.83465389\n",
      "Iteration 37, loss = 3.83230205\n",
      "Iteration 38, loss = 3.83022549\n",
      "Iteration 39, loss = 3.82767236\n",
      "Iteration 40, loss = 3.82444170\n",
      "Iteration 41, loss = 3.82081226\n",
      "Iteration 42, loss = 3.81710250\n",
      "Iteration 43, loss = 3.81344417\n",
      "Iteration 44, loss = 3.80990201\n",
      "Iteration 45, loss = 3.80658355\n",
      "Iteration 46, loss = 3.80353248\n",
      "Iteration 47, loss = 3.80062834\n",
      "Iteration 48, loss = 3.79772086\n",
      "Iteration 49, loss = 3.79483188\n",
      "Iteration 50, loss = 3.79212437\n",
      "Iteration 51, loss = 3.78968844\n",
      "Iteration 52, loss = 3.78745176\n",
      "Iteration 53, loss = 3.78530386\n",
      "Iteration 54, loss = 3.78321687\n",
      "Iteration 55, loss = 3.78120739\n",
      "Iteration 56, loss = 3.77924820\n",
      "Iteration 57, loss = 3.77728050\n",
      "Iteration 58, loss = 3.77528791\n",
      "Iteration 59, loss = 3.77330852\n",
      "Iteration 60, loss = 3.77138830\n",
      "Iteration 61, loss = 3.76956216\n",
      "Iteration 62, loss = 3.76786257\n",
      "Iteration 63, loss = 3.76629667\n",
      "Iteration 64, loss = 3.76481018\n",
      "Iteration 65, loss = 3.76331050\n",
      "Iteration 66, loss = 3.76174007\n",
      "Iteration 67, loss = 3.76011214\n",
      "Iteration 68, loss = 3.75847682\n",
      "Iteration 69, loss = 3.75687844\n",
      "Iteration 70, loss = 3.75534861\n",
      "Iteration 71, loss = 3.75390708\n",
      "Iteration 72, loss = 3.75254682\n",
      "Iteration 73, loss = 3.75123363\n",
      "Iteration 74, loss = 3.74993665\n",
      "Iteration 75, loss = 3.74864965\n",
      "Iteration 76, loss = 3.74737683\n",
      "Iteration 77, loss = 3.74611640\n",
      "Iteration 78, loss = 3.74486938\n",
      "Iteration 79, loss = 3.74364906\n",
      "Iteration 80, loss = 3.74246818\n",
      "Iteration 81, loss = 3.74132589\n",
      "Iteration 82, loss = 3.74021597\n",
      "Iteration 83, loss = 3.73913838\n",
      "Iteration 84, loss = 3.73809354\n",
      "Iteration 85, loss = 3.73707433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 86, loss = 3.73607276\n",
      "Iteration 87, loss = 3.73508921\n",
      "Iteration 88, loss = 3.73412862\n",
      "Iteration 89, loss = 3.73319305\n",
      "Iteration 90, loss = 3.73228328\n",
      "Iteration 91, loss = 3.73140252\n",
      "Iteration 92, loss = 3.73055307\n",
      "Iteration 93, loss = 3.72973233\n",
      "Iteration 94, loss = 3.72893553\n",
      "Iteration 95, loss = 3.72816043\n",
      "Iteration 96, loss = 3.72740753\n",
      "Iteration 97, loss = 3.72667820\n",
      "Iteration 98, loss = 3.72597414\n",
      "Iteration 99, loss = 3.72529646\n",
      "Iteration 100, loss = 3.72464433\n",
      "Iteration 101, loss = 3.72401536\n",
      "Iteration 102, loss = 3.72340755\n",
      "Iteration 103, loss = 3.72282006\n",
      "Iteration 104, loss = 3.72225227\n",
      "Iteration 105, loss = 3.72170349\n",
      "Iteration 106, loss = 3.72117366\n",
      "Iteration 107, loss = 3.72066367\n",
      "Iteration 108, loss = 3.72017420\n",
      "Iteration 109, loss = 3.71970458\n",
      "Iteration 110, loss = 3.71925293\n",
      "Iteration 111, loss = 3.71881748\n",
      "Iteration 112, loss = 3.71839749\n",
      "Iteration 113, loss = 3.71799294\n",
      "Iteration 114, loss = 3.71760376\n",
      "Iteration 115, loss = 3.71722956\n",
      "Iteration 116, loss = 3.71686991\n",
      "Iteration 117, loss = 3.71652413\n",
      "Iteration 118, loss = 3.71619131\n",
      "Iteration 119, loss = 3.71587060\n",
      "Iteration 120, loss = 3.71556146\n",
      "Iteration 121, loss = 3.71526356\n",
      "Iteration 122, loss = 3.71497646\n",
      "Iteration 123, loss = 3.71469967\n",
      "Iteration 124, loss = 3.71443268\n",
      "Iteration 125, loss = 3.71417497\n",
      "Iteration 126, loss = 3.71392606\n",
      "Iteration 127, loss = 3.71368553\n",
      "Iteration 128, loss = 3.71345294\n",
      "Iteration 129, loss = 3.71322787\n",
      "Iteration 130, loss = 3.71300993\n",
      "Iteration 131, loss = 3.71279887\n",
      "Iteration 132, loss = 3.71259440\n",
      "Iteration 133, loss = 3.71239619\n",
      "Iteration 134, loss = 3.71220393\n",
      "Iteration 135, loss = 3.71201734\n",
      "Iteration 136, loss = 3.71183611\n",
      "Iteration 137, loss = 3.71165994\n",
      "Iteration 138, loss = 3.71148863\n",
      "Iteration 139, loss = 3.71132209\n",
      "Iteration 140, loss = 3.71116018\n",
      "Iteration 141, loss = 3.71100269\n",
      "Iteration 142, loss = 3.71084938\n",
      "Iteration 143, loss = 3.71070004\n",
      "Iteration 144, loss = 3.71055451\n",
      "Iteration 145, loss = 3.71041273\n",
      "Iteration 146, loss = 3.71027459\n",
      "Iteration 147, loss = 3.71013998\n",
      "Iteration 148, loss = 3.71000877\n",
      "Iteration 149, loss = 3.70988080\n",
      "Iteration 150, loss = 3.70975595\n",
      "Iteration 151, loss = 3.70963414\n",
      "Iteration 152, loss = 3.70951529\n",
      "Iteration 153, loss = 3.70939934\n",
      "Iteration 154, loss = 3.70928619\n",
      "Iteration 155, loss = 3.70917575\n",
      "Iteration 156, loss = 3.70906791\n",
      "Iteration 157, loss = 3.70896262\n",
      "Iteration 158, loss = 3.70885979\n",
      "Iteration 159, loss = 3.70875937\n",
      "Iteration 160, loss = 3.70866129\n",
      "Iteration 161, loss = 3.70856547\n",
      "Iteration 162, loss = 3.70847185\n",
      "Iteration 163, loss = 3.70838036\n",
      "Iteration 164, loss = 3.70829093\n",
      "Iteration 165, loss = 3.70820350\n",
      "Iteration 166, loss = 3.70811803\n",
      "Iteration 167, loss = 3.70803445\n",
      "Iteration 168, loss = 3.70795272\n",
      "Iteration 169, loss = 3.70787277\n",
      "Iteration 170, loss = 3.70779456\n",
      "Iteration 171, loss = 3.70771804\n",
      "Iteration 172, loss = 3.70764316\n",
      "Iteration 173, loss = 3.70756987\n",
      "Iteration 174, loss = 3.70749813\n",
      "Iteration 175, loss = 3.70742789\n",
      "Iteration 176, loss = 3.70735912\n",
      "Iteration 177, loss = 3.70729177\n",
      "Iteration 178, loss = 3.70722581\n",
      "Iteration 179, loss = 3.70716119\n",
      "Iteration 180, loss = 3.70709789\n",
      "Iteration 181, loss = 3.70703586\n",
      "Iteration 182, loss = 3.70697507\n",
      "Iteration 183, loss = 3.70691549\n",
      "Iteration 184, loss = 3.70685709\n",
      "Iteration 185, loss = 3.70679983\n",
      "Iteration 186, loss = 3.70674370\n",
      "Iteration 187, loss = 3.70668865\n",
      "Iteration 188, loss = 3.70663466\n",
      "Iteration 189, loss = 3.70658171\n",
      "Iteration 190, loss = 3.70652977\n",
      "Iteration 191, loss = 3.70647881\n",
      "Iteration 192, loss = 3.70642882\n",
      "Iteration 193, loss = 3.70637975\n",
      "Iteration 194, loss = 3.70633161\n",
      "Iteration 195, loss = 3.70628435\n",
      "Iteration 196, loss = 3.70623797\n",
      "Iteration 197, loss = 3.70619243\n",
      "Iteration 198, loss = 3.70614773\n",
      "Iteration 199, loss = 3.70610383\n",
      "Iteration 200, loss = 3.70606072\n",
      "Iteration 201, loss = 3.70601839\n",
      "Iteration 202, loss = 3.70597681\n",
      "Iteration 203, loss = 3.70593597\n",
      "Iteration 204, loss = 3.70589585\n",
      "Iteration 205, loss = 3.70585643\n",
      "Iteration 206, loss = 3.70581770\n",
      "Iteration 207, loss = 3.70577964\n",
      "Iteration 208, loss = 3.70574224\n",
      "Iteration 209, loss = 3.70570548\n",
      "Iteration 210, loss = 3.70566934\n",
      "Iteration 211, loss = 3.70563382\n",
      "Iteration 212, loss = 3.70559890\n",
      "Iteration 213, loss = 3.70556457\n",
      "Iteration 214, loss = 3.70553080\n",
      "Iteration 215, loss = 3.70549761\n",
      "Iteration 216, loss = 3.70546495\n",
      "Iteration 217, loss = 3.70543284\n",
      "Iteration 218, loss = 3.70540125\n",
      "Iteration 219, loss = 3.70537018\n",
      "Iteration 220, loss = 3.70533961\n",
      "Iteration 221, loss = 3.70530953\n",
      "Iteration 222, loss = 3.70527993\n",
      "Iteration 223, loss = 3.70525080\n",
      "Iteration 224, loss = 3.70522214\n",
      "Iteration 225, loss = 3.70519393\n",
      "Iteration 226, loss = 3.70516616\n",
      "Iteration 227, loss = 3.70513883\n",
      "Iteration 228, loss = 3.70511192\n",
      "Iteration 229, loss = 3.70508543\n",
      "Iteration 230, loss = 3.70505935\n",
      "Iteration 231, loss = 3.70503366\n",
      "Iteration 232, loss = 3.70500837\n",
      "Iteration 233, loss = 3.70498346\n",
      "Iteration 234, loss = 3.70495893\n",
      "Iteration 235, loss = 3.70493476\n",
      "Iteration 236, loss = 3.70491096\n",
      "Iteration 237, loss = 3.70488751\n",
      "Iteration 238, loss = 3.70486441\n",
      "Iteration 239, loss = 3.70484165\n",
      "Iteration 240, loss = 3.70481923\n",
      "Iteration 241, loss = 3.70479713\n",
      "Iteration 242, loss = 3.70477535\n",
      "Iteration 243, loss = 3.70475389\n",
      "Iteration 244, loss = 3.70473274\n",
      "Iteration 245, loss = 3.70471189\n",
      "Iteration 246, loss = 3.70469134\n",
      "Iteration 247, loss = 3.70467108\n",
      "Iteration 248, loss = 3.70465111\n",
      "Iteration 249, loss = 3.70463142\n",
      "Iteration 250, loss = 3.70461201\n",
      "Iteration 251, loss = 3.70459286\n",
      "Iteration 252, loss = 3.70457398\n",
      "Iteration 253, loss = 3.70455537\n",
      "Iteration 254, loss = 3.70453701\n",
      "Iteration 255, loss = 3.70451890\n",
      "Iteration 256, loss = 3.70450104\n",
      "Iteration 257, loss = 3.70448342\n",
      "Iteration 258, loss = 3.70446604\n",
      "Iteration 259, loss = 3.70444889\n",
      "Iteration 260, loss = 3.70443198\n",
      "Iteration 261, loss = 3.70441529\n",
      "Iteration 262, loss = 3.70439882\n",
      "Iteration 263, loss = 3.70438257\n",
      "Iteration 264, loss = 3.70436653\n",
      "Iteration 265, loss = 3.70435071\n",
      "Iteration 266, loss = 3.70433509\n",
      "Iteration 267, loss = 3.70431968\n",
      "Iteration 268, loss = 3.70430446\n",
      "Iteration 269, loss = 3.70428944\n",
      "Iteration 270, loss = 3.70427462\n",
      "Iteration 271, loss = 3.70425998\n",
      "Iteration 272, loss = 3.70424553\n",
      "Iteration 273, loss = 3.70423127\n",
      "Iteration 274, loss = 3.70421718\n",
      "Iteration 275, loss = 3.70420327\n",
      "Iteration 276, loss = 3.70418954\n",
      "Iteration 277, loss = 3.70417598\n",
      "Iteration 278, loss = 3.70416259\n",
      "Iteration 279, loss = 3.70414936\n",
      "Iteration 280, loss = 3.70413630\n",
      "Iteration 281, loss = 3.70412339\n",
      "Iteration 282, loss = 3.70411065\n",
      "Iteration 283, loss = 3.70409806\n",
      "Iteration 284, loss = 3.70408562\n",
      "Iteration 285, loss = 3.70407333\n",
      "Iteration 286, loss = 3.70406119\n",
      "Iteration 287, loss = 3.70404920\n",
      "Iteration 288, loss = 3.70403735\n",
      "Iteration 289, loss = 3.70402564\n",
      "Iteration 290, loss = 3.70401407\n",
      "Iteration 291, loss = 3.70400264\n",
      "Iteration 292, loss = 3.70399134\n",
      "Iteration 293, loss = 3.70398017\n",
      "Iteration 294, loss = 3.70396914\n",
      "Iteration 295, loss = 3.70395823\n",
      "Iteration 296, loss = 3.70394745\n",
      "Iteration 297, loss = 3.70393679\n",
      "Iteration 298, loss = 3.70392626\n",
      "Iteration 299, loss = 3.70391584\n",
      "Iteration 300, loss = 3.70390555\n",
      "Iteration 301, loss = 3.70389537\n",
      "Iteration 302, loss = 3.70388531\n",
      "Iteration 303, loss = 3.70387536\n",
      "Iteration 304, loss = 3.70386552\n",
      "Iteration 305, loss = 3.70385580\n",
      "Iteration 306, loss = 3.70384618\n",
      "Iteration 307, loss = 3.70383667\n",
      "Iteration 308, loss = 3.70382726\n",
      "Iteration 309, loss = 3.70381796\n",
      "Iteration 310, loss = 3.70380876\n",
      "Iteration 311, loss = 3.70379966\n",
      "Iteration 312, loss = 3.70379066\n",
      "Iteration 313, loss = 3.70378176\n",
      "Iteration 314, loss = 3.70377296\n",
      "Iteration 315, loss = 3.70376425\n",
      "Iteration 316, loss = 3.70375563\n",
      "Iteration 317, loss = 3.70374711\n",
      "Iteration 318, loss = 3.70373867\n",
      "Iteration 319, loss = 3.70373033\n",
      "Iteration 320, loss = 3.70372208\n",
      "Iteration 321, loss = 3.70371391\n",
      "Iteration 322, loss = 3.70370583\n",
      "Iteration 323, loss = 3.70369783\n",
      "Iteration 324, loss = 3.70368992\n",
      "Iteration 325, loss = 3.70368209\n",
      "Iteration 326, loss = 3.70367434\n",
      "Iteration 327, loss = 3.70366667\n",
      "Iteration 328, loss = 3.70365908\n",
      "Iteration 329, loss = 3.70365157\n",
      "Iteration 330, loss = 3.70364414\n",
      "Iteration 331, loss = 3.70363678\n",
      "Iteration 332, loss = 3.70362949\n",
      "Iteration 333, loss = 3.70362228\n",
      "Iteration 334, loss = 3.70361515\n",
      "Iteration 335, loss = 3.70360808\n",
      "Iteration 336, loss = 3.70360109\n",
      "Iteration 337, loss = 3.70359417\n",
      "Iteration 338, loss = 3.70358731\n",
      "Iteration 339, loss = 3.70358052\n",
      "Iteration 340, loss = 3.70357380\n",
      "Iteration 341, loss = 3.70356715\n",
      "Iteration 342, loss = 3.70356056\n",
      "Iteration 343, loss = 3.70355404\n",
      "Iteration 344, loss = 3.70354758\n",
      "Iteration 345, loss = 3.70354119\n",
      "Iteration 346, loss = 3.70353485\n",
      "Iteration 347, loss = 3.70352858\n",
      "Iteration 348, loss = 3.70352237\n",
      "Iteration 349, loss = 3.70351622\n",
      "Iteration 350, loss = 3.70351012\n",
      "Iteration 351, loss = 3.70350409\n",
      "Iteration 352, loss = 3.70349811\n",
      "Iteration 353, loss = 3.70349219\n",
      "Iteration 354, loss = 3.70348632\n",
      "Iteration 355, loss = 3.70348051\n",
      "Iteration 356, loss = 3.70347476\n",
      "Iteration 357, loss = 3.70346906\n",
      "Iteration 358, loss = 3.70346341\n",
      "Iteration 359, loss = 3.70345782\n",
      "Iteration 360, loss = 3.70345227\n",
      "Iteration 361, loss = 3.70344678\n",
      "Iteration 362, loss = 3.70344134\n",
      "Iteration 363, loss = 3.70343595\n",
      "Iteration 364, loss = 3.70343061\n",
      "Iteration 365, loss = 3.70342532\n",
      "Iteration 366, loss = 3.70342007\n",
      "Iteration 367, loss = 3.70341488\n",
      "Iteration 368, loss = 3.70340973\n",
      "Iteration 369, loss = 3.70340463\n",
      "Iteration 370, loss = 3.70339957\n",
      "Iteration 371, loss = 3.70339456\n",
      "Iteration 372, loss = 3.70338959\n",
      "Iteration 373, loss = 3.70338467\n",
      "Iteration 374, loss = 3.70337979\n",
      "Iteration 375, loss = 3.70337496\n",
      "Iteration 376, loss = 3.70337017\n",
      "Iteration 377, loss = 3.70336542\n",
      "Iteration 378, loss = 3.70336071\n",
      "Iteration 379, loss = 3.70335604\n",
      "Iteration 380, loss = 3.70335142\n",
      "Iteration 381, loss = 3.70334683\n",
      "Iteration 382, loss = 3.70334228\n",
      "Iteration 383, loss = 3.70333778\n",
      "Iteration 384, loss = 3.70333331\n",
      "Iteration 385, loss = 3.70332888\n",
      "Iteration 386, loss = 3.70332449\n",
      "Iteration 387, loss = 3.70332014\n",
      "Iteration 388, loss = 3.70331582\n",
      "Iteration 389, loss = 3.70331154\n",
      "Iteration 390, loss = 3.70330730\n",
      "Iteration 391, loss = 3.70330309\n",
      "Iteration 392, loss = 3.70329892\n",
      "Iteration 393, loss = 3.70329479\n",
      "Iteration 394, loss = 3.70329068\n",
      "Iteration 395, loss = 3.70328662\n",
      "Iteration 396, loss = 3.70328258\n",
      "Iteration 397, loss = 3.70327858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 398, loss = 3.70327462\n",
      "Iteration 399, loss = 3.70327068\n",
      "Iteration 400, loss = 3.70326678\n",
      "Iteration 401, loss = 3.70326291\n",
      "Iteration 402, loss = 3.70325908\n",
      "Iteration 403, loss = 3.70325527\n",
      "Iteration 404, loss = 3.70325150\n",
      "Iteration 405, loss = 3.70324775\n",
      "Iteration 406, loss = 3.70324404\n",
      "Iteration 407, loss = 3.70324036\n",
      "Iteration 408, loss = 3.70323670\n",
      "Iteration 409, loss = 3.70323308\n",
      "Iteration 410, loss = 3.70322948\n",
      "Iteration 411, loss = 3.70322592\n",
      "Iteration 412, loss = 3.70322238\n",
      "Iteration 413, loss = 3.70321887\n",
      "Iteration 414, loss = 3.70321539\n",
      "Iteration 415, loss = 3.70321193\n",
      "Iteration 416, loss = 3.70320851\n",
      "Iteration 417, loss = 3.70320511\n",
      "Iteration 418, loss = 3.70320174\n",
      "Iteration 419, loss = 3.70319839\n",
      "Iteration 420, loss = 3.70319507\n",
      "Iteration 421, loss = 3.70319177\n",
      "Iteration 422, loss = 3.70318850\n",
      "Iteration 423, loss = 3.70318526\n",
      "Iteration 424, loss = 3.70318204\n",
      "Iteration 425, loss = 3.70317885\n",
      "Iteration 426, loss = 3.70317568\n",
      "Iteration 427, loss = 3.70317254\n",
      "Iteration 428, loss = 3.70316942\n",
      "Iteration 429, loss = 3.70316632\n",
      "Iteration 430, loss = 3.70316325\n",
      "Iteration 431, loss = 3.70316020\n",
      "Iteration 432, loss = 3.70315717\n",
      "Iteration 433, loss = 3.70315417\n",
      "Iteration 434, loss = 3.70315118\n",
      "Iteration 435, loss = 3.70314823\n",
      "Iteration 436, loss = 3.70314529\n",
      "Iteration 437, loss = 3.70314238\n",
      "Iteration 438, loss = 3.70313948\n",
      "Iteration 439, loss = 3.70313661\n",
      "Iteration 440, loss = 3.70313376\n",
      "Iteration 441, loss = 3.70313093\n",
      "Iteration 442, loss = 3.70312813\n",
      "Iteration 443, loss = 3.70312534\n",
      "Iteration 444, loss = 3.70312257\n",
      "Iteration 445, loss = 3.70311983\n",
      "Iteration 446, loss = 3.70311710\n",
      "Iteration 447, loss = 3.70311439\n",
      "Iteration 448, loss = 3.70311171\n",
      "Iteration 449, loss = 3.70310904\n",
      "Iteration 450, loss = 3.70310639\n",
      "Iteration 451, loss = 3.70310376\n",
      "Iteration 452, loss = 3.70310115\n",
      "Iteration 453, loss = 3.70309856\n",
      "Iteration 454, loss = 3.70309599\n",
      "Iteration 455, loss = 3.70309344\n",
      "Iteration 456, loss = 3.70309090\n",
      "Iteration 457, loss = 3.70308838\n",
      "Iteration 458, loss = 3.70308588\n",
      "Iteration 459, loss = 3.70308340\n",
      "Iteration 460, loss = 3.70308094\n",
      "Iteration 461, loss = 3.70307849\n",
      "Iteration 462, loss = 3.70307606\n",
      "Iteration 463, loss = 3.70307365\n",
      "Iteration 464, loss = 3.70307125\n",
      "Iteration 465, loss = 3.70306887\n",
      "Iteration 466, loss = 3.70306651\n",
      "Iteration 467, loss = 3.70306416\n",
      "Iteration 468, loss = 3.70306183\n",
      "Iteration 469, loss = 3.70305952\n",
      "Iteration 470, loss = 3.70305722\n",
      "Iteration 471, loss = 3.70305494\n",
      "Iteration 472, loss = 3.70305267\n",
      "Iteration 473, loss = 3.70305042\n",
      "Iteration 474, loss = 3.70304819\n",
      "Iteration 475, loss = 3.70304597\n",
      "Iteration 476, loss = 3.70304376\n",
      "Iteration 477, loss = 3.70304157\n",
      "Iteration 478, loss = 3.70303940\n",
      "Iteration 479, loss = 3.70303724\n",
      "Iteration 480, loss = 3.70303509\n",
      "Iteration 481, loss = 3.70303296\n",
      "Iteration 482, loss = 3.70303084\n",
      "Iteration 483, loss = 3.70302874\n",
      "Iteration 484, loss = 3.70302665\n",
      "Iteration 485, loss = 3.70302458\n",
      "Iteration 486, loss = 3.70302252\n",
      "Iteration 487, loss = 3.70302047\n",
      "Iteration 488, loss = 3.70301844\n",
      "Iteration 489, loss = 3.70301642\n",
      "Iteration 490, loss = 3.70301441\n",
      "Iteration 491, loss = 3.70301242\n",
      "Iteration 492, loss = 3.70301043\n",
      "Iteration 493, loss = 3.70300847\n",
      "Iteration 494, loss = 3.70300651\n",
      "Iteration 495, loss = 3.70300457\n",
      "Iteration 496, loss = 3.70300264\n",
      "Iteration 497, loss = 3.70300072\n",
      "Iteration 498, loss = 3.70299882\n",
      "Iteration 499, loss = 3.70299693\n",
      "Iteration 500, loss = 3.70299505\n",
      "Iteration 501, loss = 3.70299318\n",
      "Iteration 502, loss = 3.70299132\n",
      "Iteration 503, loss = 3.70298948\n",
      "Iteration 504, loss = 3.70298765\n",
      "Iteration 505, loss = 3.70298583\n",
      "Iteration 506, loss = 3.70298402\n",
      "Iteration 507, loss = 3.70298222\n",
      "Iteration 508, loss = 3.70298044\n",
      "Iteration 509, loss = 3.70297866\n",
      "Iteration 510, loss = 3.70297690\n",
      "Iteration 511, loss = 3.70297515\n",
      "Iteration 512, loss = 3.70297340\n",
      "Iteration 513, loss = 3.70297167\n",
      "Iteration 514, loss = 3.70296995\n",
      "Iteration 515, loss = 3.70296825\n",
      "Iteration 516, loss = 3.70296655\n",
      "Iteration 517, loss = 3.70296486\n",
      "Iteration 518, loss = 3.70296318\n",
      "Iteration 519, loss = 3.70296152\n",
      "Iteration 520, loss = 3.70295986\n",
      "Iteration 521, loss = 3.70295821\n",
      "Iteration 522, loss = 3.70295658\n",
      "Iteration 523, loss = 3.70295495\n",
      "Iteration 524, loss = 3.70295334\n",
      "Iteration 525, loss = 3.70295173\n",
      "Iteration 526, loss = 3.70295013\n",
      "Iteration 527, loss = 3.70294855\n",
      "Iteration 528, loss = 3.70294697\n",
      "Iteration 529, loss = 3.70294540\n",
      "Iteration 530, loss = 3.70294384\n",
      "Iteration 531, loss = 3.70294230\n",
      "Iteration 532, loss = 3.70294076\n",
      "Iteration 533, loss = 3.70293923\n",
      "Iteration 534, loss = 3.70293771\n",
      "Iteration 535, loss = 3.70293620\n",
      "Iteration 536, loss = 3.70293469\n",
      "Iteration 537, loss = 3.70293320\n",
      "Iteration 538, loss = 3.70293171\n",
      "Iteration 539, loss = 3.70293024\n",
      "Iteration 540, loss = 3.70292877\n",
      "Iteration 541, loss = 3.70292731\n",
      "Iteration 542, loss = 3.70292586\n",
      "Iteration 543, loss = 3.70292442\n",
      "Iteration 544, loss = 3.70292299\n",
      "Iteration 545, loss = 3.70292157\n",
      "Iteration 546, loss = 3.70292015\n",
      "Iteration 547, loss = 3.70291874\n",
      "Iteration 548, loss = 3.70291734\n",
      "Iteration 549, loss = 3.70291595\n",
      "Iteration 550, loss = 3.70291457\n",
      "Iteration 551, loss = 3.70291319\n",
      "Iteration 552, loss = 3.70291183\n",
      "Iteration 553, loss = 3.70291047\n",
      "Iteration 554, loss = 3.70290912\n",
      "Iteration 555, loss = 3.70290777\n",
      "Iteration 556, loss = 3.70290644\n",
      "Iteration 557, loss = 3.70290511\n",
      "Iteration 558, loss = 3.70290379\n",
      "Iteration 559, loss = 3.70290247\n",
      "Iteration 560, loss = 3.70290117\n",
      "Iteration 561, loss = 3.70289987\n",
      "Iteration 562, loss = 3.70289858\n",
      "Iteration 563, loss = 3.70289730\n",
      "Iteration 564, loss = 3.70289602\n",
      "Iteration 565, loss = 3.70289475\n",
      "Iteration 566, loss = 3.70289349\n",
      "Iteration 567, loss = 3.70289223\n",
      "Iteration 568, loss = 3.70289099\n",
      "Iteration 569, loss = 3.70288975\n",
      "Iteration 570, loss = 3.70288851\n",
      "Iteration 571, loss = 3.70288728\n",
      "Iteration 572, loss = 3.70288606\n",
      "Iteration 573, loss = 3.70288485\n",
      "Iteration 574, loss = 3.70288365\n",
      "Iteration 575, loss = 3.70288245\n",
      "Iteration 576, loss = 3.70288125\n",
      "Iteration 577, loss = 3.70288007\n",
      "Iteration 578, loss = 3.70287889\n",
      "Iteration 579, loss = 3.70287771\n",
      "Iteration 580, loss = 3.70287655\n",
      "Iteration 581, loss = 3.70287538\n",
      "Iteration 582, loss = 3.70287423\n",
      "Iteration 583, loss = 3.70287308\n",
      "Iteration 584, loss = 3.70287194\n",
      "Iteration 585, loss = 3.70287080\n",
      "Iteration 586, loss = 3.70286968\n",
      "Iteration 587, loss = 3.70286855\n",
      "Iteration 588, loss = 3.70286743\n",
      "Iteration 589, loss = 3.70286632\n",
      "Iteration 590, loss = 3.70286522\n",
      "Iteration 591, loss = 3.70286412\n",
      "Iteration 592, loss = 3.70286303\n",
      "Iteration 593, loss = 3.70286194\n",
      "Iteration 594, loss = 3.70286086\n",
      "Iteration 595, loss = 3.70285978\n",
      "Iteration 596, loss = 3.70285871\n",
      "Iteration 597, loss = 3.70285765\n",
      "Iteration 598, loss = 3.70285659\n",
      "Iteration 599, loss = 3.70285553\n",
      "Iteration 600, loss = 3.70285449\n",
      "Iteration 601, loss = 3.70285345\n",
      "Iteration 602, loss = 3.70285241\n",
      "Iteration 603, loss = 3.70285138\n",
      "Iteration 604, loss = 3.70285035\n",
      "Iteration 605, loss = 3.70284933\n",
      "Iteration 606, loss = 3.70284832\n",
      "Iteration 607, loss = 3.70284731\n",
      "Iteration 608, loss = 3.70284630\n",
      "Iteration 609, loss = 3.70284530\n",
      "Iteration 610, loss = 3.70284431\n",
      "Iteration 611, loss = 3.70284332\n",
      "Iteration 612, loss = 3.70284234\n",
      "Iteration 613, loss = 3.70284136\n",
      "Iteration 614, loss = 3.70284039\n",
      "Iteration 615, loss = 3.70283942\n",
      "Iteration 616, loss = 3.70283845\n",
      "Iteration 617, loss = 3.70283750\n",
      "Iteration 618, loss = 3.70283654\n",
      "Iteration 619, loss = 3.70283559\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#setting up variable that will store confusion matrices\n",
    "confusion_matrices_train4 = []\n",
    "\n",
    "#We iterate over datasets for each fold\n",
    "for dataset in model4_data_indexes:\n",
    "    #From the list of all indexes we get only the ones for a given fold\n",
    "    train_indexes=dataset[0]\n",
    "    test_indexes=dataset[1]\n",
    "\n",
    "    #We fit the model using data with indexes for a given fold\n",
    "    clf4.fit(X_data.iloc[train_indexes], y_data.iloc[train_indexes])\n",
    "    #Predict values on the training data\n",
    "    y_pred4 = clf4.predict(X_data.iloc[train_indexes])\n",
    "    \n",
    "    #calculating multilabel_confusion_matrix\n",
    "    cm = multilabel_confusion_matrix(y_data.iloc[train_indexes], y_pred4)\n",
    "    \n",
    "    #setting up variable for cell-by-cell summation\n",
    "    res = np.matrix([[0, 0], [0, 0]])  \n",
    "    \n",
    "    #cell-by-cell summation of the confusion matrices\n",
    "    for item in cm:\n",
    "        single_cm = np.matrix(item)\n",
    "        res += single_cm\n",
    "    \n",
    "    #adding summed confussion_matrix to the variable with the results\n",
    "    confusion_matrices_train4.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold index 0\n",
      "[[367  86]\n",
      " [ 94 244]]\n",
      "Fold index 1\n",
      "[[363  78]\n",
      " [133 217]]\n",
      "Fold index 2\n",
      "[[332  98]\n",
      " [119 249]]\n"
     ]
    }
   ],
   "source": [
    "#printing resulted confusion matrices for the model4\n",
    "for fold, cm in enumerate(confusion_matrices_train4):\n",
    "    print(\"Fold index\", fold)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the cell-by-cell summation of the confusion matrices on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.97430284\n",
      "Iteration 2, loss = 4.94988089\n",
      "Iteration 3, loss = 4.91593219\n",
      "Iteration 4, loss = 4.87429500\n",
      "Iteration 5, loss = 4.82676940\n",
      "Iteration 6, loss = 4.77506967\n",
      "Iteration 7, loss = 4.72078416\n",
      "Iteration 8, loss = 4.66534235\n",
      "Iteration 9, loss = 4.60998984\n",
      "Iteration 10, loss = 4.55577232\n",
      "Iteration 11, loss = 4.50352902\n",
      "Iteration 12, loss = 4.45389585\n",
      "Iteration 13, loss = 4.40731728\n",
      "Iteration 14, loss = 4.36406533\n",
      "Iteration 15, loss = 4.32426360\n",
      "Iteration 16, loss = 4.28791377\n",
      "Iteration 17, loss = 4.25492260\n",
      "Iteration 18, loss = 4.22512733\n",
      "Iteration 19, loss = 4.19831835\n",
      "Iteration 20, loss = 4.17425844\n",
      "Iteration 21, loss = 4.15269814\n",
      "Iteration 22, loss = 4.13338762\n",
      "Iteration 23, loss = 4.11608520\n",
      "Iteration 24, loss = 4.10056323\n",
      "Iteration 25, loss = 4.08661160\n",
      "Iteration 26, loss = 4.07403963\n",
      "Iteration 27, loss = 4.06267652\n",
      "Iteration 28, loss = 4.05237105\n",
      "Iteration 29, loss = 4.04299050\n",
      "Iteration 30, loss = 4.03441928\n",
      "Iteration 31, loss = 4.02655727\n",
      "Iteration 32, loss = 4.01931821\n",
      "Iteration 33, loss = 4.01262791\n",
      "Iteration 34, loss = 4.00642273\n",
      "Iteration 35, loss = 4.00064806\n",
      "Iteration 36, loss = 3.99525695\n",
      "Iteration 37, loss = 3.99020895\n",
      "Iteration 38, loss = 3.98546903\n",
      "Iteration 39, loss = 3.98100672\n",
      "Iteration 40, loss = 3.97679530\n",
      "Iteration 41, loss = 3.97281120\n",
      "Iteration 42, loss = 3.96903347\n",
      "Iteration 43, loss = 3.96544336\n",
      "Iteration 44, loss = 3.96202394\n",
      "Iteration 45, loss = 3.95875988\n",
      "Iteration 46, loss = 3.95563720\n",
      "Iteration 47, loss = 3.95264313\n",
      "Iteration 48, loss = 3.94976594\n",
      "Iteration 49, loss = 3.94699487\n",
      "Iteration 50, loss = 3.94432003\n",
      "Iteration 51, loss = 3.94173234\n",
      "Iteration 52, loss = 3.93922347\n",
      "Iteration 53, loss = 3.93678579\n",
      "Iteration 54, loss = 3.93441231\n",
      "Iteration 55, loss = 3.93209667\n",
      "Iteration 56, loss = 3.92983306\n",
      "Iteration 57, loss = 3.92761621\n",
      "Iteration 58, loss = 3.92544135\n",
      "Iteration 59, loss = 3.92330413\n",
      "Iteration 60, loss = 3.92120065\n",
      "Iteration 61, loss = 3.91912736\n",
      "Iteration 62, loss = 3.91708108\n",
      "Iteration 63, loss = 3.91505894\n",
      "Iteration 64, loss = 3.91305834\n",
      "Iteration 65, loss = 3.91107694\n",
      "Iteration 66, loss = 3.90911263\n",
      "Iteration 67, loss = 3.90716353\n",
      "Iteration 68, loss = 3.90522791\n",
      "Iteration 69, loss = 3.90330424\n",
      "Iteration 70, loss = 3.90139112\n",
      "Iteration 71, loss = 3.89948729\n",
      "Iteration 72, loss = 3.89759163\n",
      "Iteration 73, loss = 3.89570312\n",
      "Iteration 74, loss = 3.89382083\n",
      "Iteration 75, loss = 3.89194393\n",
      "Iteration 76, loss = 3.89007169\n",
      "Iteration 77, loss = 3.88820343\n",
      "Iteration 78, loss = 3.88633856\n",
      "Iteration 79, loss = 3.88447652\n",
      "Iteration 80, loss = 3.88261685\n",
      "Iteration 81, loss = 3.88075910\n",
      "Iteration 82, loss = 3.87890289\n",
      "Iteration 83, loss = 3.87704787\n",
      "Iteration 84, loss = 3.87519373\n",
      "Iteration 85, loss = 3.87334019\n",
      "Iteration 86, loss = 3.87148700\n",
      "Iteration 87, loss = 3.86963393\n",
      "Iteration 88, loss = 3.86778078\n",
      "Iteration 89, loss = 3.86592737\n",
      "Iteration 90, loss = 3.86407353\n",
      "Iteration 91, loss = 3.86221910\n",
      "Iteration 92, loss = 3.86036395\n",
      "Iteration 93, loss = 3.85850795\n",
      "Iteration 94, loss = 3.85665099\n",
      "Iteration 95, loss = 3.85479296\n",
      "Iteration 96, loss = 3.85293375\n",
      "Iteration 97, loss = 3.85107328\n",
      "Iteration 98, loss = 3.84921147\n",
      "Iteration 99, loss = 3.84734823\n",
      "Iteration 100, loss = 3.84548351\n",
      "Iteration 101, loss = 3.84361723\n",
      "Iteration 102, loss = 3.84174933\n",
      "Iteration 103, loss = 3.83987978\n",
      "Iteration 104, loss = 3.83800852\n",
      "Iteration 105, loss = 3.83613551\n",
      "Iteration 106, loss = 3.83426072\n",
      "Iteration 107, loss = 3.83238413\n",
      "Iteration 108, loss = 3.83050571\n",
      "Iteration 109, loss = 3.82862545\n",
      "Iteration 110, loss = 3.82674333\n",
      "Iteration 111, loss = 3.82485936\n",
      "Iteration 112, loss = 3.82297354\n",
      "Iteration 113, loss = 3.82108587\n",
      "Iteration 114, loss = 3.81919636\n",
      "Iteration 115, loss = 3.81730504\n",
      "Iteration 116, loss = 3.81541193\n",
      "Iteration 117, loss = 3.81351706\n",
      "Iteration 118, loss = 3.81162045\n",
      "Iteration 119, loss = 3.80972216\n",
      "Iteration 120, loss = 3.80782222\n",
      "Iteration 121, loss = 3.80592068\n",
      "Iteration 122, loss = 3.80401760\n",
      "Iteration 123, loss = 3.80211304\n",
      "Iteration 124, loss = 3.80020704\n",
      "Iteration 125, loss = 3.79829970\n",
      "Iteration 126, loss = 3.79639106\n",
      "Iteration 127, loss = 3.79448122\n",
      "Iteration 128, loss = 3.79257024\n",
      "Iteration 129, loss = 3.79065822\n",
      "Iteration 130, loss = 3.78874524\n",
      "Iteration 131, loss = 3.78683140\n",
      "Iteration 132, loss = 3.78491678\n",
      "Iteration 133, loss = 3.78300150\n",
      "Iteration 134, loss = 3.78108565\n",
      "Iteration 135, loss = 3.77916935\n",
      "Iteration 136, loss = 3.77725270\n",
      "Iteration 137, loss = 3.77533582\n",
      "Iteration 138, loss = 3.77341883\n",
      "Iteration 139, loss = 3.77150186\n",
      "Iteration 140, loss = 3.76958502\n",
      "Iteration 141, loss = 3.76766845\n",
      "Iteration 142, loss = 3.76575228\n",
      "Iteration 143, loss = 3.76383666\n",
      "Iteration 144, loss = 3.76192171\n",
      "Iteration 145, loss = 3.76000759\n",
      "Iteration 146, loss = 3.75809444\n",
      "Iteration 147, loss = 3.75618241\n",
      "Iteration 148, loss = 3.75427165\n",
      "Iteration 149, loss = 3.75236232\n",
      "Iteration 150, loss = 3.75045458\n",
      "Iteration 151, loss = 3.74854858\n",
      "Iteration 152, loss = 3.74664450\n",
      "Iteration 153, loss = 3.74474250\n",
      "Iteration 154, loss = 3.74284274\n",
      "Iteration 155, loss = 3.74094540\n",
      "Iteration 156, loss = 3.73905066\n",
      "Iteration 157, loss = 3.73715868\n",
      "Iteration 158, loss = 3.73526965\n",
      "Iteration 159, loss = 3.73338374\n",
      "Iteration 160, loss = 3.73150114\n",
      "Iteration 161, loss = 3.72962202\n",
      "Iteration 162, loss = 3.72774658\n",
      "Iteration 163, loss = 3.72587499\n",
      "Iteration 164, loss = 3.72400744\n",
      "Iteration 165, loss = 3.72214412\n",
      "Iteration 166, loss = 3.72028521\n",
      "Iteration 167, loss = 3.71843091\n",
      "Iteration 168, loss = 3.71658140\n",
      "Iteration 169, loss = 3.71473688\n",
      "Iteration 170, loss = 3.71289753\n",
      "Iteration 171, loss = 3.71106353\n",
      "Iteration 172, loss = 3.70923508\n",
      "Iteration 173, loss = 3.70741237\n",
      "Iteration 174, loss = 3.70559559\n",
      "Iteration 175, loss = 3.70378492\n",
      "Iteration 176, loss = 3.70198054\n",
      "Iteration 177, loss = 3.70018264\n",
      "Iteration 178, loss = 3.69839141\n",
      "Iteration 179, loss = 3.69660703\n",
      "Iteration 180, loss = 3.69482968\n",
      "Iteration 181, loss = 3.69305953\n",
      "Iteration 182, loss = 3.69129676\n",
      "Iteration 183, loss = 3.68954156\n",
      "Iteration 184, loss = 3.68779408\n",
      "Iteration 185, loss = 3.68605450\n",
      "Iteration 186, loss = 3.68432299\n",
      "Iteration 187, loss = 3.68259971\n",
      "Iteration 188, loss = 3.68088481\n",
      "Iteration 189, loss = 3.67917847\n",
      "Iteration 190, loss = 3.67748084\n",
      "Iteration 191, loss = 3.67579206\n",
      "Iteration 192, loss = 3.67411228\n",
      "Iteration 193, loss = 3.67244166\n",
      "Iteration 194, loss = 3.67078032\n",
      "Iteration 195, loss = 3.66912841\n",
      "Iteration 196, loss = 3.66748606\n",
      "Iteration 197, loss = 3.66585339\n",
      "Iteration 198, loss = 3.66423054\n",
      "Iteration 199, loss = 3.66261762\n",
      "Iteration 200, loss = 3.66101475\n",
      "Iteration 201, loss = 3.65942204\n",
      "Iteration 202, loss = 3.65783960\n",
      "Iteration 203, loss = 3.65626752\n",
      "Iteration 204, loss = 3.65470592\n",
      "Iteration 205, loss = 3.65315487\n",
      "Iteration 206, loss = 3.65161447\n",
      "Iteration 207, loss = 3.65008480\n",
      "Iteration 208, loss = 3.64856594\n",
      "Iteration 209, loss = 3.64705797\n",
      "Iteration 210, loss = 3.64556095\n",
      "Iteration 211, loss = 3.64407495\n",
      "Iteration 212, loss = 3.64260002\n",
      "Iteration 213, loss = 3.64113622\n",
      "Iteration 214, loss = 3.63968361\n",
      "Iteration 215, loss = 3.63824222\n",
      "Iteration 216, loss = 3.63681209\n",
      "Iteration 217, loss = 3.63539326\n",
      "Iteration 218, loss = 3.63398576\n",
      "Iteration 219, loss = 3.63258962\n",
      "Iteration 220, loss = 3.63120485\n",
      "Iteration 221, loss = 3.62983147\n",
      "Iteration 222, loss = 3.62846949\n",
      "Iteration 223, loss = 3.62711892\n",
      "Iteration 224, loss = 3.62577977\n",
      "Iteration 225, loss = 3.62445202\n",
      "Iteration 226, loss = 3.62313568\n",
      "Iteration 227, loss = 3.62183073\n",
      "Iteration 228, loss = 3.62053715\n",
      "Iteration 229, loss = 3.61925494\n",
      "Iteration 230, loss = 3.61798405\n",
      "Iteration 231, loss = 3.61672448\n",
      "Iteration 232, loss = 3.61547618\n",
      "Iteration 233, loss = 3.61423912\n",
      "Iteration 234, loss = 3.61301327\n",
      "Iteration 235, loss = 3.61179857\n",
      "Iteration 236, loss = 3.61059499\n",
      "Iteration 237, loss = 3.60940248\n",
      "Iteration 238, loss = 3.60822098\n",
      "Iteration 239, loss = 3.60705043\n",
      "Iteration 240, loss = 3.60589079\n",
      "Iteration 241, loss = 3.60474198\n",
      "Iteration 242, loss = 3.60360395\n",
      "Iteration 243, loss = 3.60247662\n",
      "Iteration 244, loss = 3.60135993\n",
      "Iteration 245, loss = 3.60025380\n",
      "Iteration 246, loss = 3.59915816\n",
      "Iteration 247, loss = 3.59807293\n",
      "Iteration 248, loss = 3.59699804\n",
      "Iteration 249, loss = 3.59593339\n",
      "Iteration 250, loss = 3.59487891\n",
      "Iteration 251, loss = 3.59383451\n",
      "Iteration 252, loss = 3.59280010\n",
      "Iteration 253, loss = 3.59177560\n",
      "Iteration 254, loss = 3.59076091\n",
      "Iteration 255, loss = 3.58975594\n",
      "Iteration 256, loss = 3.58876059\n",
      "Iteration 257, loss = 3.58777478\n",
      "Iteration 258, loss = 3.58679841\n",
      "Iteration 259, loss = 3.58583137\n",
      "Iteration 260, loss = 3.58487357\n",
      "Iteration 261, loss = 3.58392491\n",
      "Iteration 262, loss = 3.58298528\n",
      "Iteration 263, loss = 3.58205460\n",
      "Iteration 264, loss = 3.58113275\n",
      "Iteration 265, loss = 3.58021964\n",
      "Iteration 266, loss = 3.57931516\n",
      "Iteration 267, loss = 3.57841920\n",
      "Iteration 268, loss = 3.57753167\n",
      "Iteration 269, loss = 3.57665245\n",
      "Iteration 270, loss = 3.57578145\n",
      "Iteration 271, loss = 3.57491856\n",
      "Iteration 272, loss = 3.57406367\n",
      "Iteration 273, loss = 3.57321668\n",
      "Iteration 274, loss = 3.57237749\n",
      "Iteration 275, loss = 3.57154598\n",
      "Iteration 276, loss = 3.57072206\n",
      "Iteration 277, loss = 3.56990562\n",
      "Iteration 278, loss = 3.56909656\n",
      "Iteration 279, loss = 3.56829477\n",
      "Iteration 280, loss = 3.56750015\n",
      "Iteration 281, loss = 3.56671259\n",
      "Iteration 282, loss = 3.56593200\n",
      "Iteration 283, loss = 3.56515826\n",
      "Iteration 284, loss = 3.56439129\n",
      "Iteration 285, loss = 3.56363097\n",
      "Iteration 286, loss = 3.56287721\n",
      "Iteration 287, loss = 3.56212991\n",
      "Iteration 288, loss = 3.56138896\n",
      "Iteration 289, loss = 3.56065427\n",
      "Iteration 290, loss = 3.55992575\n",
      "Iteration 291, loss = 3.55920328\n",
      "Iteration 292, loss = 3.55848678\n",
      "Iteration 293, loss = 3.55777616\n",
      "Iteration 294, loss = 3.55707131\n",
      "Iteration 295, loss = 3.55637215\n",
      "Iteration 296, loss = 3.55567857\n",
      "Iteration 297, loss = 3.55499049\n",
      "Iteration 298, loss = 3.55430782\n",
      "Iteration 299, loss = 3.55363047\n",
      "Iteration 300, loss = 3.55295834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 301, loss = 3.55229135\n",
      "Iteration 302, loss = 3.55162942\n",
      "Iteration 303, loss = 3.55097245\n",
      "Iteration 304, loss = 3.55032035\n",
      "Iteration 305, loss = 3.54967306\n",
      "Iteration 306, loss = 3.54903047\n",
      "Iteration 307, loss = 3.54839252\n",
      "Iteration 308, loss = 3.54775911\n",
      "Iteration 309, loss = 3.54713017\n",
      "Iteration 310, loss = 3.54650562\n",
      "Iteration 311, loss = 3.54588538\n",
      "Iteration 312, loss = 3.54526937\n",
      "Iteration 313, loss = 3.54465752\n",
      "Iteration 314, loss = 3.54404976\n",
      "Iteration 315, loss = 3.54344599\n",
      "Iteration 316, loss = 3.54284617\n",
      "Iteration 317, loss = 3.54225020\n",
      "Iteration 318, loss = 3.54165803\n",
      "Iteration 319, loss = 3.54106958\n",
      "Iteration 320, loss = 3.54048478\n",
      "Iteration 321, loss = 3.53990356\n",
      "Iteration 322, loss = 3.53932586\n",
      "Iteration 323, loss = 3.53875161\n",
      "Iteration 324, loss = 3.53818075\n",
      "Iteration 325, loss = 3.53761322\n",
      "Iteration 326, loss = 3.53704894\n",
      "Iteration 327, loss = 3.53648785\n",
      "Iteration 328, loss = 3.53592991\n",
      "Iteration 329, loss = 3.53537504\n",
      "Iteration 330, loss = 3.53482319\n",
      "Iteration 331, loss = 3.53427430\n",
      "Iteration 332, loss = 3.53372831\n",
      "Iteration 333, loss = 3.53318516\n",
      "Iteration 334, loss = 3.53264481\n",
      "Iteration 335, loss = 3.53210719\n",
      "Iteration 336, loss = 3.53157225\n",
      "Iteration 337, loss = 3.53103994\n",
      "Iteration 338, loss = 3.53051021\n",
      "Iteration 339, loss = 3.52998301\n",
      "Iteration 340, loss = 3.52945828\n",
      "Iteration 341, loss = 3.52893598\n",
      "Iteration 342, loss = 3.52841606\n",
      "Iteration 343, loss = 3.52789848\n",
      "Iteration 344, loss = 3.52738317\n",
      "Iteration 345, loss = 3.52687011\n",
      "Iteration 346, loss = 3.52635924\n",
      "Iteration 347, loss = 3.52585052\n",
      "Iteration 348, loss = 3.52534391\n",
      "Iteration 349, loss = 3.52483936\n",
      "Iteration 350, loss = 3.52433683\n",
      "Iteration 351, loss = 3.52383628\n",
      "Iteration 352, loss = 3.52333767\n",
      "Iteration 353, loss = 3.52284096\n",
      "Iteration 354, loss = 3.52234611\n",
      "Iteration 355, loss = 3.52185308\n",
      "Iteration 356, loss = 3.52136184\n",
      "Iteration 357, loss = 3.52087235\n",
      "Iteration 358, loss = 3.52038456\n",
      "Iteration 359, loss = 3.51989845\n",
      "Iteration 360, loss = 3.51941398\n",
      "Iteration 361, loss = 3.51893112\n",
      "Iteration 362, loss = 3.51844983\n",
      "Iteration 363, loss = 3.51797008\n",
      "Iteration 364, loss = 3.51749183\n",
      "Iteration 365, loss = 3.51701506\n",
      "Iteration 366, loss = 3.51653973\n",
      "Iteration 367, loss = 3.51606582\n",
      "Iteration 368, loss = 3.51559328\n",
      "Iteration 369, loss = 3.51512210\n",
      "Iteration 370, loss = 3.51465224\n",
      "Iteration 371, loss = 3.51418367\n",
      "Iteration 372, loss = 3.51371637\n",
      "Iteration 373, loss = 3.51325031\n",
      "Iteration 374, loss = 3.51278545\n",
      "Iteration 375, loss = 3.51232179\n",
      "Iteration 376, loss = 3.51185928\n",
      "Iteration 377, loss = 3.51139790\n",
      "Iteration 378, loss = 3.51093764\n",
      "Iteration 379, loss = 3.51047845\n",
      "Iteration 380, loss = 3.51002033\n",
      "Iteration 381, loss = 3.50956324\n",
      "Iteration 382, loss = 3.50910716\n",
      "Iteration 383, loss = 3.50865207\n",
      "Iteration 384, loss = 3.50819795\n",
      "Iteration 385, loss = 3.50774477\n",
      "Iteration 386, loss = 3.50729251\n",
      "Iteration 387, loss = 3.50684116\n",
      "Iteration 388, loss = 3.50639069\n",
      "Iteration 389, loss = 3.50594107\n",
      "Iteration 390, loss = 3.50549230\n",
      "Iteration 391, loss = 3.50504434\n",
      "Iteration 392, loss = 3.50459719\n",
      "Iteration 393, loss = 3.50415082\n",
      "Iteration 394, loss = 3.50370521\n",
      "Iteration 395, loss = 3.50326035\n",
      "Iteration 396, loss = 3.50281621\n",
      "Iteration 397, loss = 3.50237278\n",
      "Iteration 398, loss = 3.50193004\n",
      "Iteration 399, loss = 3.50148798\n",
      "Iteration 400, loss = 3.50104658\n",
      "Iteration 401, loss = 3.50060581\n",
      "Iteration 402, loss = 3.50016568\n",
      "Iteration 403, loss = 3.49972615\n",
      "Iteration 404, loss = 3.49928722\n",
      "Iteration 405, loss = 3.49884886\n",
      "Iteration 406, loss = 3.49841107\n",
      "Iteration 407, loss = 3.49797383\n",
      "Iteration 408, loss = 3.49753712\n",
      "Iteration 409, loss = 3.49710093\n",
      "Iteration 410, loss = 3.49666525\n",
      "Iteration 411, loss = 3.49623006\n",
      "Iteration 412, loss = 3.49579536\n",
      "Iteration 413, loss = 3.49536111\n",
      "Iteration 414, loss = 3.49492732\n",
      "Iteration 415, loss = 3.49449397\n",
      "Iteration 416, loss = 3.49406105\n",
      "Iteration 417, loss = 3.49362855\n",
      "Iteration 418, loss = 3.49319645\n",
      "Iteration 419, loss = 3.49276474\n",
      "Iteration 420, loss = 3.49233340\n",
      "Iteration 421, loss = 3.49190244\n",
      "Iteration 422, loss = 3.49147184\n",
      "Iteration 423, loss = 3.49104158\n",
      "Iteration 424, loss = 3.49061166\n",
      "Iteration 425, loss = 3.49018206\n",
      "Iteration 426, loss = 3.48975278\n",
      "Iteration 427, loss = 3.48932380\n",
      "Iteration 428, loss = 3.48889511\n",
      "Iteration 429, loss = 3.48846671\n",
      "Iteration 430, loss = 3.48803858\n",
      "Iteration 431, loss = 3.48761071\n",
      "Iteration 432, loss = 3.48718311\n",
      "Iteration 433, loss = 3.48675574\n",
      "Iteration 434, loss = 3.48632862\n",
      "Iteration 435, loss = 3.48590172\n",
      "Iteration 436, loss = 3.48547504\n",
      "Iteration 437, loss = 3.48504857\n",
      "Iteration 438, loss = 3.48462230\n",
      "Iteration 439, loss = 3.48419622\n",
      "Iteration 440, loss = 3.48377033\n",
      "Iteration 441, loss = 3.48334462\n",
      "Iteration 442, loss = 3.48291908\n",
      "Iteration 443, loss = 3.48249369\n",
      "Iteration 444, loss = 3.48206846\n",
      "Iteration 445, loss = 3.48164338\n",
      "Iteration 446, loss = 3.48121843\n",
      "Iteration 447, loss = 3.48079362\n",
      "Iteration 448, loss = 3.48036893\n",
      "Iteration 449, loss = 3.47994435\n",
      "Iteration 450, loss = 3.47951989\n",
      "Iteration 451, loss = 3.47909552\n",
      "Iteration 452, loss = 3.47867126\n",
      "Iteration 453, loss = 3.47824708\n",
      "Iteration 454, loss = 3.47782299\n",
      "Iteration 455, loss = 3.47739897\n",
      "Iteration 456, loss = 3.47697502\n",
      "Iteration 457, loss = 3.47655113\n",
      "Iteration 458, loss = 3.47612731\n",
      "Iteration 459, loss = 3.47570353\n",
      "Iteration 460, loss = 3.47527980\n",
      "Iteration 461, loss = 3.47485611\n",
      "Iteration 462, loss = 3.47443246\n",
      "Iteration 463, loss = 3.47400883\n",
      "Iteration 464, loss = 3.47358523\n",
      "Iteration 465, loss = 3.47316164\n",
      "Iteration 466, loss = 3.47273806\n",
      "Iteration 467, loss = 3.47231449\n",
      "Iteration 468, loss = 3.47189093\n",
      "Iteration 469, loss = 3.47146736\n",
      "Iteration 470, loss = 3.47104378\n",
      "Iteration 471, loss = 3.47062018\n",
      "Iteration 472, loss = 3.47019657\n",
      "Iteration 473, loss = 3.46977293\n",
      "Iteration 474, loss = 3.46934927\n",
      "Iteration 475, loss = 3.46892557\n",
      "Iteration 476, loss = 3.46850183\n",
      "Iteration 477, loss = 3.46807805\n",
      "Iteration 478, loss = 3.46765423\n",
      "Iteration 479, loss = 3.46723035\n",
      "Iteration 480, loss = 3.46680641\n",
      "Iteration 481, loss = 3.46638242\n",
      "Iteration 482, loss = 3.46595836\n",
      "Iteration 483, loss = 3.46553424\n",
      "Iteration 484, loss = 3.46511004\n",
      "Iteration 485, loss = 3.46468576\n",
      "Iteration 486, loss = 3.46426141\n",
      "Iteration 487, loss = 3.46383697\n",
      "Iteration 488, loss = 3.46341244\n",
      "Iteration 489, loss = 3.46298782\n",
      "Iteration 490, loss = 3.46256310\n",
      "Iteration 491, loss = 3.46213829\n",
      "Iteration 492, loss = 3.46171337\n",
      "Iteration 493, loss = 3.46128834\n",
      "Iteration 494, loss = 3.46086320\n",
      "Iteration 495, loss = 3.46043795\n",
      "Iteration 496, loss = 3.46001258\n",
      "Iteration 497, loss = 3.45958709\n",
      "Iteration 498, loss = 3.45916148\n",
      "Iteration 499, loss = 3.45873574\n",
      "Iteration 500, loss = 3.45830987\n",
      "Iteration 501, loss = 3.45788386\n",
      "Iteration 502, loss = 3.45745772\n",
      "Iteration 503, loss = 3.45703144\n",
      "Iteration 504, loss = 3.45660501\n",
      "Iteration 505, loss = 3.45617844\n",
      "Iteration 506, loss = 3.45575172\n",
      "Iteration 507, loss = 3.45532485\n",
      "Iteration 508, loss = 3.45489782\n",
      "Iteration 509, loss = 3.45447063\n",
      "Iteration 510, loss = 3.45404329\n",
      "Iteration 511, loss = 3.45361578\n",
      "Iteration 512, loss = 3.45318810\n",
      "Iteration 513, loss = 3.45276026\n",
      "Iteration 514, loss = 3.45233224\n",
      "Iteration 515, loss = 3.45190405\n",
      "Iteration 516, loss = 3.45147568\n",
      "Iteration 517, loss = 3.45104714\n",
      "Iteration 518, loss = 3.45061841\n",
      "Iteration 519, loss = 3.45018950\n",
      "Iteration 520, loss = 3.44976040\n",
      "Iteration 521, loss = 3.44933112\n",
      "Iteration 522, loss = 3.44890164\n",
      "Iteration 523, loss = 3.44847197\n",
      "Iteration 524, loss = 3.44804210\n",
      "Iteration 525, loss = 3.44761204\n",
      "Iteration 526, loss = 3.44718177\n",
      "Iteration 527, loss = 3.44675130\n",
      "Iteration 528, loss = 3.44632063\n",
      "Iteration 529, loss = 3.44588975\n",
      "Iteration 530, loss = 3.44545867\n",
      "Iteration 531, loss = 3.44502737\n",
      "Iteration 532, loss = 3.44459586\n",
      "Iteration 533, loss = 3.44416413\n",
      "Iteration 534, loss = 3.44373219\n",
      "Iteration 535, loss = 3.44330003\n",
      "Iteration 536, loss = 3.44286765\n",
      "Iteration 537, loss = 3.44243504\n",
      "Iteration 538, loss = 3.44200222\n",
      "Iteration 539, loss = 3.44156916\n",
      "Iteration 540, loss = 3.44113588\n",
      "Iteration 541, loss = 3.44070237\n",
      "Iteration 542, loss = 3.44026863\n",
      "Iteration 543, loss = 3.43983465\n",
      "Iteration 544, loss = 3.43940045\n",
      "Iteration 545, loss = 3.43896600\n",
      "Iteration 546, loss = 3.43853132\n",
      "Iteration 547, loss = 3.43809640\n",
      "Iteration 548, loss = 3.43766123\n",
      "Iteration 549, loss = 3.43722583\n",
      "Iteration 550, loss = 3.43679018\n",
      "Iteration 551, loss = 3.43635429\n",
      "Iteration 552, loss = 3.43591815\n",
      "Iteration 553, loss = 3.43548176\n",
      "Iteration 554, loss = 3.43504512\n",
      "Iteration 555, loss = 3.43460823\n",
      "Iteration 556, loss = 3.43417109\n",
      "Iteration 557, loss = 3.43373369\n",
      "Iteration 558, loss = 3.43329604\n",
      "Iteration 559, loss = 3.43285814\n",
      "Iteration 560, loss = 3.43241998\n",
      "Iteration 561, loss = 3.43198156\n",
      "Iteration 562, loss = 3.43154288\n",
      "Iteration 563, loss = 3.43110394\n",
      "Iteration 564, loss = 3.43066473\n",
      "Iteration 565, loss = 3.43022527\n",
      "Iteration 566, loss = 3.42978554\n",
      "Iteration 567, loss = 3.42934554\n",
      "Iteration 568, loss = 3.42890528\n",
      "Iteration 569, loss = 3.42846476\n",
      "Iteration 570, loss = 3.42802396\n",
      "Iteration 571, loss = 3.42758290\n",
      "Iteration 572, loss = 3.42714156\n",
      "Iteration 573, loss = 3.42669996\n",
      "Iteration 574, loss = 3.42625808\n",
      "Iteration 575, loss = 3.42581593\n",
      "Iteration 576, loss = 3.42537351\n",
      "Iteration 577, loss = 3.42493081\n",
      "Iteration 578, loss = 3.42448784\n",
      "Iteration 579, loss = 3.42404459\n",
      "Iteration 580, loss = 3.42360107\n",
      "Iteration 581, loss = 3.42315727\n",
      "Iteration 582, loss = 3.42271319\n",
      "Iteration 583, loss = 3.42226883\n",
      "Iteration 584, loss = 3.42182419\n",
      "Iteration 585, loss = 3.42137928\n",
      "Iteration 586, loss = 3.42093408\n",
      "Iteration 587, loss = 3.42048860\n",
      "Iteration 588, loss = 3.42004284\n",
      "Iteration 589, loss = 3.41959680\n",
      "Iteration 590, loss = 3.41915048\n",
      "Iteration 591, loss = 3.41870387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 592, loss = 3.41825698\n",
      "Iteration 593, loss = 3.41780980\n",
      "Iteration 594, loss = 3.41736234\n",
      "Iteration 595, loss = 3.41691460\n",
      "Iteration 596, loss = 3.41646657\n",
      "Iteration 597, loss = 3.41601825\n",
      "Iteration 598, loss = 3.41556965\n",
      "Iteration 599, loss = 3.41512076\n",
      "Iteration 600, loss = 3.41467159\n",
      "Iteration 601, loss = 3.41422213\n",
      "Iteration 602, loss = 3.41377238\n",
      "Iteration 603, loss = 3.41332234\n",
      "Iteration 604, loss = 3.41287202\n",
      "Iteration 605, loss = 3.41242141\n",
      "Iteration 606, loss = 3.41197051\n",
      "Iteration 607, loss = 3.41151932\n",
      "Iteration 608, loss = 3.41106785\n",
      "Iteration 609, loss = 3.41061609\n",
      "Iteration 610, loss = 3.41016403\n",
      "Iteration 611, loss = 3.40971169\n",
      "Iteration 612, loss = 3.40925907\n",
      "Iteration 613, loss = 3.40880615\n",
      "Iteration 614, loss = 3.40835294\n",
      "Iteration 615, loss = 3.40789945\n",
      "Iteration 616, loss = 3.40744567\n",
      "Iteration 617, loss = 3.40699160\n",
      "Iteration 618, loss = 3.40653724\n",
      "Iteration 619, loss = 3.40608260\n",
      "Iteration 620, loss = 3.40562766\n",
      "Iteration 621, loss = 3.40517244\n",
      "Iteration 622, loss = 3.40471693\n",
      "Iteration 623, loss = 3.40426113\n",
      "Iteration 624, loss = 3.40380505\n",
      "Iteration 625, loss = 3.40334868\n",
      "Iteration 626, loss = 3.40289202\n",
      "Iteration 627, loss = 3.40243508\n",
      "Iteration 628, loss = 3.40197785\n",
      "Iteration 629, loss = 3.40152033\n",
      "Iteration 630, loss = 3.40106253\n",
      "Iteration 631, loss = 3.40060444\n",
      "Iteration 632, loss = 3.40014607\n",
      "Iteration 633, loss = 3.39968742\n",
      "Iteration 634, loss = 3.39922848\n",
      "Iteration 635, loss = 3.39876925\n",
      "Iteration 636, loss = 3.39830975\n",
      "Iteration 637, loss = 3.39784996\n",
      "Iteration 638, loss = 3.39738989\n",
      "Iteration 639, loss = 3.39692954\n",
      "Iteration 640, loss = 3.39646891\n",
      "Iteration 641, loss = 3.39600800\n",
      "Iteration 642, loss = 3.39554680\n",
      "Iteration 643, loss = 3.39508533\n",
      "Iteration 644, loss = 3.39462358\n",
      "Iteration 645, loss = 3.39416155\n",
      "Iteration 646, loss = 3.39369925\n",
      "Iteration 647, loss = 3.39323667\n",
      "Iteration 648, loss = 3.39277381\n",
      "Iteration 649, loss = 3.39231068\n",
      "Iteration 650, loss = 3.39184727\n",
      "Iteration 651, loss = 3.39138359\n",
      "Iteration 652, loss = 3.39091964\n",
      "Iteration 653, loss = 3.39045542\n",
      "Iteration 654, loss = 3.38999092\n",
      "Iteration 655, loss = 3.38952615\n",
      "Iteration 656, loss = 3.38906112\n",
      "Iteration 657, loss = 3.38859581\n",
      "Iteration 658, loss = 3.38813024\n",
      "Iteration 659, loss = 3.38766441\n",
      "Iteration 660, loss = 3.38719830\n",
      "Iteration 661, loss = 3.38673193\n",
      "Iteration 662, loss = 3.38626530\n",
      "Iteration 663, loss = 3.38579841\n",
      "Iteration 664, loss = 3.38533125\n",
      "Iteration 665, loss = 3.38486383\n",
      "Iteration 666, loss = 3.38439615\n",
      "Iteration 667, loss = 3.38392822\n",
      "Iteration 668, loss = 3.38346003\n",
      "Iteration 669, loss = 3.38299158\n",
      "Iteration 670, loss = 3.38252287\n",
      "Iteration 671, loss = 3.38205391\n",
      "Iteration 672, loss = 3.38158470\n",
      "Iteration 673, loss = 3.38111524\n",
      "Iteration 674, loss = 3.38064552\n",
      "Iteration 675, loss = 3.38017556\n",
      "Iteration 676, loss = 3.37970535\n",
      "Iteration 677, loss = 3.37923489\n",
      "Iteration 678, loss = 3.37876419\n",
      "Iteration 679, loss = 3.37829324\n",
      "Iteration 680, loss = 3.37782205\n",
      "Iteration 681, loss = 3.37735062\n",
      "Iteration 682, loss = 3.37687895\n",
      "Iteration 683, loss = 3.37640704\n",
      "Iteration 684, loss = 3.37593489\n",
      "Iteration 685, loss = 3.37546251\n",
      "Iteration 686, loss = 3.37498989\n",
      "Iteration 687, loss = 3.37451704\n",
      "Iteration 688, loss = 3.37404396\n",
      "Iteration 689, loss = 3.37357064\n",
      "Iteration 690, loss = 3.37309710\n",
      "Iteration 691, loss = 3.37262333\n",
      "Iteration 692, loss = 3.37214934\n",
      "Iteration 693, loss = 3.37167512\n",
      "Iteration 694, loss = 3.37120068\n",
      "Iteration 695, loss = 3.37072602\n",
      "Iteration 696, loss = 3.37025114\n",
      "Iteration 697, loss = 3.36977604\n",
      "Iteration 698, loss = 3.36930073\n",
      "Iteration 699, loss = 3.36882520\n",
      "Iteration 700, loss = 3.36834946\n",
      "Iteration 701, loss = 3.36787351\n",
      "Iteration 702, loss = 3.36739735\n",
      "Iteration 703, loss = 3.36692098\n",
      "Iteration 704, loss = 3.36644441\n",
      "Iteration 705, loss = 3.36596763\n",
      "Iteration 706, loss = 3.36549065\n",
      "Iteration 707, loss = 3.36501347\n",
      "Iteration 708, loss = 3.36453609\n",
      "Iteration 709, loss = 3.36405851\n",
      "Iteration 710, loss = 3.36358074\n",
      "Iteration 711, loss = 3.36310278\n",
      "Iteration 712, loss = 3.36262462\n",
      "Iteration 713, loss = 3.36214628\n",
      "Iteration 714, loss = 3.36166775\n",
      "Iteration 715, loss = 3.36118903\n",
      "Iteration 716, loss = 3.36071013\n",
      "Iteration 717, loss = 3.36023104\n",
      "Iteration 718, loss = 3.35975178\n",
      "Iteration 719, loss = 3.35927234\n",
      "Iteration 720, loss = 3.35879273\n",
      "Iteration 721, loss = 3.35831294\n",
      "Iteration 722, loss = 3.35783298\n",
      "Iteration 723, loss = 3.35735285\n",
      "Iteration 724, loss = 3.35687255\n",
      "Iteration 725, loss = 3.35639209\n",
      "Iteration 726, loss = 3.35591146\n",
      "Iteration 727, loss = 3.35543067\n",
      "Iteration 728, loss = 3.35494972\n",
      "Iteration 729, loss = 3.35446862\n",
      "Iteration 730, loss = 3.35398736\n",
      "Iteration 731, loss = 3.35350595\n",
      "Iteration 732, loss = 3.35302439\n",
      "Iteration 733, loss = 3.35254268\n",
      "Iteration 734, loss = 3.35206082\n",
      "Iteration 735, loss = 3.35157882\n",
      "Iteration 736, loss = 3.35109667\n",
      "Iteration 737, loss = 3.35061439\n",
      "Iteration 738, loss = 3.35013197\n",
      "Iteration 739, loss = 3.34964942\n",
      "Iteration 740, loss = 3.34916673\n",
      "Iteration 741, loss = 3.34868392\n",
      "Iteration 742, loss = 3.34820097\n",
      "Iteration 743, loss = 3.34771790\n",
      "Iteration 744, loss = 3.34723470\n",
      "Iteration 745, loss = 3.34675139\n",
      "Iteration 746, loss = 3.34626796\n",
      "Iteration 747, loss = 3.34578440\n",
      "Iteration 748, loss = 3.34530074\n",
      "Iteration 749, loss = 3.34481696\n",
      "Iteration 750, loss = 3.34433308\n",
      "Iteration 751, loss = 3.34384909\n",
      "Iteration 752, loss = 3.34336499\n",
      "Iteration 753, loss = 3.34288079\n",
      "Iteration 754, loss = 3.34239650\n",
      "Iteration 755, loss = 3.34191210\n",
      "Iteration 756, loss = 3.34142761\n",
      "Iteration 757, loss = 3.34094303\n",
      "Iteration 758, loss = 3.34045836\n",
      "Iteration 759, loss = 3.33997361\n",
      "Iteration 760, loss = 3.33948877\n",
      "Iteration 761, loss = 3.33900384\n",
      "Iteration 762, loss = 3.33851884\n",
      "Iteration 763, loss = 3.33803376\n",
      "Iteration 764, loss = 3.33754861\n",
      "Iteration 765, loss = 3.33706338\n",
      "Iteration 766, loss = 3.33657809\n",
      "Iteration 767, loss = 3.33609273\n",
      "Iteration 768, loss = 3.33560731\n",
      "Iteration 769, loss = 3.33512182\n",
      "Iteration 770, loss = 3.33463628\n",
      "Iteration 771, loss = 3.33415068\n",
      "Iteration 772, loss = 3.33366503\n",
      "Iteration 773, loss = 3.33317932\n",
      "Iteration 774, loss = 3.33269357\n",
      "Iteration 775, loss = 3.33220778\n",
      "Iteration 776, loss = 3.33172194\n",
      "Iteration 777, loss = 3.33123606\n",
      "Iteration 778, loss = 3.33075014\n",
      "Iteration 779, loss = 3.33026419\n",
      "Iteration 780, loss = 3.32977821\n",
      "Iteration 781, loss = 3.32929220\n",
      "Iteration 782, loss = 3.32880616\n",
      "Iteration 783, loss = 3.32832010\n",
      "Iteration 784, loss = 3.32783402\n",
      "Iteration 785, loss = 3.32734792\n",
      "Iteration 786, loss = 3.32686180\n",
      "Iteration 787, loss = 3.32637568\n",
      "Iteration 788, loss = 3.32588954\n",
      "Iteration 789, loss = 3.32540340\n",
      "Iteration 790, loss = 3.32491725\n",
      "Iteration 791, loss = 3.32443110\n",
      "Iteration 792, loss = 3.32394495\n",
      "Iteration 793, loss = 3.32345881\n",
      "Iteration 794, loss = 3.32297267\n",
      "Iteration 795, loss = 3.32248654\n",
      "Iteration 796, loss = 3.32200043\n",
      "Iteration 797, loss = 3.32151433\n",
      "Iteration 798, loss = 3.32102825\n",
      "Iteration 799, loss = 3.32054219\n",
      "Iteration 800, loss = 3.32005616\n",
      "Iteration 801, loss = 3.31957015\n",
      "Iteration 802, loss = 3.31908417\n",
      "Iteration 803, loss = 3.31859823\n",
      "Iteration 804, loss = 3.31811232\n",
      "Iteration 805, loss = 3.31762645\n",
      "Iteration 806, loss = 3.31714062\n",
      "Iteration 807, loss = 3.31665483\n",
      "Iteration 808, loss = 3.31616910\n",
      "Iteration 809, loss = 3.31568341\n",
      "Iteration 810, loss = 3.31519777\n",
      "Iteration 811, loss = 3.31471219\n",
      "Iteration 812, loss = 3.31422667\n",
      "Iteration 813, loss = 3.31374121\n",
      "Iteration 814, loss = 3.31325582\n",
      "Iteration 815, loss = 3.31277049\n",
      "Iteration 816, loss = 3.31228524\n",
      "Iteration 817, loss = 3.31180005\n",
      "Iteration 818, loss = 3.31131495\n",
      "Iteration 819, loss = 3.31082992\n",
      "Iteration 820, loss = 3.31034497\n",
      "Iteration 821, loss = 3.30986011\n",
      "Iteration 822, loss = 3.30937534\n",
      "Iteration 823, loss = 3.30889065\n",
      "Iteration 824, loss = 3.30840606\n",
      "Iteration 825, loss = 3.30792157\n",
      "Iteration 826, loss = 3.30743718\n",
      "Iteration 827, loss = 3.30695289\n",
      "Iteration 828, loss = 3.30646870\n",
      "Iteration 829, loss = 3.30598462\n",
      "Iteration 830, loss = 3.30550066\n",
      "Iteration 831, loss = 3.30501681\n",
      "Iteration 832, loss = 3.30453307\n",
      "Iteration 833, loss = 3.30404946\n",
      "Iteration 834, loss = 3.30356597\n",
      "Iteration 835, loss = 3.30308260\n",
      "Iteration 836, loss = 3.30259936\n",
      "Iteration 837, loss = 3.30211626\n",
      "Iteration 838, loss = 3.30163328\n",
      "Iteration 839, loss = 3.30115045\n",
      "Iteration 840, loss = 3.30066776\n",
      "Iteration 841, loss = 3.30018521\n",
      "Iteration 842, loss = 3.29970280\n",
      "Iteration 843, loss = 3.29922055\n",
      "Iteration 844, loss = 3.29873844\n",
      "Iteration 845, loss = 3.29825649\n",
      "Iteration 846, loss = 3.29777470\n",
      "Iteration 847, loss = 3.29729307\n",
      "Iteration 848, loss = 3.29681161\n",
      "Iteration 849, loss = 3.29633031\n",
      "Iteration 850, loss = 3.29584917\n",
      "Iteration 851, loss = 3.29536821\n",
      "Iteration 852, loss = 3.29488743\n",
      "Iteration 853, loss = 3.29440682\n",
      "Iteration 854, loss = 3.29392640\n",
      "Iteration 855, loss = 3.29344616\n",
      "Iteration 856, loss = 3.29296610\n",
      "Iteration 857, loss = 3.29248623\n",
      "Iteration 858, loss = 3.29200656\n",
      "Iteration 859, loss = 3.29152708\n",
      "Iteration 860, loss = 3.29104780\n",
      "Iteration 861, loss = 3.29056872\n",
      "Iteration 862, loss = 3.29008984\n",
      "Iteration 863, loss = 3.28961117\n",
      "Iteration 864, loss = 3.28913270\n",
      "Iteration 865, loss = 3.28865445\n",
      "Iteration 866, loss = 3.28817642\n",
      "Iteration 867, loss = 3.28769860\n",
      "Iteration 868, loss = 3.28722100\n",
      "Iteration 869, loss = 3.28674362\n",
      "Iteration 870, loss = 3.28626647\n",
      "Iteration 871, loss = 3.28578955\n",
      "Iteration 872, loss = 3.28531286\n",
      "Iteration 873, loss = 3.28483640\n",
      "Iteration 874, loss = 3.28436018\n",
      "Iteration 875, loss = 3.28388420\n",
      "Iteration 876, loss = 3.28340846\n",
      "Iteration 877, loss = 3.28293296\n",
      "Iteration 878, loss = 3.28245771\n",
      "Iteration 879, loss = 3.28198271\n",
      "Iteration 880, loss = 3.28150797\n",
      "Iteration 881, loss = 3.28103348\n",
      "Iteration 882, loss = 3.28055925\n",
      "Iteration 883, loss = 3.28008528\n",
      "Iteration 884, loss = 3.27961157\n",
      "Iteration 885, loss = 3.27913813\n",
      "Iteration 886, loss = 3.27866496\n",
      "Iteration 887, loss = 3.27819205\n",
      "Iteration 888, loss = 3.27771943\n",
      "Iteration 889, loss = 3.27724707\n",
      "Iteration 890, loss = 3.27677500\n",
      "Iteration 891, loss = 3.27630321\n",
      "Iteration 892, loss = 3.27583170\n",
      "Iteration 893, loss = 3.27536048\n",
      "Iteration 894, loss = 3.27488955\n",
      "Iteration 895, loss = 3.27441891\n",
      "Iteration 896, loss = 3.27394856\n",
      "Iteration 897, loss = 3.27347852\n",
      "Iteration 898, loss = 3.27300877\n",
      "Iteration 899, loss = 3.27253932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 900, loss = 3.27207017\n",
      "Iteration 901, loss = 3.27160134\n",
      "Iteration 902, loss = 3.27113281\n",
      "Iteration 903, loss = 3.27066459\n",
      "Iteration 904, loss = 3.27019669\n",
      "Iteration 905, loss = 3.26972910\n",
      "Iteration 906, loss = 3.26926183\n",
      "Iteration 907, loss = 3.26879488\n",
      "Iteration 908, loss = 3.26832826\n",
      "Iteration 909, loss = 3.26786196\n",
      "Iteration 910, loss = 3.26739599\n",
      "Iteration 911, loss = 3.26693035\n",
      "Iteration 912, loss = 3.26646504\n",
      "Iteration 913, loss = 3.26600007\n",
      "Iteration 914, loss = 3.26553544\n",
      "Iteration 915, loss = 3.26507114\n",
      "Iteration 916, loss = 3.26460719\n",
      "Iteration 917, loss = 3.26414358\n",
      "Iteration 918, loss = 3.26368032\n",
      "Iteration 919, loss = 3.26321740\n",
      "Iteration 920, loss = 3.26275484\n",
      "Iteration 921, loss = 3.26229263\n",
      "Iteration 922, loss = 3.26183078\n",
      "Iteration 923, loss = 3.26136928\n",
      "Iteration 924, loss = 3.26090814\n",
      "Iteration 925, loss = 3.26044736\n",
      "Iteration 926, loss = 3.25998695\n",
      "Iteration 927, loss = 3.25952690\n",
      "Iteration 928, loss = 3.25906723\n",
      "Iteration 929, loss = 3.25860792\n",
      "Iteration 930, loss = 3.25814898\n",
      "Iteration 931, loss = 3.25769042\n",
      "Iteration 932, loss = 3.25723223\n",
      "Iteration 933, loss = 3.25677443\n",
      "Iteration 934, loss = 3.25631700\n",
      "Iteration 935, loss = 3.25585995\n",
      "Iteration 936, loss = 3.25540329\n",
      "Iteration 937, loss = 3.25494702\n",
      "Iteration 938, loss = 3.25449113\n",
      "Iteration 939, loss = 3.25403564\n",
      "Iteration 940, loss = 3.25358053\n",
      "Iteration 941, loss = 3.25312582\n",
      "Iteration 942, loss = 3.25267151\n",
      "Iteration 943, loss = 3.25221759\n",
      "Iteration 944, loss = 3.25176408\n",
      "Iteration 945, loss = 3.25131096\n",
      "Iteration 946, loss = 3.25085825\n",
      "Iteration 947, loss = 3.25040594\n",
      "Iteration 948, loss = 3.24995404\n",
      "Iteration 949, loss = 3.24950255\n",
      "Iteration 950, loss = 3.24905147\n",
      "Iteration 951, loss = 3.24860080\n",
      "Iteration 952, loss = 3.24815055\n",
      "Iteration 953, loss = 3.24770071\n",
      "Iteration 954, loss = 3.24725129\n",
      "Iteration 955, loss = 3.24680229\n",
      "Iteration 956, loss = 3.24635371\n",
      "Iteration 957, loss = 3.24590555\n",
      "Iteration 958, loss = 3.24545782\n",
      "Iteration 959, loss = 3.24501051\n",
      "Iteration 960, loss = 3.24456363\n",
      "Iteration 961, loss = 3.24411718\n",
      "Iteration 962, loss = 3.24367116\n",
      "Iteration 963, loss = 3.24322557\n",
      "Iteration 964, loss = 3.24278041\n",
      "Iteration 965, loss = 3.24233569\n",
      "Iteration 966, loss = 3.24189141\n",
      "Iteration 967, loss = 3.24144757\n",
      "Iteration 968, loss = 3.24100416\n",
      "Iteration 969, loss = 3.24056120\n",
      "Iteration 970, loss = 3.24011868\n",
      "Iteration 971, loss = 3.23967660\n",
      "Iteration 972, loss = 3.23923497\n",
      "Iteration 973, loss = 3.23879379\n",
      "Iteration 974, loss = 3.23835305\n",
      "Iteration 975, loss = 3.23791276\n",
      "Iteration 976, loss = 3.23747293\n",
      "Iteration 977, loss = 3.23703355\n",
      "Iteration 978, loss = 3.23659462\n",
      "Iteration 979, loss = 3.23615615\n",
      "Iteration 980, loss = 3.23571813\n",
      "Iteration 981, loss = 3.23528057\n",
      "Iteration 982, loss = 3.23484347\n",
      "Iteration 983, loss = 3.23440683\n",
      "Iteration 984, loss = 3.23397065\n",
      "Iteration 985, loss = 3.23353494\n",
      "Iteration 986, loss = 3.23309969\n",
      "Iteration 987, loss = 3.23266490\n",
      "Iteration 988, loss = 3.23223058\n",
      "Iteration 989, loss = 3.23179673\n",
      "Iteration 990, loss = 3.23136335\n",
      "Iteration 991, loss = 3.23093043\n",
      "Iteration 992, loss = 3.23049799\n",
      "Iteration 993, loss = 3.23006602\n",
      "Iteration 994, loss = 3.22963452\n",
      "Iteration 995, loss = 3.22920350\n",
      "Iteration 996, loss = 3.22877295\n",
      "Iteration 997, loss = 3.22834287\n",
      "Iteration 998, loss = 3.22791328\n",
      "Iteration 999, loss = 3.22748416\n",
      "Iteration 1000, loss = 3.22705552\n",
      "Iteration 1001, loss = 3.22662736\n",
      "Iteration 1002, loss = 3.22619968\n",
      "Iteration 1003, loss = 3.22577249\n",
      "Iteration 1004, loss = 3.22534578\n",
      "Iteration 1005, loss = 3.22491955\n",
      "Iteration 1006, loss = 3.22449380\n",
      "Iteration 1007, loss = 3.22406854\n",
      "Iteration 1008, loss = 3.22364377\n",
      "Iteration 1009, loss = 3.22321949\n",
      "Iteration 1010, loss = 3.22279569\n",
      "Iteration 1011, loss = 3.22237238\n",
      "Iteration 1012, loss = 3.22194956\n",
      "Iteration 1013, loss = 3.22152723\n",
      "Iteration 1014, loss = 3.22110539\n",
      "Iteration 1015, loss = 3.22068405\n",
      "Iteration 1016, loss = 3.22026320\n",
      "Iteration 1017, loss = 3.21984284\n",
      "Iteration 1018, loss = 3.21942297\n",
      "Iteration 1019, loss = 3.21900360\n",
      "Iteration 1020, loss = 3.21858472\n",
      "Iteration 1021, loss = 3.21816634\n",
      "Iteration 1022, loss = 3.21774846\n",
      "Iteration 1023, loss = 3.21733107\n",
      "Iteration 1024, loss = 3.21691418\n",
      "Iteration 1025, loss = 3.21649779\n",
      "Iteration 1026, loss = 3.21608190\n",
      "Iteration 1027, loss = 3.21566651\n",
      "Iteration 1028, loss = 3.21525162\n",
      "Iteration 1029, loss = 3.21483723\n",
      "Iteration 1030, loss = 3.21442334\n",
      "Iteration 1031, loss = 3.21400995\n",
      "Iteration 1032, loss = 3.21359706\n",
      "Iteration 1033, loss = 3.21318468\n",
      "Iteration 1034, loss = 3.21277280\n",
      "Iteration 1035, loss = 3.21236142\n",
      "Iteration 1036, loss = 3.21195055\n",
      "Iteration 1037, loss = 3.21154018\n",
      "Iteration 1038, loss = 3.21113031\n",
      "Iteration 1039, loss = 3.21072095\n",
      "Iteration 1040, loss = 3.21031210\n",
      "Iteration 1041, loss = 3.20990375\n",
      "Iteration 1042, loss = 3.20949590\n",
      "Iteration 1043, loss = 3.20908857\n",
      "Iteration 1044, loss = 3.20868174\n",
      "Iteration 1045, loss = 3.20827541\n",
      "Iteration 1046, loss = 3.20786960\n",
      "Iteration 1047, loss = 3.20746429\n",
      "Iteration 1048, loss = 3.20705949\n",
      "Iteration 1049, loss = 3.20665519\n",
      "Iteration 1050, loss = 3.20625141\n",
      "Iteration 1051, loss = 3.20584813\n",
      "Iteration 1052, loss = 3.20544536\n",
      "Iteration 1053, loss = 3.20504310\n",
      "Iteration 1054, loss = 3.20464135\n",
      "Iteration 1055, loss = 3.20424011\n",
      "Iteration 1056, loss = 3.20383937\n",
      "Iteration 1057, loss = 3.20343915\n",
      "Iteration 1058, loss = 3.20303943\n",
      "Iteration 1059, loss = 3.20264023\n",
      "Iteration 1060, loss = 3.20224153\n",
      "Iteration 1061, loss = 3.20184334\n",
      "Iteration 1062, loss = 3.20144566\n",
      "Iteration 1063, loss = 3.20104849\n",
      "Iteration 1064, loss = 3.20065184\n",
      "Iteration 1065, loss = 3.20025569\n",
      "Iteration 1066, loss = 3.19986005\n",
      "Iteration 1067, loss = 3.19946492\n",
      "Iteration 1068, loss = 3.19907029\n",
      "Iteration 1069, loss = 3.19867618\n",
      "Iteration 1070, loss = 3.19828258\n",
      "Iteration 1071, loss = 3.19788949\n",
      "Iteration 1072, loss = 3.19749690\n",
      "Iteration 1073, loss = 3.19710483\n",
      "Iteration 1074, loss = 3.19671326\n",
      "Iteration 1075, loss = 3.19632221\n",
      "Iteration 1076, loss = 3.19593166\n",
      "Iteration 1077, loss = 3.19554162\n",
      "Iteration 1078, loss = 3.19515209\n",
      "Iteration 1079, loss = 3.19476306\n",
      "Iteration 1080, loss = 3.19437455\n",
      "Iteration 1081, loss = 3.19398654\n",
      "Iteration 1082, loss = 3.19359904\n",
      "Iteration 1083, loss = 3.19321205\n",
      "Iteration 1084, loss = 3.19282556\n",
      "Iteration 1085, loss = 3.19243958\n",
      "Iteration 1086, loss = 3.19205411\n",
      "Iteration 1087, loss = 3.19166915\n",
      "Iteration 1088, loss = 3.19128469\n",
      "Iteration 1089, loss = 3.19090073\n",
      "Iteration 1090, loss = 3.19051728\n",
      "Iteration 1091, loss = 3.19013434\n",
      "Iteration 1092, loss = 3.18975190\n",
      "Iteration 1093, loss = 3.18936997\n",
      "Iteration 1094, loss = 3.18898854\n",
      "Iteration 1095, loss = 3.18860761\n",
      "Iteration 1096, loss = 3.18822719\n",
      "Iteration 1097, loss = 3.18784727\n",
      "Iteration 1098, loss = 3.18746786\n",
      "Iteration 1099, loss = 3.18708894\n",
      "Iteration 1100, loss = 3.18671053\n",
      "Iteration 1101, loss = 3.18633262\n",
      "Iteration 1102, loss = 3.18595521\n",
      "Iteration 1103, loss = 3.18557830\n",
      "Iteration 1104, loss = 3.18520189\n",
      "Iteration 1105, loss = 3.18482598\n",
      "Iteration 1106, loss = 3.18445057\n",
      "Iteration 1107, loss = 3.18407566\n",
      "Iteration 1108, loss = 3.18370125\n",
      "Iteration 1109, loss = 3.18332733\n",
      "Iteration 1110, loss = 3.18295391\n",
      "Iteration 1111, loss = 3.18258099\n",
      "Iteration 1112, loss = 3.18220856\n",
      "Iteration 1113, loss = 3.18183663\n",
      "Iteration 1114, loss = 3.18146520\n",
      "Iteration 1115, loss = 3.18109426\n",
      "Iteration 1116, loss = 3.18072381\n",
      "Iteration 1117, loss = 3.18035386\n",
      "Iteration 1118, loss = 3.17998440\n",
      "Iteration 1119, loss = 3.17961543\n",
      "Iteration 1120, loss = 3.17924695\n",
      "Iteration 1121, loss = 3.17887897\n",
      "Iteration 1122, loss = 3.17851147\n",
      "Iteration 1123, loss = 3.17814447\n",
      "Iteration 1124, loss = 3.17777795\n",
      "Iteration 1125, loss = 3.17741193\n",
      "Iteration 1126, loss = 3.17704639\n",
      "Iteration 1127, loss = 3.17668133\n",
      "Iteration 1128, loss = 3.17631677\n",
      "Iteration 1129, loss = 3.17595269\n",
      "Iteration 1130, loss = 3.17558909\n",
      "Iteration 1131, loss = 3.17522598\n",
      "Iteration 1132, loss = 3.17486336\n",
      "Iteration 1133, loss = 3.17450121\n",
      "Iteration 1134, loss = 3.17413955\n",
      "Iteration 1135, loss = 3.17377837\n",
      "Iteration 1136, loss = 3.17341767\n",
      "Iteration 1137, loss = 3.17305746\n",
      "Iteration 1138, loss = 3.17269772\n",
      "Iteration 1139, loss = 3.17233846\n",
      "Iteration 1140, loss = 3.17197968\n",
      "Iteration 1141, loss = 3.17162137\n",
      "Iteration 1142, loss = 3.17126355\n",
      "Iteration 1143, loss = 3.17090619\n",
      "Iteration 1144, loss = 3.17054932\n",
      "Iteration 1145, loss = 3.17019291\n",
      "Iteration 1146, loss = 3.16983699\n",
      "Iteration 1147, loss = 3.16948153\n",
      "Iteration 1148, loss = 3.16912655\n",
      "Iteration 1149, loss = 3.16877203\n",
      "Iteration 1150, loss = 3.16841799\n",
      "Iteration 1151, loss = 3.16806442\n",
      "Iteration 1152, loss = 3.16771131\n",
      "Iteration 1153, loss = 3.16735868\n",
      "Iteration 1154, loss = 3.16700651\n",
      "Iteration 1155, loss = 3.16665480\n",
      "Iteration 1156, loss = 3.16630356\n",
      "Iteration 1157, loss = 3.16595279\n",
      "Iteration 1158, loss = 3.16560248\n",
      "Iteration 1159, loss = 3.16525263\n",
      "Iteration 1160, loss = 3.16490325\n",
      "Iteration 1161, loss = 3.16455433\n",
      "Iteration 1162, loss = 3.16420586\n",
      "Iteration 1163, loss = 3.16385786\n",
      "Iteration 1164, loss = 3.16351031\n",
      "Iteration 1165, loss = 3.16316323\n",
      "Iteration 1166, loss = 3.16281660\n",
      "Iteration 1167, loss = 3.16247042\n",
      "Iteration 1168, loss = 3.16212470\n",
      "Iteration 1169, loss = 3.16177944\n",
      "Iteration 1170, loss = 3.16143463\n",
      "Iteration 1171, loss = 3.16109027\n",
      "Iteration 1172, loss = 3.16074636\n",
      "Iteration 1173, loss = 3.16040290\n",
      "Iteration 1174, loss = 3.16005989\n",
      "Iteration 1175, loss = 3.15971733\n",
      "Iteration 1176, loss = 3.15937522\n",
      "Iteration 1177, loss = 3.15903356\n",
      "Iteration 1178, loss = 3.15869234\n",
      "Iteration 1179, loss = 3.15835157\n",
      "Iteration 1180, loss = 3.15801124\n",
      "Iteration 1181, loss = 3.15767136\n",
      "Iteration 1182, loss = 3.15733191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1183, loss = 3.15699291\n",
      "Iteration 1184, loss = 3.15665435\n",
      "Iteration 1185, loss = 3.15631623\n",
      "Iteration 1186, loss = 3.15597855\n",
      "Iteration 1187, loss = 3.15564130\n",
      "Iteration 1188, loss = 3.15530450\n",
      "Iteration 1189, loss = 3.15496813\n",
      "Iteration 1190, loss = 3.15463219\n",
      "Iteration 1191, loss = 3.15429669\n",
      "Iteration 1192, loss = 3.15396162\n",
      "Iteration 1193, loss = 3.15362698\n",
      "Iteration 1194, loss = 3.15329277\n",
      "Iteration 1195, loss = 3.15295899\n",
      "Iteration 1196, loss = 3.15262565\n",
      "Iteration 1197, loss = 3.15229273\n",
      "Iteration 1198, loss = 3.15196024\n",
      "Iteration 1199, loss = 3.15162817\n",
      "Iteration 1200, loss = 3.15129653\n",
      "Iteration 1201, loss = 3.15096532\n",
      "Iteration 1202, loss = 3.15063452\n",
      "Iteration 1203, loss = 3.15030416\n",
      "Iteration 1204, loss = 3.14997421\n",
      "Iteration 1205, loss = 3.14964468\n",
      "Iteration 1206, loss = 3.14931557\n",
      "Iteration 1207, loss = 3.14898688\n",
      "Iteration 1208, loss = 3.14865861\n",
      "Iteration 1209, loss = 3.14833076\n",
      "Iteration 1210, loss = 3.14800332\n",
      "Iteration 1211, loss = 3.14767630\n",
      "Iteration 1212, loss = 3.14734969\n",
      "Iteration 1213, loss = 3.14702349\n",
      "Iteration 1214, loss = 3.14669770\n",
      "Iteration 1215, loss = 3.14637233\n",
      "Iteration 1216, loss = 3.14604737\n",
      "Iteration 1217, loss = 3.14572281\n",
      "Iteration 1218, loss = 3.14539866\n",
      "Iteration 1219, loss = 3.14507492\n",
      "Iteration 1220, loss = 3.14475159\n",
      "Iteration 1221, loss = 3.14442866\n",
      "Iteration 1222, loss = 3.14410614\n",
      "Iteration 1223, loss = 3.14378401\n",
      "Iteration 1224, loss = 3.14346230\n",
      "Iteration 1225, loss = 3.14314098\n",
      "Iteration 1226, loss = 3.14282006\n",
      "Iteration 1227, loss = 3.14249954\n",
      "Iteration 1228, loss = 3.14217942\n",
      "Iteration 1229, loss = 3.14185970\n",
      "Iteration 1230, loss = 3.14154037\n",
      "Iteration 1231, loss = 3.14122144\n",
      "Iteration 1232, loss = 3.14090291\n",
      "Iteration 1233, loss = 3.14058476\n",
      "Iteration 1234, loss = 3.14026701\n",
      "Iteration 1235, loss = 3.13994966\n",
      "Iteration 1236, loss = 3.13963269\n",
      "Iteration 1237, loss = 3.13931611\n",
      "Iteration 1238, loss = 3.13899992\n",
      "Iteration 1239, loss = 3.13868412\n",
      "Iteration 1240, loss = 3.13836870\n",
      "Iteration 1241, loss = 3.13805368\n",
      "Iteration 1242, loss = 3.13773903\n",
      "Iteration 1243, loss = 3.13742477\n",
      "Iteration 1244, loss = 3.13711090\n",
      "Iteration 1245, loss = 3.13679740\n",
      "Iteration 1246, loss = 3.13648429\n",
      "Iteration 1247, loss = 3.13617155\n",
      "Iteration 1248, loss = 3.13585920\n",
      "Iteration 1249, loss = 3.13554722\n",
      "Iteration 1250, loss = 3.13523562\n",
      "Iteration 1251, loss = 3.13492440\n",
      "Iteration 1252, loss = 3.13461356\n",
      "Iteration 1253, loss = 3.13430308\n",
      "Iteration 1254, loss = 3.13399298\n",
      "Iteration 1255, loss = 3.13368326\n",
      "Iteration 1256, loss = 3.13337390\n",
      "Iteration 1257, loss = 3.13306492\n",
      "Iteration 1258, loss = 3.13275631\n",
      "Iteration 1259, loss = 3.13244806\n",
      "Iteration 1260, loss = 3.13214018\n",
      "Iteration 1261, loss = 3.13183267\n",
      "Iteration 1262, loss = 3.13152553\n",
      "Iteration 1263, loss = 3.13121875\n",
      "Iteration 1264, loss = 3.13091233\n",
      "Iteration 1265, loss = 3.13060628\n",
      "Iteration 1266, loss = 3.13030059\n",
      "Iteration 1267, loss = 3.12999527\n",
      "Iteration 1268, loss = 3.12969030\n",
      "Iteration 1269, loss = 3.12938569\n",
      "Iteration 1270, loss = 3.12908144\n",
      "Iteration 1271, loss = 3.12877755\n",
      "Iteration 1272, loss = 3.12847402\n",
      "Iteration 1273, loss = 3.12817084\n",
      "Iteration 1274, loss = 3.12786802\n",
      "Iteration 1275, loss = 3.12756555\n",
      "Iteration 1276, loss = 3.12726343\n",
      "Iteration 1277, loss = 3.12696167\n",
      "Iteration 1278, loss = 3.12666026\n",
      "Iteration 1279, loss = 3.12635920\n",
      "Iteration 1280, loss = 3.12605849\n",
      "Iteration 1281, loss = 3.12575813\n",
      "Iteration 1282, loss = 3.12545811\n",
      "Iteration 1283, loss = 3.12515844\n",
      "Iteration 1284, loss = 3.12485912\n",
      "Iteration 1285, loss = 3.12456015\n",
      "Iteration 1286, loss = 3.12426152\n",
      "Iteration 1287, loss = 3.12396323\n",
      "Iteration 1288, loss = 3.12366528\n",
      "Iteration 1289, loss = 3.12336768\n",
      "Iteration 1290, loss = 3.12307042\n",
      "Iteration 1291, loss = 3.12277349\n",
      "Iteration 1292, loss = 3.12247691\n",
      "Iteration 1293, loss = 3.12218067\n",
      "Iteration 1294, loss = 3.12188476\n",
      "Iteration 1295, loss = 3.12158919\n",
      "Iteration 1296, loss = 3.12129395\n",
      "Iteration 1297, loss = 3.12099905\n",
      "Iteration 1298, loss = 3.12070449\n",
      "Iteration 1299, loss = 3.12041025\n",
      "Iteration 1300, loss = 3.12011635\n",
      "Iteration 1301, loss = 3.11982278\n",
      "Iteration 1302, loss = 3.11952954\n",
      "Iteration 1303, loss = 3.11923663\n",
      "Iteration 1304, loss = 3.11894405\n",
      "Iteration 1305, loss = 3.11865180\n",
      "Iteration 1306, loss = 3.11835988\n",
      "Iteration 1307, loss = 3.11806828\n",
      "Iteration 1308, loss = 3.11777701\n",
      "Iteration 1309, loss = 3.11748606\n",
      "Iteration 1310, loss = 3.11719543\n",
      "Iteration 1311, loss = 3.11690513\n",
      "Iteration 1312, loss = 3.11661515\n",
      "Iteration 1313, loss = 3.11632550\n",
      "Iteration 1314, loss = 3.11603616\n",
      "Iteration 1315, loss = 3.11574715\n",
      "Iteration 1316, loss = 3.11545845\n",
      "Iteration 1317, loss = 3.11517007\n",
      "Iteration 1318, loss = 3.11488201\n",
      "Iteration 1319, loss = 3.11459426\n",
      "Iteration 1320, loss = 3.11430683\n",
      "Iteration 1321, loss = 3.11401972\n",
      "Iteration 1322, loss = 3.11373292\n",
      "Iteration 1323, loss = 3.11344643\n",
      "Iteration 1324, loss = 3.11316026\n",
      "Iteration 1325, loss = 3.11287440\n",
      "Iteration 1326, loss = 3.11258885\n",
      "Iteration 1327, loss = 3.11230360\n",
      "Iteration 1328, loss = 3.11201867\n",
      "Iteration 1329, loss = 3.11173405\n",
      "Iteration 1330, loss = 3.11144974\n",
      "Iteration 1331, loss = 3.11116573\n",
      "Iteration 1332, loss = 3.11088203\n",
      "Iteration 1333, loss = 3.11059863\n",
      "Iteration 1334, loss = 3.11031554\n",
      "Iteration 1335, loss = 3.11003276\n",
      "Iteration 1336, loss = 3.10975027\n",
      "Iteration 1337, loss = 3.10946809\n",
      "Iteration 1338, loss = 3.10918622\n",
      "Iteration 1339, loss = 3.10890464\n",
      "Iteration 1340, loss = 3.10862336\n",
      "Iteration 1341, loss = 3.10834238\n",
      "Iteration 1342, loss = 3.10806170\n",
      "Iteration 1343, loss = 3.10778132\n",
      "Iteration 1344, loss = 3.10750124\n",
      "Iteration 1345, loss = 3.10722145\n",
      "Iteration 1346, loss = 3.10694196\n",
      "Iteration 1347, loss = 3.10666277\n",
      "Iteration 1348, loss = 3.10638386\n",
      "Iteration 1349, loss = 3.10610526\n",
      "Iteration 1350, loss = 3.10582694\n",
      "Iteration 1351, loss = 3.10554892\n",
      "Iteration 1352, loss = 3.10527119\n",
      "Iteration 1353, loss = 3.10499375\n",
      "Iteration 1354, loss = 3.10471660\n",
      "Iteration 1355, loss = 3.10443973\n",
      "Iteration 1356, loss = 3.10416316\n",
      "Iteration 1357, loss = 3.10388688\n",
      "Iteration 1358, loss = 3.10361088\n",
      "Iteration 1359, loss = 3.10333517\n",
      "Iteration 1360, loss = 3.10305974\n",
      "Iteration 1361, loss = 3.10278460\n",
      "Iteration 1362, loss = 3.10250974\n",
      "Iteration 1363, loss = 3.10223517\n",
      "Iteration 1364, loss = 3.10196088\n",
      "Iteration 1365, loss = 3.10168687\n",
      "Iteration 1366, loss = 3.10141315\n",
      "Iteration 1367, loss = 3.10113970\n",
      "Iteration 1368, loss = 3.10086653\n",
      "Iteration 1369, loss = 3.10059365\n",
      "Iteration 1370, loss = 3.10032104\n",
      "Iteration 1371, loss = 3.10004871\n",
      "Iteration 1372, loss = 3.09977666\n",
      "Iteration 1373, loss = 3.09950488\n",
      "Iteration 1374, loss = 3.09923338\n",
      "Iteration 1375, loss = 3.09896216\n",
      "Iteration 1376, loss = 3.09869121\n",
      "Iteration 1377, loss = 3.09842054\n",
      "Iteration 1378, loss = 3.09815013\n",
      "Iteration 1379, loss = 3.09788000\n",
      "Iteration 1380, loss = 3.09761015\n",
      "Iteration 1381, loss = 3.09734056\n",
      "Iteration 1382, loss = 3.09707124\n",
      "Iteration 1383, loss = 3.09680220\n",
      "Iteration 1384, loss = 3.09653342\n",
      "Iteration 1385, loss = 3.09626491\n",
      "Iteration 1386, loss = 3.09599667\n",
      "Iteration 1387, loss = 3.09572870\n",
      "Iteration 1388, loss = 3.09546100\n",
      "Iteration 1389, loss = 3.09519356\n",
      "Iteration 1390, loss = 3.09492638\n",
      "Iteration 1391, loss = 3.09465947\n",
      "Iteration 1392, loss = 3.09439283\n",
      "Iteration 1393, loss = 3.09412645\n",
      "Iteration 1394, loss = 3.09386033\n",
      "Iteration 1395, loss = 3.09359447\n",
      "Iteration 1396, loss = 3.09332888\n",
      "Iteration 1397, loss = 3.09306354\n",
      "Iteration 1398, loss = 3.09279847\n",
      "Iteration 1399, loss = 3.09253365\n",
      "Iteration 1400, loss = 3.09226910\n",
      "Iteration 1401, loss = 3.09200480\n",
      "Iteration 1402, loss = 3.09174076\n",
      "Iteration 1403, loss = 3.09147698\n",
      "Iteration 1404, loss = 3.09121345\n",
      "Iteration 1405, loss = 3.09095018\n",
      "Iteration 1406, loss = 3.09068717\n",
      "Iteration 1407, loss = 3.09042441\n",
      "Iteration 1408, loss = 3.09016190\n",
      "Iteration 1409, loss = 3.08989965\n",
      "Iteration 1410, loss = 3.08963765\n",
      "Iteration 1411, loss = 3.08937591\n",
      "Iteration 1412, loss = 3.08911441\n",
      "Iteration 1413, loss = 3.08885317\n",
      "Iteration 1414, loss = 3.08859217\n",
      "Iteration 1415, loss = 3.08833143\n",
      "Iteration 1416, loss = 3.08807093\n",
      "Iteration 1417, loss = 3.08781068\n",
      "Iteration 1418, loss = 3.08755069\n",
      "Iteration 1419, loss = 3.08729094\n",
      "Iteration 1420, loss = 3.08703143\n",
      "Iteration 1421, loss = 3.08677217\n",
      "Iteration 1422, loss = 3.08651316\n",
      "Iteration 1423, loss = 3.08625439\n",
      "Iteration 1424, loss = 3.08599587\n",
      "Iteration 1425, loss = 3.08573759\n",
      "Iteration 1426, loss = 3.08547955\n",
      "Iteration 1427, loss = 3.08522176\n",
      "Iteration 1428, loss = 3.08496421\n",
      "Iteration 1429, loss = 3.08470690\n",
      "Iteration 1430, loss = 3.08444983\n",
      "Iteration 1431, loss = 3.08419300\n",
      "Iteration 1432, loss = 3.08393641\n",
      "Iteration 1433, loss = 3.08368006\n",
      "Iteration 1434, loss = 3.08342395\n",
      "Iteration 1435, loss = 3.08316808\n",
      "Iteration 1436, loss = 3.08291244\n",
      "Iteration 1437, loss = 3.08265704\n",
      "Iteration 1438, loss = 3.08240188\n",
      "Iteration 1439, loss = 3.08214696\n",
      "Iteration 1440, loss = 3.08189226\n",
      "Iteration 1441, loss = 3.08163781\n",
      "Iteration 1442, loss = 3.08138358\n",
      "Iteration 1443, loss = 3.08112960\n",
      "Iteration 1444, loss = 3.08087584\n",
      "Iteration 1445, loss = 3.08062231\n",
      "Iteration 1446, loss = 3.08036902\n",
      "Iteration 1447, loss = 3.08011596\n",
      "Iteration 1448, loss = 3.07986313\n",
      "Iteration 1449, loss = 3.07961053\n",
      "Iteration 1450, loss = 3.07935816\n",
      "Iteration 1451, loss = 3.07910602\n",
      "Iteration 1452, loss = 3.07885411\n",
      "Iteration 1453, loss = 3.07860242\n",
      "Iteration 1454, loss = 3.07835096\n",
      "Iteration 1455, loss = 3.07809973\n",
      "Iteration 1456, loss = 3.07784873\n",
      "Iteration 1457, loss = 3.07759795\n",
      "Iteration 1458, loss = 3.07734740\n",
      "Iteration 1459, loss = 3.07709707\n",
      "Iteration 1460, loss = 3.07684696\n",
      "Iteration 1461, loss = 3.07659708\n",
      "Iteration 1462, loss = 3.07634742\n",
      "Iteration 1463, loss = 3.07609799\n",
      "Iteration 1464, loss = 3.07584877\n",
      "Iteration 1465, loss = 3.07559978\n",
      "Iteration 1466, loss = 3.07535101\n",
      "Iteration 1467, loss = 3.07510246\n",
      "Iteration 1468, loss = 3.07485413\n",
      "Iteration 1469, loss = 3.07460602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1470, loss = 3.07435812\n",
      "Iteration 1471, loss = 3.07411045\n",
      "Iteration 1472, loss = 3.07386299\n",
      "Iteration 1473, loss = 3.07361575\n",
      "Iteration 1474, loss = 3.07336873\n",
      "Iteration 1475, loss = 3.07312192\n",
      "Iteration 1476, loss = 3.07287533\n",
      "Iteration 1477, loss = 3.07262895\n",
      "Iteration 1478, loss = 3.07238279\n",
      "Iteration 1479, loss = 3.07213684\n",
      "Iteration 1480, loss = 3.07189111\n",
      "Iteration 1481, loss = 3.07164559\n",
      "Iteration 1482, loss = 3.07140028\n",
      "Iteration 1483, loss = 3.07115518\n",
      "Iteration 1484, loss = 3.07091030\n",
      "Iteration 1485, loss = 3.07066562\n",
      "Iteration 1486, loss = 3.07042116\n",
      "Iteration 1487, loss = 3.07017690\n",
      "Iteration 1488, loss = 3.06993286\n",
      "Iteration 1489, loss = 3.06968902\n",
      "Iteration 1490, loss = 3.06944540\n",
      "Iteration 1491, loss = 3.06920198\n",
      "Iteration 1492, loss = 3.06895876\n",
      "Iteration 1493, loss = 3.06871576\n",
      "Iteration 1494, loss = 3.06847296\n",
      "Iteration 1495, loss = 3.06823037\n",
      "Iteration 1496, loss = 3.06798798\n",
      "Iteration 1497, loss = 3.06774580\n",
      "Iteration 1498, loss = 3.06750382\n",
      "Iteration 1499, loss = 3.06726204\n",
      "Iteration 1500, loss = 3.06702047\n",
      "Iteration 1501, loss = 3.06677910\n",
      "Iteration 1502, loss = 3.06653794\n",
      "Iteration 1503, loss = 3.06629697\n",
      "Iteration 1504, loss = 3.06605621\n",
      "Iteration 1505, loss = 3.06581565\n",
      "Iteration 1506, loss = 3.06557529\n",
      "Iteration 1507, loss = 3.06533513\n",
      "Iteration 1508, loss = 3.06509516\n",
      "Iteration 1509, loss = 3.06485540\n",
      "Iteration 1510, loss = 3.06461584\n",
      "Iteration 1511, loss = 3.06437647\n",
      "Iteration 1512, loss = 3.06413730\n",
      "Iteration 1513, loss = 3.06389833\n",
      "Iteration 1514, loss = 3.06365955\n",
      "Iteration 1515, loss = 3.06342097\n",
      "Iteration 1516, loss = 3.06318258\n",
      "Iteration 1517, loss = 3.06294439\n",
      "Iteration 1518, loss = 3.06270640\n",
      "Iteration 1519, loss = 3.06246860\n",
      "Iteration 1520, loss = 3.06223099\n",
      "Iteration 1521, loss = 3.06199358\n",
      "Iteration 1522, loss = 3.06175635\n",
      "Iteration 1523, loss = 3.06151933\n",
      "Iteration 1524, loss = 3.06128249\n",
      "Iteration 1525, loss = 3.06104584\n",
      "Iteration 1526, loss = 3.06080938\n",
      "Iteration 1527, loss = 3.06057312\n",
      "Iteration 1528, loss = 3.06033704\n",
      "Iteration 1529, loss = 3.06010116\n",
      "Iteration 1530, loss = 3.05986546\n",
      "Iteration 1531, loss = 3.05962995\n",
      "Iteration 1532, loss = 3.05939463\n",
      "Iteration 1533, loss = 3.05915949\n",
      "Iteration 1534, loss = 3.05892454\n",
      "Iteration 1535, loss = 3.05868978\n",
      "Iteration 1536, loss = 3.05845521\n",
      "Iteration 1537, loss = 3.05822082\n",
      "Iteration 1538, loss = 3.05798661\n",
      "Iteration 1539, loss = 3.05775260\n",
      "Iteration 1540, loss = 3.05751876\n",
      "Iteration 1541, loss = 3.05728511\n",
      "Iteration 1542, loss = 3.05705164\n",
      "Iteration 1543, loss = 3.05681835\n",
      "Iteration 1544, loss = 3.05658525\n",
      "Iteration 1545, loss = 3.05635233\n",
      "Iteration 1546, loss = 3.05611959\n",
      "Iteration 1547, loss = 3.05588703\n",
      "Iteration 1548, loss = 3.05565465\n",
      "Iteration 1549, loss = 3.05542245\n",
      "Iteration 1550, loss = 3.05519043\n",
      "Iteration 1551, loss = 3.05495859\n",
      "Iteration 1552, loss = 3.05472693\n",
      "Iteration 1553, loss = 3.05449545\n",
      "Iteration 1554, loss = 3.05426415\n",
      "Iteration 1555, loss = 3.05403302\n",
      "Iteration 1556, loss = 3.05380207\n",
      "Iteration 1557, loss = 3.05357129\n",
      "Iteration 1558, loss = 3.05334070\n",
      "Iteration 1559, loss = 3.05311027\n",
      "Iteration 1560, loss = 3.05288003\n",
      "Iteration 1561, loss = 3.05264995\n",
      "Iteration 1562, loss = 3.05242005\n",
      "Iteration 1563, loss = 3.05219033\n",
      "Iteration 1564, loss = 3.05196078\n",
      "Iteration 1565, loss = 3.05173140\n",
      "Iteration 1566, loss = 3.05150219\n",
      "Iteration 1567, loss = 3.05127316\n",
      "Iteration 1568, loss = 3.05104430\n",
      "Iteration 1569, loss = 3.05081561\n",
      "Iteration 1570, loss = 3.05058709\n",
      "Iteration 1571, loss = 3.05035874\n",
      "Iteration 1572, loss = 3.05013056\n",
      "Iteration 1573, loss = 3.04990255\n",
      "Iteration 1574, loss = 3.04967471\n",
      "Iteration 1575, loss = 3.04944704\n",
      "Iteration 1576, loss = 3.04921953\n",
      "Iteration 1577, loss = 3.04899220\n",
      "Iteration 1578, loss = 3.04876503\n",
      "Iteration 1579, loss = 3.04853803\n",
      "Iteration 1580, loss = 3.04831119\n",
      "Iteration 1581, loss = 3.04808452\n",
      "Iteration 1582, loss = 3.04785802\n",
      "Iteration 1583, loss = 3.04763168\n",
      "Iteration 1584, loss = 3.04740551\n",
      "Iteration 1585, loss = 3.04717950\n",
      "Iteration 1586, loss = 3.04695366\n",
      "Iteration 1587, loss = 3.04672798\n",
      "Iteration 1588, loss = 3.04650246\n",
      "Iteration 1589, loss = 3.04627710\n",
      "Iteration 1590, loss = 3.04605191\n",
      "Iteration 1591, loss = 3.04582688\n",
      "Iteration 1592, loss = 3.04560201\n",
      "Iteration 1593, loss = 3.04537731\n",
      "Iteration 1594, loss = 3.04515276\n",
      "Iteration 1595, loss = 3.04492838\n",
      "Iteration 1596, loss = 3.04470415\n",
      "Iteration 1597, loss = 3.04448008\n",
      "Iteration 1598, loss = 3.04425618\n",
      "Iteration 1599, loss = 3.04403243\n",
      "Iteration 1600, loss = 3.04380884\n",
      "Iteration 1601, loss = 3.04358541\n",
      "Iteration 1602, loss = 3.04336214\n",
      "Iteration 1603, loss = 3.04313902\n",
      "Iteration 1604, loss = 3.04291606\n",
      "Iteration 1605, loss = 3.04269326\n",
      "Iteration 1606, loss = 3.04247061\n",
      "Iteration 1607, loss = 3.04224812\n",
      "Iteration 1608, loss = 3.04202579\n",
      "Iteration 1609, loss = 3.04180361\n",
      "Iteration 1610, loss = 3.04158158\n",
      "Iteration 1611, loss = 3.04135971\n",
      "Iteration 1612, loss = 3.04113799\n",
      "Iteration 1613, loss = 3.04091643\n",
      "Iteration 1614, loss = 3.04069502\n",
      "Iteration 1615, loss = 3.04047376\n",
      "Iteration 1616, loss = 3.04025265\n",
      "Iteration 1617, loss = 3.04003170\n",
      "Iteration 1618, loss = 3.03981090\n",
      "Iteration 1619, loss = 3.03959025\n",
      "Iteration 1620, loss = 3.03936975\n",
      "Iteration 1621, loss = 3.03914940\n",
      "Iteration 1622, loss = 3.03892920\n",
      "Iteration 1623, loss = 3.03870915\n",
      "Iteration 1624, loss = 3.03848926\n",
      "Iteration 1625, loss = 3.03826951\n",
      "Iteration 1626, loss = 3.03804991\n",
      "Iteration 1627, loss = 3.03783045\n",
      "Iteration 1628, loss = 3.03761115\n",
      "Iteration 1629, loss = 3.03739199\n",
      "Iteration 1630, loss = 3.03717298\n",
      "Iteration 1631, loss = 3.03695412\n",
      "Iteration 1632, loss = 3.03673541\n",
      "Iteration 1633, loss = 3.03651684\n",
      "Iteration 1634, loss = 3.03629842\n",
      "Iteration 1635, loss = 3.03608014\n",
      "Iteration 1636, loss = 3.03586201\n",
      "Iteration 1637, loss = 3.03564402\n",
      "Iteration 1638, loss = 3.03542618\n",
      "Iteration 1639, loss = 3.03520849\n",
      "Iteration 1640, loss = 3.03499093\n",
      "Iteration 1641, loss = 3.03477352\n",
      "Iteration 1642, loss = 3.03455626\n",
      "Iteration 1643, loss = 3.03433914\n",
      "Iteration 1644, loss = 3.03412216\n",
      "Iteration 1645, loss = 3.03390532\n",
      "Iteration 1646, loss = 3.03368863\n",
      "Iteration 1647, loss = 3.03347207\n",
      "Iteration 1648, loss = 3.03325566\n",
      "Iteration 1649, loss = 3.03303940\n",
      "Iteration 1650, loss = 3.03282327\n",
      "Iteration 1651, loss = 3.03260728\n",
      "Iteration 1652, loss = 3.03239143\n",
      "Iteration 1653, loss = 3.03217573\n",
      "Iteration 1654, loss = 3.03196016\n",
      "Iteration 1655, loss = 3.03174473\n",
      "Iteration 1656, loss = 3.03152944\n",
      "Iteration 1657, loss = 3.03131429\n",
      "Iteration 1658, loss = 3.03109928\n",
      "Iteration 1659, loss = 3.03088441\n",
      "Iteration 1660, loss = 3.03066968\n",
      "Iteration 1661, loss = 3.03045508\n",
      "Iteration 1662, loss = 3.03024062\n",
      "Iteration 1663, loss = 3.03002630\n",
      "Iteration 1664, loss = 3.02981211\n",
      "Iteration 1665, loss = 3.02959807\n",
      "Iteration 1666, loss = 3.02938416\n",
      "Iteration 1667, loss = 3.02917038\n",
      "Iteration 1668, loss = 3.02895674\n",
      "Iteration 1669, loss = 3.02874324\n",
      "Iteration 1670, loss = 3.02852987\n",
      "Iteration 1671, loss = 3.02831664\n",
      "Iteration 1672, loss = 3.02810354\n",
      "Iteration 1673, loss = 3.02789058\n",
      "Iteration 1674, loss = 3.02767775\n",
      "Iteration 1675, loss = 3.02746505\n",
      "Iteration 1676, loss = 3.02725249\n",
      "Iteration 1677, loss = 3.02704007\n",
      "Iteration 1678, loss = 3.02682777\n",
      "Iteration 1679, loss = 3.02661561\n",
      "Iteration 1680, loss = 3.02640358\n",
      "Iteration 1681, loss = 3.02619169\n",
      "Iteration 1682, loss = 3.02597993\n",
      "Iteration 1683, loss = 3.02576830\n",
      "Iteration 1684, loss = 3.02555680\n",
      "Iteration 1685, loss = 3.02534543\n",
      "Iteration 1686, loss = 3.02513420\n",
      "Iteration 1687, loss = 3.02492310\n",
      "Iteration 1688, loss = 3.02471212\n",
      "Iteration 1689, loss = 3.02450128\n",
      "Iteration 1690, loss = 3.02429057\n",
      "Iteration 1691, loss = 3.02407999\n",
      "Iteration 1692, loss = 3.02386954\n",
      "Iteration 1693, loss = 3.02365923\n",
      "Iteration 1694, loss = 3.02344904\n",
      "Iteration 1695, loss = 3.02323898\n",
      "Iteration 1696, loss = 3.02302905\n",
      "Iteration 1697, loss = 3.02281925\n",
      "Iteration 1698, loss = 3.02260957\n",
      "Iteration 1699, loss = 3.02240003\n",
      "Iteration 1700, loss = 3.02219062\n",
      "Iteration 1701, loss = 3.02198133\n",
      "Iteration 1702, loss = 3.02177218\n",
      "Iteration 1703, loss = 3.02156315\n",
      "Iteration 1704, loss = 3.02135425\n",
      "Iteration 1705, loss = 3.02114548\n",
      "Iteration 1706, loss = 3.02093683\n",
      "Iteration 1707, loss = 3.02072832\n",
      "Iteration 1708, loss = 3.02051993\n",
      "Iteration 1709, loss = 3.02031166\n",
      "Iteration 1710, loss = 3.02010353\n",
      "Iteration 1711, loss = 3.01989552\n",
      "Iteration 1712, loss = 3.01968764\n",
      "Iteration 1713, loss = 3.01947988\n",
      "Iteration 1714, loss = 3.01927226\n",
      "Iteration 1715, loss = 3.01906475\n",
      "Iteration 1716, loss = 3.01885738\n",
      "Iteration 1717, loss = 3.01865013\n",
      "Iteration 1718, loss = 3.01844300\n",
      "Iteration 1719, loss = 3.01823601\n",
      "Iteration 1720, loss = 3.01802913\n",
      "Iteration 1721, loss = 3.01782239\n",
      "Iteration 1722, loss = 3.01761576\n",
      "Iteration 1723, loss = 3.01740927\n",
      "Iteration 1724, loss = 3.01720290\n",
      "Iteration 1725, loss = 3.01699665\n",
      "Iteration 1726, loss = 3.01679053\n",
      "Iteration 1727, loss = 3.01658453\n",
      "Iteration 1728, loss = 3.01637866\n",
      "Iteration 1729, loss = 3.01617291\n",
      "Iteration 1730, loss = 3.01596729\n",
      "Iteration 1731, loss = 3.01576179\n",
      "Iteration 1732, loss = 3.01555642\n",
      "Iteration 1733, loss = 3.01535117\n",
      "Iteration 1734, loss = 3.01514604\n",
      "Iteration 1735, loss = 3.01494104\n",
      "Iteration 1736, loss = 3.01473616\n",
      "Iteration 1737, loss = 3.01453140\n",
      "Iteration 1738, loss = 3.01432677\n",
      "Iteration 1739, loss = 3.01412226\n",
      "Iteration 1740, loss = 3.01391788\n",
      "Iteration 1741, loss = 3.01371362\n",
      "Iteration 1742, loss = 3.01350948\n",
      "Iteration 1743, loss = 3.01330547\n",
      "Iteration 1744, loss = 3.01310158\n",
      "Iteration 1745, loss = 3.01289781\n",
      "Iteration 1746, loss = 3.01269416\n",
      "Iteration 1747, loss = 3.01249064\n",
      "Iteration 1748, loss = 3.01228724\n",
      "Iteration 1749, loss = 3.01208397\n",
      "Iteration 1750, loss = 3.01188081\n",
      "Iteration 1751, loss = 3.01167778\n",
      "Iteration 1752, loss = 3.01147487\n",
      "Iteration 1753, loss = 3.01127209\n",
      "Iteration 1754, loss = 3.01106942\n",
      "Iteration 1755, loss = 3.01086688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1756, loss = 3.01066446\n",
      "Iteration 1757, loss = 3.01046217\n",
      "Iteration 1758, loss = 3.01025999\n",
      "Iteration 1759, loss = 3.01005794\n",
      "Iteration 1760, loss = 3.00985601\n",
      "Iteration 1761, loss = 3.00965420\n",
      "Iteration 1762, loss = 3.00945252\n",
      "Iteration 1763, loss = 3.00925096\n",
      "Iteration 1764, loss = 3.00904952\n",
      "Iteration 1765, loss = 3.00884820\n",
      "Iteration 1766, loss = 3.00864700\n",
      "Iteration 1767, loss = 3.00844592\n",
      "Iteration 1768, loss = 3.00824497\n",
      "Iteration 1769, loss = 3.00804414\n",
      "Iteration 1770, loss = 3.00784343\n",
      "Iteration 1771, loss = 3.00764284\n",
      "Iteration 1772, loss = 3.00744238\n",
      "Iteration 1773, loss = 3.00724203\n",
      "Iteration 1774, loss = 3.00704181\n",
      "Iteration 1775, loss = 3.00684171\n",
      "Iteration 1776, loss = 3.00664173\n",
      "Iteration 1777, loss = 3.00644187\n",
      "Iteration 1778, loss = 3.00624214\n",
      "Iteration 1779, loss = 3.00604252\n",
      "Iteration 1780, loss = 3.00584303\n",
      "Iteration 1781, loss = 3.00564366\n",
      "Iteration 1782, loss = 3.00544441\n",
      "Iteration 1783, loss = 3.00524529\n",
      "Iteration 1784, loss = 3.00504628\n",
      "Iteration 1785, loss = 3.00484740\n",
      "Iteration 1786, loss = 3.00464864\n",
      "Iteration 1787, loss = 3.00444999\n",
      "Iteration 1788, loss = 3.00425148\n",
      "Iteration 1789, loss = 3.00405308\n",
      "Iteration 1790, loss = 3.00385480\n",
      "Iteration 1791, loss = 3.00365665\n",
      "Iteration 1792, loss = 3.00345862\n",
      "Iteration 1793, loss = 3.00326071\n",
      "Iteration 1794, loss = 3.00306292\n",
      "Iteration 1795, loss = 3.00286525\n",
      "Iteration 1796, loss = 3.00266770\n",
      "Iteration 1797, loss = 3.00247028\n",
      "Iteration 1798, loss = 3.00227298\n",
      "Iteration 1799, loss = 3.00207579\n",
      "Iteration 1800, loss = 3.00187874\n",
      "Iteration 1801, loss = 3.00168180\n",
      "Iteration 1802, loss = 3.00148498\n",
      "Iteration 1803, loss = 3.00128829\n",
      "Iteration 1804, loss = 3.00109171\n",
      "Iteration 1805, loss = 3.00089526\n",
      "Iteration 1806, loss = 3.00069893\n",
      "Iteration 1807, loss = 3.00050273\n",
      "Iteration 1808, loss = 3.00030664\n",
      "Iteration 1809, loss = 3.00011068\n",
      "Iteration 1810, loss = 2.99991483\n",
      "Iteration 1811, loss = 2.99971911\n",
      "Iteration 1812, loss = 2.99952351\n",
      "Iteration 1813, loss = 2.99932804\n",
      "Iteration 1814, loss = 2.99913268\n",
      "Iteration 1815, loss = 2.99893745\n",
      "Iteration 1816, loss = 2.99874233\n",
      "Iteration 1817, loss = 2.99854734\n",
      "Iteration 1818, loss = 2.99835248\n",
      "Iteration 1819, loss = 2.99815773\n",
      "Iteration 1820, loss = 2.99796310\n",
      "Iteration 1821, loss = 2.99776860\n",
      "Iteration 1822, loss = 2.99757422\n",
      "Iteration 1823, loss = 2.99737996\n",
      "Iteration 1824, loss = 2.99718582\n",
      "Iteration 1825, loss = 2.99699181\n",
      "Iteration 1826, loss = 2.99679792\n",
      "Iteration 1827, loss = 2.99660414\n",
      "Iteration 1828, loss = 2.99641049\n",
      "Iteration 1829, loss = 2.99621697\n",
      "Iteration 1830, loss = 2.99602356\n",
      "Iteration 1831, loss = 2.99583028\n",
      "Iteration 1832, loss = 2.99563712\n",
      "Iteration 1833, loss = 2.99544408\n",
      "Iteration 1834, loss = 2.99525116\n",
      "Iteration 1835, loss = 2.99505836\n",
      "Iteration 1836, loss = 2.99486569\n",
      "Iteration 1837, loss = 2.99467314\n",
      "Iteration 1838, loss = 2.99448071\n",
      "Iteration 1839, loss = 2.99428840\n",
      "Iteration 1840, loss = 2.99409621\n",
      "Iteration 1841, loss = 2.99390415\n",
      "Iteration 1842, loss = 2.99371221\n",
      "Iteration 1843, loss = 2.99352039\n",
      "Iteration 1844, loss = 2.99332869\n",
      "Iteration 1845, loss = 2.99313711\n",
      "Iteration 1846, loss = 2.99294566\n",
      "Iteration 1847, loss = 2.99275433\n",
      "Iteration 1848, loss = 2.99256312\n",
      "Iteration 1849, loss = 2.99237203\n",
      "Iteration 1850, loss = 2.99218106\n",
      "Iteration 1851, loss = 2.99199022\n",
      "Iteration 1852, loss = 2.99179949\n",
      "Iteration 1853, loss = 2.99160889\n",
      "Iteration 1854, loss = 2.99141841\n",
      "Iteration 1855, loss = 2.99122806\n",
      "Iteration 1856, loss = 2.99103782\n",
      "Iteration 1857, loss = 2.99084771\n",
      "Iteration 1858, loss = 2.99065772\n",
      "Iteration 1859, loss = 2.99046785\n",
      "Iteration 1860, loss = 2.99027810\n",
      "Iteration 1861, loss = 2.99008848\n",
      "Iteration 1862, loss = 2.98989897\n",
      "Iteration 1863, loss = 2.98970959\n",
      "Iteration 1864, loss = 2.98952033\n",
      "Iteration 1865, loss = 2.98933119\n",
      "Iteration 1866, loss = 2.98914218\n",
      "Iteration 1867, loss = 2.98895328\n",
      "Iteration 1868, loss = 2.98876451\n",
      "Iteration 1869, loss = 2.98857586\n",
      "Iteration 1870, loss = 2.98838733\n",
      "Iteration 1871, loss = 2.98819892\n",
      "Iteration 1872, loss = 2.98801063\n",
      "Iteration 1873, loss = 2.98782246\n",
      "Iteration 1874, loss = 2.98763442\n",
      "Iteration 1875, loss = 2.98744650\n",
      "Iteration 1876, loss = 2.98725870\n",
      "Iteration 1877, loss = 2.98707102\n",
      "Iteration 1878, loss = 2.98688346\n",
      "Iteration 1879, loss = 2.98669602\n",
      "Iteration 1880, loss = 2.98650870\n",
      "Iteration 1881, loss = 2.98632151\n",
      "Iteration 1882, loss = 2.98613443\n",
      "Iteration 1883, loss = 2.98594748\n",
      "Iteration 1884, loss = 2.98576065\n",
      "Iteration 1885, loss = 2.98557394\n",
      "Iteration 1886, loss = 2.98538735\n",
      "Iteration 1887, loss = 2.98520088\n",
      "Iteration 1888, loss = 2.98501453\n",
      "Iteration 1889, loss = 2.98482830\n",
      "Iteration 1890, loss = 2.98464219\n",
      "Iteration 1891, loss = 2.98445620\n",
      "Iteration 1892, loss = 2.98427034\n",
      "Iteration 1893, loss = 2.98408459\n",
      "Iteration 1894, loss = 2.98389897\n",
      "Iteration 1895, loss = 2.98371346\n",
      "Iteration 1896, loss = 2.98352808\n",
      "Iteration 1897, loss = 2.98334281\n",
      "Iteration 1898, loss = 2.98315767\n",
      "Iteration 1899, loss = 2.98297264\n",
      "Iteration 1900, loss = 2.98278774\n",
      "Iteration 1901, loss = 2.98260295\n",
      "Iteration 1902, loss = 2.98241829\n",
      "Iteration 1903, loss = 2.98223374\n",
      "Iteration 1904, loss = 2.98204931\n",
      "Iteration 1905, loss = 2.98186501\n",
      "Iteration 1906, loss = 2.98168082\n",
      "Iteration 1907, loss = 2.98149675\n",
      "Iteration 1908, loss = 2.98131281\n",
      "Iteration 1909, loss = 2.98112898\n",
      "Iteration 1910, loss = 2.98094527\n",
      "Iteration 1911, loss = 2.98076167\n",
      "Iteration 1912, loss = 2.98057820\n",
      "Iteration 1913, loss = 2.98039485\n",
      "Iteration 1914, loss = 2.98021161\n",
      "Iteration 1915, loss = 2.98002850\n",
      "Iteration 1916, loss = 2.97984550\n",
      "Iteration 1917, loss = 2.97966262\n",
      "Iteration 1918, loss = 2.97947986\n",
      "Iteration 1919, loss = 2.97929722\n",
      "Iteration 1920, loss = 2.97911469\n",
      "Iteration 1921, loss = 2.97893228\n",
      "Iteration 1922, loss = 2.97875000\n",
      "Iteration 1923, loss = 2.97856782\n",
      "Iteration 1924, loss = 2.97838577\n",
      "Iteration 1925, loss = 2.97820383\n",
      "Iteration 1926, loss = 2.97802201\n",
      "Iteration 1927, loss = 2.97784031\n",
      "Iteration 1928, loss = 2.97765873\n",
      "Iteration 1929, loss = 2.97747726\n",
      "Iteration 1930, loss = 2.97729591\n",
      "Iteration 1931, loss = 2.97711467\n",
      "Iteration 1932, loss = 2.97693356\n",
      "Iteration 1933, loss = 2.97675256\n",
      "Iteration 1934, loss = 2.97657167\n",
      "Iteration 1935, loss = 2.97639090\n",
      "Iteration 1936, loss = 2.97621025\n",
      "Iteration 1937, loss = 2.97602971\n",
      "Iteration 1938, loss = 2.97584929\n",
      "Iteration 1939, loss = 2.97566899\n",
      "Iteration 1940, loss = 2.97548880\n",
      "Iteration 1941, loss = 2.97530872\n",
      "Iteration 1942, loss = 2.97512876\n",
      "Iteration 1943, loss = 2.97494892\n",
      "Iteration 1944, loss = 2.97476919\n",
      "Iteration 1945, loss = 2.97458958\n",
      "Iteration 1946, loss = 2.97441008\n",
      "Iteration 1947, loss = 2.97423069\n",
      "Iteration 1948, loss = 2.97405142\n",
      "Iteration 1949, loss = 2.97387227\n",
      "Iteration 1950, loss = 2.97369322\n",
      "Iteration 1951, loss = 2.97351430\n",
      "Iteration 1952, loss = 2.97333548\n",
      "Iteration 1953, loss = 2.97315678\n",
      "Iteration 1954, loss = 2.97297819\n",
      "Iteration 1955, loss = 2.97279972\n",
      "Iteration 1956, loss = 2.97262136\n",
      "Iteration 1957, loss = 2.97244311\n",
      "Iteration 1958, loss = 2.97226497\n",
      "Iteration 1959, loss = 2.97208695\n",
      "Iteration 1960, loss = 2.97190904\n",
      "Iteration 1961, loss = 2.97173124\n",
      "Iteration 1962, loss = 2.97155355\n",
      "Iteration 1963, loss = 2.97137598\n",
      "Iteration 1964, loss = 2.97119852\n",
      "Iteration 1965, loss = 2.97102117\n",
      "Iteration 1966, loss = 2.97084393\n",
      "Iteration 1967, loss = 2.97066680\n",
      "Iteration 1968, loss = 2.97048978\n",
      "Iteration 1969, loss = 2.97031287\n",
      "Iteration 1970, loss = 2.97013608\n",
      "Iteration 1971, loss = 2.96995939\n",
      "Iteration 1972, loss = 2.96978282\n",
      "Iteration 1973, loss = 2.96960635\n",
      "Iteration 1974, loss = 2.96943000\n",
      "Iteration 1975, loss = 2.96925376\n",
      "Iteration 1976, loss = 2.96907762\n",
      "Iteration 1977, loss = 2.96890160\n",
      "Iteration 1978, loss = 2.96872568\n",
      "Iteration 1979, loss = 2.96854987\n",
      "Iteration 1980, loss = 2.96837417\n",
      "Iteration 1981, loss = 2.96819858\n",
      "Iteration 1982, loss = 2.96802310\n",
      "Iteration 1983, loss = 2.96784773\n",
      "Iteration 1984, loss = 2.96767247\n",
      "Iteration 1985, loss = 2.96749731\n",
      "Iteration 1986, loss = 2.96732226\n",
      "Iteration 1987, loss = 2.96714732\n",
      "Iteration 1988, loss = 2.96697249\n",
      "Iteration 1989, loss = 2.96679776\n",
      "Iteration 1990, loss = 2.96662314\n",
      "Iteration 1991, loss = 2.96644863\n",
      "Iteration 1992, loss = 2.96627422\n",
      "Iteration 1993, loss = 2.96609992\n",
      "Iteration 1994, loss = 2.96592573\n",
      "Iteration 1995, loss = 2.96575164\n",
      "Iteration 1996, loss = 2.96557766\n",
      "Iteration 1997, loss = 2.96540378\n",
      "Iteration 1998, loss = 2.96523001\n",
      "Iteration 1999, loss = 2.96505635\n",
      "Iteration 2000, loss = 2.96488279\n",
      "Iteration 1, loss = 4.93691655\n",
      "Iteration 2, loss = 4.91550823\n",
      "Iteration 3, loss = 4.88578824\n",
      "Iteration 4, loss = 4.84939718\n",
      "Iteration 5, loss = 4.80793722\n",
      "Iteration 6, loss = 4.76292727\n",
      "Iteration 7, loss = 4.71576705\n",
      "Iteration 8, loss = 4.66770928\n",
      "Iteration 9, loss = 4.61984008\n",
      "Iteration 10, loss = 4.57306754\n",
      "Iteration 11, loss = 4.52811847\n",
      "Iteration 12, loss = 4.48554279\n",
      "Iteration 13, loss = 4.44572466\n",
      "Iteration 14, loss = 4.40889894\n",
      "Iteration 15, loss = 4.37517145\n",
      "Iteration 16, loss = 4.34454112\n",
      "Iteration 17, loss = 4.31692258\n",
      "Iteration 18, loss = 4.29216770\n",
      "Iteration 19, loss = 4.27008511\n",
      "Iteration 20, loss = 4.25045703\n",
      "Iteration 21, loss = 4.23305317\n",
      "Iteration 22, loss = 4.21764162\n",
      "Iteration 23, loss = 4.20399710\n",
      "Iteration 24, loss = 4.19190663\n",
      "Iteration 25, loss = 4.18117333\n",
      "Iteration 26, loss = 4.17161844\n",
      "Iteration 27, loss = 4.16308218\n",
      "Iteration 28, loss = 4.15542359\n",
      "Iteration 29, loss = 4.14851975\n",
      "Iteration 30, loss = 4.14226452\n",
      "Iteration 31, loss = 4.13656706\n",
      "Iteration 32, loss = 4.13135019\n",
      "Iteration 33, loss = 4.12654870\n",
      "Iteration 34, loss = 4.12210779\n",
      "Iteration 35, loss = 4.11798149\n",
      "Iteration 36, loss = 4.11413132\n",
      "Iteration 37, loss = 4.11052498\n",
      "Iteration 38, loss = 4.10713532\n",
      "Iteration 39, loss = 4.10393936\n",
      "Iteration 40, loss = 4.10091748\n",
      "Iteration 41, loss = 4.09805280\n",
      "Iteration 42, loss = 4.09533058\n",
      "Iteration 43, loss = 4.09273783\n",
      "Iteration 44, loss = 4.09026295\n",
      "Iteration 45, loss = 4.08789547\n",
      "Iteration 46, loss = 4.08562586\n",
      "Iteration 47, loss = 4.08344538\n",
      "Iteration 48, loss = 4.08134595\n",
      "Iteration 49, loss = 4.07932013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50, loss = 4.07736102\n",
      "Iteration 51, loss = 4.07546223\n",
      "Iteration 52, loss = 4.07361790\n",
      "Iteration 53, loss = 4.07182260\n",
      "Iteration 54, loss = 4.07007138\n",
      "Iteration 55, loss = 4.06835973\n",
      "Iteration 56, loss = 4.06668352\n",
      "Iteration 57, loss = 4.06503906\n",
      "Iteration 58, loss = 4.06342300\n",
      "Iteration 59, loss = 4.06183236\n",
      "Iteration 60, loss = 4.06026446\n",
      "Iteration 61, loss = 4.05871694\n",
      "Iteration 62, loss = 4.05718769\n",
      "Iteration 63, loss = 4.05567485\n",
      "Iteration 64, loss = 4.05417678\n",
      "Iteration 65, loss = 4.05269202\n",
      "Iteration 66, loss = 4.05121931\n",
      "Iteration 67, loss = 4.04975751\n",
      "Iteration 68, loss = 4.04830563\n",
      "Iteration 69, loss = 4.04686279\n",
      "Iteration 70, loss = 4.04542821\n",
      "Iteration 71, loss = 4.04400122\n",
      "Iteration 72, loss = 4.04258119\n",
      "Iteration 73, loss = 4.04116759\n",
      "Iteration 74, loss = 4.03975993\n",
      "Iteration 75, loss = 4.03835778\n",
      "Iteration 76, loss = 4.03696076\n",
      "Iteration 77, loss = 4.03556854\n",
      "Iteration 78, loss = 4.03418079\n",
      "Iteration 79, loss = 4.03279725\n",
      "Iteration 80, loss = 4.03141768\n",
      "Iteration 81, loss = 4.03004184\n",
      "Iteration 82, loss = 4.02866956\n",
      "Iteration 83, loss = 4.02730063\n",
      "Iteration 84, loss = 4.02593491\n",
      "Iteration 85, loss = 4.02457225\n",
      "Iteration 86, loss = 4.02321251\n",
      "Iteration 87, loss = 4.02185555\n",
      "Iteration 88, loss = 4.02050127\n",
      "Iteration 89, loss = 4.01914956\n",
      "Iteration 90, loss = 4.01780030\n",
      "Iteration 91, loss = 4.01645340\n",
      "Iteration 92, loss = 4.01510875\n",
      "Iteration 93, loss = 4.01376627\n",
      "Iteration 94, loss = 4.01242585\n",
      "Iteration 95, loss = 4.01108742\n",
      "Iteration 96, loss = 4.00975087\n",
      "Iteration 97, loss = 4.00841611\n",
      "Iteration 98, loss = 4.00708307\n",
      "Iteration 99, loss = 4.00575164\n",
      "Iteration 100, loss = 4.00442175\n",
      "Iteration 101, loss = 4.00309331\n",
      "Iteration 102, loss = 4.00176624\n",
      "Iteration 103, loss = 4.00044045\n",
      "Iteration 104, loss = 3.99911588\n",
      "Iteration 105, loss = 3.99779244\n",
      "Iteration 106, loss = 3.99647005\n",
      "Iteration 107, loss = 3.99514866\n",
      "Iteration 108, loss = 3.99382819\n",
      "Iteration 109, loss = 3.99250859\n",
      "Iteration 110, loss = 3.99118978\n",
      "Iteration 111, loss = 3.98987171\n",
      "Iteration 112, loss = 3.98855434\n",
      "Iteration 113, loss = 3.98723762\n",
      "Iteration 114, loss = 3.98592149\n",
      "Iteration 115, loss = 3.98460592\n",
      "Iteration 116, loss = 3.98329087\n",
      "Iteration 117, loss = 3.98197632\n",
      "Iteration 118, loss = 3.98066223\n",
      "Iteration 119, loss = 3.97934857\n",
      "Iteration 120, loss = 3.97803534\n",
      "Iteration 121, loss = 3.97672250\n",
      "Iteration 122, loss = 3.97541005\n",
      "Iteration 123, loss = 3.97409798\n",
      "Iteration 124, loss = 3.97278628\n",
      "Iteration 125, loss = 3.97147496\n",
      "Iteration 126, loss = 3.97016400\n",
      "Iteration 127, loss = 3.96885342\n",
      "Iteration 128, loss = 3.96754323\n",
      "Iteration 129, loss = 3.96623343\n",
      "Iteration 130, loss = 3.96492404\n",
      "Iteration 131, loss = 3.96361508\n",
      "Iteration 132, loss = 3.96230657\n",
      "Iteration 133, loss = 3.96099854\n",
      "Iteration 134, loss = 3.95969100\n",
      "Iteration 135, loss = 3.95838398\n",
      "Iteration 136, loss = 3.95707753\n",
      "Iteration 137, loss = 3.95577168\n",
      "Iteration 138, loss = 3.95446646\n",
      "Iteration 139, loss = 3.95316191\n",
      "Iteration 140, loss = 3.95185808\n",
      "Iteration 141, loss = 3.95055501\n",
      "Iteration 142, loss = 3.94925274\n",
      "Iteration 143, loss = 3.94795134\n",
      "Iteration 144, loss = 3.94665085\n",
      "Iteration 145, loss = 3.94535133\n",
      "Iteration 146, loss = 3.94405282\n",
      "Iteration 147, loss = 3.94275540\n",
      "Iteration 148, loss = 3.94145912\n",
      "Iteration 149, loss = 3.94016405\n",
      "Iteration 150, loss = 3.93887025\n",
      "Iteration 151, loss = 3.93757778\n",
      "Iteration 152, loss = 3.93628672\n",
      "Iteration 153, loss = 3.93499713\n",
      "Iteration 154, loss = 3.93370909\n",
      "Iteration 155, loss = 3.93242267\n",
      "Iteration 156, loss = 3.93113794\n",
      "Iteration 157, loss = 3.92985498\n",
      "Iteration 158, loss = 3.92857387\n",
      "Iteration 159, loss = 3.92729468\n",
      "Iteration 160, loss = 3.92601749\n",
      "Iteration 161, loss = 3.92474239\n",
      "Iteration 162, loss = 3.92346945\n",
      "Iteration 163, loss = 3.92219877\n",
      "Iteration 164, loss = 3.92093041\n",
      "Iteration 165, loss = 3.91966447\n",
      "Iteration 166, loss = 3.91840103\n",
      "Iteration 167, loss = 3.91714017\n",
      "Iteration 168, loss = 3.91588198\n",
      "Iteration 169, loss = 3.91462655\n",
      "Iteration 170, loss = 3.91337396\n",
      "Iteration 171, loss = 3.91212431\n",
      "Iteration 172, loss = 3.91087766\n",
      "Iteration 173, loss = 3.90963412\n",
      "Iteration 174, loss = 3.90839377\n",
      "Iteration 175, loss = 3.90715669\n",
      "Iteration 176, loss = 3.90592298\n",
      "Iteration 177, loss = 3.90469272\n",
      "Iteration 178, loss = 3.90346599\n",
      "Iteration 179, loss = 3.90224288\n",
      "Iteration 180, loss = 3.90102347\n",
      "Iteration 181, loss = 3.89980786\n",
      "Iteration 182, loss = 3.89859612\n",
      "Iteration 183, loss = 3.89738834\n",
      "Iteration 184, loss = 3.89618459\n",
      "Iteration 185, loss = 3.89498497\n",
      "Iteration 186, loss = 3.89378954\n",
      "Iteration 187, loss = 3.89259840\n",
      "Iteration 188, loss = 3.89141162\n",
      "Iteration 189, loss = 3.89022927\n",
      "Iteration 190, loss = 3.88905143\n",
      "Iteration 191, loss = 3.88787819\n",
      "Iteration 192, loss = 3.88670960\n",
      "Iteration 193, loss = 3.88554575\n",
      "Iteration 194, loss = 3.88438669\n",
      "Iteration 195, loss = 3.88323252\n",
      "Iteration 196, loss = 3.88208328\n",
      "Iteration 197, loss = 3.88093905\n",
      "Iteration 198, loss = 3.87979988\n",
      "Iteration 199, loss = 3.87866586\n",
      "Iteration 200, loss = 3.87753702\n",
      "Iteration 201, loss = 3.87641344\n",
      "Iteration 202, loss = 3.87529517\n",
      "Iteration 203, loss = 3.87418226\n",
      "Iteration 204, loss = 3.87307477\n",
      "Iteration 205, loss = 3.87197276\n",
      "Iteration 206, loss = 3.87087626\n",
      "Iteration 207, loss = 3.86978533\n",
      "Iteration 208, loss = 3.86870001\n",
      "Iteration 209, loss = 3.86762035\n",
      "Iteration 210, loss = 3.86654639\n",
      "Iteration 211, loss = 3.86547817\n",
      "Iteration 212, loss = 3.86441572\n",
      "Iteration 213, loss = 3.86335908\n",
      "Iteration 214, loss = 3.86230828\n",
      "Iteration 215, loss = 3.86126335\n",
      "Iteration 216, loss = 3.86022433\n",
      "Iteration 217, loss = 3.85919124\n",
      "Iteration 218, loss = 3.85816409\n",
      "Iteration 219, loss = 3.85714293\n",
      "Iteration 220, loss = 3.85612776\n",
      "Iteration 221, loss = 3.85511860\n",
      "Iteration 222, loss = 3.85411548\n",
      "Iteration 223, loss = 3.85311840\n",
      "Iteration 224, loss = 3.85212737\n",
      "Iteration 225, loss = 3.85114241\n",
      "Iteration 226, loss = 3.85016352\n",
      "Iteration 227, loss = 3.84919071\n",
      "Iteration 228, loss = 3.84822398\n",
      "Iteration 229, loss = 3.84726334\n",
      "Iteration 230, loss = 3.84630878\n",
      "Iteration 231, loss = 3.84536030\n",
      "Iteration 232, loss = 3.84441790\n",
      "Iteration 233, loss = 3.84348156\n",
      "Iteration 234, loss = 3.84255129\n",
      "Iteration 235, loss = 3.84162707\n",
      "Iteration 236, loss = 3.84070889\n",
      "Iteration 237, loss = 3.83979674\n",
      "Iteration 238, loss = 3.83889061\n",
      "Iteration 239, loss = 3.83799046\n",
      "Iteration 240, loss = 3.83709630\n",
      "Iteration 241, loss = 3.83620808\n",
      "Iteration 242, loss = 3.83532581\n",
      "Iteration 243, loss = 3.83444944\n",
      "Iteration 244, loss = 3.83357897\n",
      "Iteration 245, loss = 3.83271435\n",
      "Iteration 246, loss = 3.83185556\n",
      "Iteration 247, loss = 3.83100258\n",
      "Iteration 248, loss = 3.83015537\n",
      "Iteration 249, loss = 3.82931390\n",
      "Iteration 250, loss = 3.82847814\n",
      "Iteration 251, loss = 3.82764806\n",
      "Iteration 252, loss = 3.82682361\n",
      "Iteration 253, loss = 3.82600476\n",
      "Iteration 254, loss = 3.82519148\n",
      "Iteration 255, loss = 3.82438373\n",
      "Iteration 256, loss = 3.82358146\n",
      "Iteration 257, loss = 3.82278463\n",
      "Iteration 258, loss = 3.82199321\n",
      "Iteration 259, loss = 3.82120715\n",
      "Iteration 260, loss = 3.82042641\n",
      "Iteration 261, loss = 3.81965094\n",
      "Iteration 262, loss = 3.81888070\n",
      "Iteration 263, loss = 3.81811565\n",
      "Iteration 264, loss = 3.81735573\n",
      "Iteration 265, loss = 3.81660091\n",
      "Iteration 266, loss = 3.81585113\n",
      "Iteration 267, loss = 3.81510634\n",
      "Iteration 268, loss = 3.81436650\n",
      "Iteration 269, loss = 3.81363156\n",
      "Iteration 270, loss = 3.81290147\n",
      "Iteration 271, loss = 3.81217618\n",
      "Iteration 272, loss = 3.81145564\n",
      "Iteration 273, loss = 3.81073980\n",
      "Iteration 274, loss = 3.81002861\n",
      "Iteration 275, loss = 3.80932201\n",
      "Iteration 276, loss = 3.80861996\n",
      "Iteration 277, loss = 3.80792241\n",
      "Iteration 278, loss = 3.80722931\n",
      "Iteration 279, loss = 3.80654059\n",
      "Iteration 280, loss = 3.80585622\n",
      "Iteration 281, loss = 3.80517613\n",
      "Iteration 282, loss = 3.80450029\n",
      "Iteration 283, loss = 3.80382863\n",
      "Iteration 284, loss = 3.80316110\n",
      "Iteration 285, loss = 3.80249766\n",
      "Iteration 286, loss = 3.80183824\n",
      "Iteration 287, loss = 3.80118281\n",
      "Iteration 288, loss = 3.80053131\n",
      "Iteration 289, loss = 3.79988368\n",
      "Iteration 290, loss = 3.79923988\n",
      "Iteration 291, loss = 3.79859986\n",
      "Iteration 292, loss = 3.79796356\n",
      "Iteration 293, loss = 3.79733093\n",
      "Iteration 294, loss = 3.79670193\n",
      "Iteration 295, loss = 3.79607651\n",
      "Iteration 296, loss = 3.79545461\n",
      "Iteration 297, loss = 3.79483618\n",
      "Iteration 298, loss = 3.79422118\n",
      "Iteration 299, loss = 3.79360956\n",
      "Iteration 300, loss = 3.79300127\n",
      "Iteration 301, loss = 3.79239626\n",
      "Iteration 302, loss = 3.79179449\n",
      "Iteration 303, loss = 3.79119590\n",
      "Iteration 304, loss = 3.79060045\n",
      "Iteration 305, loss = 3.79000810\n",
      "Iteration 306, loss = 3.78941880\n",
      "Iteration 307, loss = 3.78883250\n",
      "Iteration 308, loss = 3.78824915\n",
      "Iteration 309, loss = 3.78766872\n",
      "Iteration 310, loss = 3.78709116\n",
      "Iteration 311, loss = 3.78651642\n",
      "Iteration 312, loss = 3.78594446\n",
      "Iteration 313, loss = 3.78537525\n",
      "Iteration 314, loss = 3.78480873\n",
      "Iteration 315, loss = 3.78424486\n",
      "Iteration 316, loss = 3.78368361\n",
      "Iteration 317, loss = 3.78312493\n",
      "Iteration 318, loss = 3.78256878\n",
      "Iteration 319, loss = 3.78201513\n",
      "Iteration 320, loss = 3.78146393\n",
      "Iteration 321, loss = 3.78091514\n",
      "Iteration 322, loss = 3.78036873\n",
      "Iteration 323, loss = 3.77982465\n",
      "Iteration 324, loss = 3.77928288\n",
      "Iteration 325, loss = 3.77874337\n",
      "Iteration 326, loss = 3.77820609\n",
      "Iteration 327, loss = 3.77767100\n",
      "Iteration 328, loss = 3.77713806\n",
      "Iteration 329, loss = 3.77660725\n",
      "Iteration 330, loss = 3.77607852\n",
      "Iteration 331, loss = 3.77555185\n",
      "Iteration 332, loss = 3.77502719\n",
      "Iteration 333, loss = 3.77450452\n",
      "Iteration 334, loss = 3.77398381\n",
      "Iteration 335, loss = 3.77346502\n",
      "Iteration 336, loss = 3.77294812\n",
      "Iteration 337, loss = 3.77243308\n",
      "Iteration 338, loss = 3.77191988\n",
      "Iteration 339, loss = 3.77140847\n",
      "Iteration 340, loss = 3.77089883\n",
      "Iteration 341, loss = 3.77039093\n",
      "Iteration 342, loss = 3.76988475\n",
      "Iteration 343, loss = 3.76938026\n",
      "Iteration 344, loss = 3.76887742\n",
      "Iteration 345, loss = 3.76837621\n",
      "Iteration 346, loss = 3.76787660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 347, loss = 3.76737858\n",
      "Iteration 348, loss = 3.76688210\n",
      "Iteration 349, loss = 3.76638716\n",
      "Iteration 350, loss = 3.76589371\n",
      "Iteration 351, loss = 3.76540175\n",
      "Iteration 352, loss = 3.76491123\n",
      "Iteration 353, loss = 3.76442215\n",
      "Iteration 354, loss = 3.76393447\n",
      "Iteration 355, loss = 3.76344818\n",
      "Iteration 356, loss = 3.76296325\n",
      "Iteration 357, loss = 3.76247966\n",
      "Iteration 358, loss = 3.76199739\n",
      "Iteration 359, loss = 3.76151642\n",
      "Iteration 360, loss = 3.76103673\n",
      "Iteration 361, loss = 3.76055829\n",
      "Iteration 362, loss = 3.76008108\n",
      "Iteration 363, loss = 3.75960510\n",
      "Iteration 364, loss = 3.75913031\n",
      "Iteration 365, loss = 3.75865671\n",
      "Iteration 366, loss = 3.75818426\n",
      "Iteration 367, loss = 3.75771295\n",
      "Iteration 368, loss = 3.75724278\n",
      "Iteration 369, loss = 3.75677370\n",
      "Iteration 370, loss = 3.75630572\n",
      "Iteration 371, loss = 3.75583881\n",
      "Iteration 372, loss = 3.75537296\n",
      "Iteration 373, loss = 3.75490816\n",
      "Iteration 374, loss = 3.75444437\n",
      "Iteration 375, loss = 3.75398160\n",
      "Iteration 376, loss = 3.75351982\n",
      "Iteration 377, loss = 3.75305902\n",
      "Iteration 378, loss = 3.75259919\n",
      "Iteration 379, loss = 3.75214031\n",
      "Iteration 380, loss = 3.75168237\n",
      "Iteration 381, loss = 3.75122535\n",
      "Iteration 382, loss = 3.75076924\n",
      "Iteration 383, loss = 3.75031403\n",
      "Iteration 384, loss = 3.74985970\n",
      "Iteration 385, loss = 3.74940624\n",
      "Iteration 386, loss = 3.74895365\n",
      "Iteration 387, loss = 3.74850190\n",
      "Iteration 388, loss = 3.74805099\n",
      "Iteration 389, loss = 3.74760091\n",
      "Iteration 390, loss = 3.74715163\n",
      "Iteration 391, loss = 3.74670316\n",
      "Iteration 392, loss = 3.74625549\n",
      "Iteration 393, loss = 3.74580859\n",
      "Iteration 394, loss = 3.74536246\n",
      "Iteration 395, loss = 3.74491710\n",
      "Iteration 396, loss = 3.74447248\n",
      "Iteration 397, loss = 3.74402861\n",
      "Iteration 398, loss = 3.74358547\n",
      "Iteration 399, loss = 3.74314305\n",
      "Iteration 400, loss = 3.74270134\n",
      "Iteration 401, loss = 3.74226034\n",
      "Iteration 402, loss = 3.74182004\n",
      "Iteration 403, loss = 3.74138042\n",
      "Iteration 404, loss = 3.74094148\n",
      "Iteration 405, loss = 3.74050322\n",
      "Iteration 406, loss = 3.74006562\n",
      "Iteration 407, loss = 3.73962867\n",
      "Iteration 408, loss = 3.73919237\n",
      "Iteration 409, loss = 3.73875672\n",
      "Iteration 410, loss = 3.73832170\n",
      "Iteration 411, loss = 3.73788730\n",
      "Iteration 412, loss = 3.73745353\n",
      "Iteration 413, loss = 3.73702037\n",
      "Iteration 414, loss = 3.73658782\n",
      "Iteration 415, loss = 3.73615586\n",
      "Iteration 416, loss = 3.73572451\n",
      "Iteration 417, loss = 3.73529374\n",
      "Iteration 418, loss = 3.73486356\n",
      "Iteration 419, loss = 3.73443395\n",
      "Iteration 420, loss = 3.73400491\n",
      "Iteration 421, loss = 3.73357644\n",
      "Iteration 422, loss = 3.73314853\n",
      "Iteration 423, loss = 3.73272118\n",
      "Iteration 424, loss = 3.73229438\n",
      "Iteration 425, loss = 3.73186812\n",
      "Iteration 426, loss = 3.73144241\n",
      "Iteration 427, loss = 3.73101723\n",
      "Iteration 428, loss = 3.73059258\n",
      "Iteration 429, loss = 3.73016846\n",
      "Iteration 430, loss = 3.72974486\n",
      "Iteration 431, loss = 3.72932178\n",
      "Iteration 432, loss = 3.72889922\n",
      "Iteration 433, loss = 3.72847717\n",
      "Iteration 434, loss = 3.72805562\n",
      "Iteration 435, loss = 3.72763458\n",
      "Iteration 436, loss = 3.72721404\n",
      "Iteration 437, loss = 3.72679399\n",
      "Iteration 438, loss = 3.72637443\n",
      "Iteration 439, loss = 3.72595537\n",
      "Iteration 440, loss = 3.72553679\n",
      "Iteration 441, loss = 3.72511869\n",
      "Iteration 442, loss = 3.72470107\n",
      "Iteration 443, loss = 3.72428393\n",
      "Iteration 444, loss = 3.72386726\n",
      "Iteration 445, loss = 3.72345107\n",
      "Iteration 446, loss = 3.72303534\n",
      "Iteration 447, loss = 3.72262007\n",
      "Iteration 448, loss = 3.72220527\n",
      "Iteration 449, loss = 3.72179093\n",
      "Iteration 450, loss = 3.72137705\n",
      "Iteration 451, loss = 3.72096362\n",
      "Iteration 452, loss = 3.72055064\n",
      "Iteration 453, loss = 3.72013812\n",
      "Iteration 454, loss = 3.71972604\n",
      "Iteration 455, loss = 3.71931441\n",
      "Iteration 456, loss = 3.71890323\n",
      "Iteration 457, loss = 3.71849248\n",
      "Iteration 458, loss = 3.71808218\n",
      "Iteration 459, loss = 3.71767232\n",
      "Iteration 460, loss = 3.71726289\n",
      "Iteration 461, loss = 3.71685390\n",
      "Iteration 462, loss = 3.71644535\n",
      "Iteration 463, loss = 3.71603722\n",
      "Iteration 464, loss = 3.71562953\n",
      "Iteration 465, loss = 3.71522226\n",
      "Iteration 466, loss = 3.71481542\n",
      "Iteration 467, loss = 3.71440901\n",
      "Iteration 468, loss = 3.71400302\n",
      "Iteration 469, loss = 3.71359746\n",
      "Iteration 470, loss = 3.71319232\n",
      "Iteration 471, loss = 3.71278760\n",
      "Iteration 472, loss = 3.71238330\n",
      "Iteration 473, loss = 3.71197942\n",
      "Iteration 474, loss = 3.71157595\n",
      "Iteration 475, loss = 3.71117290\n",
      "Iteration 476, loss = 3.71077027\n",
      "Iteration 477, loss = 3.71036805\n",
      "Iteration 478, loss = 3.70996625\n",
      "Iteration 479, loss = 3.70956486\n",
      "Iteration 480, loss = 3.70916388\n",
      "Iteration 481, loss = 3.70876331\n",
      "Iteration 482, loss = 3.70836316\n",
      "Iteration 483, loss = 3.70796341\n",
      "Iteration 484, loss = 3.70756407\n",
      "Iteration 485, loss = 3.70716514\n",
      "Iteration 486, loss = 3.70676662\n",
      "Iteration 487, loss = 3.70636850\n",
      "Iteration 488, loss = 3.70597079\n",
      "Iteration 489, loss = 3.70557349\n",
      "Iteration 490, loss = 3.70517659\n",
      "Iteration 491, loss = 3.70478010\n",
      "Iteration 492, loss = 3.70438401\n",
      "Iteration 493, loss = 3.70398832\n",
      "Iteration 494, loss = 3.70359304\n",
      "Iteration 495, loss = 3.70319816\n",
      "Iteration 496, loss = 3.70280369\n",
      "Iteration 497, loss = 3.70240961\n",
      "Iteration 498, loss = 3.70201594\n",
      "Iteration 499, loss = 3.70162267\n",
      "Iteration 500, loss = 3.70122980\n",
      "Iteration 501, loss = 3.70083733\n",
      "Iteration 502, loss = 3.70044527\n",
      "Iteration 503, loss = 3.70005360\n",
      "Iteration 504, loss = 3.69966233\n",
      "Iteration 505, loss = 3.69927146\n",
      "Iteration 506, loss = 3.69888100\n",
      "Iteration 507, loss = 3.69849093\n",
      "Iteration 508, loss = 3.69810126\n",
      "Iteration 509, loss = 3.69771199\n",
      "Iteration 510, loss = 3.69732312\n",
      "Iteration 511, loss = 3.69693465\n",
      "Iteration 512, loss = 3.69654658\n",
      "Iteration 513, loss = 3.69615891\n",
      "Iteration 514, loss = 3.69577163\n",
      "Iteration 515, loss = 3.69538475\n",
      "Iteration 516, loss = 3.69499828\n",
      "Iteration 517, loss = 3.69461220\n",
      "Iteration 518, loss = 3.69422651\n",
      "Iteration 519, loss = 3.69384123\n",
      "Iteration 520, loss = 3.69345635\n",
      "Iteration 521, loss = 3.69307186\n",
      "Iteration 522, loss = 3.69268777\n",
      "Iteration 523, loss = 3.69230408\n",
      "Iteration 524, loss = 3.69192078\n",
      "Iteration 525, loss = 3.69153789\n",
      "Iteration 526, loss = 3.69115539\n",
      "Iteration 527, loss = 3.69077329\n",
      "Iteration 528, loss = 3.69039159\n",
      "Iteration 529, loss = 3.69001029\n",
      "Iteration 530, loss = 3.68962938\n",
      "Iteration 531, loss = 3.68924888\n",
      "Iteration 532, loss = 3.68886877\n",
      "Iteration 533, loss = 3.68848906\n",
      "Iteration 534, loss = 3.68810974\n",
      "Iteration 535, loss = 3.68773083\n",
      "Iteration 536, loss = 3.68735231\n",
      "Iteration 537, loss = 3.68697419\n",
      "Iteration 538, loss = 3.68659647\n",
      "Iteration 539, loss = 3.68621914\n",
      "Iteration 540, loss = 3.68584222\n",
      "Iteration 541, loss = 3.68546569\n",
      "Iteration 542, loss = 3.68508956\n",
      "Iteration 543, loss = 3.68471383\n",
      "Iteration 544, loss = 3.68433850\n",
      "Iteration 545, loss = 3.68396357\n",
      "Iteration 546, loss = 3.68358903\n",
      "Iteration 547, loss = 3.68321489\n",
      "Iteration 548, loss = 3.68284115\n",
      "Iteration 549, loss = 3.68246781\n",
      "Iteration 550, loss = 3.68209487\n",
      "Iteration 551, loss = 3.68172232\n",
      "Iteration 552, loss = 3.68135018\n",
      "Iteration 553, loss = 3.68097843\n",
      "Iteration 554, loss = 3.68060708\n",
      "Iteration 555, loss = 3.68023613\n",
      "Iteration 556, loss = 3.67986557\n",
      "Iteration 557, loss = 3.67949542\n",
      "Iteration 558, loss = 3.67912566\n",
      "Iteration 559, loss = 3.67875630\n",
      "Iteration 560, loss = 3.67838734\n",
      "Iteration 561, loss = 3.67801877\n",
      "Iteration 562, loss = 3.67765061\n",
      "Iteration 563, loss = 3.67728284\n",
      "Iteration 564, loss = 3.67691547\n",
      "Iteration 565, loss = 3.67654850\n",
      "Iteration 566, loss = 3.67618193\n",
      "Iteration 567, loss = 3.67581575\n",
      "Iteration 568, loss = 3.67544998\n",
      "Iteration 569, loss = 3.67508459\n",
      "Iteration 570, loss = 3.67471961\n",
      "Iteration 571, loss = 3.67435503\n",
      "Iteration 572, loss = 3.67399084\n",
      "Iteration 573, loss = 3.67362705\n",
      "Iteration 574, loss = 3.67326365\n",
      "Iteration 575, loss = 3.67290066\n",
      "Iteration 576, loss = 3.67253806\n",
      "Iteration 577, loss = 3.67217585\n",
      "Iteration 578, loss = 3.67181405\n",
      "Iteration 579, loss = 3.67145264\n",
      "Iteration 580, loss = 3.67109162\n",
      "Iteration 581, loss = 3.67073101\n",
      "Iteration 582, loss = 3.67037079\n",
      "Iteration 583, loss = 3.67001096\n",
      "Iteration 584, loss = 3.66965153\n",
      "Iteration 585, loss = 3.66929250\n",
      "Iteration 586, loss = 3.66893386\n",
      "Iteration 587, loss = 3.66857561\n",
      "Iteration 588, loss = 3.66821776\n",
      "Iteration 589, loss = 3.66786031\n",
      "Iteration 590, loss = 3.66750325\n",
      "Iteration 591, loss = 3.66714658\n",
      "Iteration 592, loss = 3.66679031\n",
      "Iteration 593, loss = 3.66643443\n",
      "Iteration 594, loss = 3.66607895\n",
      "Iteration 595, loss = 3.66572386\n",
      "Iteration 596, loss = 3.66536916\n",
      "Iteration 597, loss = 3.66501485\n",
      "Iteration 598, loss = 3.66466094\n",
      "Iteration 599, loss = 3.66430742\n",
      "Iteration 600, loss = 3.66395429\n",
      "Iteration 601, loss = 3.66360155\n",
      "Iteration 602, loss = 3.66324920\n",
      "Iteration 603, loss = 3.66289725\n",
      "Iteration 604, loss = 3.66254568\n",
      "Iteration 605, loss = 3.66219451\n",
      "Iteration 606, loss = 3.66184372\n",
      "Iteration 607, loss = 3.66149333\n",
      "Iteration 608, loss = 3.66114332\n",
      "Iteration 609, loss = 3.66079370\n",
      "Iteration 610, loss = 3.66044447\n",
      "Iteration 611, loss = 3.66009563\n",
      "Iteration 612, loss = 3.65974718\n",
      "Iteration 613, loss = 3.65939911\n",
      "Iteration 614, loss = 3.65905143\n",
      "Iteration 615, loss = 3.65870414\n",
      "Iteration 616, loss = 3.65835723\n",
      "Iteration 617, loss = 3.65801071\n",
      "Iteration 618, loss = 3.65766457\n",
      "Iteration 619, loss = 3.65731882\n",
      "Iteration 620, loss = 3.65697345\n",
      "Iteration 621, loss = 3.65662847\n",
      "Iteration 622, loss = 3.65628387\n",
      "Iteration 623, loss = 3.65593965\n",
      "Iteration 624, loss = 3.65559582\n",
      "Iteration 625, loss = 3.65525236\n",
      "Iteration 626, loss = 3.65490929\n",
      "Iteration 627, loss = 3.65456660\n",
      "Iteration 628, loss = 3.65422429\n",
      "Iteration 629, loss = 3.65388236\n",
      "Iteration 630, loss = 3.65354081\n",
      "Iteration 631, loss = 3.65319964\n",
      "Iteration 632, loss = 3.65285885\n",
      "Iteration 633, loss = 3.65251844\n",
      "Iteration 634, loss = 3.65217840\n",
      "Iteration 635, loss = 3.65183874\n",
      "Iteration 636, loss = 3.65149945\n",
      "Iteration 637, loss = 3.65116055\n",
      "Iteration 638, loss = 3.65082201\n",
      "Iteration 639, loss = 3.65048385\n",
      "Iteration 640, loss = 3.65014607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 641, loss = 3.64980866\n",
      "Iteration 642, loss = 3.64947162\n",
      "Iteration 643, loss = 3.64913496\n",
      "Iteration 644, loss = 3.64879866\n",
      "Iteration 645, loss = 3.64846274\n",
      "Iteration 646, loss = 3.64812719\n",
      "Iteration 647, loss = 3.64779201\n",
      "Iteration 648, loss = 3.64745719\n",
      "Iteration 649, loss = 3.64712275\n",
      "Iteration 650, loss = 3.64678867\n",
      "Iteration 651, loss = 3.64645497\n",
      "Iteration 652, loss = 3.64612162\n",
      "Iteration 653, loss = 3.64578865\n",
      "Iteration 654, loss = 3.64545604\n",
      "Iteration 655, loss = 3.64512379\n",
      "Iteration 656, loss = 3.64479191\n",
      "Iteration 657, loss = 3.64446040\n",
      "Iteration 658, loss = 3.64412924\n",
      "Iteration 659, loss = 3.64379845\n",
      "Iteration 660, loss = 3.64346802\n",
      "Iteration 661, loss = 3.64313796\n",
      "Iteration 662, loss = 3.64280825\n",
      "Iteration 663, loss = 3.64247890\n",
      "Iteration 664, loss = 3.64214991\n",
      "Iteration 665, loss = 3.64182128\n",
      "Iteration 666, loss = 3.64149301\n",
      "Iteration 667, loss = 3.64116509\n",
      "Iteration 668, loss = 3.64083753\n",
      "Iteration 669, loss = 3.64051033\n",
      "Iteration 670, loss = 3.64018348\n",
      "Iteration 671, loss = 3.63985698\n",
      "Iteration 672, loss = 3.63953084\n",
      "Iteration 673, loss = 3.63920505\n",
      "Iteration 674, loss = 3.63887962\n",
      "Iteration 675, loss = 3.63855453\n",
      "Iteration 676, loss = 3.63822980\n",
      "Iteration 677, loss = 3.63790542\n",
      "Iteration 678, loss = 3.63758138\n",
      "Iteration 679, loss = 3.63725770\n",
      "Iteration 680, loss = 3.63693436\n",
      "Iteration 681, loss = 3.63661137\n",
      "Iteration 682, loss = 3.63628872\n",
      "Iteration 683, loss = 3.63596642\n",
      "Iteration 684, loss = 3.63564447\n",
      "Iteration 685, loss = 3.63532286\n",
      "Iteration 686, loss = 3.63500160\n",
      "Iteration 687, loss = 3.63468067\n",
      "Iteration 688, loss = 3.63436009\n",
      "Iteration 689, loss = 3.63403986\n",
      "Iteration 690, loss = 3.63371996\n",
      "Iteration 691, loss = 3.63340040\n",
      "Iteration 692, loss = 3.63308118\n",
      "Iteration 693, loss = 3.63276230\n",
      "Iteration 694, loss = 3.63244376\n",
      "Iteration 695, loss = 3.63212555\n",
      "Iteration 696, loss = 3.63180768\n",
      "Iteration 697, loss = 3.63149015\n",
      "Iteration 698, loss = 3.63117295\n",
      "Iteration 699, loss = 3.63085609\n",
      "Iteration 700, loss = 3.63053956\n",
      "Iteration 701, loss = 3.63022336\n",
      "Iteration 702, loss = 3.62990749\n",
      "Iteration 703, loss = 3.62959196\n",
      "Iteration 704, loss = 3.62927675\n",
      "Iteration 705, loss = 3.62896188\n",
      "Iteration 706, loss = 3.62864733\n",
      "Iteration 707, loss = 3.62833312\n",
      "Iteration 708, loss = 3.62801923\n",
      "Iteration 709, loss = 3.62770566\n",
      "Iteration 710, loss = 3.62739243\n",
      "Iteration 711, loss = 3.62707952\n",
      "Iteration 712, loss = 3.62676693\n",
      "Iteration 713, loss = 3.62645467\n",
      "Iteration 714, loss = 3.62614273\n",
      "Iteration 715, loss = 3.62583111\n",
      "Iteration 716, loss = 3.62551982\n",
      "Iteration 717, loss = 3.62520884\n",
      "Iteration 718, loss = 3.62489819\n",
      "Iteration 719, loss = 3.62458786\n",
      "Iteration 720, loss = 3.62427784\n",
      "Iteration 721, loss = 3.62396814\n",
      "Iteration 722, loss = 3.62365876\n",
      "Iteration 723, loss = 3.62334970\n",
      "Iteration 724, loss = 3.62304096\n",
      "Iteration 725, loss = 3.62273253\n",
      "Iteration 726, loss = 3.62242441\n",
      "Iteration 727, loss = 3.62211661\n",
      "Iteration 728, loss = 3.62180912\n",
      "Iteration 729, loss = 3.62150194\n",
      "Iteration 730, loss = 3.62119508\n",
      "Iteration 731, loss = 3.62088852\n",
      "Iteration 732, loss = 3.62058228\n",
      "Iteration 733, loss = 3.62027634\n",
      "Iteration 734, loss = 3.61997072\n",
      "Iteration 735, loss = 3.61966540\n",
      "Iteration 736, loss = 3.61936039\n",
      "Iteration 737, loss = 3.61905569\n",
      "Iteration 738, loss = 3.61875130\n",
      "Iteration 739, loss = 3.61844721\n",
      "Iteration 740, loss = 3.61814342\n",
      "Iteration 741, loss = 3.61783994\n",
      "Iteration 742, loss = 3.61753676\n",
      "Iteration 743, loss = 3.61723389\n",
      "Iteration 744, loss = 3.61693132\n",
      "Iteration 745, loss = 3.61662905\n",
      "Iteration 746, loss = 3.61632708\n",
      "Iteration 747, loss = 3.61602541\n",
      "Iteration 748, loss = 3.61572404\n",
      "Iteration 749, loss = 3.61542296\n",
      "Iteration 750, loss = 3.61512219\n",
      "Iteration 751, loss = 3.61482171\n",
      "Iteration 752, loss = 3.61452153\n",
      "Iteration 753, loss = 3.61422165\n",
      "Iteration 754, loss = 3.61392206\n",
      "Iteration 755, loss = 3.61362277\n",
      "Iteration 756, loss = 3.61332377\n",
      "Iteration 757, loss = 3.61302507\n",
      "Iteration 758, loss = 3.61272666\n",
      "Iteration 759, loss = 3.61242854\n",
      "Iteration 760, loss = 3.61213071\n",
      "Iteration 761, loss = 3.61183317\n",
      "Iteration 762, loss = 3.61153593\n",
      "Iteration 763, loss = 3.61123897\n",
      "Iteration 764, loss = 3.61094230\n",
      "Iteration 765, loss = 3.61064592\n",
      "Iteration 766, loss = 3.61034983\n",
      "Iteration 767, loss = 3.61005403\n",
      "Iteration 768, loss = 3.60975851\n",
      "Iteration 769, loss = 3.60946328\n",
      "Iteration 770, loss = 3.60916833\n",
      "Iteration 771, loss = 3.60887367\n",
      "Iteration 772, loss = 3.60857930\n",
      "Iteration 773, loss = 3.60828520\n",
      "Iteration 774, loss = 3.60799139\n",
      "Iteration 775, loss = 3.60769787\n",
      "Iteration 776, loss = 3.60740462\n",
      "Iteration 777, loss = 3.60711166\n",
      "Iteration 778, loss = 3.60681897\n",
      "Iteration 779, loss = 3.60652657\n",
      "Iteration 780, loss = 3.60623445\n",
      "Iteration 781, loss = 3.60594260\n",
      "Iteration 782, loss = 3.60565104\n",
      "Iteration 783, loss = 3.60535975\n",
      "Iteration 784, loss = 3.60506874\n",
      "Iteration 785, loss = 3.60477800\n",
      "Iteration 786, loss = 3.60448754\n",
      "Iteration 787, loss = 3.60419736\n",
      "Iteration 788, loss = 3.60390745\n",
      "Iteration 789, loss = 3.60361782\n",
      "Iteration 790, loss = 3.60332846\n",
      "Iteration 791, loss = 3.60303937\n",
      "Iteration 792, loss = 3.60275056\n",
      "Iteration 793, loss = 3.60246201\n",
      "Iteration 794, loss = 3.60217374\n",
      "Iteration 795, loss = 3.60188575\n",
      "Iteration 796, loss = 3.60159802\n",
      "Iteration 797, loss = 3.60131056\n",
      "Iteration 798, loss = 3.60102337\n",
      "Iteration 799, loss = 3.60073645\n",
      "Iteration 800, loss = 3.60044980\n",
      "Iteration 801, loss = 3.60016342\n",
      "Iteration 802, loss = 3.59987730\n",
      "Iteration 803, loss = 3.59959145\n",
      "Iteration 804, loss = 3.59930587\n",
      "Iteration 805, loss = 3.59902056\n",
      "Iteration 806, loss = 3.59873551\n",
      "Iteration 807, loss = 3.59845072\n",
      "Iteration 808, loss = 3.59816620\n",
      "Iteration 809, loss = 3.59788194\n",
      "Iteration 810, loss = 3.59759795\n",
      "Iteration 811, loss = 3.59731422\n",
      "Iteration 812, loss = 3.59703075\n",
      "Iteration 813, loss = 3.59674754\n",
      "Iteration 814, loss = 3.59646459\n",
      "Iteration 815, loss = 3.59618191\n",
      "Iteration 816, loss = 3.59589949\n",
      "Iteration 817, loss = 3.59561732\n",
      "Iteration 818, loss = 3.59533542\n",
      "Iteration 819, loss = 3.59505377\n",
      "Iteration 820, loss = 3.59477239\n",
      "Iteration 821, loss = 3.59449126\n",
      "Iteration 822, loss = 3.59421039\n",
      "Iteration 823, loss = 3.59392977\n",
      "Iteration 824, loss = 3.59364942\n",
      "Iteration 825, loss = 3.59336931\n",
      "Iteration 826, loss = 3.59308947\n",
      "Iteration 827, loss = 3.59280988\n",
      "Iteration 828, loss = 3.59253055\n",
      "Iteration 829, loss = 3.59225147\n",
      "Iteration 830, loss = 3.59197264\n",
      "Iteration 831, loss = 3.59169407\n",
      "Iteration 832, loss = 3.59141575\n",
      "Iteration 833, loss = 3.59113768\n",
      "Iteration 834, loss = 3.59085987\n",
      "Iteration 835, loss = 3.59058230\n",
      "Iteration 836, loss = 3.59030499\n",
      "Iteration 837, loss = 3.59002793\n",
      "Iteration 838, loss = 3.58975112\n",
      "Iteration 839, loss = 3.58947456\n",
      "Iteration 840, loss = 3.58919825\n",
      "Iteration 841, loss = 3.58892219\n",
      "Iteration 842, loss = 3.58864638\n",
      "Iteration 843, loss = 3.58837082\n",
      "Iteration 844, loss = 3.58809550\n",
      "Iteration 845, loss = 3.58782043\n",
      "Iteration 846, loss = 3.58754561\n",
      "Iteration 847, loss = 3.58727104\n",
      "Iteration 848, loss = 3.58699671\n",
      "Iteration 849, loss = 3.58672263\n",
      "Iteration 850, loss = 3.58644880\n",
      "Iteration 851, loss = 3.58617521\n",
      "Iteration 852, loss = 3.58590186\n",
      "Iteration 853, loss = 3.58562876\n",
      "Iteration 854, loss = 3.58535590\n",
      "Iteration 855, loss = 3.58508329\n",
      "Iteration 856, loss = 3.58481092\n",
      "Iteration 857, loss = 3.58453879\n",
      "Iteration 858, loss = 3.58426690\n",
      "Iteration 859, loss = 3.58399526\n",
      "Iteration 860, loss = 3.58372386\n",
      "Iteration 861, loss = 3.58345270\n",
      "Iteration 862, loss = 3.58318178\n",
      "Iteration 863, loss = 3.58291110\n",
      "Iteration 864, loss = 3.58264066\n",
      "Iteration 865, loss = 3.58237046\n",
      "Iteration 866, loss = 3.58210050\n",
      "Iteration 867, loss = 3.58183078\n",
      "Iteration 868, loss = 3.58156130\n",
      "Iteration 869, loss = 3.58129206\n",
      "Iteration 870, loss = 3.58102305\n",
      "Iteration 871, loss = 3.58075429\n",
      "Iteration 872, loss = 3.58048576\n",
      "Iteration 873, loss = 3.58021746\n",
      "Iteration 874, loss = 3.57994941\n",
      "Iteration 875, loss = 3.57968159\n",
      "Iteration 876, loss = 3.57941400\n",
      "Iteration 877, loss = 3.57914665\n",
      "Iteration 878, loss = 3.57887954\n",
      "Iteration 879, loss = 3.57861266\n",
      "Iteration 880, loss = 3.57834601\n",
      "Iteration 881, loss = 3.57807960\n",
      "Iteration 882, loss = 3.57781342\n",
      "Iteration 883, loss = 3.57754748\n",
      "Iteration 884, loss = 3.57728177\n",
      "Iteration 885, loss = 3.57701629\n",
      "Iteration 886, loss = 3.57675104\n",
      "Iteration 887, loss = 3.57648603\n",
      "Iteration 888, loss = 3.57622125\n",
      "Iteration 889, loss = 3.57595670\n",
      "Iteration 890, loss = 3.57569238\n",
      "Iteration 891, loss = 3.57542829\n",
      "Iteration 892, loss = 3.57516443\n",
      "Iteration 893, loss = 3.57490080\n",
      "Iteration 894, loss = 3.57463740\n",
      "Iteration 895, loss = 3.57437423\n",
      "Iteration 896, loss = 3.57411129\n",
      "Iteration 897, loss = 3.57384858\n",
      "Iteration 898, loss = 3.57358609\n",
      "Iteration 899, loss = 3.57332384\n",
      "Iteration 900, loss = 3.57306181\n",
      "Iteration 901, loss = 3.57280001\n",
      "Iteration 902, loss = 3.57253843\n",
      "Iteration 903, loss = 3.57227709\n",
      "Iteration 904, loss = 3.57201597\n",
      "Iteration 905, loss = 3.57175507\n",
      "Iteration 906, loss = 3.57149440\n",
      "Iteration 907, loss = 3.57123396\n",
      "Iteration 908, loss = 3.57097374\n",
      "Iteration 909, loss = 3.57071375\n",
      "Iteration 910, loss = 3.57045398\n",
      "Iteration 911, loss = 3.57019444\n",
      "Iteration 912, loss = 3.56993512\n",
      "Iteration 913, loss = 3.56967602\n",
      "Iteration 914, loss = 3.56941715\n",
      "Iteration 915, loss = 3.56915850\n",
      "Iteration 916, loss = 3.56890007\n",
      "Iteration 917, loss = 3.56864187\n",
      "Iteration 918, loss = 3.56838389\n",
      "Iteration 919, loss = 3.56812613\n",
      "Iteration 920, loss = 3.56786859\n",
      "Iteration 921, loss = 3.56761127\n",
      "Iteration 922, loss = 3.56735417\n",
      "Iteration 923, loss = 3.56709730\n",
      "Iteration 924, loss = 3.56684064\n",
      "Iteration 925, loss = 3.56658420\n",
      "Iteration 926, loss = 3.56632799\n",
      "Iteration 927, loss = 3.56607199\n",
      "Iteration 928, loss = 3.56581621\n",
      "Iteration 929, loss = 3.56556065\n",
      "Iteration 930, loss = 3.56530531\n",
      "Iteration 931, loss = 3.56505019\n",
      "Iteration 932, loss = 3.56479529\n",
      "Iteration 933, loss = 3.56454060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 934, loss = 3.56428613\n",
      "Iteration 935, loss = 3.56403188\n",
      "Iteration 936, loss = 3.56377785\n",
      "Iteration 937, loss = 3.56352403\n",
      "Iteration 938, loss = 3.56327043\n",
      "Iteration 939, loss = 3.56301704\n",
      "Iteration 940, loss = 3.56276387\n",
      "Iteration 941, loss = 3.56251092\n",
      "Iteration 942, loss = 3.56225818\n",
      "Iteration 943, loss = 3.56200565\n",
      "Iteration 944, loss = 3.56175334\n",
      "Iteration 945, loss = 3.56150124\n",
      "Iteration 946, loss = 3.56124936\n",
      "Iteration 947, loss = 3.56099769\n",
      "Iteration 948, loss = 3.56074624\n",
      "Iteration 949, loss = 3.56049499\n",
      "Iteration 950, loss = 3.56024397\n",
      "Iteration 951, loss = 3.55999315\n",
      "Iteration 952, loss = 3.55974254\n",
      "Iteration 953, loss = 3.55949215\n",
      "Iteration 954, loss = 3.55924197\n",
      "Iteration 955, loss = 3.55899200\n",
      "Iteration 956, loss = 3.55874224\n",
      "Iteration 957, loss = 3.55849270\n",
      "Iteration 958, loss = 3.55824336\n",
      "Iteration 959, loss = 3.55799423\n",
      "Iteration 960, loss = 3.55774532\n",
      "Iteration 961, loss = 3.55749661\n",
      "Iteration 962, loss = 3.55724812\n",
      "Iteration 963, loss = 3.55699983\n",
      "Iteration 964, loss = 3.55675175\n",
      "Iteration 965, loss = 3.55650388\n",
      "Iteration 966, loss = 3.55625622\n",
      "Iteration 967, loss = 3.55600877\n",
      "Iteration 968, loss = 3.55576152\n",
      "Iteration 969, loss = 3.55551448\n",
      "Iteration 970, loss = 3.55526765\n",
      "Iteration 971, loss = 3.55502103\n",
      "Iteration 972, loss = 3.55477461\n",
      "Iteration 973, loss = 3.55452840\n",
      "Iteration 974, loss = 3.55428240\n",
      "Iteration 975, loss = 3.55403660\n",
      "Iteration 976, loss = 3.55379101\n",
      "Iteration 977, loss = 3.55354562\n",
      "Iteration 978, loss = 3.55330044\n",
      "Iteration 979, loss = 3.55305547\n",
      "Iteration 980, loss = 3.55281069\n",
      "Iteration 981, loss = 3.55256613\n",
      "Iteration 982, loss = 3.55232176\n",
      "Iteration 983, loss = 3.55207761\n",
      "Iteration 984, loss = 3.55183365\n",
      "Iteration 985, loss = 3.55158990\n",
      "Iteration 986, loss = 3.55134635\n",
      "Iteration 987, loss = 3.55110300\n",
      "Iteration 988, loss = 3.55085986\n",
      "Iteration 989, loss = 3.55061692\n",
      "Iteration 990, loss = 3.55037418\n",
      "Iteration 991, loss = 3.55013164\n",
      "Iteration 992, loss = 3.54988930\n",
      "Iteration 993, loss = 3.54964717\n",
      "Iteration 994, loss = 3.54940523\n",
      "Iteration 995, loss = 3.54916350\n",
      "Iteration 996, loss = 3.54892197\n",
      "Iteration 997, loss = 3.54868063\n",
      "Iteration 998, loss = 3.54843950\n",
      "Iteration 999, loss = 3.54819857\n",
      "Iteration 1000, loss = 3.54795783\n",
      "Iteration 1001, loss = 3.54771730\n",
      "Iteration 1002, loss = 3.54747696\n",
      "Iteration 1003, loss = 3.54723683\n",
      "Iteration 1004, loss = 3.54699689\n",
      "Iteration 1005, loss = 3.54675715\n",
      "Iteration 1006, loss = 3.54651760\n",
      "Iteration 1007, loss = 3.54627826\n",
      "Iteration 1008, loss = 3.54603911\n",
      "Iteration 1009, loss = 3.54580016\n",
      "Iteration 1010, loss = 3.54556140\n",
      "Iteration 1011, loss = 3.54532285\n",
      "Iteration 1012, loss = 3.54508448\n",
      "Iteration 1013, loss = 3.54484632\n",
      "Iteration 1014, loss = 3.54460835\n",
      "Iteration 1015, loss = 3.54437057\n",
      "Iteration 1016, loss = 3.54413299\n",
      "Iteration 1017, loss = 3.54389561\n",
      "Iteration 1018, loss = 3.54365842\n",
      "Iteration 1019, loss = 3.54342142\n",
      "Iteration 1020, loss = 3.54318462\n",
      "Iteration 1021, loss = 3.54294801\n",
      "Iteration 1022, loss = 3.54271160\n",
      "Iteration 1023, loss = 3.54247538\n",
      "Iteration 1024, loss = 3.54223935\n",
      "Iteration 1025, loss = 3.54200352\n",
      "Iteration 1026, loss = 3.54176788\n",
      "Iteration 1027, loss = 3.54153243\n",
      "Iteration 1028, loss = 3.54129717\n",
      "Iteration 1029, loss = 3.54106211\n",
      "Iteration 1030, loss = 3.54082723\n",
      "Iteration 1031, loss = 3.54059255\n",
      "Iteration 1032, loss = 3.54035806\n",
      "Iteration 1033, loss = 3.54012376\n",
      "Iteration 1034, loss = 3.53988965\n",
      "Iteration 1035, loss = 3.53965573\n",
      "Iteration 1036, loss = 3.53942200\n",
      "Iteration 1037, loss = 3.53918846\n",
      "Iteration 1038, loss = 3.53895511\n",
      "Iteration 1039, loss = 3.53872195\n",
      "Iteration 1040, loss = 3.53848897\n",
      "Iteration 1041, loss = 3.53825619\n",
      "Iteration 1042, loss = 3.53802359\n",
      "Iteration 1043, loss = 3.53779119\n",
      "Iteration 1044, loss = 3.53755897\n",
      "Iteration 1045, loss = 3.53732694\n",
      "Iteration 1046, loss = 3.53709509\n",
      "Iteration 1047, loss = 3.53686344\n",
      "Iteration 1048, loss = 3.53663197\n",
      "Iteration 1049, loss = 3.53640068\n",
      "Iteration 1050, loss = 3.53616959\n",
      "Iteration 1051, loss = 3.53593868\n",
      "Iteration 1052, loss = 3.53570795\n",
      "Iteration 1053, loss = 3.53547741\n",
      "Iteration 1054, loss = 3.53524706\n",
      "Iteration 1055, loss = 3.53501689\n",
      "Iteration 1056, loss = 3.53478691\n",
      "Iteration 1057, loss = 3.53455711\n",
      "Iteration 1058, loss = 3.53432750\n",
      "Iteration 1059, loss = 3.53409807\n",
      "Iteration 1060, loss = 3.53386882\n",
      "Iteration 1061, loss = 3.53363976\n",
      "Iteration 1062, loss = 3.53341088\n",
      "Iteration 1063, loss = 3.53318218\n",
      "Iteration 1064, loss = 3.53295367\n",
      "Iteration 1065, loss = 3.53272534\n",
      "Iteration 1066, loss = 3.53249719\n",
      "Iteration 1067, loss = 3.53226922\n",
      "Iteration 1068, loss = 3.53204144\n",
      "Iteration 1069, loss = 3.53181383\n",
      "Iteration 1070, loss = 3.53158641\n",
      "Iteration 1071, loss = 3.53135917\n",
      "Iteration 1072, loss = 3.53113211\n",
      "Iteration 1073, loss = 3.53090523\n",
      "Iteration 1074, loss = 3.53067853\n",
      "Iteration 1075, loss = 3.53045201\n",
      "Iteration 1076, loss = 3.53022567\n",
      "Iteration 1077, loss = 3.52999951\n",
      "Iteration 1078, loss = 3.52977353\n",
      "Iteration 1079, loss = 3.52954773\n",
      "Iteration 1080, loss = 3.52932211\n",
      "Iteration 1081, loss = 3.52909666\n",
      "Iteration 1082, loss = 3.52887140\n",
      "Iteration 1083, loss = 3.52864631\n",
      "Iteration 1084, loss = 3.52842140\n",
      "Iteration 1085, loss = 3.52819666\n",
      "Iteration 1086, loss = 3.52797211\n",
      "Iteration 1087, loss = 3.52774773\n",
      "Iteration 1088, loss = 3.52752353\n",
      "Iteration 1089, loss = 3.52729950\n",
      "Iteration 1090, loss = 3.52707565\n",
      "Iteration 1091, loss = 3.52685198\n",
      "Iteration 1092, loss = 3.52662848\n",
      "Iteration 1093, loss = 3.52640515\n",
      "Iteration 1094, loss = 3.52618201\n",
      "Iteration 1095, loss = 3.52595903\n",
      "Iteration 1096, loss = 3.52573624\n",
      "Iteration 1097, loss = 3.52551361\n",
      "Iteration 1098, loss = 3.52529116\n",
      "Iteration 1099, loss = 3.52506889\n",
      "Iteration 1100, loss = 3.52484678\n",
      "Iteration 1101, loss = 3.52462485\n",
      "Iteration 1102, loss = 3.52440310\n",
      "Iteration 1103, loss = 3.52418151\n",
      "Iteration 1104, loss = 3.52396010\n",
      "Iteration 1105, loss = 3.52373886\n",
      "Iteration 1106, loss = 3.52351780\n",
      "Iteration 1107, loss = 3.52329690\n",
      "Iteration 1108, loss = 3.52307618\n",
      "Iteration 1109, loss = 3.52285563\n",
      "Iteration 1110, loss = 3.52263525\n",
      "Iteration 1111, loss = 3.52241504\n",
      "Iteration 1112, loss = 3.52219500\n",
      "Iteration 1113, loss = 3.52197513\n",
      "Iteration 1114, loss = 3.52175543\n",
      "Iteration 1115, loss = 3.52153590\n",
      "Iteration 1116, loss = 3.52131654\n",
      "Iteration 1117, loss = 3.52109735\n",
      "Iteration 1118, loss = 3.52087833\n",
      "Iteration 1119, loss = 3.52065947\n",
      "Iteration 1120, loss = 3.52044079\n",
      "Iteration 1121, loss = 3.52022227\n",
      "Iteration 1122, loss = 3.52000392\n",
      "Iteration 1123, loss = 3.51978574\n",
      "Iteration 1124, loss = 3.51956773\n",
      "Iteration 1125, loss = 3.51934988\n",
      "Iteration 1126, loss = 3.51913220\n",
      "Iteration 1127, loss = 3.51891469\n",
      "Iteration 1128, loss = 3.51869734\n",
      "Iteration 1129, loss = 3.51848016\n",
      "Iteration 1130, loss = 3.51826314\n",
      "Iteration 1131, loss = 3.51804630\n",
      "Iteration 1132, loss = 3.51782961\n",
      "Iteration 1133, loss = 3.51761309\n",
      "Iteration 1134, loss = 3.51739674\n",
      "Iteration 1135, loss = 3.51718055\n",
      "Iteration 1136, loss = 3.51696452\n",
      "Iteration 1137, loss = 3.51674866\n",
      "Iteration 1138, loss = 3.51653297\n",
      "Iteration 1139, loss = 3.51631743\n",
      "Iteration 1140, loss = 3.51610206\n",
      "Iteration 1141, loss = 3.51588685\n",
      "Iteration 1142, loss = 3.51567181\n",
      "Iteration 1143, loss = 3.51545693\n",
      "Iteration 1144, loss = 3.51524221\n",
      "Iteration 1145, loss = 3.51502765\n",
      "Iteration 1146, loss = 3.51481325\n",
      "Iteration 1147, loss = 3.51459902\n",
      "Iteration 1148, loss = 3.51438494\n",
      "Iteration 1149, loss = 3.51417103\n",
      "Iteration 1150, loss = 3.51395728\n",
      "Iteration 1151, loss = 3.51374369\n",
      "Iteration 1152, loss = 3.51353026\n",
      "Iteration 1153, loss = 3.51331698\n",
      "Iteration 1154, loss = 3.51310387\n",
      "Iteration 1155, loss = 3.51289092\n",
      "Iteration 1156, loss = 3.51267813\n",
      "Iteration 1157, loss = 3.51246549\n",
      "Iteration 1158, loss = 3.51225302\n",
      "Iteration 1159, loss = 3.51204070\n",
      "Iteration 1160, loss = 3.51182854\n",
      "Iteration 1161, loss = 3.51161654\n",
      "Iteration 1162, loss = 3.51140469\n",
      "Iteration 1163, loss = 3.51119301\n",
      "Iteration 1164, loss = 3.51098148\n",
      "Iteration 1165, loss = 3.51077010\n",
      "Iteration 1166, loss = 3.51055889\n",
      "Iteration 1167, loss = 3.51034783\n",
      "Iteration 1168, loss = 3.51013692\n",
      "Iteration 1169, loss = 3.50992617\n",
      "Iteration 1170, loss = 3.50971558\n",
      "Iteration 1171, loss = 3.50950514\n",
      "Iteration 1172, loss = 3.50929486\n",
      "Iteration 1173, loss = 3.50908473\n",
      "Iteration 1174, loss = 3.50887476\n",
      "Iteration 1175, loss = 3.50866494\n",
      "Iteration 1176, loss = 3.50845527\n",
      "Iteration 1177, loss = 3.50824576\n",
      "Iteration 1178, loss = 3.50803640\n",
      "Iteration 1179, loss = 3.50782720\n",
      "Iteration 1180, loss = 3.50761814\n",
      "Iteration 1181, loss = 3.50740924\n",
      "Iteration 1182, loss = 3.50720050\n",
      "Iteration 1183, loss = 3.50699190\n",
      "Iteration 1184, loss = 3.50678346\n",
      "Iteration 1185, loss = 3.50657516\n",
      "Iteration 1186, loss = 3.50636702\n",
      "Iteration 1187, loss = 3.50615903\n",
      "Iteration 1188, loss = 3.50595119\n",
      "Iteration 1189, loss = 3.50574351\n",
      "Iteration 1190, loss = 3.50553597\n",
      "Iteration 1191, loss = 3.50532858\n",
      "Iteration 1192, loss = 3.50512134\n",
      "Iteration 1193, loss = 3.50491425\n",
      "Iteration 1194, loss = 3.50470731\n",
      "Iteration 1195, loss = 3.50450052\n",
      "Iteration 1196, loss = 3.50429388\n",
      "Iteration 1197, loss = 3.50408738\n",
      "Iteration 1198, loss = 3.50388104\n",
      "Iteration 1199, loss = 3.50367484\n",
      "Iteration 1200, loss = 3.50346879\n",
      "Iteration 1201, loss = 3.50326289\n",
      "Iteration 1202, loss = 3.50305713\n",
      "Iteration 1203, loss = 3.50285152\n",
      "Iteration 1204, loss = 3.50264606\n",
      "Iteration 1205, loss = 3.50244075\n",
      "Iteration 1206, loss = 3.50223558\n",
      "Iteration 1207, loss = 3.50203055\n",
      "Iteration 1208, loss = 3.50182567\n",
      "Iteration 1209, loss = 3.50162094\n",
      "Iteration 1210, loss = 3.50141635\n",
      "Iteration 1211, loss = 3.50121191\n",
      "Iteration 1212, loss = 3.50100761\n",
      "Iteration 1213, loss = 3.50080345\n",
      "Iteration 1214, loss = 3.50059944\n",
      "Iteration 1215, loss = 3.50039558\n",
      "Iteration 1216, loss = 3.50019185\n",
      "Iteration 1217, loss = 3.49998827\n",
      "Iteration 1218, loss = 3.49978483\n",
      "Iteration 1219, loss = 3.49958154\n",
      "Iteration 1220, loss = 3.49937839\n",
      "Iteration 1221, loss = 3.49917538\n",
      "Iteration 1222, loss = 3.49897251\n",
      "Iteration 1223, loss = 3.49876978\n",
      "Iteration 1224, loss = 3.49856720\n",
      "Iteration 1225, loss = 3.49836475\n",
      "Iteration 1226, loss = 3.49816245\n",
      "Iteration 1227, loss = 3.49796028\n",
      "Iteration 1228, loss = 3.49775826\n",
      "Iteration 1229, loss = 3.49755638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1230, loss = 3.49735463\n",
      "Iteration 1231, loss = 3.49715303\n",
      "Iteration 1232, loss = 3.49695157\n",
      "Iteration 1233, loss = 3.49675024\n",
      "Iteration 1234, loss = 3.49654905\n",
      "Iteration 1235, loss = 3.49634801\n",
      "Iteration 1236, loss = 3.49614709\n",
      "Iteration 1237, loss = 3.49594632\n",
      "Iteration 1238, loss = 3.49574569\n",
      "Iteration 1239, loss = 3.49554519\n",
      "Iteration 1240, loss = 3.49534483\n",
      "Iteration 1241, loss = 3.49514461\n",
      "Iteration 1242, loss = 3.49494452\n",
      "Iteration 1243, loss = 3.49474457\n",
      "Iteration 1244, loss = 3.49454475\n",
      "Iteration 1245, loss = 3.49434507\n",
      "Iteration 1246, loss = 3.49414553\n",
      "Iteration 1247, loss = 3.49394612\n",
      "Iteration 1248, loss = 3.49374685\n",
      "Iteration 1249, loss = 3.49354771\n",
      "Iteration 1250, loss = 3.49334871\n",
      "Iteration 1251, loss = 3.49314984\n",
      "Iteration 1252, loss = 3.49295110\n",
      "Iteration 1253, loss = 3.49275250\n",
      "Iteration 1254, loss = 3.49255403\n",
      "Iteration 1255, loss = 3.49235570\n",
      "Iteration 1256, loss = 3.49215749\n",
      "Iteration 1257, loss = 3.49195942\n",
      "Iteration 1258, loss = 3.49176148\n",
      "Iteration 1259, loss = 3.49156368\n",
      "Iteration 1260, loss = 3.49136600\n",
      "Iteration 1261, loss = 3.49116846\n",
      "Iteration 1262, loss = 3.49097105\n",
      "Iteration 1263, loss = 3.49077377\n",
      "Iteration 1264, loss = 3.49057662\n",
      "Iteration 1265, loss = 3.49037960\n",
      "Iteration 1266, loss = 3.49018271\n",
      "Iteration 1267, loss = 3.48998595\n",
      "Iteration 1268, loss = 3.48978932\n",
      "Iteration 1269, loss = 3.48959282\n",
      "Iteration 1270, loss = 3.48939645\n",
      "Iteration 1271, loss = 3.48920021\n",
      "Iteration 1272, loss = 3.48900410\n",
      "Iteration 1273, loss = 3.48880811\n",
      "Iteration 1274, loss = 3.48861226\n",
      "Iteration 1275, loss = 3.48841653\n",
      "Iteration 1276, loss = 3.48822093\n",
      "Iteration 1277, loss = 3.48802545\n",
      "Iteration 1278, loss = 3.48783011\n",
      "Iteration 1279, loss = 3.48763488\n",
      "Iteration 1280, loss = 3.48743979\n",
      "Iteration 1281, loss = 3.48724482\n",
      "Iteration 1282, loss = 3.48704998\n",
      "Iteration 1283, loss = 3.48685526\n",
      "Iteration 1284, loss = 3.48666067\n",
      "Iteration 1285, loss = 3.48646621\n",
      "Iteration 1286, loss = 3.48627187\n",
      "Iteration 1287, loss = 3.48607765\n",
      "Iteration 1288, loss = 3.48588356\n",
      "Iteration 1289, loss = 3.48568959\n",
      "Iteration 1290, loss = 3.48549575\n",
      "Iteration 1291, loss = 3.48530203\n",
      "Iteration 1292, loss = 3.48510843\n",
      "Iteration 1293, loss = 3.48491496\n",
      "Iteration 1294, loss = 3.48472161\n",
      "Iteration 1295, loss = 3.48452838\n",
      "Iteration 1296, loss = 3.48433527\n",
      "Iteration 1297, loss = 3.48414229\n",
      "Iteration 1298, loss = 3.48394942\n",
      "Iteration 1299, loss = 3.48375668\n",
      "Iteration 1300, loss = 3.48356406\n",
      "Iteration 1301, loss = 3.48337156\n",
      "Iteration 1302, loss = 3.48317918\n",
      "Iteration 1303, loss = 3.48298693\n",
      "Iteration 1304, loss = 3.48279479\n",
      "Iteration 1305, loss = 3.48260277\n",
      "Iteration 1306, loss = 3.48241087\n",
      "Iteration 1307, loss = 3.48221909\n",
      "Iteration 1308, loss = 3.48202743\n",
      "Iteration 1309, loss = 3.48183589\n",
      "Iteration 1310, loss = 3.48164446\n",
      "Iteration 1311, loss = 3.48145316\n",
      "Iteration 1312, loss = 3.48126197\n",
      "Iteration 1313, loss = 3.48107090\n",
      "Iteration 1314, loss = 3.48087995\n",
      "Iteration 1315, loss = 3.48068911\n",
      "Iteration 1316, loss = 3.48049840\n",
      "Iteration 1317, loss = 3.48030779\n",
      "Iteration 1318, loss = 3.48011731\n",
      "Iteration 1319, loss = 3.47992694\n",
      "Iteration 1320, loss = 3.47973669\n",
      "Iteration 1321, loss = 3.47954655\n",
      "Iteration 1322, loss = 3.47935653\n",
      "Iteration 1323, loss = 3.47916662\n",
      "Iteration 1324, loss = 3.47897683\n",
      "Iteration 1325, loss = 3.47878715\n",
      "Iteration 1326, loss = 3.47859759\n",
      "Iteration 1327, loss = 3.47840814\n",
      "Iteration 1328, loss = 3.47821880\n",
      "Iteration 1329, loss = 3.47802958\n",
      "Iteration 1330, loss = 3.47784047\n",
      "Iteration 1331, loss = 3.47765147\n",
      "Iteration 1332, loss = 3.47746259\n",
      "Iteration 1333, loss = 3.47727381\n",
      "Iteration 1334, loss = 3.47708515\n",
      "Iteration 1335, loss = 3.47689661\n",
      "Iteration 1336, loss = 3.47670817\n",
      "Iteration 1337, loss = 3.47651985\n",
      "Iteration 1338, loss = 3.47633163\n",
      "Iteration 1339, loss = 3.47614353\n",
      "Iteration 1340, loss = 3.47595554\n",
      "Iteration 1341, loss = 3.47576765\n",
      "Iteration 1342, loss = 3.47557988\n",
      "Iteration 1343, loss = 3.47539222\n",
      "Iteration 1344, loss = 3.47520467\n",
      "Iteration 1345, loss = 3.47501722\n",
      "Iteration 1346, loss = 3.47482989\n",
      "Iteration 1347, loss = 3.47464266\n",
      "Iteration 1348, loss = 3.47445554\n",
      "Iteration 1349, loss = 3.47426853\n",
      "Iteration 1350, loss = 3.47408163\n",
      "Iteration 1351, loss = 3.47389484\n",
      "Iteration 1352, loss = 3.47370815\n",
      "Iteration 1353, loss = 3.47352157\n",
      "Iteration 1354, loss = 3.47333509\n",
      "Iteration 1355, loss = 3.47314873\n",
      "Iteration 1356, loss = 3.47296247\n",
      "Iteration 1357, loss = 3.47277631\n",
      "Iteration 1358, loss = 3.47259026\n",
      "Iteration 1359, loss = 3.47240432\n",
      "Iteration 1360, loss = 3.47221848\n",
      "Iteration 1361, loss = 3.47203275\n",
      "Iteration 1362, loss = 3.47184712\n",
      "Iteration 1363, loss = 3.47166160\n",
      "Iteration 1364, loss = 3.47147618\n",
      "Iteration 1365, loss = 3.47129086\n",
      "Iteration 1366, loss = 3.47110565\n",
      "Iteration 1367, loss = 3.47092054\n",
      "Iteration 1368, loss = 3.47073553\n",
      "Iteration 1369, loss = 3.47055063\n",
      "Iteration 1370, loss = 3.47036583\n",
      "Iteration 1371, loss = 3.47018113\n",
      "Iteration 1372, loss = 3.46999654\n",
      "Iteration 1373, loss = 3.46981204\n",
      "Iteration 1374, loss = 3.46962765\n",
      "Iteration 1375, loss = 3.46944336\n",
      "Iteration 1376, loss = 3.46925917\n",
      "Iteration 1377, loss = 3.46907508\n",
      "Iteration 1378, loss = 3.46889109\n",
      "Iteration 1379, loss = 3.46870720\n",
      "Iteration 1380, loss = 3.46852341\n",
      "Iteration 1381, loss = 3.46833972\n",
      "Iteration 1382, loss = 3.46815613\n",
      "Iteration 1383, loss = 3.46797264\n",
      "Iteration 1384, loss = 3.46778925\n",
      "Iteration 1385, loss = 3.46760595\n",
      "Iteration 1386, loss = 3.46742276\n",
      "Iteration 1387, loss = 3.46723966\n",
      "Iteration 1388, loss = 3.46705666\n",
      "Iteration 1389, loss = 3.46687376\n",
      "Iteration 1390, loss = 3.46669096\n",
      "Iteration 1391, loss = 3.46650825\n",
      "Iteration 1392, loss = 3.46632564\n",
      "Iteration 1393, loss = 3.46614313\n",
      "Iteration 1394, loss = 3.46596071\n",
      "Iteration 1395, loss = 3.46577839\n",
      "Iteration 1396, loss = 3.46559617\n",
      "Iteration 1397, loss = 3.46541404\n",
      "Iteration 1398, loss = 3.46523200\n",
      "Iteration 1399, loss = 3.46505006\n",
      "Iteration 1400, loss = 3.46486822\n",
      "Iteration 1401, loss = 3.46468647\n",
      "Iteration 1402, loss = 3.46450481\n",
      "Iteration 1403, loss = 3.46432325\n",
      "Iteration 1404, loss = 3.46414178\n",
      "Iteration 1405, loss = 3.46396041\n",
      "Iteration 1406, loss = 3.46377912\n",
      "Iteration 1407, loss = 3.46359794\n",
      "Iteration 1408, loss = 3.46341684\n",
      "Iteration 1409, loss = 3.46323584\n",
      "Iteration 1410, loss = 3.46305492\n",
      "Iteration 1411, loss = 3.46287410\n",
      "Iteration 1412, loss = 3.46269338\n",
      "Iteration 1413, loss = 3.46251274\n",
      "Iteration 1414, loss = 3.46233220\n",
      "Iteration 1415, loss = 3.46215174\n",
      "Iteration 1416, loss = 3.46197138\n",
      "Iteration 1417, loss = 3.46179110\n",
      "Iteration 1418, loss = 3.46161092\n",
      "Iteration 1419, loss = 3.46143083\n",
      "Iteration 1420, loss = 3.46125082\n",
      "Iteration 1421, loss = 3.46107091\n",
      "Iteration 1422, loss = 3.46089109\n",
      "Iteration 1423, loss = 3.46071135\n",
      "Iteration 1424, loss = 3.46053170\n",
      "Iteration 1425, loss = 3.46035214\n",
      "Iteration 1426, loss = 3.46017267\n",
      "Iteration 1427, loss = 3.45999329\n",
      "Iteration 1428, loss = 3.45981399\n",
      "Iteration 1429, loss = 3.45963478\n",
      "Iteration 1430, loss = 3.45945566\n",
      "Iteration 1431, loss = 3.45927663\n",
      "Iteration 1432, loss = 3.45909768\n",
      "Iteration 1433, loss = 3.45891882\n",
      "Iteration 1434, loss = 3.45874004\n",
      "Iteration 1435, loss = 3.45856135\n",
      "Iteration 1436, loss = 3.45838275\n",
      "Iteration 1437, loss = 3.45820423\n",
      "Iteration 1438, loss = 3.45802580\n",
      "Iteration 1439, loss = 3.45784745\n",
      "Iteration 1440, loss = 3.45766918\n",
      "Iteration 1441, loss = 3.45749100\n",
      "Iteration 1442, loss = 3.45731291\n",
      "Iteration 1443, loss = 3.45713490\n",
      "Iteration 1444, loss = 3.45695697\n",
      "Iteration 1445, loss = 3.45677912\n",
      "Iteration 1446, loss = 3.45660136\n",
      "Iteration 1447, loss = 3.45642368\n",
      "Iteration 1448, loss = 3.45624608\n",
      "Iteration 1449, loss = 3.45606857\n",
      "Iteration 1450, loss = 3.45589114\n",
      "Iteration 1451, loss = 3.45571379\n",
      "Iteration 1452, loss = 3.45553652\n",
      "Iteration 1453, loss = 3.45535933\n",
      "Iteration 1454, loss = 3.45518223\n",
      "Iteration 1455, loss = 3.45500520\n",
      "Iteration 1456, loss = 3.45482826\n",
      "Iteration 1457, loss = 3.45465139\n",
      "Iteration 1458, loss = 3.45447461\n",
      "Iteration 1459, loss = 3.45429790\n",
      "Iteration 1460, loss = 3.45412128\n",
      "Iteration 1461, loss = 3.45394473\n",
      "Iteration 1462, loss = 3.45376827\n",
      "Iteration 1463, loss = 3.45359188\n",
      "Iteration 1464, loss = 3.45341557\n",
      "Iteration 1465, loss = 3.45323934\n",
      "Iteration 1466, loss = 3.45306319\n",
      "Iteration 1467, loss = 3.45288712\n",
      "Iteration 1468, loss = 3.45271112\n",
      "Iteration 1469, loss = 3.45253520\n",
      "Iteration 1470, loss = 3.45235936\n",
      "Iteration 1471, loss = 3.45218359\n",
      "Iteration 1472, loss = 3.45200791\n",
      "Iteration 1473, loss = 3.45183230\n",
      "Iteration 1474, loss = 3.45165676\n",
      "Iteration 1475, loss = 3.45148130\n",
      "Iteration 1476, loss = 3.45130592\n",
      "Iteration 1477, loss = 3.45113061\n",
      "Iteration 1478, loss = 3.45095538\n",
      "Iteration 1479, loss = 3.45078022\n",
      "Iteration 1480, loss = 3.45060514\n",
      "Iteration 1481, loss = 3.45043013\n",
      "Iteration 1482, loss = 3.45025520\n",
      "Iteration 1483, loss = 3.45008034\n",
      "Iteration 1484, loss = 3.44990555\n",
      "Iteration 1485, loss = 3.44973084\n",
      "Iteration 1486, loss = 3.44955620\n",
      "Iteration 1487, loss = 3.44938163\n",
      "Iteration 1488, loss = 3.44920714\n",
      "Iteration 1489, loss = 3.44903272\n",
      "Iteration 1490, loss = 3.44885838\n",
      "Iteration 1491, loss = 3.44868410\n",
      "Iteration 1492, loss = 3.44850990\n",
      "Iteration 1493, loss = 3.44833577\n",
      "Iteration 1494, loss = 3.44816171\n",
      "Iteration 1495, loss = 3.44798772\n",
      "Iteration 1496, loss = 3.44781380\n",
      "Iteration 1497, loss = 3.44763995\n",
      "Iteration 1498, loss = 3.44746618\n",
      "Iteration 1499, loss = 3.44729247\n",
      "Iteration 1500, loss = 3.44711884\n",
      "Iteration 1501, loss = 3.44694527\n",
      "Iteration 1502, loss = 3.44677178\n",
      "Iteration 1503, loss = 3.44659835\n",
      "Iteration 1504, loss = 3.44642499\n",
      "Iteration 1505, loss = 3.44625170\n",
      "Iteration 1506, loss = 3.44607849\n",
      "Iteration 1507, loss = 3.44590533\n",
      "Iteration 1508, loss = 3.44573225\n",
      "Iteration 1509, loss = 3.44555924\n",
      "Iteration 1510, loss = 3.44538629\n",
      "Iteration 1511, loss = 3.44521341\n",
      "Iteration 1512, loss = 3.44504060\n",
      "Iteration 1513, loss = 3.44486786\n",
      "Iteration 1514, loss = 3.44469518\n",
      "Iteration 1515, loss = 3.44452257\n",
      "Iteration 1516, loss = 3.44435002\n",
      "Iteration 1517, loss = 3.44417755\n",
      "Iteration 1518, loss = 3.44400513\n",
      "Iteration 1519, loss = 3.44383279\n",
      "Iteration 1520, loss = 3.44366051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1521, loss = 3.44348829\n",
      "Iteration 1522, loss = 3.44331614\n",
      "Iteration 1523, loss = 3.44314406\n",
      "Iteration 1524, loss = 3.44297204\n",
      "Iteration 1525, loss = 3.44280008\n",
      "Iteration 1526, loss = 3.44262819\n",
      "Iteration 1527, loss = 3.44245636\n",
      "Iteration 1528, loss = 3.44228460\n",
      "Iteration 1529, loss = 3.44211290\n",
      "Iteration 1530, loss = 3.44194127\n",
      "Iteration 1531, loss = 3.44176969\n",
      "Iteration 1532, loss = 3.44159818\n",
      "Iteration 1533, loss = 3.44142673\n",
      "Iteration 1534, loss = 3.44125535\n",
      "Iteration 1535, loss = 3.44108403\n",
      "Iteration 1536, loss = 3.44091277\n",
      "Iteration 1537, loss = 3.44074157\n",
      "Iteration 1538, loss = 3.44057043\n",
      "Iteration 1539, loss = 3.44039936\n",
      "Iteration 1540, loss = 3.44022834\n",
      "Iteration 1541, loss = 3.44005739\n",
      "Iteration 1542, loss = 3.43988650\n",
      "Iteration 1543, loss = 3.43971566\n",
      "Iteration 1544, loss = 3.43954489\n",
      "Iteration 1545, loss = 3.43937418\n",
      "Iteration 1546, loss = 3.43920353\n",
      "Iteration 1547, loss = 3.43903294\n",
      "Iteration 1548, loss = 3.43886241\n",
      "Iteration 1549, loss = 3.43869193\n",
      "Iteration 1550, loss = 3.43852152\n",
      "Iteration 1551, loss = 3.43835117\n",
      "Iteration 1552, loss = 3.43818087\n",
      "Iteration 1553, loss = 3.43801063\n",
      "Iteration 1554, loss = 3.43784045\n",
      "Iteration 1555, loss = 3.43767033\n",
      "Iteration 1556, loss = 3.43750027\n",
      "Iteration 1557, loss = 3.43733026\n",
      "Iteration 1558, loss = 3.43716032\n",
      "Iteration 1559, loss = 3.43699042\n",
      "Iteration 1560, loss = 3.43682059\n",
      "Iteration 1561, loss = 3.43665081\n",
      "Iteration 1562, loss = 3.43648109\n",
      "Iteration 1563, loss = 3.43631143\n",
      "Iteration 1564, loss = 3.43614182\n",
      "Iteration 1565, loss = 3.43597227\n",
      "Iteration 1566, loss = 3.43580277\n",
      "Iteration 1567, loss = 3.43563333\n",
      "Iteration 1568, loss = 3.43546395\n",
      "Iteration 1569, loss = 3.43529462\n",
      "Iteration 1570, loss = 3.43512534\n",
      "Iteration 1571, loss = 3.43495612\n",
      "Iteration 1572, loss = 3.43478696\n",
      "Iteration 1573, loss = 3.43461785\n",
      "Iteration 1574, loss = 3.43444879\n",
      "Iteration 1575, loss = 3.43427979\n",
      "Iteration 1576, loss = 3.43411084\n",
      "Iteration 1577, loss = 3.43394195\n",
      "Iteration 1578, loss = 3.43377310\n",
      "Iteration 1579, loss = 3.43360431\n",
      "Iteration 1580, loss = 3.43343558\n",
      "Iteration 1581, loss = 3.43326690\n",
      "Iteration 1582, loss = 3.43309827\n",
      "Iteration 1583, loss = 3.43292969\n",
      "Iteration 1584, loss = 3.43276116\n",
      "Iteration 1585, loss = 3.43259269\n",
      "Iteration 1586, loss = 3.43242427\n",
      "Iteration 1587, loss = 3.43225590\n",
      "Iteration 1588, loss = 3.43208758\n",
      "Iteration 1589, loss = 3.43191931\n",
      "Iteration 1590, loss = 3.43175110\n",
      "Iteration 1591, loss = 3.43158293\n",
      "Iteration 1592, loss = 3.43141482\n",
      "Iteration 1593, loss = 3.43124675\n",
      "Iteration 1594, loss = 3.43107874\n",
      "Iteration 1595, loss = 3.43091077\n",
      "Iteration 1596, loss = 3.43074286\n",
      "Iteration 1597, loss = 3.43057500\n",
      "Iteration 1598, loss = 3.43040718\n",
      "Iteration 1599, loss = 3.43023942\n",
      "Iteration 1600, loss = 3.43007170\n",
      "Iteration 1601, loss = 3.42990403\n",
      "Iteration 1602, loss = 3.42973641\n",
      "Iteration 1603, loss = 3.42956884\n",
      "Iteration 1604, loss = 3.42940132\n",
      "Iteration 1605, loss = 3.42923385\n",
      "Iteration 1606, loss = 3.42906643\n",
      "Iteration 1607, loss = 3.42889905\n",
      "Iteration 1608, loss = 3.42873172\n",
      "Iteration 1609, loss = 3.42856444\n",
      "Iteration 1610, loss = 3.42839720\n",
      "Iteration 1611, loss = 3.42823002\n",
      "Iteration 1612, loss = 3.42806287\n",
      "Iteration 1613, loss = 3.42789578\n",
      "Iteration 1614, loss = 3.42772873\n",
      "Iteration 1615, loss = 3.42756173\n",
      "Iteration 1616, loss = 3.42739478\n",
      "Iteration 1617, loss = 3.42722787\n",
      "Iteration 1618, loss = 3.42706101\n",
      "Iteration 1619, loss = 3.42689419\n",
      "Iteration 1620, loss = 3.42672742\n",
      "Iteration 1621, loss = 3.42656069\n",
      "Iteration 1622, loss = 3.42639401\n",
      "Iteration 1623, loss = 3.42622738\n",
      "Iteration 1624, loss = 3.42606079\n",
      "Iteration 1625, loss = 3.42589424\n",
      "Iteration 1626, loss = 3.42572774\n",
      "Iteration 1627, loss = 3.42556128\n",
      "Iteration 1628, loss = 3.42539487\n",
      "Iteration 1629, loss = 3.42522850\n",
      "Iteration 1630, loss = 3.42506217\n",
      "Iteration 1631, loss = 3.42489589\n",
      "Iteration 1632, loss = 3.42472965\n",
      "Iteration 1633, loss = 3.42456345\n",
      "Iteration 1634, loss = 3.42439730\n",
      "Iteration 1635, loss = 3.42423119\n",
      "Iteration 1636, loss = 3.42406512\n",
      "Iteration 1637, loss = 3.42389910\n",
      "Iteration 1638, loss = 3.42373312\n",
      "Iteration 1639, loss = 3.42356718\n",
      "Iteration 1640, loss = 3.42340128\n",
      "Iteration 1641, loss = 3.42323542\n",
      "Iteration 1642, loss = 3.42306961\n",
      "Iteration 1643, loss = 3.42290383\n",
      "Iteration 1644, loss = 3.42273810\n",
      "Iteration 1645, loss = 3.42257241\n",
      "Iteration 1646, loss = 3.42240676\n",
      "Iteration 1647, loss = 3.42224116\n",
      "Iteration 1648, loss = 3.42207559\n",
      "Iteration 1649, loss = 3.42191006\n",
      "Iteration 1650, loss = 3.42174457\n",
      "Iteration 1651, loss = 3.42157913\n",
      "Iteration 1652, loss = 3.42141372\n",
      "Iteration 1653, loss = 3.42124835\n",
      "Iteration 1654, loss = 3.42108303\n",
      "Iteration 1655, loss = 3.42091774\n",
      "Iteration 1656, loss = 3.42075249\n",
      "Iteration 1657, loss = 3.42058728\n",
      "Iteration 1658, loss = 3.42042211\n",
      "Iteration 1659, loss = 3.42025698\n",
      "Iteration 1660, loss = 3.42009189\n",
      "Iteration 1661, loss = 3.41992684\n",
      "Iteration 1662, loss = 3.41976182\n",
      "Iteration 1663, loss = 3.41959685\n",
      "Iteration 1664, loss = 3.41943191\n",
      "Iteration 1665, loss = 3.41926701\n",
      "Iteration 1666, loss = 3.41910215\n",
      "Iteration 1667, loss = 3.41893732\n",
      "Iteration 1668, loss = 3.41877253\n",
      "Iteration 1669, loss = 3.41860778\n",
      "Iteration 1670, loss = 3.41844307\n",
      "Iteration 1671, loss = 3.41827840\n",
      "Iteration 1672, loss = 3.41811376\n",
      "Iteration 1673, loss = 3.41794915\n",
      "Iteration 1674, loss = 3.41778459\n",
      "Iteration 1675, loss = 3.41762006\n",
      "Iteration 1676, loss = 3.41745557\n",
      "Iteration 1677, loss = 3.41729111\n",
      "Iteration 1678, loss = 3.41712669\n",
      "Iteration 1679, loss = 3.41696230\n",
      "Iteration 1680, loss = 3.41679795\n",
      "Iteration 1681, loss = 3.41663364\n",
      "Iteration 1682, loss = 3.41646936\n",
      "Iteration 1683, loss = 3.41630512\n",
      "Iteration 1684, loss = 3.41614091\n",
      "Iteration 1685, loss = 3.41597674\n",
      "Iteration 1686, loss = 3.41581260\n",
      "Iteration 1687, loss = 3.41564850\n",
      "Iteration 1688, loss = 3.41548443\n",
      "Iteration 1689, loss = 3.41532039\n",
      "Iteration 1690, loss = 3.41515639\n",
      "Iteration 1691, loss = 3.41499242\n",
      "Iteration 1692, loss = 3.41482849\n",
      "Iteration 1693, loss = 3.41466459\n",
      "Iteration 1694, loss = 3.41450073\n",
      "Iteration 1695, loss = 3.41433689\n",
      "Iteration 1696, loss = 3.41417310\n",
      "Iteration 1697, loss = 3.41400933\n",
      "Iteration 1698, loss = 3.41384560\n",
      "Iteration 1699, loss = 3.41368190\n",
      "Iteration 1700, loss = 3.41351823\n",
      "Iteration 1701, loss = 3.41335460\n",
      "Iteration 1702, loss = 3.41319100\n",
      "Iteration 1703, loss = 3.41302743\n",
      "Iteration 1704, loss = 3.41286389\n",
      "Iteration 1705, loss = 3.41270038\n",
      "Iteration 1706, loss = 3.41253691\n",
      "Iteration 1707, loss = 3.41237347\n",
      "Iteration 1708, loss = 3.41221006\n",
      "Iteration 1709, loss = 3.41204668\n",
      "Iteration 1710, loss = 3.41188334\n",
      "Iteration 1711, loss = 3.41172002\n",
      "Iteration 1712, loss = 3.41155674\n",
      "Iteration 1713, loss = 3.41139348\n",
      "Iteration 1714, loss = 3.41123026\n",
      "Iteration 1715, loss = 3.41106707\n",
      "Iteration 1716, loss = 3.41090391\n",
      "Iteration 1717, loss = 3.41074078\n",
      "Iteration 1718, loss = 3.41057768\n",
      "Iteration 1719, loss = 3.41041460\n",
      "Iteration 1720, loss = 3.41025156\n",
      "Iteration 1721, loss = 3.41008855\n",
      "Iteration 1722, loss = 3.40992557\n",
      "Iteration 1723, loss = 3.40976262\n",
      "Iteration 1724, loss = 3.40959970\n",
      "Iteration 1725, loss = 3.40943681\n",
      "Iteration 1726, loss = 3.40927395\n",
      "Iteration 1727, loss = 3.40911111\n",
      "Iteration 1728, loss = 3.40894831\n",
      "Iteration 1729, loss = 3.40878553\n",
      "Iteration 1730, loss = 3.40862279\n",
      "Iteration 1731, loss = 3.40846007\n",
      "Iteration 1732, loss = 3.40829738\n",
      "Iteration 1733, loss = 3.40813472\n",
      "Iteration 1734, loss = 3.40797208\n",
      "Iteration 1735, loss = 3.40780948\n",
      "Iteration 1736, loss = 3.40764690\n",
      "Iteration 1737, loss = 3.40748435\n",
      "Iteration 1738, loss = 3.40732183\n",
      "Iteration 1739, loss = 3.40715934\n",
      "Iteration 1740, loss = 3.40699687\n",
      "Iteration 1741, loss = 3.40683443\n",
      "Iteration 1742, loss = 3.40667202\n",
      "Iteration 1743, loss = 3.40650964\n",
      "Iteration 1744, loss = 3.40634728\n",
      "Iteration 1745, loss = 3.40618495\n",
      "Iteration 1746, loss = 3.40602264\n",
      "Iteration 1747, loss = 3.40586037\n",
      "Iteration 1748, loss = 3.40569812\n",
      "Iteration 1749, loss = 3.40553589\n",
      "Iteration 1750, loss = 3.40537369\n",
      "Iteration 1751, loss = 3.40521152\n",
      "Iteration 1752, loss = 3.40504938\n",
      "Iteration 1753, loss = 3.40488726\n",
      "Iteration 1754, loss = 3.40472516\n",
      "Iteration 1755, loss = 3.40456309\n",
      "Iteration 1756, loss = 3.40440105\n",
      "Iteration 1757, loss = 3.40423903\n",
      "Iteration 1758, loss = 3.40407704\n",
      "Iteration 1759, loss = 3.40391508\n",
      "Iteration 1760, loss = 3.40375314\n",
      "Iteration 1761, loss = 3.40359122\n",
      "Iteration 1762, loss = 3.40342933\n",
      "Iteration 1763, loss = 3.40326746\n",
      "Iteration 1764, loss = 3.40310562\n",
      "Iteration 1765, loss = 3.40294380\n",
      "Iteration 1766, loss = 3.40278201\n",
      "Iteration 1767, loss = 3.40262024\n",
      "Iteration 1768, loss = 3.40245850\n",
      "Iteration 1769, loss = 3.40229678\n",
      "Iteration 1770, loss = 3.40213508\n",
      "Iteration 1771, loss = 3.40197341\n",
      "Iteration 1772, loss = 3.40181176\n",
      "Iteration 1773, loss = 3.40165014\n",
      "Iteration 1774, loss = 3.40148853\n",
      "Iteration 1775, loss = 3.40132696\n",
      "Iteration 1776, loss = 3.40116540\n",
      "Iteration 1777, loss = 3.40100387\n",
      "Iteration 1778, loss = 3.40084236\n",
      "Iteration 1779, loss = 3.40068088\n",
      "Iteration 1780, loss = 3.40051942\n",
      "Iteration 1781, loss = 3.40035798\n",
      "Iteration 1782, loss = 3.40019656\n",
      "Iteration 1783, loss = 3.40003517\n",
      "Iteration 1784, loss = 3.39987380\n",
      "Iteration 1785, loss = 3.39971245\n",
      "Iteration 1786, loss = 3.39955112\n",
      "Iteration 1787, loss = 3.39938982\n",
      "Iteration 1788, loss = 3.39922854\n",
      "Iteration 1789, loss = 3.39906728\n",
      "Iteration 1790, loss = 3.39890604\n",
      "Iteration 1791, loss = 3.39874482\n",
      "Iteration 1792, loss = 3.39858363\n",
      "Iteration 1793, loss = 3.39842246\n",
      "Iteration 1794, loss = 3.39826131\n",
      "Iteration 1795, loss = 3.39810018\n",
      "Iteration 1796, loss = 3.39793907\n",
      "Iteration 1797, loss = 3.39777798\n",
      "Iteration 1798, loss = 3.39761691\n",
      "Iteration 1799, loss = 3.39745587\n",
      "Iteration 1800, loss = 3.39729484\n",
      "Iteration 1801, loss = 3.39713384\n",
      "Iteration 1802, loss = 3.39697286\n",
      "Iteration 1803, loss = 3.39681190\n",
      "Iteration 1804, loss = 3.39665095\n",
      "Iteration 1805, loss = 3.39649003\n",
      "Iteration 1806, loss = 3.39632913\n",
      "Iteration 1807, loss = 3.39616825\n",
      "Iteration 1808, loss = 3.39600739\n",
      "Iteration 1809, loss = 3.39584655\n",
      "Iteration 1810, loss = 3.39568573\n",
      "Iteration 1811, loss = 3.39552493\n",
      "Iteration 1812, loss = 3.39536415\n",
      "Iteration 1813, loss = 3.39520339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1814, loss = 3.39504265\n",
      "Iteration 1815, loss = 3.39488193\n",
      "Iteration 1816, loss = 3.39472122\n",
      "Iteration 1817, loss = 3.39456054\n",
      "Iteration 1818, loss = 3.39439988\n",
      "Iteration 1819, loss = 3.39423923\n",
      "Iteration 1820, loss = 3.39407861\n",
      "Iteration 1821, loss = 3.39391800\n",
      "Iteration 1822, loss = 3.39375741\n",
      "Iteration 1823, loss = 3.39359684\n",
      "Iteration 1824, loss = 3.39343629\n",
      "Iteration 1825, loss = 3.39327576\n",
      "Iteration 1826, loss = 3.39311525\n",
      "Iteration 1827, loss = 3.39295475\n",
      "Iteration 1828, loss = 3.39279428\n",
      "Iteration 1829, loss = 3.39263382\n",
      "Iteration 1830, loss = 3.39247338\n",
      "Iteration 1831, loss = 3.39231296\n",
      "Iteration 1832, loss = 3.39215255\n",
      "Iteration 1833, loss = 3.39199217\n",
      "Iteration 1834, loss = 3.39183180\n",
      "Iteration 1835, loss = 3.39167145\n",
      "Iteration 1836, loss = 3.39151112\n",
      "Iteration 1837, loss = 3.39135080\n",
      "Iteration 1838, loss = 3.39119051\n",
      "Iteration 1839, loss = 3.39103023\n",
      "Iteration 1840, loss = 3.39086996\n",
      "Iteration 1841, loss = 3.39070972\n",
      "Iteration 1842, loss = 3.39054949\n",
      "Iteration 1843, loss = 3.39038928\n",
      "Iteration 1844, loss = 3.39022908\n",
      "Iteration 1845, loss = 3.39006891\n",
      "Iteration 1846, loss = 3.38990875\n",
      "Iteration 1847, loss = 3.38974860\n",
      "Iteration 1848, loss = 3.38958848\n",
      "Iteration 1849, loss = 3.38942837\n",
      "Iteration 1850, loss = 3.38926827\n",
      "Iteration 1851, loss = 3.38910820\n",
      "Iteration 1852, loss = 3.38894813\n",
      "Iteration 1853, loss = 3.38878809\n",
      "Iteration 1854, loss = 3.38862806\n",
      "Iteration 1855, loss = 3.38846805\n",
      "Iteration 1856, loss = 3.38830805\n",
      "Iteration 1857, loss = 3.38814807\n",
      "Iteration 1858, loss = 3.38798811\n",
      "Iteration 1859, loss = 3.38782816\n",
      "Iteration 1860, loss = 3.38766823\n",
      "Iteration 1861, loss = 3.38750831\n",
      "Iteration 1862, loss = 3.38734841\n",
      "Iteration 1863, loss = 3.38718853\n",
      "Iteration 1864, loss = 3.38702866\n",
      "Iteration 1865, loss = 3.38686880\n",
      "Iteration 1866, loss = 3.38670896\n",
      "Iteration 1867, loss = 3.38654914\n",
      "Iteration 1868, loss = 3.38638933\n",
      "Iteration 1869, loss = 3.38622954\n",
      "Iteration 1870, loss = 3.38606976\n",
      "Iteration 1871, loss = 3.38590999\n",
      "Iteration 1872, loss = 3.38575025\n",
      "Iteration 1873, loss = 3.38559051\n",
      "Iteration 1874, loss = 3.38543079\n",
      "Iteration 1875, loss = 3.38527109\n",
      "Iteration 1876, loss = 3.38511140\n",
      "Iteration 1877, loss = 3.38495172\n",
      "Iteration 1878, loss = 3.38479206\n",
      "Iteration 1879, loss = 3.38463242\n",
      "Iteration 1880, loss = 3.38447279\n",
      "Iteration 1881, loss = 3.38431317\n",
      "Iteration 1882, loss = 3.38415356\n",
      "Iteration 1883, loss = 3.38399398\n",
      "Iteration 1884, loss = 3.38383440\n",
      "Iteration 1885, loss = 3.38367484\n",
      "Iteration 1886, loss = 3.38351529\n",
      "Iteration 1887, loss = 3.38335576\n",
      "Iteration 1888, loss = 3.38319624\n",
      "Iteration 1889, loss = 3.38303673\n",
      "Iteration 1890, loss = 3.38287724\n",
      "Iteration 1891, loss = 3.38271776\n",
      "Iteration 1892, loss = 3.38255830\n",
      "Iteration 1893, loss = 3.38239885\n",
      "Iteration 1894, loss = 3.38223941\n",
      "Iteration 1895, loss = 3.38207999\n",
      "Iteration 1896, loss = 3.38192058\n",
      "Iteration 1897, loss = 3.38176118\n",
      "Iteration 1898, loss = 3.38160179\n",
      "Iteration 1899, loss = 3.38144242\n",
      "Iteration 1900, loss = 3.38128306\n",
      "Iteration 1901, loss = 3.38112372\n",
      "Iteration 1902, loss = 3.38096439\n",
      "Iteration 1903, loss = 3.38080507\n",
      "Iteration 1904, loss = 3.38064576\n",
      "Iteration 1905, loss = 3.38048647\n",
      "Iteration 1906, loss = 3.38032719\n",
      "Iteration 1907, loss = 3.38016792\n",
      "Iteration 1908, loss = 3.38000866\n",
      "Iteration 1909, loss = 3.37984942\n",
      "Iteration 1910, loss = 3.37969019\n",
      "Iteration 1911, loss = 3.37953097\n",
      "Iteration 1912, loss = 3.37937176\n",
      "Iteration 1913, loss = 3.37921257\n",
      "Iteration 1914, loss = 3.37905339\n",
      "Iteration 1915, loss = 3.37889422\n",
      "Iteration 1916, loss = 3.37873506\n",
      "Iteration 1917, loss = 3.37857592\n",
      "Iteration 1918, loss = 3.37841678\n",
      "Iteration 1919, loss = 3.37825766\n",
      "Iteration 1920, loss = 3.37809855\n",
      "Iteration 1921, loss = 3.37793945\n",
      "Iteration 1922, loss = 3.37778037\n",
      "Iteration 1923, loss = 3.37762130\n",
      "Iteration 1924, loss = 3.37746223\n",
      "Iteration 1925, loss = 3.37730318\n",
      "Iteration 1926, loss = 3.37714414\n",
      "Iteration 1927, loss = 3.37698512\n",
      "Iteration 1928, loss = 3.37682610\n",
      "Iteration 1929, loss = 3.37666710\n",
      "Iteration 1930, loss = 3.37650810\n",
      "Iteration 1931, loss = 3.37634912\n",
      "Iteration 1932, loss = 3.37619015\n",
      "Iteration 1933, loss = 3.37603119\n",
      "Iteration 1934, loss = 3.37587225\n",
      "Iteration 1935, loss = 3.37571331\n",
      "Iteration 1936, loss = 3.37555438\n",
      "Iteration 1937, loss = 3.37539547\n",
      "Iteration 1938, loss = 3.37523656\n",
      "Iteration 1939, loss = 3.37507767\n",
      "Iteration 1940, loss = 3.37491879\n",
      "Iteration 1941, loss = 3.37475992\n",
      "Iteration 1942, loss = 3.37460106\n",
      "Iteration 1943, loss = 3.37444221\n",
      "Iteration 1944, loss = 3.37428337\n",
      "Iteration 1945, loss = 3.37412454\n",
      "Iteration 1946, loss = 3.37396572\n",
      "Iteration 1947, loss = 3.37380692\n",
      "Iteration 1948, loss = 3.37364812\n",
      "Iteration 1949, loss = 3.37348933\n",
      "Iteration 1950, loss = 3.37333056\n",
      "Iteration 1951, loss = 3.37317179\n",
      "Iteration 1952, loss = 3.37301304\n",
      "Iteration 1953, loss = 3.37285429\n",
      "Iteration 1954, loss = 3.37269556\n",
      "Iteration 1955, loss = 3.37253684\n",
      "Iteration 1956, loss = 3.37237812\n",
      "Iteration 1957, loss = 3.37221942\n",
      "Iteration 1958, loss = 3.37206072\n",
      "Iteration 1959, loss = 3.37190204\n",
      "Iteration 1960, loss = 3.37174336\n",
      "Iteration 1961, loss = 3.37158470\n",
      "Iteration 1962, loss = 3.37142605\n",
      "Iteration 1963, loss = 3.37126740\n",
      "Iteration 1964, loss = 3.37110877\n",
      "Iteration 1965, loss = 3.37095014\n",
      "Iteration 1966, loss = 3.37079153\n",
      "Iteration 1967, loss = 3.37063292\n",
      "Iteration 1968, loss = 3.37047432\n",
      "Iteration 1969, loss = 3.37031574\n",
      "Iteration 1970, loss = 3.37015716\n",
      "Iteration 1971, loss = 3.36999859\n",
      "Iteration 1972, loss = 3.36984004\n",
      "Iteration 1973, loss = 3.36968149\n",
      "Iteration 1974, loss = 3.36952295\n",
      "Iteration 1975, loss = 3.36936442\n",
      "Iteration 1976, loss = 3.36920590\n",
      "Iteration 1977, loss = 3.36904739\n",
      "Iteration 1978, loss = 3.36888888\n",
      "Iteration 1979, loss = 3.36873039\n",
      "Iteration 1980, loss = 3.36857191\n",
      "Iteration 1981, loss = 3.36841343\n",
      "Iteration 1982, loss = 3.36825497\n",
      "Iteration 1983, loss = 3.36809651\n",
      "Iteration 1984, loss = 3.36793806\n",
      "Iteration 1985, loss = 3.36777963\n",
      "Iteration 1986, loss = 3.36762120\n",
      "Iteration 1987, loss = 3.36746278\n",
      "Iteration 1988, loss = 3.36730436\n",
      "Iteration 1989, loss = 3.36714596\n",
      "Iteration 1990, loss = 3.36698757\n",
      "Iteration 1991, loss = 3.36682918\n",
      "Iteration 1992, loss = 3.36667080\n",
      "Iteration 1993, loss = 3.36651244\n",
      "Iteration 1994, loss = 3.36635408\n",
      "Iteration 1995, loss = 3.36619572\n",
      "Iteration 1996, loss = 3.36603738\n",
      "Iteration 1997, loss = 3.36587905\n",
      "Iteration 1998, loss = 3.36572072\n",
      "Iteration 1999, loss = 3.36556241\n",
      "Iteration 2000, loss = 3.36540410\n",
      "Iteration 1, loss = 4.92708450\n",
      "Iteration 2, loss = 4.90818501\n",
      "Iteration 3, loss = 4.88191501\n",
      "Iteration 4, loss = 4.84969595\n",
      "Iteration 5, loss = 4.81291643\n",
      "Iteration 6, loss = 4.77289534\n",
      "Iteration 7, loss = 4.73085200\n",
      "Iteration 8, loss = 4.68788254\n",
      "Iteration 9, loss = 4.64494268\n",
      "Iteration 10, loss = 4.60283714\n",
      "Iteration 11, loss = 4.56221586\n",
      "Iteration 12, loss = 4.52357682\n",
      "Iteration 13, loss = 4.48727472\n",
      "Iteration 14, loss = 4.45353462\n",
      "Iteration 15, loss = 4.42246887\n",
      "Iteration 16, loss = 4.39409591\n",
      "Iteration 17, loss = 4.36835949\n",
      "Iteration 18, loss = 4.34514709\n",
      "Iteration 19, loss = 4.32430654\n",
      "Iteration 20, loss = 4.30566050\n",
      "Iteration 21, loss = 4.28901838\n",
      "Iteration 22, loss = 4.27418581\n",
      "Iteration 23, loss = 4.26097179\n",
      "Iteration 24, loss = 4.24919387\n",
      "Iteration 25, loss = 4.23868156\n",
      "Iteration 26, loss = 4.22927839\n",
      "Iteration 27, loss = 4.22084293\n",
      "Iteration 28, loss = 4.21324891\n",
      "Iteration 29, loss = 4.20638485\n",
      "Iteration 30, loss = 4.20015326\n",
      "Iteration 31, loss = 4.19446952\n",
      "Iteration 32, loss = 4.18926075\n",
      "Iteration 33, loss = 4.18446447\n",
      "Iteration 34, loss = 4.18002743\n",
      "Iteration 35, loss = 4.17590433\n",
      "Iteration 36, loss = 4.17205679\n",
      "Iteration 37, loss = 4.16845221\n",
      "Iteration 38, loss = 4.16506297\n",
      "Iteration 39, loss = 4.16186555\n",
      "Iteration 40, loss = 4.15883985\n",
      "Iteration 41, loss = 4.15596857\n",
      "Iteration 42, loss = 4.15323676\n",
      "Iteration 43, loss = 4.15063134\n",
      "Iteration 44, loss = 4.14814079\n",
      "Iteration 45, loss = 4.14575485\n",
      "Iteration 46, loss = 4.14346432\n",
      "Iteration 47, loss = 4.14126087\n",
      "Iteration 48, loss = 4.13913691\n",
      "Iteration 49, loss = 4.13708548\n",
      "Iteration 50, loss = 4.13510017\n",
      "Iteration 51, loss = 4.13317507\n",
      "Iteration 52, loss = 4.13130474\n",
      "Iteration 53, loss = 4.12948411\n",
      "Iteration 54, loss = 4.12770855\n",
      "Iteration 55, loss = 4.12597377\n",
      "Iteration 56, loss = 4.12427582\n",
      "Iteration 57, loss = 4.12261110\n",
      "Iteration 58, loss = 4.12097631\n",
      "Iteration 59, loss = 4.11936846\n",
      "Iteration 60, loss = 4.11778484\n",
      "Iteration 61, loss = 4.11622300\n",
      "Iteration 62, loss = 4.11468073\n",
      "Iteration 63, loss = 4.11315606\n",
      "Iteration 64, loss = 4.11164724\n",
      "Iteration 65, loss = 4.11015269\n",
      "Iteration 66, loss = 4.10867103\n",
      "Iteration 67, loss = 4.10720103\n",
      "Iteration 68, loss = 4.10574160\n",
      "Iteration 69, loss = 4.10429180\n",
      "Iteration 70, loss = 4.10285079\n",
      "Iteration 71, loss = 4.10141783\n",
      "Iteration 72, loss = 4.09999228\n",
      "Iteration 73, loss = 4.09857357\n",
      "Iteration 74, loss = 4.09716121\n",
      "Iteration 75, loss = 4.09575476\n",
      "Iteration 76, loss = 4.09435385\n",
      "Iteration 77, loss = 4.09295814\n",
      "Iteration 78, loss = 4.09156732\n",
      "Iteration 79, loss = 4.09018114\n",
      "Iteration 80, loss = 4.08879936\n",
      "Iteration 81, loss = 4.08742178\n",
      "Iteration 82, loss = 4.08604820\n",
      "Iteration 83, loss = 4.08467846\n",
      "Iteration 84, loss = 4.08331240\n",
      "Iteration 85, loss = 4.08194988\n",
      "Iteration 86, loss = 4.08059078\n",
      "Iteration 87, loss = 4.07923496\n",
      "Iteration 88, loss = 4.07788232\n",
      "Iteration 89, loss = 4.07653276\n",
      "Iteration 90, loss = 4.07518617\n",
      "Iteration 91, loss = 4.07384245\n",
      "Iteration 92, loss = 4.07250153\n",
      "Iteration 93, loss = 4.07116330\n",
      "Iteration 94, loss = 4.06982770\n",
      "Iteration 95, loss = 4.06849464\n",
      "Iteration 96, loss = 4.06716403\n",
      "Iteration 97, loss = 4.06583582\n",
      "Iteration 98, loss = 4.06450993\n",
      "Iteration 99, loss = 4.06318628\n",
      "Iteration 100, loss = 4.06186482\n",
      "Iteration 101, loss = 4.06054548\n",
      "Iteration 102, loss = 4.05922820\n",
      "Iteration 103, loss = 4.05791293\n",
      "Iteration 104, loss = 4.05659960\n",
      "Iteration 105, loss = 4.05528816\n",
      "Iteration 106, loss = 4.05397857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 107, loss = 4.05267078\n",
      "Iteration 108, loss = 4.05136474\n",
      "Iteration 109, loss = 4.05006041\n",
      "Iteration 110, loss = 4.04875776\n",
      "Iteration 111, loss = 4.04745674\n",
      "Iteration 112, loss = 4.04615733\n",
      "Iteration 113, loss = 4.04485950\n",
      "Iteration 114, loss = 4.04356321\n",
      "Iteration 115, loss = 4.04226844\n",
      "Iteration 116, loss = 4.04097517\n",
      "Iteration 117, loss = 4.03968338\n",
      "Iteration 118, loss = 4.03839305\n",
      "Iteration 119, loss = 4.03710417\n",
      "Iteration 120, loss = 4.03581673\n",
      "Iteration 121, loss = 4.03453070\n",
      "Iteration 122, loss = 4.03324609\n",
      "Iteration 123, loss = 4.03196289\n",
      "Iteration 124, loss = 4.03068109\n",
      "Iteration 125, loss = 4.02940070\n",
      "Iteration 126, loss = 4.02812170\n",
      "Iteration 127, loss = 4.02684411\n",
      "Iteration 128, loss = 4.02556793\n",
      "Iteration 129, loss = 4.02429315\n",
      "Iteration 130, loss = 4.02301979\n",
      "Iteration 131, loss = 4.02174785\n",
      "Iteration 132, loss = 4.02047735\n",
      "Iteration 133, loss = 4.01920830\n",
      "Iteration 134, loss = 4.01794070\n",
      "Iteration 135, loss = 4.01667458\n",
      "Iteration 136, loss = 4.01540994\n",
      "Iteration 137, loss = 4.01414681\n",
      "Iteration 138, loss = 4.01288520\n",
      "Iteration 139, loss = 4.01162514\n",
      "Iteration 140, loss = 4.01036663\n",
      "Iteration 141, loss = 4.00910972\n",
      "Iteration 142, loss = 4.00785441\n",
      "Iteration 143, loss = 4.00660073\n",
      "Iteration 144, loss = 4.00534872\n",
      "Iteration 145, loss = 4.00409839\n",
      "Iteration 146, loss = 4.00284977\n",
      "Iteration 147, loss = 4.00160290\n",
      "Iteration 148, loss = 4.00035779\n",
      "Iteration 149, loss = 3.99911449\n",
      "Iteration 150, loss = 3.99787303\n",
      "Iteration 151, loss = 3.99663343\n",
      "Iteration 152, loss = 3.99539573\n",
      "Iteration 153, loss = 3.99415997\n",
      "Iteration 154, loss = 3.99292618\n",
      "Iteration 155, loss = 3.99169439\n",
      "Iteration 156, loss = 3.99046465\n",
      "Iteration 157, loss = 3.98923699\n",
      "Iteration 158, loss = 3.98801145\n",
      "Iteration 159, loss = 3.98678807\n",
      "Iteration 160, loss = 3.98556689\n",
      "Iteration 161, loss = 3.98434795\n",
      "Iteration 162, loss = 3.98313129\n",
      "Iteration 163, loss = 3.98191695\n",
      "Iteration 164, loss = 3.98070497\n",
      "Iteration 165, loss = 3.97949540\n",
      "Iteration 166, loss = 3.97828828\n",
      "Iteration 167, loss = 3.97708366\n",
      "Iteration 168, loss = 3.97588157\n",
      "Iteration 169, loss = 3.97468206\n",
      "Iteration 170, loss = 3.97348518\n",
      "Iteration 171, loss = 3.97229098\n",
      "Iteration 172, loss = 3.97109949\n",
      "Iteration 173, loss = 3.96991076\n",
      "Iteration 174, loss = 3.96872484\n",
      "Iteration 175, loss = 3.96754178\n",
      "Iteration 176, loss = 3.96636161\n",
      "Iteration 177, loss = 3.96518440\n",
      "Iteration 178, loss = 3.96401018\n",
      "Iteration 179, loss = 3.96283899\n",
      "Iteration 180, loss = 3.96167090\n",
      "Iteration 181, loss = 3.96050594\n",
      "Iteration 182, loss = 3.95934416\n",
      "Iteration 183, loss = 3.95818560\n",
      "Iteration 184, loss = 3.95703032\n",
      "Iteration 185, loss = 3.95587836\n",
      "Iteration 186, loss = 3.95472976\n",
      "Iteration 187, loss = 3.95358458\n",
      "Iteration 188, loss = 3.95244285\n",
      "Iteration 189, loss = 3.95130462\n",
      "Iteration 190, loss = 3.95016994\n",
      "Iteration 191, loss = 3.94903886\n",
      "Iteration 192, loss = 3.94791141\n",
      "Iteration 193, loss = 3.94678764\n",
      "Iteration 194, loss = 3.94566760\n",
      "Iteration 195, loss = 3.94455132\n",
      "Iteration 196, loss = 3.94343886\n",
      "Iteration 197, loss = 3.94233025\n",
      "Iteration 198, loss = 3.94122553\n",
      "Iteration 199, loss = 3.94012475\n",
      "Iteration 200, loss = 3.93902795\n",
      "Iteration 201, loss = 3.93793517\n",
      "Iteration 202, loss = 3.93684645\n",
      "Iteration 203, loss = 3.93576182\n",
      "Iteration 204, loss = 3.93468133\n",
      "Iteration 205, loss = 3.93360501\n",
      "Iteration 206, loss = 3.93253289\n",
      "Iteration 207, loss = 3.93146503\n",
      "Iteration 208, loss = 3.93040144\n",
      "Iteration 209, loss = 3.92934217\n",
      "Iteration 210, loss = 3.92828726\n",
      "Iteration 211, loss = 3.92723672\n",
      "Iteration 212, loss = 3.92619060\n",
      "Iteration 213, loss = 3.92514892\n",
      "Iteration 214, loss = 3.92411172\n",
      "Iteration 215, loss = 3.92307903\n",
      "Iteration 216, loss = 3.92205088\n",
      "Iteration 217, loss = 3.92102729\n",
      "Iteration 218, loss = 3.92000829\n",
      "Iteration 219, loss = 3.91899390\n",
      "Iteration 220, loss = 3.91798416\n",
      "Iteration 221, loss = 3.91697908\n",
      "Iteration 222, loss = 3.91597870\n",
      "Iteration 223, loss = 3.91498302\n",
      "Iteration 224, loss = 3.91399208\n",
      "Iteration 225, loss = 3.91300590\n",
      "Iteration 226, loss = 3.91202448\n",
      "Iteration 227, loss = 3.91104786\n",
      "Iteration 228, loss = 3.91007605\n",
      "Iteration 229, loss = 3.90910906\n",
      "Iteration 230, loss = 3.90814691\n",
      "Iteration 231, loss = 3.90718962\n",
      "Iteration 232, loss = 3.90623720\n",
      "Iteration 233, loss = 3.90528966\n",
      "Iteration 234, loss = 3.90434701\n",
      "Iteration 235, loss = 3.90340926\n",
      "Iteration 236, loss = 3.90247643\n",
      "Iteration 237, loss = 3.90154852\n",
      "Iteration 238, loss = 3.90062554\n",
      "Iteration 239, loss = 3.89970749\n",
      "Iteration 240, loss = 3.89879438\n",
      "Iteration 241, loss = 3.89788622\n",
      "Iteration 242, loss = 3.89698300\n",
      "Iteration 243, loss = 3.89608474\n",
      "Iteration 244, loss = 3.89519143\n",
      "Iteration 245, loss = 3.89430307\n",
      "Iteration 246, loss = 3.89341966\n",
      "Iteration 247, loss = 3.89254121\n",
      "Iteration 248, loss = 3.89166770\n",
      "Iteration 249, loss = 3.89079914\n",
      "Iteration 250, loss = 3.88993553\n",
      "Iteration 251, loss = 3.88907685\n",
      "Iteration 252, loss = 3.88822310\n",
      "Iteration 253, loss = 3.88737427\n",
      "Iteration 254, loss = 3.88653037\n",
      "Iteration 255, loss = 3.88569137\n",
      "Iteration 256, loss = 3.88485727\n",
      "Iteration 257, loss = 3.88402805\n",
      "Iteration 258, loss = 3.88320372\n",
      "Iteration 259, loss = 3.88238425\n",
      "Iteration 260, loss = 3.88156964\n",
      "Iteration 261, loss = 3.88075987\n",
      "Iteration 262, loss = 3.87995492\n",
      "Iteration 263, loss = 3.87915479\n",
      "Iteration 264, loss = 3.87835945\n",
      "Iteration 265, loss = 3.87756889\n",
      "Iteration 266, loss = 3.87678310\n",
      "Iteration 267, loss = 3.87600205\n",
      "Iteration 268, loss = 3.87522572\n",
      "Iteration 269, loss = 3.87445411\n",
      "Iteration 270, loss = 3.87368718\n",
      "Iteration 271, loss = 3.87292492\n",
      "Iteration 272, loss = 3.87216731\n",
      "Iteration 273, loss = 3.87141432\n",
      "Iteration 274, loss = 3.87066594\n",
      "Iteration 275, loss = 3.86992214\n",
      "Iteration 276, loss = 3.86918290\n",
      "Iteration 277, loss = 3.86844820\n",
      "Iteration 278, loss = 3.86771800\n",
      "Iteration 279, loss = 3.86699229\n",
      "Iteration 280, loss = 3.86627104\n",
      "Iteration 281, loss = 3.86555423\n",
      "Iteration 282, loss = 3.86484183\n",
      "Iteration 283, loss = 3.86413381\n",
      "Iteration 284, loss = 3.86343015\n",
      "Iteration 285, loss = 3.86273081\n",
      "Iteration 286, loss = 3.86203578\n",
      "Iteration 287, loss = 3.86134503\n",
      "Iteration 288, loss = 3.86065852\n",
      "Iteration 289, loss = 3.85997622\n",
      "Iteration 290, loss = 3.85929812\n",
      "Iteration 291, loss = 3.85862417\n",
      "Iteration 292, loss = 3.85795436\n",
      "Iteration 293, loss = 3.85728864\n",
      "Iteration 294, loss = 3.85662700\n",
      "Iteration 295, loss = 3.85596939\n",
      "Iteration 296, loss = 3.85531580\n",
      "Iteration 297, loss = 3.85466618\n",
      "Iteration 298, loss = 3.85402051\n",
      "Iteration 299, loss = 3.85337876\n",
      "Iteration 300, loss = 3.85274090\n",
      "Iteration 301, loss = 3.85210689\n",
      "Iteration 302, loss = 3.85147670\n",
      "Iteration 303, loss = 3.85085031\n",
      "Iteration 304, loss = 3.85022768\n",
      "Iteration 305, loss = 3.84960877\n",
      "Iteration 306, loss = 3.84899356\n",
      "Iteration 307, loss = 3.84838201\n",
      "Iteration 308, loss = 3.84777410\n",
      "Iteration 309, loss = 3.84716979\n",
      "Iteration 310, loss = 3.84656904\n",
      "Iteration 311, loss = 3.84597184\n",
      "Iteration 312, loss = 3.84537813\n",
      "Iteration 313, loss = 3.84478790\n",
      "Iteration 314, loss = 3.84420111\n",
      "Iteration 315, loss = 3.84361772\n",
      "Iteration 316, loss = 3.84303771\n",
      "Iteration 317, loss = 3.84246104\n",
      "Iteration 318, loss = 3.84188769\n",
      "Iteration 319, loss = 3.84131761\n",
      "Iteration 320, loss = 3.84075078\n",
      "Iteration 321, loss = 3.84018717\n",
      "Iteration 322, loss = 3.83962674\n",
      "Iteration 323, loss = 3.83906946\n",
      "Iteration 324, loss = 3.83851530\n",
      "Iteration 325, loss = 3.83796423\n",
      "Iteration 326, loss = 3.83741621\n",
      "Iteration 327, loss = 3.83687123\n",
      "Iteration 328, loss = 3.83632923\n",
      "Iteration 329, loss = 3.83579020\n",
      "Iteration 330, loss = 3.83525411\n",
      "Iteration 331, loss = 3.83472091\n",
      "Iteration 332, loss = 3.83419058\n",
      "Iteration 333, loss = 3.83366310\n",
      "Iteration 334, loss = 3.83313843\n",
      "Iteration 335, loss = 3.83261653\n",
      "Iteration 336, loss = 3.83209739\n",
      "Iteration 337, loss = 3.83158096\n",
      "Iteration 338, loss = 3.83106723\n",
      "Iteration 339, loss = 3.83055616\n",
      "Iteration 340, loss = 3.83004772\n",
      "Iteration 341, loss = 3.82954188\n",
      "Iteration 342, loss = 3.82903862\n",
      "Iteration 343, loss = 3.82853790\n",
      "Iteration 344, loss = 3.82803969\n",
      "Iteration 345, loss = 3.82754398\n",
      "Iteration 346, loss = 3.82705072\n",
      "Iteration 347, loss = 3.82655990\n",
      "Iteration 348, loss = 3.82607148\n",
      "Iteration 349, loss = 3.82558544\n",
      "Iteration 350, loss = 3.82510175\n",
      "Iteration 351, loss = 3.82462038\n",
      "Iteration 352, loss = 3.82414130\n",
      "Iteration 353, loss = 3.82366450\n",
      "Iteration 354, loss = 3.82318994\n",
      "Iteration 355, loss = 3.82271760\n",
      "Iteration 356, loss = 3.82224744\n",
      "Iteration 357, loss = 3.82177946\n",
      "Iteration 358, loss = 3.82131361\n",
      "Iteration 359, loss = 3.82084988\n",
      "Iteration 360, loss = 3.82038823\n",
      "Iteration 361, loss = 3.81992866\n",
      "Iteration 362, loss = 3.81947112\n",
      "Iteration 363, loss = 3.81901560\n",
      "Iteration 364, loss = 3.81856207\n",
      "Iteration 365, loss = 3.81811051\n",
      "Iteration 366, loss = 3.81766090\n",
      "Iteration 367, loss = 3.81721321\n",
      "Iteration 368, loss = 3.81676742\n",
      "Iteration 369, loss = 3.81632350\n",
      "Iteration 370, loss = 3.81588144\n",
      "Iteration 371, loss = 3.81544121\n",
      "Iteration 372, loss = 3.81500279\n",
      "Iteration 373, loss = 3.81456615\n",
      "Iteration 374, loss = 3.81413128\n",
      "Iteration 375, loss = 3.81369816\n",
      "Iteration 376, loss = 3.81326676\n",
      "Iteration 377, loss = 3.81283706\n",
      "Iteration 378, loss = 3.81240905\n",
      "Iteration 379, loss = 3.81198270\n",
      "Iteration 380, loss = 3.81155798\n",
      "Iteration 381, loss = 3.81113489\n",
      "Iteration 382, loss = 3.81071341\n",
      "Iteration 383, loss = 3.81029350\n",
      "Iteration 384, loss = 3.80987516\n",
      "Iteration 385, loss = 3.80945836\n",
      "Iteration 386, loss = 3.80904309\n",
      "Iteration 387, loss = 3.80862932\n",
      "Iteration 388, loss = 3.80821705\n",
      "Iteration 389, loss = 3.80780624\n",
      "Iteration 390, loss = 3.80739689\n",
      "Iteration 391, loss = 3.80698897\n",
      "Iteration 392, loss = 3.80658247\n",
      "Iteration 393, loss = 3.80617738\n",
      "Iteration 394, loss = 3.80577366\n",
      "Iteration 395, loss = 3.80537131\n",
      "Iteration 396, loss = 3.80497031\n",
      "Iteration 397, loss = 3.80457065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 398, loss = 3.80417231\n",
      "Iteration 399, loss = 3.80377526\n",
      "Iteration 400, loss = 3.80337951\n",
      "Iteration 401, loss = 3.80298502\n",
      "Iteration 402, loss = 3.80259179\n",
      "Iteration 403, loss = 3.80219980\n",
      "Iteration 404, loss = 3.80180904\n",
      "Iteration 405, loss = 3.80141948\n",
      "Iteration 406, loss = 3.80103113\n",
      "Iteration 407, loss = 3.80064395\n",
      "Iteration 408, loss = 3.80025795\n",
      "Iteration 409, loss = 3.79987310\n",
      "Iteration 410, loss = 3.79948939\n",
      "Iteration 411, loss = 3.79910680\n",
      "Iteration 412, loss = 3.79872533\n",
      "Iteration 413, loss = 3.79834496\n",
      "Iteration 414, loss = 3.79796568\n",
      "Iteration 415, loss = 3.79758748\n",
      "Iteration 416, loss = 3.79721033\n",
      "Iteration 417, loss = 3.79683424\n",
      "Iteration 418, loss = 3.79645918\n",
      "Iteration 419, loss = 3.79608515\n",
      "Iteration 420, loss = 3.79571213\n",
      "Iteration 421, loss = 3.79534012\n",
      "Iteration 422, loss = 3.79496909\n",
      "Iteration 423, loss = 3.79459905\n",
      "Iteration 424, loss = 3.79422997\n",
      "Iteration 425, loss = 3.79386185\n",
      "Iteration 426, loss = 3.79349467\n",
      "Iteration 427, loss = 3.79312843\n",
      "Iteration 428, loss = 3.79276311\n",
      "Iteration 429, loss = 3.79239871\n",
      "Iteration 430, loss = 3.79203521\n",
      "Iteration 431, loss = 3.79167260\n",
      "Iteration 432, loss = 3.79131088\n",
      "Iteration 433, loss = 3.79095003\n",
      "Iteration 434, loss = 3.79059004\n",
      "Iteration 435, loss = 3.79023091\n",
      "Iteration 436, loss = 3.78987262\n",
      "Iteration 437, loss = 3.78951517\n",
      "Iteration 438, loss = 3.78915855\n",
      "Iteration 439, loss = 3.78880274\n",
      "Iteration 440, loss = 3.78844774\n",
      "Iteration 441, loss = 3.78809354\n",
      "Iteration 442, loss = 3.78774013\n",
      "Iteration 443, loss = 3.78738751\n",
      "Iteration 444, loss = 3.78703566\n",
      "Iteration 445, loss = 3.78668457\n",
      "Iteration 446, loss = 3.78633424\n",
      "Iteration 447, loss = 3.78598466\n",
      "Iteration 448, loss = 3.78563583\n",
      "Iteration 449, loss = 3.78528772\n",
      "Iteration 450, loss = 3.78494035\n",
      "Iteration 451, loss = 3.78459369\n",
      "Iteration 452, loss = 3.78424775\n",
      "Iteration 453, loss = 3.78390251\n",
      "Iteration 454, loss = 3.78355796\n",
      "Iteration 455, loss = 3.78321411\n",
      "Iteration 456, loss = 3.78287094\n",
      "Iteration 457, loss = 3.78252844\n",
      "Iteration 458, loss = 3.78218662\n",
      "Iteration 459, loss = 3.78184545\n",
      "Iteration 460, loss = 3.78150495\n",
      "Iteration 461, loss = 3.78116509\n",
      "Iteration 462, loss = 3.78082588\n",
      "Iteration 463, loss = 3.78048730\n",
      "Iteration 464, loss = 3.78014935\n",
      "Iteration 465, loss = 3.77981203\n",
      "Iteration 466, loss = 3.77947533\n",
      "Iteration 467, loss = 3.77913924\n",
      "Iteration 468, loss = 3.77880376\n",
      "Iteration 469, loss = 3.77846888\n",
      "Iteration 470, loss = 3.77813459\n",
      "Iteration 471, loss = 3.77780089\n",
      "Iteration 472, loss = 3.77746778\n",
      "Iteration 473, loss = 3.77713525\n",
      "Iteration 474, loss = 3.77680329\n",
      "Iteration 475, loss = 3.77647191\n",
      "Iteration 476, loss = 3.77614108\n",
      "Iteration 477, loss = 3.77581081\n",
      "Iteration 478, loss = 3.77548110\n",
      "Iteration 479, loss = 3.77515194\n",
      "Iteration 480, loss = 3.77482331\n",
      "Iteration 481, loss = 3.77449523\n",
      "Iteration 482, loss = 3.77416769\n",
      "Iteration 483, loss = 3.77384067\n",
      "Iteration 484, loss = 3.77351418\n",
      "Iteration 485, loss = 3.77318821\n",
      "Iteration 486, loss = 3.77286275\n",
      "Iteration 487, loss = 3.77253781\n",
      "Iteration 488, loss = 3.77221337\n",
      "Iteration 489, loss = 3.77188944\n",
      "Iteration 490, loss = 3.77156601\n",
      "Iteration 491, loss = 3.77124307\n",
      "Iteration 492, loss = 3.77092063\n",
      "Iteration 493, loss = 3.77059867\n",
      "Iteration 494, loss = 3.77027720\n",
      "Iteration 495, loss = 3.76995620\n",
      "Iteration 496, loss = 3.76963568\n",
      "Iteration 497, loss = 3.76931564\n",
      "Iteration 498, loss = 3.76899606\n",
      "Iteration 499, loss = 3.76867695\n",
      "Iteration 500, loss = 3.76835830\n",
      "Iteration 501, loss = 3.76804010\n",
      "Iteration 502, loss = 3.76772236\n",
      "Iteration 503, loss = 3.76740508\n",
      "Iteration 504, loss = 3.76708823\n",
      "Iteration 505, loss = 3.76677184\n",
      "Iteration 506, loss = 3.76645588\n",
      "Iteration 507, loss = 3.76614037\n",
      "Iteration 508, loss = 3.76582529\n",
      "Iteration 509, loss = 3.76551064\n",
      "Iteration 510, loss = 3.76519642\n",
      "Iteration 511, loss = 3.76488262\n",
      "Iteration 512, loss = 3.76456925\n",
      "Iteration 513, loss = 3.76425629\n",
      "Iteration 514, loss = 3.76394376\n",
      "Iteration 515, loss = 3.76363164\n",
      "Iteration 516, loss = 3.76331993\n",
      "Iteration 517, loss = 3.76300863\n",
      "Iteration 518, loss = 3.76269773\n",
      "Iteration 519, loss = 3.76238724\n",
      "Iteration 520, loss = 3.76207715\n",
      "Iteration 521, loss = 3.76176746\n",
      "Iteration 522, loss = 3.76145816\n",
      "Iteration 523, loss = 3.76114926\n",
      "Iteration 524, loss = 3.76084074\n",
      "Iteration 525, loss = 3.76053262\n",
      "Iteration 526, loss = 3.76022488\n",
      "Iteration 527, loss = 3.75991752\n",
      "Iteration 528, loss = 3.75961055\n",
      "Iteration 529, loss = 3.75930395\n",
      "Iteration 530, loss = 3.75899774\n",
      "Iteration 531, loss = 3.75869189\n",
      "Iteration 532, loss = 3.75838642\n",
      "Iteration 533, loss = 3.75808132\n",
      "Iteration 534, loss = 3.75777659\n",
      "Iteration 535, loss = 3.75747222\n",
      "Iteration 536, loss = 3.75716822\n",
      "Iteration 537, loss = 3.75686458\n",
      "Iteration 538, loss = 3.75656129\n",
      "Iteration 539, loss = 3.75625837\n",
      "Iteration 540, loss = 3.75595580\n",
      "Iteration 541, loss = 3.75565359\n",
      "Iteration 542, loss = 3.75535173\n",
      "Iteration 543, loss = 3.75505022\n",
      "Iteration 544, loss = 3.75474906\n",
      "Iteration 545, loss = 3.75444824\n",
      "Iteration 546, loss = 3.75414777\n",
      "Iteration 547, loss = 3.75384765\n",
      "Iteration 548, loss = 3.75354786\n",
      "Iteration 549, loss = 3.75324842\n",
      "Iteration 550, loss = 3.75294931\n",
      "Iteration 551, loss = 3.75265054\n",
      "Iteration 552, loss = 3.75235211\n",
      "Iteration 553, loss = 3.75205401\n",
      "Iteration 554, loss = 3.75175624\n",
      "Iteration 555, loss = 3.75145880\n",
      "Iteration 556, loss = 3.75116169\n",
      "Iteration 557, loss = 3.75086490\n",
      "Iteration 558, loss = 3.75056845\n",
      "Iteration 559, loss = 3.75027232\n",
      "Iteration 560, loss = 3.74997651\n",
      "Iteration 561, loss = 3.74968102\n",
      "Iteration 562, loss = 3.74938585\n",
      "Iteration 563, loss = 3.74909100\n",
      "Iteration 564, loss = 3.74879647\n",
      "Iteration 565, loss = 3.74850225\n",
      "Iteration 566, loss = 3.74820835\n",
      "Iteration 567, loss = 3.74791476\n",
      "Iteration 568, loss = 3.74762149\n",
      "Iteration 569, loss = 3.74732852\n",
      "Iteration 570, loss = 3.74703587\n",
      "Iteration 571, loss = 3.74674352\n",
      "Iteration 572, loss = 3.74645148\n",
      "Iteration 573, loss = 3.74615975\n",
      "Iteration 574, loss = 3.74586832\n",
      "Iteration 575, loss = 3.74557719\n",
      "Iteration 576, loss = 3.74528637\n",
      "Iteration 577, loss = 3.74499585\n",
      "Iteration 578, loss = 3.74470563\n",
      "Iteration 579, loss = 3.74441571\n",
      "Iteration 580, loss = 3.74412609\n",
      "Iteration 581, loss = 3.74383676\n",
      "Iteration 582, loss = 3.74354773\n",
      "Iteration 583, loss = 3.74325900\n",
      "Iteration 584, loss = 3.74297055\n",
      "Iteration 585, loss = 3.74268241\n",
      "Iteration 586, loss = 3.74239455\n",
      "Iteration 587, loss = 3.74210698\n",
      "Iteration 588, loss = 3.74181971\n",
      "Iteration 589, loss = 3.74153272\n",
      "Iteration 590, loss = 3.74124603\n",
      "Iteration 591, loss = 3.74095961\n",
      "Iteration 592, loss = 3.74067349\n",
      "Iteration 593, loss = 3.74038765\n",
      "Iteration 594, loss = 3.74010210\n",
      "Iteration 595, loss = 3.73981682\n",
      "Iteration 596, loss = 3.73953183\n",
      "Iteration 597, loss = 3.73924713\n",
      "Iteration 598, loss = 3.73896270\n",
      "Iteration 599, loss = 3.73867856\n",
      "Iteration 600, loss = 3.73839469\n",
      "Iteration 601, loss = 3.73811110\n",
      "Iteration 602, loss = 3.73782779\n",
      "Iteration 603, loss = 3.73754476\n",
      "Iteration 604, loss = 3.73726200\n",
      "Iteration 605, loss = 3.73697952\n",
      "Iteration 606, loss = 3.73669731\n",
      "Iteration 607, loss = 3.73641537\n",
      "Iteration 608, loss = 3.73613371\n",
      "Iteration 609, loss = 3.73585232\n",
      "Iteration 610, loss = 3.73557121\n",
      "Iteration 611, loss = 3.73529036\n",
      "Iteration 612, loss = 3.73500978\n",
      "Iteration 613, loss = 3.73472948\n",
      "Iteration 614, loss = 3.73444944\n",
      "Iteration 615, loss = 3.73416967\n",
      "Iteration 616, loss = 3.73389016\n",
      "Iteration 617, loss = 3.73361093\n",
      "Iteration 618, loss = 3.73333196\n",
      "Iteration 619, loss = 3.73305325\n",
      "Iteration 620, loss = 3.73277481\n",
      "Iteration 621, loss = 3.73249663\n",
      "Iteration 622, loss = 3.73221872\n",
      "Iteration 623, loss = 3.73194107\n",
      "Iteration 624, loss = 3.73166368\n",
      "Iteration 625, loss = 3.73138655\n",
      "Iteration 626, loss = 3.73110968\n",
      "Iteration 627, loss = 3.73083308\n",
      "Iteration 628, loss = 3.73055673\n",
      "Iteration 629, loss = 3.73028064\n",
      "Iteration 630, loss = 3.73000481\n",
      "Iteration 631, loss = 3.72972924\n",
      "Iteration 632, loss = 3.72945392\n",
      "Iteration 633, loss = 3.72917886\n",
      "Iteration 634, loss = 3.72890406\n",
      "Iteration 635, loss = 3.72862951\n",
      "Iteration 636, loss = 3.72835522\n",
      "Iteration 637, loss = 3.72808118\n",
      "Iteration 638, loss = 3.72780739\n",
      "Iteration 639, loss = 3.72753386\n",
      "Iteration 640, loss = 3.72726058\n",
      "Iteration 641, loss = 3.72698755\n",
      "Iteration 642, loss = 3.72671478\n",
      "Iteration 643, loss = 3.72644225\n",
      "Iteration 644, loss = 3.72616998\n",
      "Iteration 645, loss = 3.72589795\n",
      "Iteration 646, loss = 3.72562618\n",
      "Iteration 647, loss = 3.72535465\n",
      "Iteration 648, loss = 3.72508338\n",
      "Iteration 649, loss = 3.72481234\n",
      "Iteration 650, loss = 3.72454156\n",
      "Iteration 651, loss = 3.72427103\n",
      "Iteration 652, loss = 3.72400074\n",
      "Iteration 653, loss = 3.72373069\n",
      "Iteration 654, loss = 3.72346089\n",
      "Iteration 655, loss = 3.72319134\n",
      "Iteration 656, loss = 3.72292203\n",
      "Iteration 657, loss = 3.72265296\n",
      "Iteration 658, loss = 3.72238414\n",
      "Iteration 659, loss = 3.72211556\n",
      "Iteration 660, loss = 3.72184722\n",
      "Iteration 661, loss = 3.72157912\n",
      "Iteration 662, loss = 3.72131127\n",
      "Iteration 663, loss = 3.72104365\n",
      "Iteration 664, loss = 3.72077628\n",
      "Iteration 665, loss = 3.72050914\n",
      "Iteration 666, loss = 3.72024225\n",
      "Iteration 667, loss = 3.71997559\n",
      "Iteration 668, loss = 3.71970918\n",
      "Iteration 669, loss = 3.71944300\n",
      "Iteration 670, loss = 3.71917705\n",
      "Iteration 671, loss = 3.71891135\n",
      "Iteration 672, loss = 3.71864588\n",
      "Iteration 673, loss = 3.71838065\n",
      "Iteration 674, loss = 3.71811565\n",
      "Iteration 675, loss = 3.71785089\n",
      "Iteration 676, loss = 3.71758636\n",
      "Iteration 677, loss = 3.71732206\n",
      "Iteration 678, loss = 3.71705800\n",
      "Iteration 679, loss = 3.71679418\n",
      "Iteration 680, loss = 3.71653058\n",
      "Iteration 681, loss = 3.71626722\n",
      "Iteration 682, loss = 3.71600409\n",
      "Iteration 683, loss = 3.71574119\n",
      "Iteration 684, loss = 3.71547852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 685, loss = 3.71521608\n",
      "Iteration 686, loss = 3.71495388\n",
      "Iteration 687, loss = 3.71469190\n",
      "Iteration 688, loss = 3.71443015\n",
      "Iteration 689, loss = 3.71416863\n",
      "Iteration 690, loss = 3.71390733\n",
      "Iteration 691, loss = 3.71364627\n",
      "Iteration 692, loss = 3.71338543\n",
      "Iteration 693, loss = 3.71312482\n",
      "Iteration 694, loss = 3.71286443\n",
      "Iteration 695, loss = 3.71260427\n",
      "Iteration 696, loss = 3.71234434\n",
      "Iteration 697, loss = 3.71208463\n",
      "Iteration 698, loss = 3.71182514\n",
      "Iteration 699, loss = 3.71156588\n",
      "Iteration 700, loss = 3.71130684\n",
      "Iteration 701, loss = 3.71104802\n",
      "Iteration 702, loss = 3.71078943\n",
      "Iteration 703, loss = 3.71053105\n",
      "Iteration 704, loss = 3.71027290\n",
      "Iteration 705, loss = 3.71001497\n",
      "Iteration 706, loss = 3.70975726\n",
      "Iteration 707, loss = 3.70949977\n",
      "Iteration 708, loss = 3.70924250\n",
      "Iteration 709, loss = 3.70898545\n",
      "Iteration 710, loss = 3.70872862\n",
      "Iteration 711, loss = 3.70847200\n",
      "Iteration 712, loss = 3.70821561\n",
      "Iteration 713, loss = 3.70795943\n",
      "Iteration 714, loss = 3.70770346\n",
      "Iteration 715, loss = 3.70744771\n",
      "Iteration 716, loss = 3.70719218\n",
      "Iteration 717, loss = 3.70693686\n",
      "Iteration 718, loss = 3.70668176\n",
      "Iteration 719, loss = 3.70642687\n",
      "Iteration 720, loss = 3.70617220\n",
      "Iteration 721, loss = 3.70591773\n",
      "Iteration 722, loss = 3.70566348\n",
      "Iteration 723, loss = 3.70540945\n",
      "Iteration 724, loss = 3.70515562\n",
      "Iteration 725, loss = 3.70490200\n",
      "Iteration 726, loss = 3.70464860\n",
      "Iteration 727, loss = 3.70439540\n",
      "Iteration 728, loss = 3.70414242\n",
      "Iteration 729, loss = 3.70388964\n",
      "Iteration 730, loss = 3.70363707\n",
      "Iteration 731, loss = 3.70338471\n",
      "Iteration 732, loss = 3.70313256\n",
      "Iteration 733, loss = 3.70288061\n",
      "Iteration 734, loss = 3.70262887\n",
      "Iteration 735, loss = 3.70237734\n",
      "Iteration 736, loss = 3.70212601\n",
      "Iteration 737, loss = 3.70187488\n",
      "Iteration 738, loss = 3.70162396\n",
      "Iteration 739, loss = 3.70137325\n",
      "Iteration 740, loss = 3.70112273\n",
      "Iteration 741, loss = 3.70087242\n",
      "Iteration 742, loss = 3.70062231\n",
      "Iteration 743, loss = 3.70037240\n",
      "Iteration 744, loss = 3.70012270\n",
      "Iteration 745, loss = 3.69987319\n",
      "Iteration 746, loss = 3.69962388\n",
      "Iteration 747, loss = 3.69937478\n",
      "Iteration 748, loss = 3.69912587\n",
      "Iteration 749, loss = 3.69887716\n",
      "Iteration 750, loss = 3.69862864\n",
      "Iteration 751, loss = 3.69838033\n",
      "Iteration 752, loss = 3.69813221\n",
      "Iteration 753, loss = 3.69788428\n",
      "Iteration 754, loss = 3.69763655\n",
      "Iteration 755, loss = 3.69738902\n",
      "Iteration 756, loss = 3.69714168\n",
      "Iteration 757, loss = 3.69689453\n",
      "Iteration 758, loss = 3.69664758\n",
      "Iteration 759, loss = 3.69640082\n",
      "Iteration 760, loss = 3.69615425\n",
      "Iteration 761, loss = 3.69590787\n",
      "Iteration 762, loss = 3.69566168\n",
      "Iteration 763, loss = 3.69541569\n",
      "Iteration 764, loss = 3.69516988\n",
      "Iteration 765, loss = 3.69492426\n",
      "Iteration 766, loss = 3.69467883\n",
      "Iteration 767, loss = 3.69443359\n",
      "Iteration 768, loss = 3.69418853\n",
      "Iteration 769, loss = 3.69394366\n",
      "Iteration 770, loss = 3.69369898\n",
      "Iteration 771, loss = 3.69345448\n",
      "Iteration 772, loss = 3.69321016\n",
      "Iteration 773, loss = 3.69296603\n",
      "Iteration 774, loss = 3.69272209\n",
      "Iteration 775, loss = 3.69247832\n",
      "Iteration 776, loss = 3.69223474\n",
      "Iteration 777, loss = 3.69199134\n",
      "Iteration 778, loss = 3.69174812\n",
      "Iteration 779, loss = 3.69150508\n",
      "Iteration 780, loss = 3.69126223\n",
      "Iteration 781, loss = 3.69101955\n",
      "Iteration 782, loss = 3.69077704\n",
      "Iteration 783, loss = 3.69053472\n",
      "Iteration 784, loss = 3.69029257\n",
      "Iteration 785, loss = 3.69005060\n",
      "Iteration 786, loss = 3.68980881\n",
      "Iteration 787, loss = 3.68956719\n",
      "Iteration 788, loss = 3.68932575\n",
      "Iteration 789, loss = 3.68908448\n",
      "Iteration 790, loss = 3.68884338\n",
      "Iteration 791, loss = 3.68860246\n",
      "Iteration 792, loss = 3.68836170\n",
      "Iteration 793, loss = 3.68812112\n",
      "Iteration 794, loss = 3.68788071\n",
      "Iteration 795, loss = 3.68764047\n",
      "Iteration 796, loss = 3.68740040\n",
      "Iteration 797, loss = 3.68716050\n",
      "Iteration 798, loss = 3.68692077\n",
      "Iteration 799, loss = 3.68668120\n",
      "Iteration 800, loss = 3.68644180\n",
      "Iteration 801, loss = 3.68620257\n",
      "Iteration 802, loss = 3.68596350\n",
      "Iteration 803, loss = 3.68572460\n",
      "Iteration 804, loss = 3.68548586\n",
      "Iteration 805, loss = 3.68524728\n",
      "Iteration 806, loss = 3.68500887\n",
      "Iteration 807, loss = 3.68477062\n",
      "Iteration 808, loss = 3.68453253\n",
      "Iteration 809, loss = 3.68429461\n",
      "Iteration 810, loss = 3.68405684\n",
      "Iteration 811, loss = 3.68381923\n",
      "Iteration 812, loss = 3.68358178\n",
      "Iteration 813, loss = 3.68334449\n",
      "Iteration 814, loss = 3.68310735\n",
      "Iteration 815, loss = 3.68287038\n",
      "Iteration 816, loss = 3.68263356\n",
      "Iteration 817, loss = 3.68239689\n",
      "Iteration 818, loss = 3.68216038\n",
      "Iteration 819, loss = 3.68192402\n",
      "Iteration 820, loss = 3.68168782\n",
      "Iteration 821, loss = 3.68145177\n",
      "Iteration 822, loss = 3.68121587\n",
      "Iteration 823, loss = 3.68098012\n",
      "Iteration 824, loss = 3.68074452\n",
      "Iteration 825, loss = 3.68050908\n",
      "Iteration 826, loss = 3.68027378\n",
      "Iteration 827, loss = 3.68003863\n",
      "Iteration 828, loss = 3.67980363\n",
      "Iteration 829, loss = 3.67956877\n",
      "Iteration 830, loss = 3.67933406\n",
      "Iteration 831, loss = 3.67909950\n",
      "Iteration 832, loss = 3.67886508\n",
      "Iteration 833, loss = 3.67863081\n",
      "Iteration 834, loss = 3.67839668\n",
      "Iteration 835, loss = 3.67816269\n",
      "Iteration 836, loss = 3.67792885\n",
      "Iteration 837, loss = 3.67769515\n",
      "Iteration 838, loss = 3.67746159\n",
      "Iteration 839, loss = 3.67722817\n",
      "Iteration 840, loss = 3.67699488\n",
      "Iteration 841, loss = 3.67676174\n",
      "Iteration 842, loss = 3.67652874\n",
      "Iteration 843, loss = 3.67629587\n",
      "Iteration 844, loss = 3.67606314\n",
      "Iteration 845, loss = 3.67583054\n",
      "Iteration 846, loss = 3.67559808\n",
      "Iteration 847, loss = 3.67536576\n",
      "Iteration 848, loss = 3.67513357\n",
      "Iteration 849, loss = 3.67490151\n",
      "Iteration 850, loss = 3.67466959\n",
      "Iteration 851, loss = 3.67443780\n",
      "Iteration 852, loss = 3.67420613\n",
      "Iteration 853, loss = 3.67397460\n",
      "Iteration 854, loss = 3.67374320\n",
      "Iteration 855, loss = 3.67351193\n",
      "Iteration 856, loss = 3.67328079\n",
      "Iteration 857, loss = 3.67304977\n",
      "Iteration 858, loss = 3.67281888\n",
      "Iteration 859, loss = 3.67258812\n",
      "Iteration 860, loss = 3.67235748\n",
      "Iteration 861, loss = 3.67212697\n",
      "Iteration 862, loss = 3.67189658\n",
      "Iteration 863, loss = 3.67166632\n",
      "Iteration 864, loss = 3.67143618\n",
      "Iteration 865, loss = 3.67120616\n",
      "Iteration 866, loss = 3.67097626\n",
      "Iteration 867, loss = 3.67074648\n",
      "Iteration 868, loss = 3.67051683\n",
      "Iteration 869, loss = 3.67028729\n",
      "Iteration 870, loss = 3.67005787\n",
      "Iteration 871, loss = 3.66982857\n",
      "Iteration 872, loss = 3.66959939\n",
      "Iteration 873, loss = 3.66937032\n",
      "Iteration 874, loss = 3.66914137\n",
      "Iteration 875, loss = 3.66891254\n",
      "Iteration 876, loss = 3.66868382\n",
      "Iteration 877, loss = 3.66845521\n",
      "Iteration 878, loss = 3.66822672\n",
      "Iteration 879, loss = 3.66799834\n",
      "Iteration 880, loss = 3.66777007\n",
      "Iteration 881, loss = 3.66754192\n",
      "Iteration 882, loss = 3.66731387\n",
      "Iteration 883, loss = 3.66708594\n",
      "Iteration 884, loss = 3.66685811\n",
      "Iteration 885, loss = 3.66663039\n",
      "Iteration 886, loss = 3.66640278\n",
      "Iteration 887, loss = 3.66617528\n",
      "Iteration 888, loss = 3.66594789\n",
      "Iteration 889, loss = 3.66572060\n",
      "Iteration 890, loss = 3.66549341\n",
      "Iteration 891, loss = 3.66526633\n",
      "Iteration 892, loss = 3.66503936\n",
      "Iteration 893, loss = 3.66481249\n",
      "Iteration 894, loss = 3.66458572\n",
      "Iteration 895, loss = 3.66435905\n",
      "Iteration 896, loss = 3.66413249\n",
      "Iteration 897, loss = 3.66390602\n",
      "Iteration 898, loss = 3.66367966\n",
      "Iteration 899, loss = 3.66345339\n",
      "Iteration 900, loss = 3.66322723\n",
      "Iteration 901, loss = 3.66300116\n",
      "Iteration 902, loss = 3.66277519\n",
      "Iteration 903, loss = 3.66254932\n",
      "Iteration 904, loss = 3.66232354\n",
      "Iteration 905, loss = 3.66209786\n",
      "Iteration 906, loss = 3.66187228\n",
      "Iteration 907, loss = 3.66164679\n",
      "Iteration 908, loss = 3.66142139\n",
      "Iteration 909, loss = 3.66119609\n",
      "Iteration 910, loss = 3.66097087\n",
      "Iteration 911, loss = 3.66074576\n",
      "Iteration 912, loss = 3.66052073\n",
      "Iteration 913, loss = 3.66029579\n",
      "Iteration 914, loss = 3.66007094\n",
      "Iteration 915, loss = 3.65984619\n",
      "Iteration 916, loss = 3.65962152\n",
      "Iteration 917, loss = 3.65939694\n",
      "Iteration 918, loss = 3.65917245\n",
      "Iteration 919, loss = 3.65894804\n",
      "Iteration 920, loss = 3.65872373\n",
      "Iteration 921, loss = 3.65849949\n",
      "Iteration 922, loss = 3.65827535\n",
      "Iteration 923, loss = 3.65805129\n",
      "Iteration 924, loss = 3.65782731\n",
      "Iteration 925, loss = 3.65760341\n",
      "Iteration 926, loss = 3.65737960\n",
      "Iteration 927, loss = 3.65715588\n",
      "Iteration 928, loss = 3.65693223\n",
      "Iteration 929, loss = 3.65670867\n",
      "Iteration 930, loss = 3.65648518\n",
      "Iteration 931, loss = 3.65626178\n",
      "Iteration 932, loss = 3.65603845\n",
      "Iteration 933, loss = 3.65581521\n",
      "Iteration 934, loss = 3.65559204\n",
      "Iteration 935, loss = 3.65536895\n",
      "Iteration 936, loss = 3.65514594\n",
      "Iteration 937, loss = 3.65492301\n",
      "Iteration 938, loss = 3.65470015\n",
      "Iteration 939, loss = 3.65447737\n",
      "Iteration 940, loss = 3.65425466\n",
      "Iteration 941, loss = 3.65403203\n",
      "Iteration 942, loss = 3.65380948\n",
      "Iteration 943, loss = 3.65358699\n",
      "Iteration 944, loss = 3.65336458\n",
      "Iteration 945, loss = 3.65314224\n",
      "Iteration 946, loss = 3.65291998\n",
      "Iteration 947, loss = 3.65269778\n",
      "Iteration 948, loss = 3.65247566\n",
      "Iteration 949, loss = 3.65225361\n",
      "Iteration 950, loss = 3.65203163\n",
      "Iteration 951, loss = 3.65180971\n",
      "Iteration 952, loss = 3.65158787\n",
      "Iteration 953, loss = 3.65136610\n",
      "Iteration 954, loss = 3.65114439\n",
      "Iteration 955, loss = 3.65092275\n",
      "Iteration 956, loss = 3.65070118\n",
      "Iteration 957, loss = 3.65047967\n",
      "Iteration 958, loss = 3.65025823\n",
      "Iteration 959, loss = 3.65003686\n",
      "Iteration 960, loss = 3.64981555\n",
      "Iteration 961, loss = 3.64959430\n",
      "Iteration 962, loss = 3.64937312\n",
      "Iteration 963, loss = 3.64915201\n",
      "Iteration 964, loss = 3.64893096\n",
      "Iteration 965, loss = 3.64870997\n",
      "Iteration 966, loss = 3.64848904\n",
      "Iteration 967, loss = 3.64826817\n",
      "Iteration 968, loss = 3.64804737\n",
      "Iteration 969, loss = 3.64782663\n",
      "Iteration 970, loss = 3.64760594\n",
      "Iteration 971, loss = 3.64738532\n",
      "Iteration 972, loss = 3.64716476\n",
      "Iteration 973, loss = 3.64694425\n",
      "Iteration 974, loss = 3.64672381\n",
      "Iteration 975, loss = 3.64650342\n",
      "Iteration 976, loss = 3.64628310\n",
      "Iteration 977, loss = 3.64606283\n",
      "Iteration 978, loss = 3.64584261\n",
      "Iteration 979, loss = 3.64562246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 980, loss = 3.64540236\n",
      "Iteration 981, loss = 3.64518231\n",
      "Iteration 982, loss = 3.64496232\n",
      "Iteration 983, loss = 3.64474239\n",
      "Iteration 984, loss = 3.64452251\n",
      "Iteration 985, loss = 3.64430269\n",
      "Iteration 986, loss = 3.64408292\n",
      "Iteration 987, loss = 3.64386320\n",
      "Iteration 988, loss = 3.64364354\n",
      "Iteration 989, loss = 3.64342392\n",
      "Iteration 990, loss = 3.64320437\n",
      "Iteration 991, loss = 3.64298486\n",
      "Iteration 992, loss = 3.64276541\n",
      "Iteration 993, loss = 3.64254600\n",
      "Iteration 994, loss = 3.64232665\n",
      "Iteration 995, loss = 3.64210735\n",
      "Iteration 996, loss = 3.64188810\n",
      "Iteration 997, loss = 3.64166890\n",
      "Iteration 998, loss = 3.64144974\n",
      "Iteration 999, loss = 3.64123064\n",
      "Iteration 1000, loss = 3.64101159\n",
      "Iteration 1001, loss = 3.64079258\n",
      "Iteration 1002, loss = 3.64057363\n",
      "Iteration 1003, loss = 3.64035472\n",
      "Iteration 1004, loss = 3.64013585\n",
      "Iteration 1005, loss = 3.63991704\n",
      "Iteration 1006, loss = 3.63969827\n",
      "Iteration 1007, loss = 3.63947955\n",
      "Iteration 1008, loss = 3.63926088\n",
      "Iteration 1009, loss = 3.63904225\n",
      "Iteration 1010, loss = 3.63882367\n",
      "Iteration 1011, loss = 3.63860513\n",
      "Iteration 1012, loss = 3.63838664\n",
      "Iteration 1013, loss = 3.63816819\n",
      "Iteration 1014, loss = 3.63794979\n",
      "Iteration 1015, loss = 3.63773143\n",
      "Iteration 1016, loss = 3.63751312\n",
      "Iteration 1017, loss = 3.63729485\n",
      "Iteration 1018, loss = 3.63707662\n",
      "Iteration 1019, loss = 3.63685843\n",
      "Iteration 1020, loss = 3.63664029\n",
      "Iteration 1021, loss = 3.63642220\n",
      "Iteration 1022, loss = 3.63620414\n",
      "Iteration 1023, loss = 3.63598612\n",
      "Iteration 1024, loss = 3.63576815\n",
      "Iteration 1025, loss = 3.63555022\n",
      "Iteration 1026, loss = 3.63533233\n",
      "Iteration 1027, loss = 3.63511448\n",
      "Iteration 1028, loss = 3.63489668\n",
      "Iteration 1029, loss = 3.63467891\n",
      "Iteration 1030, loss = 3.63446118\n",
      "Iteration 1031, loss = 3.63424350\n",
      "Iteration 1032, loss = 3.63402585\n",
      "Iteration 1033, loss = 3.63380824\n",
      "Iteration 1034, loss = 3.63359068\n",
      "Iteration 1035, loss = 3.63337315\n",
      "Iteration 1036, loss = 3.63315566\n",
      "Iteration 1037, loss = 3.63293821\n",
      "Iteration 1038, loss = 3.63272080\n",
      "Iteration 1039, loss = 3.63250343\n",
      "Iteration 1040, loss = 3.63228609\n",
      "Iteration 1041, loss = 3.63206880\n",
      "Iteration 1042, loss = 3.63185154\n",
      "Iteration 1043, loss = 3.63163432\n",
      "Iteration 1044, loss = 3.63141713\n",
      "Iteration 1045, loss = 3.63119999\n",
      "Iteration 1046, loss = 3.63098288\n",
      "Iteration 1047, loss = 3.63076580\n",
      "Iteration 1048, loss = 3.63054877\n",
      "Iteration 1049, loss = 3.63033177\n",
      "Iteration 1050, loss = 3.63011481\n",
      "Iteration 1051, loss = 3.62989788\n",
      "Iteration 1052, loss = 3.62968099\n",
      "Iteration 1053, loss = 3.62946414\n",
      "Iteration 1054, loss = 3.62924732\n",
      "Iteration 1055, loss = 3.62903054\n",
      "Iteration 1056, loss = 3.62881379\n",
      "Iteration 1057, loss = 3.62859708\n",
      "Iteration 1058, loss = 3.62838040\n",
      "Iteration 1059, loss = 3.62816376\n",
      "Iteration 1060, loss = 3.62794716\n",
      "Iteration 1061, loss = 3.62773059\n",
      "Iteration 1062, loss = 3.62751405\n",
      "Iteration 1063, loss = 3.62729755\n",
      "Iteration 1064, loss = 3.62708108\n",
      "Iteration 1065, loss = 3.62686465\n",
      "Iteration 1066, loss = 3.62664825\n",
      "Iteration 1067, loss = 3.62643188\n",
      "Iteration 1068, loss = 3.62621555\n",
      "Iteration 1069, loss = 3.62599926\n",
      "Iteration 1070, loss = 3.62578299\n",
      "Iteration 1071, loss = 3.62556676\n",
      "Iteration 1072, loss = 3.62535057\n",
      "Iteration 1073, loss = 3.62513441\n",
      "Iteration 1074, loss = 3.62491828\n",
      "Iteration 1075, loss = 3.62470218\n",
      "Iteration 1076, loss = 3.62448612\n",
      "Iteration 1077, loss = 3.62427009\n",
      "Iteration 1078, loss = 3.62405410\n",
      "Iteration 1079, loss = 3.62383813\n",
      "Iteration 1080, loss = 3.62362220\n",
      "Iteration 1081, loss = 3.62340631\n",
      "Iteration 1082, loss = 3.62319044\n",
      "Iteration 1083, loss = 3.62297461\n",
      "Iteration 1084, loss = 3.62275882\n",
      "Iteration 1085, loss = 3.62254305\n",
      "Iteration 1086, loss = 3.62232732\n",
      "Iteration 1087, loss = 3.62211162\n",
      "Iteration 1088, loss = 3.62189595\n",
      "Iteration 1089, loss = 3.62168032\n",
      "Iteration 1090, loss = 3.62146471\n",
      "Iteration 1091, loss = 3.62124914\n",
      "Iteration 1092, loss = 3.62103361\n",
      "Iteration 1093, loss = 3.62081810\n",
      "Iteration 1094, loss = 3.62060263\n",
      "Iteration 1095, loss = 3.62038719\n",
      "Iteration 1096, loss = 3.62017178\n",
      "Iteration 1097, loss = 3.61995640\n",
      "Iteration 1098, loss = 3.61974106\n",
      "Iteration 1099, loss = 3.61952575\n",
      "Iteration 1100, loss = 3.61931047\n",
      "Iteration 1101, loss = 3.61909522\n",
      "Iteration 1102, loss = 3.61888001\n",
      "Iteration 1103, loss = 3.61866482\n",
      "Iteration 1104, loss = 3.61844967\n",
      "Iteration 1105, loss = 3.61823456\n",
      "Iteration 1106, loss = 3.61801947\n",
      "Iteration 1107, loss = 3.61780442\n",
      "Iteration 1108, loss = 3.61758939\n",
      "Iteration 1109, loss = 3.61737440\n",
      "Iteration 1110, loss = 3.61715945\n",
      "Iteration 1111, loss = 3.61694452\n",
      "Iteration 1112, loss = 3.61672963\n",
      "Iteration 1113, loss = 3.61651477\n",
      "Iteration 1114, loss = 3.61629994\n",
      "Iteration 1115, loss = 3.61608515\n",
      "Iteration 1116, loss = 3.61587038\n",
      "Iteration 1117, loss = 3.61565565\n",
      "Iteration 1118, loss = 3.61544096\n",
      "Iteration 1119, loss = 3.61522629\n",
      "Iteration 1120, loss = 3.61501166\n",
      "Iteration 1121, loss = 3.61479706\n",
      "Iteration 1122, loss = 3.61458249\n",
      "Iteration 1123, loss = 3.61436795\n",
      "Iteration 1124, loss = 3.61415345\n",
      "Iteration 1125, loss = 3.61393898\n",
      "Iteration 1126, loss = 3.61372455\n",
      "Iteration 1127, loss = 3.61351014\n",
      "Iteration 1128, loss = 3.61329577\n",
      "Iteration 1129, loss = 3.61308143\n",
      "Iteration 1130, loss = 3.61286713\n",
      "Iteration 1131, loss = 3.61265286\n",
      "Iteration 1132, loss = 3.61243862\n",
      "Iteration 1133, loss = 3.61222441\n",
      "Iteration 1134, loss = 3.61201024\n",
      "Iteration 1135, loss = 3.61179610\n",
      "Iteration 1136, loss = 3.61158200\n",
      "Iteration 1137, loss = 3.61136793\n",
      "Iteration 1138, loss = 3.61115389\n",
      "Iteration 1139, loss = 3.61093988\n",
      "Iteration 1140, loss = 3.61072591\n",
      "Iteration 1141, loss = 3.61051198\n",
      "Iteration 1142, loss = 3.61029808\n",
      "Iteration 1143, loss = 3.61008421\n",
      "Iteration 1144, loss = 3.60987038\n",
      "Iteration 1145, loss = 3.60965658\n",
      "Iteration 1146, loss = 3.60944281\n",
      "Iteration 1147, loss = 3.60922908\n",
      "Iteration 1148, loss = 3.60901538\n",
      "Iteration 1149, loss = 3.60880172\n",
      "Iteration 1150, loss = 3.60858810\n",
      "Iteration 1151, loss = 3.60837451\n",
      "Iteration 1152, loss = 3.60816095\n",
      "Iteration 1153, loss = 3.60794743\n",
      "Iteration 1154, loss = 3.60773394\n",
      "Iteration 1155, loss = 3.60752049\n",
      "Iteration 1156, loss = 3.60730708\n",
      "Iteration 1157, loss = 3.60709370\n",
      "Iteration 1158, loss = 3.60688035\n",
      "Iteration 1159, loss = 3.60666705\n",
      "Iteration 1160, loss = 3.60645377\n",
      "Iteration 1161, loss = 3.60624054\n",
      "Iteration 1162, loss = 3.60602734\n",
      "Iteration 1163, loss = 3.60581418\n",
      "Iteration 1164, loss = 3.60560105\n",
      "Iteration 1165, loss = 3.60538796\n",
      "Iteration 1166, loss = 3.60517491\n",
      "Iteration 1167, loss = 3.60496189\n",
      "Iteration 1168, loss = 3.60474891\n",
      "Iteration 1169, loss = 3.60453597\n",
      "Iteration 1170, loss = 3.60432306\n",
      "Iteration 1171, loss = 3.60411020\n",
      "Iteration 1172, loss = 3.60389737\n",
      "Iteration 1173, loss = 3.60368458\n",
      "Iteration 1174, loss = 3.60347182\n",
      "Iteration 1175, loss = 3.60325911\n",
      "Iteration 1176, loss = 3.60304643\n",
      "Iteration 1177, loss = 3.60283379\n",
      "Iteration 1178, loss = 3.60262119\n",
      "Iteration 1179, loss = 3.60240863\n",
      "Iteration 1180, loss = 3.60219610\n",
      "Iteration 1181, loss = 3.60198362\n",
      "Iteration 1182, loss = 3.60177118\n",
      "Iteration 1183, loss = 3.60155877\n",
      "Iteration 1184, loss = 3.60134640\n",
      "Iteration 1185, loss = 3.60113408\n",
      "Iteration 1186, loss = 3.60092179\n",
      "Iteration 1187, loss = 3.60070955\n",
      "Iteration 1188, loss = 3.60049734\n",
      "Iteration 1189, loss = 3.60028517\n",
      "Iteration 1190, loss = 3.60007305\n",
      "Iteration 1191, loss = 3.59986096\n",
      "Iteration 1192, loss = 3.59964892\n",
      "Iteration 1193, loss = 3.59943692\n",
      "Iteration 1194, loss = 3.59922496\n",
      "Iteration 1195, loss = 3.59901304\n",
      "Iteration 1196, loss = 3.59880116\n",
      "Iteration 1197, loss = 3.59858932\n",
      "Iteration 1198, loss = 3.59837753\n",
      "Iteration 1199, loss = 3.59816577\n",
      "Iteration 1200, loss = 3.59795406\n",
      "Iteration 1201, loss = 3.59774240\n",
      "Iteration 1202, loss = 3.59753077\n",
      "Iteration 1203, loss = 3.59731919\n",
      "Iteration 1204, loss = 3.59710765\n",
      "Iteration 1205, loss = 3.59689615\n",
      "Iteration 1206, loss = 3.59668470\n",
      "Iteration 1207, loss = 3.59647329\n",
      "Iteration 1208, loss = 3.59626193\n",
      "Iteration 1209, loss = 3.59605061\n",
      "Iteration 1210, loss = 3.59583933\n",
      "Iteration 1211, loss = 3.59562810\n",
      "Iteration 1212, loss = 3.59541691\n",
      "Iteration 1213, loss = 3.59520577\n",
      "Iteration 1214, loss = 3.59499467\n",
      "Iteration 1215, loss = 3.59478362\n",
      "Iteration 1216, loss = 3.59457261\n",
      "Iteration 1217, loss = 3.59436165\n",
      "Iteration 1218, loss = 3.59415073\n",
      "Iteration 1219, loss = 3.59393986\n",
      "Iteration 1220, loss = 3.59372904\n",
      "Iteration 1221, loss = 3.59351826\n",
      "Iteration 1222, loss = 3.59330753\n",
      "Iteration 1223, loss = 3.59309685\n",
      "Iteration 1224, loss = 3.59288621\n",
      "Iteration 1225, loss = 3.59267563\n",
      "Iteration 1226, loss = 3.59246508\n",
      "Iteration 1227, loss = 3.59225459\n",
      "Iteration 1228, loss = 3.59204414\n",
      "Iteration 1229, loss = 3.59183375\n",
      "Iteration 1230, loss = 3.59162340\n",
      "Iteration 1231, loss = 3.59141310\n",
      "Iteration 1232, loss = 3.59120284\n",
      "Iteration 1233, loss = 3.59099264\n",
      "Iteration 1234, loss = 3.59078249\n",
      "Iteration 1235, loss = 3.59057238\n",
      "Iteration 1236, loss = 3.59036233\n",
      "Iteration 1237, loss = 3.59015232\n",
      "Iteration 1238, loss = 3.58994237\n",
      "Iteration 1239, loss = 3.58973246\n",
      "Iteration 1240, loss = 3.58952261\n",
      "Iteration 1241, loss = 3.58931281\n",
      "Iteration 1242, loss = 3.58910305\n",
      "Iteration 1243, loss = 3.58889335\n",
      "Iteration 1244, loss = 3.58868370\n",
      "Iteration 1245, loss = 3.58847410\n",
      "Iteration 1246, loss = 3.58826456\n",
      "Iteration 1247, loss = 3.58805506\n",
      "Iteration 1248, loss = 3.58784562\n",
      "Iteration 1249, loss = 3.58763623\n",
      "Iteration 1250, loss = 3.58742689\n",
      "Iteration 1251, loss = 3.58721761\n",
      "Iteration 1252, loss = 3.58700838\n",
      "Iteration 1253, loss = 3.58679920\n",
      "Iteration 1254, loss = 3.58659008\n",
      "Iteration 1255, loss = 3.58638101\n",
      "Iteration 1256, loss = 3.58617199\n",
      "Iteration 1257, loss = 3.58596303\n",
      "Iteration 1258, loss = 3.58575412\n",
      "Iteration 1259, loss = 3.58554527\n",
      "Iteration 1260, loss = 3.58533647\n",
      "Iteration 1261, loss = 3.58512773\n",
      "Iteration 1262, loss = 3.58491904\n",
      "Iteration 1263, loss = 3.58471041\n",
      "Iteration 1264, loss = 3.58450183\n",
      "Iteration 1265, loss = 3.58429331\n",
      "Iteration 1266, loss = 3.58408485\n",
      "Iteration 1267, loss = 3.58387644\n",
      "Iteration 1268, loss = 3.58366809\n",
      "Iteration 1269, loss = 3.58345980\n",
      "Iteration 1270, loss = 3.58325156\n",
      "Iteration 1271, loss = 3.58304339\n",
      "Iteration 1272, loss = 3.58283527\n",
      "Iteration 1273, loss = 3.58262720\n",
      "Iteration 1274, loss = 3.58241920\n",
      "Iteration 1275, loss = 3.58221125\n",
      "Iteration 1276, loss = 3.58200336\n",
      "Iteration 1277, loss = 3.58179554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1278, loss = 3.58158777\n",
      "Iteration 1279, loss = 3.58138006\n",
      "Iteration 1280, loss = 3.58117240\n",
      "Iteration 1281, loss = 3.58096481\n",
      "Iteration 1282, loss = 3.58075728\n",
      "Iteration 1283, loss = 3.58054981\n",
      "Iteration 1284, loss = 3.58034240\n",
      "Iteration 1285, loss = 3.58013505\n",
      "Iteration 1286, loss = 3.57992776\n",
      "Iteration 1287, loss = 3.57972053\n",
      "Iteration 1288, loss = 3.57951337\n",
      "Iteration 1289, loss = 3.57930626\n",
      "Iteration 1290, loss = 3.57909922\n",
      "Iteration 1291, loss = 3.57889224\n",
      "Iteration 1292, loss = 3.57868532\n",
      "Iteration 1293, loss = 3.57847846\n",
      "Iteration 1294, loss = 3.57827167\n",
      "Iteration 1295, loss = 3.57806493\n",
      "Iteration 1296, loss = 3.57785827\n",
      "Iteration 1297, loss = 3.57765166\n",
      "Iteration 1298, loss = 3.57744512\n",
      "Iteration 1299, loss = 3.57723864\n",
      "Iteration 1300, loss = 3.57703223\n",
      "Iteration 1301, loss = 3.57682588\n",
      "Iteration 1302, loss = 3.57661959\n",
      "Iteration 1303, loss = 3.57641337\n",
      "Iteration 1304, loss = 3.57620722\n",
      "Iteration 1305, loss = 3.57600113\n",
      "Iteration 1306, loss = 3.57579511\n",
      "Iteration 1307, loss = 3.57558915\n",
      "Iteration 1308, loss = 3.57538325\n",
      "Iteration 1309, loss = 3.57517743\n",
      "Iteration 1310, loss = 3.57497166\n",
      "Iteration 1311, loss = 3.57476597\n",
      "Iteration 1312, loss = 3.57456034\n",
      "Iteration 1313, loss = 3.57435478\n",
      "Iteration 1314, loss = 3.57414929\n",
      "Iteration 1315, loss = 3.57394386\n",
      "Iteration 1316, loss = 3.57373850\n",
      "Iteration 1317, loss = 3.57353321\n",
      "Iteration 1318, loss = 3.57332799\n",
      "Iteration 1319, loss = 3.57312283\n",
      "Iteration 1320, loss = 3.57291774\n",
      "Iteration 1321, loss = 3.57271273\n",
      "Iteration 1322, loss = 3.57250778\n",
      "Iteration 1323, loss = 3.57230290\n",
      "Iteration 1324, loss = 3.57209809\n",
      "Iteration 1325, loss = 3.57189334\n",
      "Iteration 1326, loss = 3.57168867\n",
      "Iteration 1327, loss = 3.57148407\n",
      "Iteration 1328, loss = 3.57127954\n",
      "Iteration 1329, loss = 3.57107508\n",
      "Iteration 1330, loss = 3.57087069\n",
      "Iteration 1331, loss = 3.57066637\n",
      "Iteration 1332, loss = 3.57046212\n",
      "Iteration 1333, loss = 3.57025794\n",
      "Iteration 1334, loss = 3.57005383\n",
      "Iteration 1335, loss = 3.56984980\n",
      "Iteration 1336, loss = 3.56964583\n",
      "Iteration 1337, loss = 3.56944194\n",
      "Iteration 1338, loss = 3.56923812\n",
      "Iteration 1339, loss = 3.56903437\n",
      "Iteration 1340, loss = 3.56883070\n",
      "Iteration 1341, loss = 3.56862710\n",
      "Iteration 1342, loss = 3.56842357\n",
      "Iteration 1343, loss = 3.56822011\n",
      "Iteration 1344, loss = 3.56801673\n",
      "Iteration 1345, loss = 3.56781342\n",
      "Iteration 1346, loss = 3.56761019\n",
      "Iteration 1347, loss = 3.56740702\n",
      "Iteration 1348, loss = 3.56720394\n",
      "Iteration 1349, loss = 3.56700092\n",
      "Iteration 1350, loss = 3.56679799\n",
      "Iteration 1351, loss = 3.56659512\n",
      "Iteration 1352, loss = 3.56639233\n",
      "Iteration 1353, loss = 3.56618962\n",
      "Iteration 1354, loss = 3.56598698\n",
      "Iteration 1355, loss = 3.56578442\n",
      "Iteration 1356, loss = 3.56558193\n",
      "Iteration 1357, loss = 3.56537952\n",
      "Iteration 1358, loss = 3.56517719\n",
      "Iteration 1359, loss = 3.56497493\n",
      "Iteration 1360, loss = 3.56477275\n",
      "Iteration 1361, loss = 3.56457064\n",
      "Iteration 1362, loss = 3.56436861\n",
      "Iteration 1363, loss = 3.56416666\n",
      "Iteration 1364, loss = 3.56396478\n",
      "Iteration 1365, loss = 3.56376298\n",
      "Iteration 1366, loss = 3.56356126\n",
      "Iteration 1367, loss = 3.56335962\n",
      "Iteration 1368, loss = 3.56315806\n",
      "Iteration 1369, loss = 3.56295657\n",
      "Iteration 1370, loss = 3.56275516\n",
      "Iteration 1371, loss = 3.56255383\n",
      "Iteration 1372, loss = 3.56235258\n",
      "Iteration 1373, loss = 3.56215141\n",
      "Iteration 1374, loss = 3.56195031\n",
      "Iteration 1375, loss = 3.56174930\n",
      "Iteration 1376, loss = 3.56154836\n",
      "Iteration 1377, loss = 3.56134750\n",
      "Iteration 1378, loss = 3.56114673\n",
      "Iteration 1379, loss = 3.56094603\n",
      "Iteration 1380, loss = 3.56074541\n",
      "Iteration 1381, loss = 3.56054487\n",
      "Iteration 1382, loss = 3.56034441\n",
      "Iteration 1383, loss = 3.56014404\n",
      "Iteration 1384, loss = 3.55994374\n",
      "Iteration 1385, loss = 3.55974352\n",
      "Iteration 1386, loss = 3.55954339\n",
      "Iteration 1387, loss = 3.55934333\n",
      "Iteration 1388, loss = 3.55914336\n",
      "Iteration 1389, loss = 3.55894347\n",
      "Iteration 1390, loss = 3.55874366\n",
      "Iteration 1391, loss = 3.55854393\n",
      "Iteration 1392, loss = 3.55834428\n",
      "Iteration 1393, loss = 3.55814472\n",
      "Iteration 1394, loss = 3.55794523\n",
      "Iteration 1395, loss = 3.55774583\n",
      "Iteration 1396, loss = 3.55754651\n",
      "Iteration 1397, loss = 3.55734728\n",
      "Iteration 1398, loss = 3.55714812\n",
      "Iteration 1399, loss = 3.55694905\n",
      "Iteration 1400, loss = 3.55675006\n",
      "Iteration 1401, loss = 3.55655116\n",
      "Iteration 1402, loss = 3.55635233\n",
      "Iteration 1403, loss = 3.55615359\n",
      "Iteration 1404, loss = 3.55595494\n",
      "Iteration 1405, loss = 3.55575637\n",
      "Iteration 1406, loss = 3.55555788\n",
      "Iteration 1407, loss = 3.55535947\n",
      "Iteration 1408, loss = 3.55516115\n",
      "Iteration 1409, loss = 3.55496291\n",
      "Iteration 1410, loss = 3.55476476\n",
      "Iteration 1411, loss = 3.55456669\n",
      "Iteration 1412, loss = 3.55436871\n",
      "Iteration 1413, loss = 3.55417081\n",
      "Iteration 1414, loss = 3.55397299\n",
      "Iteration 1415, loss = 3.55377526\n",
      "Iteration 1416, loss = 3.55357762\n",
      "Iteration 1417, loss = 3.55338006\n",
      "Iteration 1418, loss = 3.55318258\n",
      "Iteration 1419, loss = 3.55298519\n",
      "Iteration 1420, loss = 3.55278789\n",
      "Iteration 1421, loss = 3.55259067\n",
      "Iteration 1422, loss = 3.55239353\n",
      "Iteration 1423, loss = 3.55219649\n",
      "Iteration 1424, loss = 3.55199952\n",
      "Iteration 1425, loss = 3.55180265\n",
      "Iteration 1426, loss = 3.55160586\n",
      "Iteration 1427, loss = 3.55140915\n",
      "Iteration 1428, loss = 3.55121253\n",
      "Iteration 1429, loss = 3.55101600\n",
      "Iteration 1430, loss = 3.55081956\n",
      "Iteration 1431, loss = 3.55062320\n",
      "Iteration 1432, loss = 3.55042693\n",
      "Iteration 1433, loss = 3.55023074\n",
      "Iteration 1434, loss = 3.55003464\n",
      "Iteration 1435, loss = 3.54983863\n",
      "Iteration 1436, loss = 3.54964270\n",
      "Iteration 1437, loss = 3.54944686\n",
      "Iteration 1438, loss = 3.54925111\n",
      "Iteration 1439, loss = 3.54905545\n",
      "Iteration 1440, loss = 3.54885987\n",
      "Iteration 1441, loss = 3.54866438\n",
      "Iteration 1442, loss = 3.54846898\n",
      "Iteration 1443, loss = 3.54827367\n",
      "Iteration 1444, loss = 3.54807844\n",
      "Iteration 1445, loss = 3.54788330\n",
      "Iteration 1446, loss = 3.54768825\n",
      "Iteration 1447, loss = 3.54749329\n",
      "Iteration 1448, loss = 3.54729841\n",
      "Iteration 1449, loss = 3.54710362\n",
      "Iteration 1450, loss = 3.54690892\n",
      "Iteration 1451, loss = 3.54671431\n",
      "Iteration 1452, loss = 3.54651979\n",
      "Iteration 1453, loss = 3.54632535\n",
      "Iteration 1454, loss = 3.54613101\n",
      "Iteration 1455, loss = 3.54593675\n",
      "Iteration 1456, loss = 3.54574258\n",
      "Iteration 1457, loss = 3.54554850\n",
      "Iteration 1458, loss = 3.54535451\n",
      "Iteration 1459, loss = 3.54516060\n",
      "Iteration 1460, loss = 3.54496679\n",
      "Iteration 1461, loss = 3.54477306\n",
      "Iteration 1462, loss = 3.54457942\n",
      "Iteration 1463, loss = 3.54438587\n",
      "Iteration 1464, loss = 3.54419241\n",
      "Iteration 1465, loss = 3.54399904\n",
      "Iteration 1466, loss = 3.54380576\n",
      "Iteration 1467, loss = 3.54361257\n",
      "Iteration 1468, loss = 3.54341946\n",
      "Iteration 1469, loss = 3.54322645\n",
      "Iteration 1470, loss = 3.54303352\n",
      "Iteration 1471, loss = 3.54284069\n",
      "Iteration 1472, loss = 3.54264794\n",
      "Iteration 1473, loss = 3.54245528\n",
      "Iteration 1474, loss = 3.54226271\n",
      "Iteration 1475, loss = 3.54207023\n",
      "Iteration 1476, loss = 3.54187784\n",
      "Iteration 1477, loss = 3.54168554\n",
      "Iteration 1478, loss = 3.54149333\n",
      "Iteration 1479, loss = 3.54130121\n",
      "Iteration 1480, loss = 3.54110918\n",
      "Iteration 1481, loss = 3.54091723\n",
      "Iteration 1482, loss = 3.54072538\n",
      "Iteration 1483, loss = 3.54053362\n",
      "Iteration 1484, loss = 3.54034194\n",
      "Iteration 1485, loss = 3.54015036\n",
      "Iteration 1486, loss = 3.53995887\n",
      "Iteration 1487, loss = 3.53976746\n",
      "Iteration 1488, loss = 3.53957614\n",
      "Iteration 1489, loss = 3.53938492\n",
      "Iteration 1490, loss = 3.53919378\n",
      "Iteration 1491, loss = 3.53900274\n",
      "Iteration 1492, loss = 3.53881178\n",
      "Iteration 1493, loss = 3.53862091\n",
      "Iteration 1494, loss = 3.53843014\n",
      "Iteration 1495, loss = 3.53823945\n",
      "Iteration 1496, loss = 3.53804885\n",
      "Iteration 1497, loss = 3.53785835\n",
      "Iteration 1498, loss = 3.53766793\n",
      "Iteration 1499, loss = 3.53747760\n",
      "Iteration 1500, loss = 3.53728736\n",
      "Iteration 1501, loss = 3.53709721\n",
      "Iteration 1502, loss = 3.53690715\n",
      "Iteration 1503, loss = 3.53671719\n",
      "Iteration 1504, loss = 3.53652731\n",
      "Iteration 1505, loss = 3.53633752\n",
      "Iteration 1506, loss = 3.53614782\n",
      "Iteration 1507, loss = 3.53595821\n",
      "Iteration 1508, loss = 3.53576869\n",
      "Iteration 1509, loss = 3.53557926\n",
      "Iteration 1510, loss = 3.53538992\n",
      "Iteration 1511, loss = 3.53520066\n",
      "Iteration 1512, loss = 3.53501150\n",
      "Iteration 1513, loss = 3.53482243\n",
      "Iteration 1514, loss = 3.53463345\n",
      "Iteration 1515, loss = 3.53444456\n",
      "Iteration 1516, loss = 3.53425575\n",
      "Iteration 1517, loss = 3.53406704\n",
      "Iteration 1518, loss = 3.53387842\n",
      "Iteration 1519, loss = 3.53368988\n",
      "Iteration 1520, loss = 3.53350144\n",
      "Iteration 1521, loss = 3.53331308\n",
      "Iteration 1522, loss = 3.53312482\n",
      "Iteration 1523, loss = 3.53293664\n",
      "Iteration 1524, loss = 3.53274855\n",
      "Iteration 1525, loss = 3.53256055\n",
      "Iteration 1526, loss = 3.53237264\n",
      "Iteration 1527, loss = 3.53218483\n",
      "Iteration 1528, loss = 3.53199710\n",
      "Iteration 1529, loss = 3.53180945\n",
      "Iteration 1530, loss = 3.53162190\n",
      "Iteration 1531, loss = 3.53143444\n",
      "Iteration 1532, loss = 3.53124707\n",
      "Iteration 1533, loss = 3.53105978\n",
      "Iteration 1534, loss = 3.53087259\n",
      "Iteration 1535, loss = 3.53068548\n",
      "Iteration 1536, loss = 3.53049846\n",
      "Iteration 1537, loss = 3.53031153\n",
      "Iteration 1538, loss = 3.53012469\n",
      "Iteration 1539, loss = 3.52993794\n",
      "Iteration 1540, loss = 3.52975128\n",
      "Iteration 1541, loss = 3.52956470\n",
      "Iteration 1542, loss = 3.52937822\n",
      "Iteration 1543, loss = 3.52919182\n",
      "Iteration 1544, loss = 3.52900551\n",
      "Iteration 1545, loss = 3.52881929\n",
      "Iteration 1546, loss = 3.52863316\n",
      "Iteration 1547, loss = 3.52844712\n",
      "Iteration 1548, loss = 3.52826116\n",
      "Iteration 1549, loss = 3.52807529\n",
      "Iteration 1550, loss = 3.52788952\n",
      "Iteration 1551, loss = 3.52770382\n",
      "Iteration 1552, loss = 3.52751822\n",
      "Iteration 1553, loss = 3.52733271\n",
      "Iteration 1554, loss = 3.52714728\n",
      "Iteration 1555, loss = 3.52696194\n",
      "Iteration 1556, loss = 3.52677669\n",
      "Iteration 1557, loss = 3.52659152\n",
      "Iteration 1558, loss = 3.52640645\n",
      "Iteration 1559, loss = 3.52622146\n",
      "Iteration 1560, loss = 3.52603656\n",
      "Iteration 1561, loss = 3.52585174\n",
      "Iteration 1562, loss = 3.52566701\n",
      "Iteration 1563, loss = 3.52548237\n",
      "Iteration 1564, loss = 3.52529782\n",
      "Iteration 1565, loss = 3.52511335\n",
      "Iteration 1566, loss = 3.52492898\n",
      "Iteration 1567, loss = 3.52474468\n",
      "Iteration 1568, loss = 3.52456048\n",
      "Iteration 1569, loss = 3.52437636\n",
      "Iteration 1570, loss = 3.52419233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1571, loss = 3.52400838\n",
      "Iteration 1572, loss = 3.52382452\n",
      "Iteration 1573, loss = 3.52364075\n",
      "Iteration 1574, loss = 3.52345706\n",
      "Iteration 1575, loss = 3.52327346\n",
      "Iteration 1576, loss = 3.52308995\n",
      "Iteration 1577, loss = 3.52290652\n",
      "Iteration 1578, loss = 3.52272317\n",
      "Iteration 1579, loss = 3.52253992\n",
      "Iteration 1580, loss = 3.52235675\n",
      "Iteration 1581, loss = 3.52217366\n",
      "Iteration 1582, loss = 3.52199066\n",
      "Iteration 1583, loss = 3.52180774\n",
      "Iteration 1584, loss = 3.52162491\n",
      "Iteration 1585, loss = 3.52144217\n",
      "Iteration 1586, loss = 3.52125951\n",
      "Iteration 1587, loss = 3.52107694\n",
      "Iteration 1588, loss = 3.52089445\n",
      "Iteration 1589, loss = 3.52071204\n",
      "Iteration 1590, loss = 3.52052972\n",
      "Iteration 1591, loss = 3.52034749\n",
      "Iteration 1592, loss = 3.52016533\n",
      "Iteration 1593, loss = 3.51998327\n",
      "Iteration 1594, loss = 3.51980129\n",
      "Iteration 1595, loss = 3.51961939\n",
      "Iteration 1596, loss = 3.51943757\n",
      "Iteration 1597, loss = 3.51925584\n",
      "Iteration 1598, loss = 3.51907419\n",
      "Iteration 1599, loss = 3.51889263\n",
      "Iteration 1600, loss = 3.51871115\n",
      "Iteration 1601, loss = 3.51852976\n",
      "Iteration 1602, loss = 3.51834844\n",
      "Iteration 1603, loss = 3.51816721\n",
      "Iteration 1604, loss = 3.51798607\n",
      "Iteration 1605, loss = 3.51780500\n",
      "Iteration 1606, loss = 3.51762402\n",
      "Iteration 1607, loss = 3.51744312\n",
      "Iteration 1608, loss = 3.51726231\n",
      "Iteration 1609, loss = 3.51708157\n",
      "Iteration 1610, loss = 3.51690092\n",
      "Iteration 1611, loss = 3.51672036\n",
      "Iteration 1612, loss = 3.51653987\n",
      "Iteration 1613, loss = 3.51635946\n",
      "Iteration 1614, loss = 3.51617914\n",
      "Iteration 1615, loss = 3.51599890\n",
      "Iteration 1616, loss = 3.51581874\n",
      "Iteration 1617, loss = 3.51563866\n",
      "Iteration 1618, loss = 3.51545867\n",
      "Iteration 1619, loss = 3.51527875\n",
      "Iteration 1620, loss = 3.51509892\n",
      "Iteration 1621, loss = 3.51491917\n",
      "Iteration 1622, loss = 3.51473949\n",
      "Iteration 1623, loss = 3.51455990\n",
      "Iteration 1624, loss = 3.51438039\n",
      "Iteration 1625, loss = 3.51420096\n",
      "Iteration 1626, loss = 3.51402161\n",
      "Iteration 1627, loss = 3.51384234\n",
      "Iteration 1628, loss = 3.51366315\n",
      "Iteration 1629, loss = 3.51348404\n",
      "Iteration 1630, loss = 3.51330501\n",
      "Iteration 1631, loss = 3.51312606\n",
      "Iteration 1632, loss = 3.51294719\n",
      "Iteration 1633, loss = 3.51276839\n",
      "Iteration 1634, loss = 3.51258968\n",
      "Iteration 1635, loss = 3.51241105\n",
      "Iteration 1636, loss = 3.51223249\n",
      "Iteration 1637, loss = 3.51205402\n",
      "Iteration 1638, loss = 3.51187562\n",
      "Iteration 1639, loss = 3.51169730\n",
      "Iteration 1640, loss = 3.51151906\n",
      "Iteration 1641, loss = 3.51134090\n",
      "Iteration 1642, loss = 3.51116281\n",
      "Iteration 1643, loss = 3.51098481\n",
      "Iteration 1644, loss = 3.51080688\n",
      "Iteration 1645, loss = 3.51062903\n",
      "Iteration 1646, loss = 3.51045125\n",
      "Iteration 1647, loss = 3.51027356\n",
      "Iteration 1648, loss = 3.51009594\n",
      "Iteration 1649, loss = 3.50991839\n",
      "Iteration 1650, loss = 3.50974093\n",
      "Iteration 1651, loss = 3.50956354\n",
      "Iteration 1652, loss = 3.50938623\n",
      "Iteration 1653, loss = 3.50920899\n",
      "Iteration 1654, loss = 3.50903183\n",
      "Iteration 1655, loss = 3.50885475\n",
      "Iteration 1656, loss = 3.50867774\n",
      "Iteration 1657, loss = 3.50850081\n",
      "Iteration 1658, loss = 3.50832396\n",
      "Iteration 1659, loss = 3.50814718\n",
      "Iteration 1660, loss = 3.50797047\n",
      "Iteration 1661, loss = 3.50779384\n",
      "Iteration 1662, loss = 3.50761729\n",
      "Iteration 1663, loss = 3.50744081\n",
      "Iteration 1664, loss = 3.50726440\n",
      "Iteration 1665, loss = 3.50708807\n",
      "Iteration 1666, loss = 3.50691182\n",
      "Iteration 1667, loss = 3.50673564\n",
      "Iteration 1668, loss = 3.50655953\n",
      "Iteration 1669, loss = 3.50638350\n",
      "Iteration 1670, loss = 3.50620754\n",
      "Iteration 1671, loss = 3.50603165\n",
      "Iteration 1672, loss = 3.50585584\n",
      "Iteration 1673, loss = 3.50568010\n",
      "Iteration 1674, loss = 3.50550443\n",
      "Iteration 1675, loss = 3.50532884\n",
      "Iteration 1676, loss = 3.50515332\n",
      "Iteration 1677, loss = 3.50497787\n",
      "Iteration 1678, loss = 3.50480250\n",
      "Iteration 1679, loss = 3.50462720\n",
      "Iteration 1680, loss = 3.50445196\n",
      "Iteration 1681, loss = 3.50427681\n",
      "Iteration 1682, loss = 3.50410172\n",
      "Iteration 1683, loss = 3.50392671\n",
      "Iteration 1684, loss = 3.50375176\n",
      "Iteration 1685, loss = 3.50357689\n",
      "Iteration 1686, loss = 3.50340209\n",
      "Iteration 1687, loss = 3.50322736\n",
      "Iteration 1688, loss = 3.50305270\n",
      "Iteration 1689, loss = 3.50287811\n",
      "Iteration 1690, loss = 3.50270360\n",
      "Iteration 1691, loss = 3.50252915\n",
      "Iteration 1692, loss = 3.50235477\n",
      "Iteration 1693, loss = 3.50218047\n",
      "Iteration 1694, loss = 3.50200623\n",
      "Iteration 1695, loss = 3.50183207\n",
      "Iteration 1696, loss = 3.50165797\n",
      "Iteration 1697, loss = 3.50148394\n",
      "Iteration 1698, loss = 3.50130998\n",
      "Iteration 1699, loss = 3.50113609\n",
      "Iteration 1700, loss = 3.50096227\n",
      "Iteration 1701, loss = 3.50078852\n",
      "Iteration 1702, loss = 3.50061484\n",
      "Iteration 1703, loss = 3.50044122\n",
      "Iteration 1704, loss = 3.50026768\n",
      "Iteration 1705, loss = 3.50009420\n",
      "Iteration 1706, loss = 3.49992079\n",
      "Iteration 1707, loss = 3.49974745\n",
      "Iteration 1708, loss = 3.49957417\n",
      "Iteration 1709, loss = 3.49940096\n",
      "Iteration 1710, loss = 3.49922782\n",
      "Iteration 1711, loss = 3.49905475\n",
      "Iteration 1712, loss = 3.49888174\n",
      "Iteration 1713, loss = 3.49870880\n",
      "Iteration 1714, loss = 3.49853593\n",
      "Iteration 1715, loss = 3.49836312\n",
      "Iteration 1716, loss = 3.49819038\n",
      "Iteration 1717, loss = 3.49801771\n",
      "Iteration 1718, loss = 3.49784510\n",
      "Iteration 1719, loss = 3.49767256\n",
      "Iteration 1720, loss = 3.49750008\n",
      "Iteration 1721, loss = 3.49732767\n",
      "Iteration 1722, loss = 3.49715532\n",
      "Iteration 1723, loss = 3.49698304\n",
      "Iteration 1724, loss = 3.49681082\n",
      "Iteration 1725, loss = 3.49663867\n",
      "Iteration 1726, loss = 3.49646659\n",
      "Iteration 1727, loss = 3.49629456\n",
      "Iteration 1728, loss = 3.49612260\n",
      "Iteration 1729, loss = 3.49595071\n",
      "Iteration 1730, loss = 3.49577888\n",
      "Iteration 1731, loss = 3.49560711\n",
      "Iteration 1732, loss = 3.49543541\n",
      "Iteration 1733, loss = 3.49526377\n",
      "Iteration 1734, loss = 3.49509219\n",
      "Iteration 1735, loss = 3.49492068\n",
      "Iteration 1736, loss = 3.49474922\n",
      "Iteration 1737, loss = 3.49457784\n",
      "Iteration 1738, loss = 3.49440651\n",
      "Iteration 1739, loss = 3.49423525\n",
      "Iteration 1740, loss = 3.49406404\n",
      "Iteration 1741, loss = 3.49389290\n",
      "Iteration 1742, loss = 3.49372183\n",
      "Iteration 1743, loss = 3.49355081\n",
      "Iteration 1744, loss = 3.49337986\n",
      "Iteration 1745, loss = 3.49320896\n",
      "Iteration 1746, loss = 3.49303813\n",
      "Iteration 1747, loss = 3.49286736\n",
      "Iteration 1748, loss = 3.49269665\n",
      "Iteration 1749, loss = 3.49252600\n",
      "Iteration 1750, loss = 3.49235541\n",
      "Iteration 1751, loss = 3.49218488\n",
      "Iteration 1752, loss = 3.49201441\n",
      "Iteration 1753, loss = 3.49184400\n",
      "Iteration 1754, loss = 3.49167365\n",
      "Iteration 1755, loss = 3.49150336\n",
      "Iteration 1756, loss = 3.49133313\n",
      "Iteration 1757, loss = 3.49116296\n",
      "Iteration 1758, loss = 3.49099285\n",
      "Iteration 1759, loss = 3.49082279\n",
      "Iteration 1760, loss = 3.49065280\n",
      "Iteration 1761, loss = 3.49048286\n",
      "Iteration 1762, loss = 3.49031298\n",
      "Iteration 1763, loss = 3.49014316\n",
      "Iteration 1764, loss = 3.48997340\n",
      "Iteration 1765, loss = 3.48980370\n",
      "Iteration 1766, loss = 3.48963405\n",
      "Iteration 1767, loss = 3.48946447\n",
      "Iteration 1768, loss = 3.48929494\n",
      "Iteration 1769, loss = 3.48912546\n",
      "Iteration 1770, loss = 3.48895605\n",
      "Iteration 1771, loss = 3.48878669\n",
      "Iteration 1772, loss = 3.48861738\n",
      "Iteration 1773, loss = 3.48844814\n",
      "Iteration 1774, loss = 3.48827895\n",
      "Iteration 1775, loss = 3.48810981\n",
      "Iteration 1776, loss = 3.48794073\n",
      "Iteration 1777, loss = 3.48777171\n",
      "Iteration 1778, loss = 3.48760275\n",
      "Iteration 1779, loss = 3.48743383\n",
      "Iteration 1780, loss = 3.48726498\n",
      "Iteration 1781, loss = 3.48709618\n",
      "Iteration 1782, loss = 3.48692743\n",
      "Iteration 1783, loss = 3.48675874\n",
      "Iteration 1784, loss = 3.48659011\n",
      "Iteration 1785, loss = 3.48642153\n",
      "Iteration 1786, loss = 3.48625300\n",
      "Iteration 1787, loss = 3.48608453\n",
      "Iteration 1788, loss = 3.48591611\n",
      "Iteration 1789, loss = 3.48574774\n",
      "Iteration 1790, loss = 3.48557943\n",
      "Iteration 1791, loss = 3.48541117\n",
      "Iteration 1792, loss = 3.48524297\n",
      "Iteration 1793, loss = 3.48507482\n",
      "Iteration 1794, loss = 3.48490672\n",
      "Iteration 1795, loss = 3.48473868\n",
      "Iteration 1796, loss = 3.48457068\n",
      "Iteration 1797, loss = 3.48440274\n",
      "Iteration 1798, loss = 3.48423486\n",
      "Iteration 1799, loss = 3.48406702\n",
      "Iteration 1800, loss = 3.48389924\n",
      "Iteration 1801, loss = 3.48373151\n",
      "Iteration 1802, loss = 3.48356383\n",
      "Iteration 1803, loss = 3.48339620\n",
      "Iteration 1804, loss = 3.48322862\n",
      "Iteration 1805, loss = 3.48306109\n",
      "Iteration 1806, loss = 3.48289362\n",
      "Iteration 1807, loss = 3.48272620\n",
      "Iteration 1808, loss = 3.48255882\n",
      "Iteration 1809, loss = 3.48239150\n",
      "Iteration 1810, loss = 3.48222423\n",
      "Iteration 1811, loss = 3.48205701\n",
      "Iteration 1812, loss = 3.48188983\n",
      "Iteration 1813, loss = 3.48172271\n",
      "Iteration 1814, loss = 3.48155564\n",
      "Iteration 1815, loss = 3.48138862\n",
      "Iteration 1816, loss = 3.48122164\n",
      "Iteration 1817, loss = 3.48105472\n",
      "Iteration 1818, loss = 3.48088784\n",
      "Iteration 1819, loss = 3.48072102\n",
      "Iteration 1820, loss = 3.48055424\n",
      "Iteration 1821, loss = 3.48038751\n",
      "Iteration 1822, loss = 3.48022083\n",
      "Iteration 1823, loss = 3.48005420\n",
      "Iteration 1824, loss = 3.47988762\n",
      "Iteration 1825, loss = 3.47972108\n",
      "Iteration 1826, loss = 3.47955459\n",
      "Iteration 1827, loss = 3.47938815\n",
      "Iteration 1828, loss = 3.47922176\n",
      "Iteration 1829, loss = 3.47905541\n",
      "Iteration 1830, loss = 3.47888912\n",
      "Iteration 1831, loss = 3.47872286\n",
      "Iteration 1832, loss = 3.47855666\n",
      "Iteration 1833, loss = 3.47839050\n",
      "Iteration 1834, loss = 3.47822439\n",
      "Iteration 1835, loss = 3.47805833\n",
      "Iteration 1836, loss = 3.47789231\n",
      "Iteration 1837, loss = 3.47772634\n",
      "Iteration 1838, loss = 3.47756041\n",
      "Iteration 1839, loss = 3.47739453\n",
      "Iteration 1840, loss = 3.47722869\n",
      "Iteration 1841, loss = 3.47706290\n",
      "Iteration 1842, loss = 3.47689716\n",
      "Iteration 1843, loss = 3.47673146\n",
      "Iteration 1844, loss = 3.47656581\n",
      "Iteration 1845, loss = 3.47640020\n",
      "Iteration 1846, loss = 3.47623463\n",
      "Iteration 1847, loss = 3.47606911\n",
      "Iteration 1848, loss = 3.47590364\n",
      "Iteration 1849, loss = 3.47573821\n",
      "Iteration 1850, loss = 3.47557282\n",
      "Iteration 1851, loss = 3.47540748\n",
      "Iteration 1852, loss = 3.47524218\n",
      "Iteration 1853, loss = 3.47507692\n",
      "Iteration 1854, loss = 3.47491171\n",
      "Iteration 1855, loss = 3.47474654\n",
      "Iteration 1856, loss = 3.47458141\n",
      "Iteration 1857, loss = 3.47441633\n",
      "Iteration 1858, loss = 3.47425129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1859, loss = 3.47408629\n",
      "Iteration 1860, loss = 3.47392134\n",
      "Iteration 1861, loss = 3.47375643\n",
      "Iteration 1862, loss = 3.47359156\n",
      "Iteration 1863, loss = 3.47342673\n",
      "Iteration 1864, loss = 3.47326194\n",
      "Iteration 1865, loss = 3.47309720\n",
      "Iteration 1866, loss = 3.47293250\n",
      "Iteration 1867, loss = 3.47276784\n",
      "Iteration 1868, loss = 3.47260322\n",
      "Iteration 1869, loss = 3.47243864\n",
      "Iteration 1870, loss = 3.47227410\n",
      "Iteration 1871, loss = 3.47210961\n",
      "Iteration 1872, loss = 3.47194515\n",
      "Iteration 1873, loss = 3.47178074\n",
      "Iteration 1874, loss = 3.47161636\n",
      "Iteration 1875, loss = 3.47145203\n",
      "Iteration 1876, loss = 3.47128773\n",
      "Iteration 1877, loss = 3.47112348\n",
      "Iteration 1878, loss = 3.47095927\n",
      "Iteration 1879, loss = 3.47079509\n",
      "Iteration 1880, loss = 3.47063096\n",
      "Iteration 1881, loss = 3.47046687\n",
      "Iteration 1882, loss = 3.47030281\n",
      "Iteration 1883, loss = 3.47013880\n",
      "Iteration 1884, loss = 3.46997482\n",
      "Iteration 1885, loss = 3.46981088\n",
      "Iteration 1886, loss = 3.46964698\n",
      "Iteration 1887, loss = 3.46948312\n",
      "Iteration 1888, loss = 3.46931930\n",
      "Iteration 1889, loss = 3.46915552\n",
      "Iteration 1890, loss = 3.46899177\n",
      "Iteration 1891, loss = 3.46882806\n",
      "Iteration 1892, loss = 3.46866440\n",
      "Iteration 1893, loss = 3.46850076\n",
      "Iteration 1894, loss = 3.46833717\n",
      "Iteration 1895, loss = 3.46817361\n",
      "Iteration 1896, loss = 3.46801010\n",
      "Iteration 1897, loss = 3.46784661\n",
      "Iteration 1898, loss = 3.46768317\n",
      "Iteration 1899, loss = 3.46751976\n",
      "Iteration 1900, loss = 3.46735639\n",
      "Iteration 1901, loss = 3.46719306\n",
      "Iteration 1902, loss = 3.46702976\n",
      "Iteration 1903, loss = 3.46686650\n",
      "Iteration 1904, loss = 3.46670328\n",
      "Iteration 1905, loss = 3.46654009\n",
      "Iteration 1906, loss = 3.46637694\n",
      "Iteration 1907, loss = 3.46621382\n",
      "Iteration 1908, loss = 3.46605074\n",
      "Iteration 1909, loss = 3.46588770\n",
      "Iteration 1910, loss = 3.46572469\n",
      "Iteration 1911, loss = 3.46556171\n",
      "Iteration 1912, loss = 3.46539878\n",
      "Iteration 1913, loss = 3.46523587\n",
      "Iteration 1914, loss = 3.46507300\n",
      "Iteration 1915, loss = 3.46491017\n",
      "Iteration 1916, loss = 3.46474737\n",
      "Iteration 1917, loss = 3.46458461\n",
      "Iteration 1918, loss = 3.46442188\n",
      "Iteration 1919, loss = 3.46425918\n",
      "Iteration 1920, loss = 3.46409652\n",
      "Iteration 1921, loss = 3.46393389\n",
      "Iteration 1922, loss = 3.46377130\n",
      "Iteration 1923, loss = 3.46360874\n",
      "Iteration 1924, loss = 3.46344622\n",
      "Iteration 1925, loss = 3.46328372\n",
      "Iteration 1926, loss = 3.46312127\n",
      "Iteration 1927, loss = 3.46295884\n",
      "Iteration 1928, loss = 3.46279645\n",
      "Iteration 1929, loss = 3.46263409\n",
      "Iteration 1930, loss = 3.46247176\n",
      "Iteration 1931, loss = 3.46230947\n",
      "Iteration 1932, loss = 3.46214721\n",
      "Iteration 1933, loss = 3.46198498\n",
      "Iteration 1934, loss = 3.46182279\n",
      "Iteration 1935, loss = 3.46166062\n",
      "Iteration 1936, loss = 3.46149849\n",
      "Iteration 1937, loss = 3.46133639\n",
      "Iteration 1938, loss = 3.46117432\n",
      "Iteration 1939, loss = 3.46101229\n",
      "Iteration 1940, loss = 3.46085028\n",
      "Iteration 1941, loss = 3.46068831\n",
      "Iteration 1942, loss = 3.46052637\n",
      "Iteration 1943, loss = 3.46036446\n",
      "Iteration 1944, loss = 3.46020258\n",
      "Iteration 1945, loss = 3.46004074\n",
      "Iteration 1946, loss = 3.45987892\n",
      "Iteration 1947, loss = 3.45971713\n",
      "Iteration 1948, loss = 3.45955538\n",
      "Iteration 1949, loss = 3.45939365\n",
      "Iteration 1950, loss = 3.45923196\n",
      "Iteration 1951, loss = 3.45907030\n",
      "Iteration 1952, loss = 3.45890866\n",
      "Iteration 1953, loss = 3.45874706\n",
      "Iteration 1954, loss = 3.45858549\n",
      "Iteration 1955, loss = 3.45842394\n",
      "Iteration 1956, loss = 3.45826243\n",
      "Iteration 1957, loss = 3.45810094\n",
      "Iteration 1958, loss = 3.45793949\n",
      "Iteration 1959, loss = 3.45777807\n",
      "Iteration 1960, loss = 3.45761667\n",
      "Iteration 1961, loss = 3.45745530\n",
      "Iteration 1962, loss = 3.45729396\n",
      "Iteration 1963, loss = 3.45713266\n",
      "Iteration 1964, loss = 3.45697138\n",
      "Iteration 1965, loss = 3.45681012\n",
      "Iteration 1966, loss = 3.45664890\n",
      "Iteration 1967, loss = 3.45648771\n",
      "Iteration 1968, loss = 3.45632654\n",
      "Iteration 1969, loss = 3.45616540\n",
      "Iteration 1970, loss = 3.45600429\n",
      "Iteration 1971, loss = 3.45584321\n",
      "Iteration 1972, loss = 3.45568216\n",
      "Iteration 1973, loss = 3.45552113\n",
      "Iteration 1974, loss = 3.45536013\n",
      "Iteration 1975, loss = 3.45519916\n",
      "Iteration 1976, loss = 3.45503822\n",
      "Iteration 1977, loss = 3.45487730\n",
      "Iteration 1978, loss = 3.45471641\n",
      "Iteration 1979, loss = 3.45455555\n",
      "Iteration 1980, loss = 3.45439472\n",
      "Iteration 1981, loss = 3.45423391\n",
      "Iteration 1982, loss = 3.45407313\n",
      "Iteration 1983, loss = 3.45391238\n",
      "Iteration 1984, loss = 3.45375165\n",
      "Iteration 1985, loss = 3.45359095\n",
      "Iteration 1986, loss = 3.45343027\n",
      "Iteration 1987, loss = 3.45326962\n",
      "Iteration 1988, loss = 3.45310900\n",
      "Iteration 1989, loss = 3.45294840\n",
      "Iteration 1990, loss = 3.45278783\n",
      "Iteration 1991, loss = 3.45262729\n",
      "Iteration 1992, loss = 3.45246677\n",
      "Iteration 1993, loss = 3.45230627\n",
      "Iteration 1994, loss = 3.45214581\n",
      "Iteration 1995, loss = 3.45198536\n",
      "Iteration 1996, loss = 3.45182494\n",
      "Iteration 1997, loss = 3.45166455\n",
      "Iteration 1998, loss = 3.45150418\n",
      "Iteration 1999, loss = 3.45134384\n",
      "Iteration 2000, loss = 3.45118352\n"
     ]
    }
   ],
   "source": [
    "#setting up variable that will store confusion matrices\n",
    "confusion_matrices_test3 = []\n",
    "\n",
    "#We iterate over datasets for each fold\n",
    "for dataset in model3_data_indexes:\n",
    "    #From the list of all indexes we get only the ones for a given fold\n",
    "    train_indexes=dataset[0]\n",
    "    test_indexes=dataset[1]\n",
    "\n",
    "    #We fit the model using data with indexes for a given fold\n",
    "    clf3.fit(X_data.iloc[train_indexes], y_data.iloc[train_indexes])\n",
    "    #Predict values on the test data\n",
    "    y_pred3 = clf3.predict(X_data.iloc[test_indexes])\n",
    "    \n",
    "    #calculating multilabel_confusion_matrix\n",
    "    cm = multilabel_confusion_matrix(y_data.iloc[test_indexes], y_pred3)\n",
    "    \n",
    "    #setting up variable for cell-by-cell summation\n",
    "    res = np.matrix([[0, 0], [0, 0]])  \n",
    "    \n",
    "    #cell-by-cell summation of the confusion matrices\n",
    "    for item in cm:\n",
    "        single_cm = np.matrix(item)\n",
    "        res += single_cm\n",
    "    \n",
    "    #adding summed confussion_matrix to the variable with the results\n",
    "    confusion_matrices_test3.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold index 0\n",
      "[[142  67]\n",
      " [ 80 110]]\n",
      "Fold index 1\n",
      "[[165  56]\n",
      " [ 56 122]]\n",
      "Fold index 2\n",
      "[[169  63]\n",
      " [ 55 105]]\n"
     ]
    }
   ],
   "source": [
    "#printing resulted confusion matrices\n",
    "for fold, cm in enumerate(confusion_matrices_test3):\n",
    "    print(\"Fold index\", fold)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.36372677\n",
      "Iteration 2, loss = 4.86860399\n",
      "Iteration 3, loss = 4.52668702\n",
      "Iteration 4, loss = 4.30290986\n",
      "Iteration 5, loss = 4.16788263\n",
      "Iteration 6, loss = 4.09707362\n",
      "Iteration 7, loss = 4.06295036\n",
      "Iteration 8, loss = 4.04499828\n",
      "Iteration 9, loss = 4.03121963\n",
      "Iteration 10, loss = 4.01560191\n",
      "Iteration 11, loss = 3.99599952\n",
      "Iteration 12, loss = 3.97183797\n",
      "Iteration 13, loss = 3.94317026\n",
      "Iteration 14, loss = 3.91094879\n",
      "Iteration 15, loss = 3.87704475\n",
      "Iteration 16, loss = 3.84348679\n",
      "Iteration 17, loss = 3.81161691\n",
      "Iteration 18, loss = 3.78205383\n",
      "Iteration 19, loss = 3.75536227\n",
      "Iteration 20, loss = 3.73235646\n",
      "Iteration 21, loss = 3.71343227\n",
      "Iteration 22, loss = 3.69770327\n",
      "Iteration 23, loss = 3.68319498\n",
      "Iteration 24, loss = 3.66815682\n",
      "Iteration 25, loss = 3.65217043\n",
      "Iteration 26, loss = 3.63612433\n",
      "Iteration 27, loss = 3.62141359\n",
      "Iteration 28, loss = 3.60913903\n",
      "Iteration 29, loss = 3.59964384\n",
      "Iteration 30, loss = 3.59232095\n",
      "Iteration 31, loss = 3.58576421\n",
      "Iteration 32, loss = 3.57850757\n",
      "Iteration 33, loss = 3.56996044\n",
      "Iteration 34, loss = 3.56064717\n",
      "Iteration 35, loss = 3.55162960\n",
      "Iteration 36, loss = 3.54379544\n",
      "Iteration 37, loss = 3.53750021\n",
      "Iteration 38, loss = 3.53255133\n",
      "Iteration 39, loss = 3.52837917\n",
      "Iteration 40, loss = 3.52430263\n",
      "Iteration 41, loss = 3.51980533\n",
      "Iteration 42, loss = 3.51472069\n",
      "Iteration 43, loss = 3.50925000\n",
      "Iteration 44, loss = 3.50379748\n",
      "Iteration 45, loss = 3.49871452\n",
      "Iteration 46, loss = 3.49414240\n",
      "Iteration 47, loss = 3.49006581\n",
      "Iteration 48, loss = 3.48646118\n",
      "Iteration 49, loss = 3.48333346\n",
      "Iteration 50, loss = 3.48061433\n",
      "Iteration 51, loss = 3.47809431\n",
      "Iteration 52, loss = 3.47552121\n",
      "Iteration 53, loss = 3.47278288\n",
      "Iteration 54, loss = 3.46997557\n",
      "Iteration 55, loss = 3.46729233\n",
      "Iteration 56, loss = 3.46486556\n",
      "Iteration 57, loss = 3.46270566\n",
      "Iteration 58, loss = 3.46073820\n",
      "Iteration 59, loss = 3.45886454\n",
      "Iteration 60, loss = 3.45700102\n",
      "Iteration 61, loss = 3.45509690\n",
      "Iteration 62, loss = 3.45314186\n",
      "Iteration 63, loss = 3.45116536\n",
      "Iteration 64, loss = 3.44922143\n",
      "Iteration 65, loss = 3.44735648\n",
      "Iteration 66, loss = 3.44557853\n",
      "Iteration 67, loss = 3.44385583\n",
      "Iteration 68, loss = 3.44214830\n",
      "Iteration 69, loss = 3.44044128\n",
      "Iteration 70, loss = 3.43875206\n",
      "Iteration 71, loss = 3.43711259\n",
      "Iteration 72, loss = 3.43554959\n",
      "Iteration 73, loss = 3.43407438\n",
      "Iteration 74, loss = 3.43268054\n",
      "Iteration 75, loss = 3.43134729\n",
      "Iteration 76, loss = 3.43004818\n",
      "Iteration 77, loss = 3.42876161\n",
      "Iteration 78, loss = 3.42747836\n",
      "Iteration 79, loss = 3.42620290\n",
      "Iteration 80, loss = 3.42494740\n",
      "Iteration 81, loss = 3.42372232\n",
      "Iteration 82, loss = 3.42253090\n",
      "Iteration 83, loss = 3.42137051\n",
      "Iteration 84, loss = 3.42023600\n",
      "Iteration 85, loss = 3.41912118\n",
      "Iteration 86, loss = 3.41802058\n",
      "Iteration 87, loss = 3.41693218\n",
      "Iteration 88, loss = 3.41585813\n",
      "Iteration 89, loss = 3.41480240\n",
      "Iteration 90, loss = 3.41376798\n",
      "Iteration 91, loss = 3.41275544\n",
      "Iteration 92, loss = 3.41176301\n",
      "Iteration 93, loss = 3.41078751\n",
      "Iteration 94, loss = 3.40982570\n",
      "Iteration 95, loss = 3.40887585\n",
      "Iteration 96, loss = 3.40793845\n",
      "Iteration 97, loss = 3.40701498\n",
      "Iteration 98, loss = 3.40610568\n",
      "Iteration 99, loss = 3.40520908\n",
      "Iteration 100, loss = 3.40432364\n",
      "Iteration 101, loss = 3.40344895\n",
      "Iteration 102, loss = 3.40258552\n",
      "Iteration 103, loss = 3.40173425\n",
      "Iteration 104, loss = 3.40089599\n",
      "Iteration 105, loss = 3.40007093\n",
      "Iteration 106, loss = 3.39925859\n",
      "Iteration 107, loss = 3.39845852\n",
      "Iteration 108, loss = 3.39767089\n",
      "Iteration 109, loss = 3.39689626\n",
      "Iteration 110, loss = 3.39613480\n",
      "Iteration 111, loss = 3.39538601\n",
      "Iteration 112, loss = 3.39464949\n",
      "Iteration 113, loss = 3.39392536\n",
      "Iteration 114, loss = 3.39321400\n",
      "Iteration 115, loss = 3.39251576\n",
      "Iteration 116, loss = 3.39183098\n",
      "Iteration 117, loss = 3.39115980\n",
      "Iteration 118, loss = 3.39050210\n",
      "Iteration 119, loss = 3.38985769\n",
      "Iteration 120, loss = 3.38922643\n",
      "Iteration 121, loss = 3.38860831\n",
      "Iteration 122, loss = 3.38800338\n",
      "Iteration 123, loss = 3.38741173\n",
      "Iteration 124, loss = 3.38683342\n",
      "Iteration 125, loss = 3.38626836\n",
      "Iteration 126, loss = 3.38571636\n",
      "Iteration 127, loss = 3.38517727\n",
      "Iteration 128, loss = 3.38465098\n",
      "Iteration 129, loss = 3.38413731\n",
      "Iteration 130, loss = 3.38363606\n",
      "Iteration 131, loss = 3.38314706\n",
      "Iteration 132, loss = 3.38267015\n",
      "Iteration 133, loss = 3.38220521\n",
      "Iteration 134, loss = 3.38175216\n",
      "Iteration 135, loss = 3.38131082\n",
      "Iteration 136, loss = 3.38088088\n",
      "Iteration 137, loss = 3.38046198\n",
      "Iteration 138, loss = 3.38005387\n",
      "Iteration 139, loss = 3.37965635\n",
      "Iteration 140, loss = 3.37926925\n",
      "Iteration 141, loss = 3.37889232\n",
      "Iteration 142, loss = 3.37852528\n",
      "Iteration 143, loss = 3.37816786\n",
      "Iteration 144, loss = 3.37781983\n",
      "Iteration 145, loss = 3.37748101\n",
      "Iteration 146, loss = 3.37715117\n",
      "Iteration 147, loss = 3.37683007\n",
      "Iteration 148, loss = 3.37651750\n",
      "Iteration 149, loss = 3.37621324\n",
      "Iteration 150, loss = 3.37591708\n",
      "Iteration 151, loss = 3.37562881\n",
      "Iteration 152, loss = 3.37534820\n",
      "Iteration 153, loss = 3.37507505\n",
      "Iteration 154, loss = 3.37480918\n",
      "Iteration 155, loss = 3.37455042\n",
      "Iteration 156, loss = 3.37429860\n",
      "Iteration 157, loss = 3.37405353\n",
      "Iteration 158, loss = 3.37381501\n",
      "Iteration 159, loss = 3.37358285\n",
      "Iteration 160, loss = 3.37335690\n",
      "Iteration 161, loss = 3.37313700\n",
      "Iteration 162, loss = 3.37292299\n",
      "Iteration 163, loss = 3.37271469\n",
      "Iteration 164, loss = 3.37251194\n",
      "Iteration 165, loss = 3.37231460\n",
      "Iteration 166, loss = 3.37212251\n",
      "Iteration 167, loss = 3.37193551\n",
      "Iteration 168, loss = 3.37175346\n",
      "Iteration 169, loss = 3.37157623\n",
      "Iteration 170, loss = 3.37140368\n",
      "Iteration 171, loss = 3.37123567\n",
      "Iteration 172, loss = 3.37107207\n",
      "Iteration 173, loss = 3.37091274\n",
      "Iteration 174, loss = 3.37075757\n",
      "Iteration 175, loss = 3.37060643\n",
      "Iteration 176, loss = 3.37045920\n",
      "Iteration 177, loss = 3.37031576\n",
      "Iteration 178, loss = 3.37017601\n",
      "Iteration 179, loss = 3.37003984\n",
      "Iteration 180, loss = 3.36990713\n",
      "Iteration 181, loss = 3.36977778\n",
      "Iteration 182, loss = 3.36965170\n",
      "Iteration 183, loss = 3.36952878\n",
      "Iteration 184, loss = 3.36940893\n",
      "Iteration 185, loss = 3.36929207\n",
      "Iteration 186, loss = 3.36917809\n",
      "Iteration 187, loss = 3.36906691\n",
      "Iteration 188, loss = 3.36895845\n",
      "Iteration 189, loss = 3.36885264\n",
      "Iteration 190, loss = 3.36874938\n",
      "Iteration 191, loss = 3.36864860\n",
      "Iteration 192, loss = 3.36855024\n",
      "Iteration 193, loss = 3.36845422\n",
      "Iteration 194, loss = 3.36836046\n",
      "Iteration 195, loss = 3.36826892\n",
      "Iteration 196, loss = 3.36817951\n",
      "Iteration 197, loss = 3.36809219\n",
      "Iteration 198, loss = 3.36800688\n",
      "Iteration 199, loss = 3.36792354\n",
      "Iteration 200, loss = 3.36784210\n",
      "Iteration 201, loss = 3.36776251\n",
      "Iteration 202, loss = 3.36768472\n",
      "Iteration 203, loss = 3.36760867\n",
      "Iteration 204, loss = 3.36753433\n",
      "Iteration 205, loss = 3.36746163\n",
      "Iteration 206, loss = 3.36739053\n",
      "Iteration 207, loss = 3.36732099\n",
      "Iteration 208, loss = 3.36725297\n",
      "Iteration 209, loss = 3.36718642\n",
      "Iteration 210, loss = 3.36712129\n",
      "Iteration 211, loss = 3.36705756\n",
      "Iteration 212, loss = 3.36699517\n",
      "Iteration 213, loss = 3.36693410\n",
      "Iteration 214, loss = 3.36687430\n",
      "Iteration 215, loss = 3.36681575\n",
      "Iteration 216, loss = 3.36675840\n",
      "Iteration 217, loss = 3.36670223\n",
      "Iteration 218, loss = 3.36664720\n",
      "Iteration 219, loss = 3.36659328\n",
      "Iteration 220, loss = 3.36654045\n",
      "Iteration 221, loss = 3.36648866\n",
      "Iteration 222, loss = 3.36643791\n",
      "Iteration 223, loss = 3.36638815\n",
      "Iteration 224, loss = 3.36633936\n",
      "Iteration 225, loss = 3.36629152\n",
      "Iteration 226, loss = 3.36624460\n",
      "Iteration 227, loss = 3.36619858\n",
      "Iteration 228, loss = 3.36615343\n",
      "Iteration 229, loss = 3.36610914\n",
      "Iteration 230, loss = 3.36606568\n",
      "Iteration 231, loss = 3.36602303\n",
      "Iteration 232, loss = 3.36598117\n",
      "Iteration 233, loss = 3.36594009\n",
      "Iteration 234, loss = 3.36589975\n",
      "Iteration 235, loss = 3.36586015\n",
      "Iteration 236, loss = 3.36582126\n",
      "Iteration 237, loss = 3.36578307\n",
      "Iteration 238, loss = 3.36574557\n",
      "Iteration 239, loss = 3.36570873\n",
      "Iteration 240, loss = 3.36567253\n",
      "Iteration 241, loss = 3.36563697\n",
      "Iteration 242, loss = 3.36560203\n",
      "Iteration 243, loss = 3.36556769\n",
      "Iteration 244, loss = 3.36553395\n",
      "Iteration 245, loss = 3.36550077\n",
      "Iteration 246, loss = 3.36546817\n",
      "Iteration 247, loss = 3.36543611\n",
      "Iteration 248, loss = 3.36540459\n",
      "Iteration 249, loss = 3.36537359\n",
      "Iteration 250, loss = 3.36534311\n",
      "Iteration 251, loss = 3.36531313\n",
      "Iteration 252, loss = 3.36528364\n",
      "Iteration 253, loss = 3.36525462\n",
      "Iteration 254, loss = 3.36522608\n",
      "Iteration 255, loss = 3.36519800\n",
      "Iteration 256, loss = 3.36517036\n",
      "Iteration 257, loss = 3.36514317\n",
      "Iteration 258, loss = 3.36511640\n",
      "Iteration 259, loss = 3.36509006\n",
      "Iteration 260, loss = 3.36506412\n",
      "Iteration 261, loss = 3.36503859\n",
      "Iteration 262, loss = 3.36501345\n",
      "Iteration 263, loss = 3.36498870\n",
      "Iteration 264, loss = 3.36496432\n",
      "Iteration 265, loss = 3.36494032\n",
      "Iteration 266, loss = 3.36491668\n",
      "Iteration 267, loss = 3.36489339\n",
      "Iteration 268, loss = 3.36487045\n",
      "Iteration 269, loss = 3.36484785\n",
      "Iteration 270, loss = 3.36482558\n",
      "Iteration 271, loss = 3.36480365\n",
      "Iteration 272, loss = 3.36478203\n",
      "Iteration 273, loss = 3.36476072\n",
      "Iteration 274, loss = 3.36473972\n",
      "Iteration 275, loss = 3.36471903\n",
      "Iteration 276, loss = 3.36469863\n",
      "Iteration 277, loss = 3.36467852\n",
      "Iteration 278, loss = 3.36465870\n",
      "Iteration 279, loss = 3.36463915\n",
      "Iteration 280, loss = 3.36461988\n",
      "Iteration 281, loss = 3.36460087\n",
      "Iteration 282, loss = 3.36458213\n",
      "Iteration 283, loss = 3.36456365\n",
      "Iteration 284, loss = 3.36454542\n",
      "Iteration 285, loss = 3.36452744\n",
      "Iteration 286, loss = 3.36450970\n",
      "Iteration 287, loss = 3.36449221\n",
      "Iteration 288, loss = 3.36447494\n",
      "Iteration 289, loss = 3.36445791\n",
      "Iteration 290, loss = 3.36444111\n",
      "Iteration 291, loss = 3.36442453\n",
      "Iteration 292, loss = 3.36440816\n",
      "Iteration 293, loss = 3.36439202\n",
      "Iteration 294, loss = 3.36437608\n",
      "Iteration 295, loss = 3.36436035\n",
      "Iteration 296, loss = 3.36434482\n",
      "Iteration 297, loss = 3.36432949\n",
      "Iteration 298, loss = 3.36431436\n",
      "Iteration 299, loss = 3.36429942\n",
      "Iteration 300, loss = 3.36428467\n",
      "Iteration 301, loss = 3.36427011\n",
      "Iteration 302, loss = 3.36425573\n",
      "Iteration 303, loss = 3.36424153\n",
      "Iteration 304, loss = 3.36422751\n",
      "Iteration 305, loss = 3.36421366\n",
      "Iteration 306, loss = 3.36419998\n",
      "Iteration 307, loss = 3.36418647\n",
      "Iteration 308, loss = 3.36417312\n",
      "Iteration 309, loss = 3.36415994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310, loss = 3.36414691\n",
      "Iteration 311, loss = 3.36413405\n",
      "Iteration 312, loss = 3.36412134\n",
      "Iteration 313, loss = 3.36410878\n",
      "Iteration 314, loss = 3.36409637\n",
      "Iteration 315, loss = 3.36408410\n",
      "Iteration 316, loss = 3.36407198\n",
      "Iteration 317, loss = 3.36406001\n",
      "Iteration 318, loss = 3.36404817\n",
      "Iteration 319, loss = 3.36403647\n",
      "Iteration 320, loss = 3.36402491\n",
      "Iteration 321, loss = 3.36401348\n",
      "Iteration 322, loss = 3.36400218\n",
      "Iteration 323, loss = 3.36399101\n",
      "Iteration 324, loss = 3.36397997\n",
      "Iteration 325, loss = 3.36396906\n",
      "Iteration 326, loss = 3.36395827\n",
      "Iteration 327, loss = 3.36394759\n",
      "Iteration 328, loss = 3.36393704\n",
      "Iteration 329, loss = 3.36392661\n",
      "Iteration 330, loss = 3.36391629\n",
      "Iteration 331, loss = 3.36390609\n",
      "Iteration 332, loss = 3.36389600\n",
      "Iteration 333, loss = 3.36388602\n",
      "Iteration 334, loss = 3.36387615\n",
      "Iteration 335, loss = 3.36386639\n",
      "Iteration 336, loss = 3.36385673\n",
      "Iteration 337, loss = 3.36384718\n",
      "Iteration 338, loss = 3.36383773\n",
      "Iteration 339, loss = 3.36382838\n",
      "Iteration 340, loss = 3.36381913\n",
      "Iteration 341, loss = 3.36380998\n",
      "Iteration 342, loss = 3.36380093\n",
      "Iteration 343, loss = 3.36379197\n",
      "Iteration 344, loss = 3.36378311\n",
      "Iteration 345, loss = 3.36377434\n",
      "Iteration 346, loss = 3.36376566\n",
      "Iteration 347, loss = 3.36375708\n",
      "Iteration 348, loss = 3.36374858\n",
      "Iteration 349, loss = 3.36374017\n",
      "Iteration 350, loss = 3.36373184\n",
      "Iteration 351, loss = 3.36372360\n",
      "Iteration 352, loss = 3.36371545\n",
      "Iteration 353, loss = 3.36370737\n",
      "Iteration 354, loss = 3.36369938\n",
      "Iteration 355, loss = 3.36369147\n",
      "Iteration 356, loss = 3.36368364\n",
      "Iteration 357, loss = 3.36367589\n",
      "Iteration 358, loss = 3.36366822\n",
      "Iteration 359, loss = 3.36366062\n",
      "Iteration 360, loss = 3.36365309\n",
      "Iteration 361, loss = 3.36364565\n",
      "Iteration 362, loss = 3.36363827\n",
      "Iteration 363, loss = 3.36363097\n",
      "Iteration 364, loss = 3.36362374\n",
      "Iteration 365, loss = 3.36361657\n",
      "Iteration 366, loss = 3.36360948\n",
      "Iteration 367, loss = 3.36360246\n",
      "Iteration 368, loss = 3.36359550\n",
      "Iteration 369, loss = 3.36358862\n",
      "Iteration 370, loss = 3.36358179\n",
      "Iteration 371, loss = 3.36357503\n",
      "Iteration 372, loss = 3.36356834\n",
      "Iteration 373, loss = 3.36356171\n",
      "Iteration 374, loss = 3.36355514\n",
      "Iteration 375, loss = 3.36354864\n",
      "Iteration 376, loss = 3.36354219\n",
      "Iteration 377, loss = 3.36353581\n",
      "Iteration 378, loss = 3.36352948\n",
      "Iteration 379, loss = 3.36352321\n",
      "Iteration 380, loss = 3.36351701\n",
      "Iteration 381, loss = 3.36351085\n",
      "Iteration 382, loss = 3.36350476\n",
      "Iteration 383, loss = 3.36349872\n",
      "Iteration 384, loss = 3.36349274\n",
      "Iteration 385, loss = 3.36348681\n",
      "Iteration 386, loss = 3.36348093\n",
      "Iteration 387, loss = 3.36347511\n",
      "Iteration 388, loss = 3.36346934\n",
      "Iteration 389, loss = 3.36346362\n",
      "Iteration 390, loss = 3.36345795\n",
      "Iteration 391, loss = 3.36345233\n",
      "Iteration 392, loss = 3.36344676\n",
      "Iteration 393, loss = 3.36344125\n",
      "Iteration 394, loss = 3.36343578\n",
      "Iteration 395, loss = 3.36343036\n",
      "Iteration 396, loss = 3.36342498\n",
      "Iteration 397, loss = 3.36341966\n",
      "Iteration 398, loss = 3.36341438\n",
      "Iteration 399, loss = 3.36340914\n",
      "Iteration 400, loss = 3.36340395\n",
      "Iteration 401, loss = 3.36339881\n",
      "Iteration 402, loss = 3.36339371\n",
      "Iteration 403, loss = 3.36338865\n",
      "Iteration 404, loss = 3.36338364\n",
      "Iteration 405, loss = 3.36337867\n",
      "Iteration 406, loss = 3.36337374\n",
      "Iteration 407, loss = 3.36336886\n",
      "Iteration 408, loss = 3.36336401\n",
      "Iteration 409, loss = 3.36335921\n",
      "Iteration 410, loss = 3.36335445\n",
      "Iteration 411, loss = 3.36334972\n",
      "Iteration 412, loss = 3.36334504\n",
      "Iteration 413, loss = 3.36334039\n",
      "Iteration 414, loss = 3.36333579\n",
      "Iteration 415, loss = 3.36333122\n",
      "Iteration 416, loss = 3.36332669\n",
      "Iteration 417, loss = 3.36332219\n",
      "Iteration 418, loss = 3.36331774\n",
      "Iteration 419, loss = 3.36331332\n",
      "Iteration 420, loss = 3.36330893\n",
      "Iteration 421, loss = 3.36330458\n",
      "Iteration 422, loss = 3.36330027\n",
      "Iteration 423, loss = 3.36329599\n",
      "Iteration 424, loss = 3.36329175\n",
      "Iteration 425, loss = 3.36328754\n",
      "Iteration 426, loss = 3.36328336\n",
      "Iteration 427, loss = 3.36327922\n",
      "Iteration 428, loss = 3.36327511\n",
      "Iteration 429, loss = 3.36327103\n",
      "Iteration 430, loss = 3.36326699\n",
      "Iteration 431, loss = 3.36326298\n",
      "Iteration 432, loss = 3.36325899\n",
      "Iteration 433, loss = 3.36325504\n",
      "Iteration 434, loss = 3.36325112\n",
      "Iteration 435, loss = 3.36324724\n",
      "Iteration 436, loss = 3.36324338\n",
      "Iteration 437, loss = 3.36323955\n",
      "Iteration 438, loss = 3.36323575\n",
      "Iteration 439, loss = 3.36323198\n",
      "Iteration 440, loss = 3.36322824\n",
      "Iteration 441, loss = 3.36322453\n",
      "Iteration 442, loss = 3.36322085\n",
      "Iteration 443, loss = 3.36321719\n",
      "Iteration 444, loss = 3.36321357\n",
      "Iteration 445, loss = 3.36320997\n",
      "Iteration 446, loss = 3.36320639\n",
      "Iteration 447, loss = 3.36320285\n",
      "Iteration 448, loss = 3.36319933\n",
      "Iteration 449, loss = 3.36319584\n",
      "Iteration 450, loss = 3.36319237\n",
      "Iteration 451, loss = 3.36318893\n",
      "Iteration 452, loss = 3.36318552\n",
      "Iteration 453, loss = 3.36318213\n",
      "Iteration 454, loss = 3.36317877\n",
      "Iteration 455, loss = 3.36317543\n",
      "Iteration 456, loss = 3.36317211\n",
      "Iteration 457, loss = 3.36316882\n",
      "Iteration 458, loss = 3.36316556\n",
      "Iteration 459, loss = 3.36316231\n",
      "Iteration 460, loss = 3.36315910\n",
      "Iteration 461, loss = 3.36315590\n",
      "Iteration 462, loss = 3.36315273\n",
      "Iteration 463, loss = 3.36314958\n",
      "Iteration 464, loss = 3.36314646\n",
      "Iteration 465, loss = 3.36314335\n",
      "Iteration 466, loss = 3.36314027\n",
      "Iteration 467, loss = 3.36313721\n",
      "Iteration 468, loss = 3.36313417\n",
      "Iteration 469, loss = 3.36313116\n",
      "Iteration 470, loss = 3.36312816\n",
      "Iteration 471, loss = 3.36312519\n",
      "Iteration 472, loss = 3.36312224\n",
      "Iteration 473, loss = 3.36311931\n",
      "Iteration 474, loss = 3.36311640\n",
      "Iteration 475, loss = 3.36311351\n",
      "Iteration 476, loss = 3.36311065\n",
      "Iteration 477, loss = 3.36310781\n",
      "Iteration 478, loss = 3.36310501\n",
      "Iteration 479, loss = 3.36310232\n",
      "Iteration 480, loss = 3.36309991\n",
      "Iteration 481, loss = 3.36309840\n",
      "Iteration 482, loss = 3.36309992\n",
      "Iteration 483, loss = 3.36311178\n",
      "Iteration 484, loss = 3.36315884\n",
      "Iteration 485, loss = 3.36332510\n",
      "Iteration 486, loss = 3.36384828\n",
      "Iteration 487, loss = 3.36522425\n",
      "Iteration 488, loss = 3.36714665\n",
      "Iteration 489, loss = 3.36741947\n",
      "Iteration 490, loss = 3.36421315\n",
      "Iteration 491, loss = 3.36330489\n",
      "Iteration 492, loss = 3.36550630\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 5.31407369\n",
      "Iteration 2, loss = 4.86067263\n",
      "Iteration 3, loss = 4.55618005\n",
      "Iteration 4, loss = 4.35698962\n",
      "Iteration 5, loss = 4.23636009\n",
      "Iteration 6, loss = 4.17812562\n",
      "Iteration 7, loss = 4.15762286\n",
      "Iteration 8, loss = 4.14777553\n",
      "Iteration 9, loss = 4.13552159\n",
      "Iteration 10, loss = 4.11892962\n",
      "Iteration 11, loss = 4.09872051\n",
      "Iteration 12, loss = 4.07465009\n",
      "Iteration 13, loss = 4.04646270\n",
      "Iteration 14, loss = 4.01553273\n",
      "Iteration 15, loss = 3.98478791\n",
      "Iteration 16, loss = 3.95738508\n",
      "Iteration 17, loss = 3.93548885\n",
      "Iteration 18, loss = 3.91988229\n",
      "Iteration 19, loss = 3.91004738\n",
      "Iteration 20, loss = 3.90415959\n",
      "Iteration 21, loss = 3.89926792\n",
      "Iteration 22, loss = 3.89252895\n",
      "Iteration 23, loss = 3.88282441\n",
      "Iteration 24, loss = 3.87091808\n",
      "Iteration 25, loss = 3.85823515\n",
      "Iteration 26, loss = 3.84574196\n",
      "Iteration 27, loss = 3.83372936\n",
      "Iteration 28, loss = 3.82223582\n",
      "Iteration 29, loss = 3.81144935\n",
      "Iteration 30, loss = 3.80173159\n",
      "Iteration 31, loss = 3.79337271\n",
      "Iteration 32, loss = 3.78635724\n",
      "Iteration 33, loss = 3.78032754\n",
      "Iteration 34, loss = 3.77474027\n",
      "Iteration 35, loss = 3.76907053\n",
      "Iteration 36, loss = 3.76296166\n",
      "Iteration 37, loss = 3.75632585\n",
      "Iteration 38, loss = 3.74937097\n",
      "Iteration 39, loss = 3.74247626\n",
      "Iteration 40, loss = 3.73594274\n",
      "Iteration 41, loss = 3.72980417\n",
      "Iteration 42, loss = 3.72387623\n",
      "Iteration 43, loss = 3.71800429\n",
      "Iteration 44, loss = 3.71225832\n",
      "Iteration 45, loss = 3.70687383\n",
      "Iteration 46, loss = 3.70201095\n",
      "Iteration 47, loss = 3.69759224\n",
      "Iteration 48, loss = 3.69337868\n",
      "Iteration 49, loss = 3.68918131\n",
      "Iteration 50, loss = 3.68498744\n",
      "Iteration 51, loss = 3.68091011\n",
      "Iteration 52, loss = 3.67705286\n",
      "Iteration 53, loss = 3.67342681\n",
      "Iteration 54, loss = 3.66997058\n",
      "Iteration 55, loss = 3.66662546\n",
      "Iteration 56, loss = 3.66338457\n",
      "Iteration 57, loss = 3.66027269\n",
      "Iteration 58, loss = 3.65728754\n",
      "Iteration 59, loss = 3.65437770\n",
      "Iteration 60, loss = 3.65148683\n",
      "Iteration 61, loss = 3.64860728\n",
      "Iteration 62, loss = 3.64577703\n",
      "Iteration 63, loss = 3.64303510\n",
      "Iteration 64, loss = 3.64039553\n",
      "Iteration 65, loss = 3.63785372\n",
      "Iteration 66, loss = 3.63539927\n",
      "Iteration 67, loss = 3.63302389\n",
      "Iteration 68, loss = 3.63072194\n",
      "Iteration 69, loss = 3.62847938\n",
      "Iteration 70, loss = 3.62627062\n",
      "Iteration 71, loss = 3.62408151\n",
      "Iteration 72, loss = 3.62192765\n",
      "Iteration 73, loss = 3.61983686\n",
      "Iteration 74, loss = 3.61782074\n",
      "Iteration 75, loss = 3.61587033\n",
      "Iteration 76, loss = 3.61397195\n",
      "Iteration 77, loss = 3.61212308\n",
      "Iteration 78, loss = 3.61033275\n",
      "Iteration 79, loss = 3.60860510\n",
      "Iteration 80, loss = 3.60693177\n",
      "Iteration 81, loss = 3.60530754\n",
      "Iteration 82, loss = 3.60374095\n",
      "Iteration 83, loss = 3.60224159\n",
      "Iteration 84, loss = 3.60080553\n",
      "Iteration 85, loss = 3.59941704\n",
      "Iteration 86, loss = 3.59806316\n",
      "Iteration 87, loss = 3.59674563\n",
      "Iteration 88, loss = 3.59547342\n",
      "Iteration 89, loss = 3.59424814\n",
      "Iteration 90, loss = 3.59306557\n",
      "Iteration 91, loss = 3.59192432\n",
      "Iteration 92, loss = 3.59082592\n",
      "Iteration 93, loss = 3.58976978\n",
      "Iteration 94, loss = 3.58875046\n",
      "Iteration 95, loss = 3.58776273\n",
      "Iteration 96, loss = 3.58680763\n",
      "Iteration 97, loss = 3.58588830\n",
      "Iteration 98, loss = 3.58500435\n",
      "Iteration 99, loss = 3.58415246\n",
      "Iteration 100, loss = 3.58332956\n",
      "Iteration 101, loss = 3.58253502\n",
      "Iteration 102, loss = 3.58176832\n",
      "Iteration 103, loss = 3.58102749\n",
      "Iteration 104, loss = 3.58031154\n",
      "Iteration 105, loss = 3.57962090\n",
      "Iteration 106, loss = 3.57895596\n",
      "Iteration 107, loss = 3.57831522\n",
      "Iteration 108, loss = 3.57769566\n",
      "Iteration 109, loss = 3.57709521\n",
      "Iteration 110, loss = 3.57651313\n",
      "Iteration 111, loss = 3.57594945\n",
      "Iteration 112, loss = 3.57540423\n",
      "Iteration 113, loss = 3.57487717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 114, loss = 3.57436772\n",
      "Iteration 115, loss = 3.57387467\n",
      "Iteration 116, loss = 3.57339677\n",
      "Iteration 117, loss = 3.57293324\n",
      "Iteration 118, loss = 3.57248397\n",
      "Iteration 119, loss = 3.57204900\n",
      "Iteration 120, loss = 3.57162794\n",
      "Iteration 121, loss = 3.57122011\n",
      "Iteration 122, loss = 3.57082476\n",
      "Iteration 123, loss = 3.57044133\n",
      "Iteration 124, loss = 3.57006947\n",
      "Iteration 125, loss = 3.56970902\n",
      "Iteration 126, loss = 3.56935986\n",
      "Iteration 127, loss = 3.56902176\n",
      "Iteration 128, loss = 3.56869421\n",
      "Iteration 129, loss = 3.56837658\n",
      "Iteration 130, loss = 3.56806842\n",
      "Iteration 131, loss = 3.56776948\n",
      "Iteration 132, loss = 3.56747959\n",
      "Iteration 133, loss = 3.56719851\n",
      "Iteration 134, loss = 3.56692601\n",
      "Iteration 135, loss = 3.56666184\n",
      "Iteration 136, loss = 3.56640565\n",
      "Iteration 137, loss = 3.56615707\n",
      "Iteration 138, loss = 3.56591586\n",
      "Iteration 139, loss = 3.56568179\n",
      "Iteration 140, loss = 3.56545463\n",
      "Iteration 141, loss = 3.56523409\n",
      "Iteration 142, loss = 3.56501997\n",
      "Iteration 143, loss = 3.56481203\n",
      "Iteration 144, loss = 3.56461005\n",
      "Iteration 145, loss = 3.56441384\n",
      "Iteration 146, loss = 3.56422325\n",
      "Iteration 147, loss = 3.56403805\n",
      "Iteration 148, loss = 3.56385800\n",
      "Iteration 149, loss = 3.56368294\n",
      "Iteration 150, loss = 3.56351271\n",
      "Iteration 151, loss = 3.56334715\n",
      "Iteration 152, loss = 3.56318610\n",
      "Iteration 153, loss = 3.56302943\n",
      "Iteration 154, loss = 3.56287698\n",
      "Iteration 155, loss = 3.56272860\n",
      "Iteration 156, loss = 3.56258416\n",
      "Iteration 157, loss = 3.56244353\n",
      "Iteration 158, loss = 3.56230656\n",
      "Iteration 159, loss = 3.56217315\n",
      "Iteration 160, loss = 3.56204320\n",
      "Iteration 161, loss = 3.56191659\n",
      "Iteration 162, loss = 3.56179323\n",
      "Iteration 163, loss = 3.56167299\n",
      "Iteration 164, loss = 3.56155579\n",
      "Iteration 165, loss = 3.56144151\n",
      "Iteration 166, loss = 3.56133007\n",
      "Iteration 167, loss = 3.56122139\n",
      "Iteration 168, loss = 3.56111538\n",
      "Iteration 169, loss = 3.56101195\n",
      "Iteration 170, loss = 3.56091102\n",
      "Iteration 171, loss = 3.56081251\n",
      "Iteration 172, loss = 3.56071635\n",
      "Iteration 173, loss = 3.56062247\n",
      "Iteration 174, loss = 3.56053080\n",
      "Iteration 175, loss = 3.56044126\n",
      "Iteration 176, loss = 3.56035379\n",
      "Iteration 177, loss = 3.56026834\n",
      "Iteration 178, loss = 3.56018484\n",
      "Iteration 179, loss = 3.56010323\n",
      "Iteration 180, loss = 3.56002346\n",
      "Iteration 181, loss = 3.55994548\n",
      "Iteration 182, loss = 3.55986922\n",
      "Iteration 183, loss = 3.55979465\n",
      "Iteration 184, loss = 3.55972171\n",
      "Iteration 185, loss = 3.55965036\n",
      "Iteration 186, loss = 3.55958055\n",
      "Iteration 187, loss = 3.55951224\n",
      "Iteration 188, loss = 3.55944538\n",
      "Iteration 189, loss = 3.55937993\n",
      "Iteration 190, loss = 3.55931586\n",
      "Iteration 191, loss = 3.55925313\n",
      "Iteration 192, loss = 3.55919169\n",
      "Iteration 193, loss = 3.55913152\n",
      "Iteration 194, loss = 3.55907259\n",
      "Iteration 195, loss = 3.55901485\n",
      "Iteration 196, loss = 3.55895827\n",
      "Iteration 197, loss = 3.55890283\n",
      "Iteration 198, loss = 3.55884849\n",
      "Iteration 199, loss = 3.55879522\n",
      "Iteration 200, loss = 3.55874300\n",
      "Iteration 201, loss = 3.55869180\n",
      "Iteration 202, loss = 3.55864159\n",
      "Iteration 203, loss = 3.55859235\n",
      "Iteration 204, loss = 3.55854405\n",
      "Iteration 205, loss = 3.55849667\n",
      "Iteration 206, loss = 3.55845018\n",
      "Iteration 207, loss = 3.55840457\n",
      "Iteration 208, loss = 3.55835980\n",
      "Iteration 209, loss = 3.55831586\n",
      "Iteration 210, loss = 3.55827273\n",
      "Iteration 211, loss = 3.55823039\n",
      "Iteration 212, loss = 3.55818882\n",
      "Iteration 213, loss = 3.55814800\n",
      "Iteration 214, loss = 3.55810791\n",
      "Iteration 215, loss = 3.55806854\n",
      "Iteration 216, loss = 3.55802986\n",
      "Iteration 217, loss = 3.55799186\n",
      "Iteration 218, loss = 3.55795453\n",
      "Iteration 219, loss = 3.55791785\n",
      "Iteration 220, loss = 3.55788180\n",
      "Iteration 221, loss = 3.55784637\n",
      "Iteration 222, loss = 3.55781155\n",
      "Iteration 223, loss = 3.55777732\n",
      "Iteration 224, loss = 3.55774367\n",
      "Iteration 225, loss = 3.55771058\n",
      "Iteration 226, loss = 3.55767804\n",
      "Iteration 227, loss = 3.55764604\n",
      "Iteration 228, loss = 3.55761457\n",
      "Iteration 229, loss = 3.55758362\n",
      "Iteration 230, loss = 3.55755317\n",
      "Iteration 231, loss = 3.55752322\n",
      "Iteration 232, loss = 3.55749374\n",
      "Iteration 233, loss = 3.55746474\n",
      "Iteration 234, loss = 3.55743620\n",
      "Iteration 235, loss = 3.55740812\n",
      "Iteration 236, loss = 3.55738047\n",
      "Iteration 237, loss = 3.55735326\n",
      "Iteration 238, loss = 3.55732648\n",
      "Iteration 239, loss = 3.55730010\n",
      "Iteration 240, loss = 3.55727414\n",
      "Iteration 241, loss = 3.55724857\n",
      "Iteration 242, loss = 3.55722340\n",
      "Iteration 243, loss = 3.55719860\n",
      "Iteration 244, loss = 3.55717418\n",
      "Iteration 245, loss = 3.55715012\n",
      "Iteration 246, loss = 3.55712643\n",
      "Iteration 247, loss = 3.55710308\n",
      "Iteration 248, loss = 3.55708008\n",
      "Iteration 249, loss = 3.55705742\n",
      "Iteration 250, loss = 3.55703509\n",
      "Iteration 251, loss = 3.55701308\n",
      "Iteration 252, loss = 3.55699140\n",
      "Iteration 253, loss = 3.55697002\n",
      "Iteration 254, loss = 3.55694895\n",
      "Iteration 255, loss = 3.55692818\n",
      "Iteration 256, loss = 3.55690771\n",
      "Iteration 257, loss = 3.55688752\n",
      "Iteration 258, loss = 3.55686762\n",
      "Iteration 259, loss = 3.55684799\n",
      "Iteration 260, loss = 3.55682864\n",
      "Iteration 261, loss = 3.55680956\n",
      "Iteration 262, loss = 3.55679073\n",
      "Iteration 263, loss = 3.55677217\n",
      "Iteration 264, loss = 3.55675386\n",
      "Iteration 265, loss = 3.55673580\n",
      "Iteration 266, loss = 3.55671798\n",
      "Iteration 267, loss = 3.55670040\n",
      "Iteration 268, loss = 3.55668305\n",
      "Iteration 269, loss = 3.55666594\n",
      "Iteration 270, loss = 3.55664905\n",
      "Iteration 271, loss = 3.55663238\n",
      "Iteration 272, loss = 3.55661594\n",
      "Iteration 273, loss = 3.55659971\n",
      "Iteration 274, loss = 3.55658369\n",
      "Iteration 275, loss = 3.55656787\n",
      "Iteration 276, loss = 3.55655226\n",
      "Iteration 277, loss = 3.55653685\n",
      "Iteration 278, loss = 3.55652164\n",
      "Iteration 279, loss = 3.55650663\n",
      "Iteration 280, loss = 3.55649182\n",
      "Iteration 281, loss = 3.55647724\n",
      "Iteration 282, loss = 3.55646297\n",
      "Iteration 283, loss = 3.55644930\n",
      "Iteration 284, loss = 3.55643717\n",
      "Iteration 285, loss = 3.55642981\n",
      "Iteration 286, loss = 3.55643821\n",
      "Iteration 287, loss = 3.55650046\n",
      "Iteration 288, loss = 3.55673607\n",
      "Iteration 289, loss = 3.55746986\n",
      "Iteration 290, loss = 3.55898552\n",
      "Iteration 291, loss = 3.56050011\n",
      "Iteration 292, loss = 3.55884578\n",
      "Iteration 293, loss = 3.55645129\n",
      "Iteration 294, loss = 3.55723108\n",
      "Iteration 295, loss = 3.55860304\n",
      "Iteration 296, loss = 3.55730042\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 5.50316831\n",
      "Iteration 2, loss = 4.98355300\n",
      "Iteration 3, loss = 4.62107767\n",
      "Iteration 4, loss = 4.39195933\n",
      "Iteration 5, loss = 4.26256098\n",
      "Iteration 6, loss = 4.20687042\n",
      "Iteration 7, loss = 4.19080588\n",
      "Iteration 8, loss = 4.18718117\n",
      "Iteration 9, loss = 4.18420012\n",
      "Iteration 10, loss = 4.17855109\n",
      "Iteration 11, loss = 4.16901915\n",
      "Iteration 12, loss = 4.15381576\n",
      "Iteration 13, loss = 4.13142390\n",
      "Iteration 14, loss = 4.10245204\n",
      "Iteration 15, loss = 4.06992294\n",
      "Iteration 16, loss = 4.03793580\n",
      "Iteration 17, loss = 4.00977521\n",
      "Iteration 18, loss = 3.98655829\n",
      "Iteration 19, loss = 3.96746255\n",
      "Iteration 20, loss = 3.95137164\n",
      "Iteration 21, loss = 3.93798468\n",
      "Iteration 22, loss = 3.92726796\n",
      "Iteration 23, loss = 3.91851332\n",
      "Iteration 24, loss = 3.91053243\n",
      "Iteration 25, loss = 3.90270953\n",
      "Iteration 26, loss = 3.89544742\n",
      "Iteration 27, loss = 3.88939876\n",
      "Iteration 28, loss = 3.88434997\n",
      "Iteration 29, loss = 3.87910167\n",
      "Iteration 30, loss = 3.87258777\n",
      "Iteration 31, loss = 3.86484511\n",
      "Iteration 32, loss = 3.85677492\n",
      "Iteration 33, loss = 3.84930782\n",
      "Iteration 34, loss = 3.84299013\n",
      "Iteration 35, loss = 3.83809022\n",
      "Iteration 36, loss = 3.83465389\n",
      "Iteration 37, loss = 3.83230205\n",
      "Iteration 38, loss = 3.83022549\n",
      "Iteration 39, loss = 3.82767236\n",
      "Iteration 40, loss = 3.82444170\n",
      "Iteration 41, loss = 3.82081226\n",
      "Iteration 42, loss = 3.81710250\n",
      "Iteration 43, loss = 3.81344417\n",
      "Iteration 44, loss = 3.80990201\n",
      "Iteration 45, loss = 3.80658355\n",
      "Iteration 46, loss = 3.80353248\n",
      "Iteration 47, loss = 3.80062834\n",
      "Iteration 48, loss = 3.79772086\n",
      "Iteration 49, loss = 3.79483188\n",
      "Iteration 50, loss = 3.79212437\n",
      "Iteration 51, loss = 3.78968844\n",
      "Iteration 52, loss = 3.78745176\n",
      "Iteration 53, loss = 3.78530386\n",
      "Iteration 54, loss = 3.78321687\n",
      "Iteration 55, loss = 3.78120739\n",
      "Iteration 56, loss = 3.77924820\n",
      "Iteration 57, loss = 3.77728050\n",
      "Iteration 58, loss = 3.77528791\n",
      "Iteration 59, loss = 3.77330852\n",
      "Iteration 60, loss = 3.77138830\n",
      "Iteration 61, loss = 3.76956216\n",
      "Iteration 62, loss = 3.76786257\n",
      "Iteration 63, loss = 3.76629667\n",
      "Iteration 64, loss = 3.76481018\n",
      "Iteration 65, loss = 3.76331050\n",
      "Iteration 66, loss = 3.76174007\n",
      "Iteration 67, loss = 3.76011214\n",
      "Iteration 68, loss = 3.75847682\n",
      "Iteration 69, loss = 3.75687844\n",
      "Iteration 70, loss = 3.75534861\n",
      "Iteration 71, loss = 3.75390708\n",
      "Iteration 72, loss = 3.75254682\n",
      "Iteration 73, loss = 3.75123363\n",
      "Iteration 74, loss = 3.74993665\n",
      "Iteration 75, loss = 3.74864965\n",
      "Iteration 76, loss = 3.74737683\n",
      "Iteration 77, loss = 3.74611640\n",
      "Iteration 78, loss = 3.74486938\n",
      "Iteration 79, loss = 3.74364906\n",
      "Iteration 80, loss = 3.74246818\n",
      "Iteration 81, loss = 3.74132589\n",
      "Iteration 82, loss = 3.74021597\n",
      "Iteration 83, loss = 3.73913838\n",
      "Iteration 84, loss = 3.73809354\n",
      "Iteration 85, loss = 3.73707433\n",
      "Iteration 86, loss = 3.73607276\n",
      "Iteration 87, loss = 3.73508921\n",
      "Iteration 88, loss = 3.73412862\n",
      "Iteration 89, loss = 3.73319305\n",
      "Iteration 90, loss = 3.73228328\n",
      "Iteration 91, loss = 3.73140252\n",
      "Iteration 92, loss = 3.73055307\n",
      "Iteration 93, loss = 3.72973233\n",
      "Iteration 94, loss = 3.72893553\n",
      "Iteration 95, loss = 3.72816043\n",
      "Iteration 96, loss = 3.72740753\n",
      "Iteration 97, loss = 3.72667820\n",
      "Iteration 98, loss = 3.72597414\n",
      "Iteration 99, loss = 3.72529646\n",
      "Iteration 100, loss = 3.72464433\n",
      "Iteration 101, loss = 3.72401536\n",
      "Iteration 102, loss = 3.72340755\n",
      "Iteration 103, loss = 3.72282006\n",
      "Iteration 104, loss = 3.72225227\n",
      "Iteration 105, loss = 3.72170349\n",
      "Iteration 106, loss = 3.72117366\n",
      "Iteration 107, loss = 3.72066367\n",
      "Iteration 108, loss = 3.72017420\n",
      "Iteration 109, loss = 3.71970458\n",
      "Iteration 110, loss = 3.71925293\n",
      "Iteration 111, loss = 3.71881748\n",
      "Iteration 112, loss = 3.71839749\n",
      "Iteration 113, loss = 3.71799294\n",
      "Iteration 114, loss = 3.71760376\n",
      "Iteration 115, loss = 3.71722956\n",
      "Iteration 116, loss = 3.71686991\n",
      "Iteration 117, loss = 3.71652413\n",
      "Iteration 118, loss = 3.71619131\n",
      "Iteration 119, loss = 3.71587060\n",
      "Iteration 120, loss = 3.71556146\n",
      "Iteration 121, loss = 3.71526356\n",
      "Iteration 122, loss = 3.71497646\n",
      "Iteration 123, loss = 3.71469967\n",
      "Iteration 124, loss = 3.71443268\n",
      "Iteration 125, loss = 3.71417497\n",
      "Iteration 126, loss = 3.71392606\n",
      "Iteration 127, loss = 3.71368553\n",
      "Iteration 128, loss = 3.71345294\n",
      "Iteration 129, loss = 3.71322787\n",
      "Iteration 130, loss = 3.71300993\n",
      "Iteration 131, loss = 3.71279887\n",
      "Iteration 132, loss = 3.71259440\n",
      "Iteration 133, loss = 3.71239619\n",
      "Iteration 134, loss = 3.71220393\n",
      "Iteration 135, loss = 3.71201734\n",
      "Iteration 136, loss = 3.71183611\n",
      "Iteration 137, loss = 3.71165994\n",
      "Iteration 138, loss = 3.71148863\n",
      "Iteration 139, loss = 3.71132209\n",
      "Iteration 140, loss = 3.71116018\n",
      "Iteration 141, loss = 3.71100269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 142, loss = 3.71084938\n",
      "Iteration 143, loss = 3.71070004\n",
      "Iteration 144, loss = 3.71055451\n",
      "Iteration 145, loss = 3.71041273\n",
      "Iteration 146, loss = 3.71027459\n",
      "Iteration 147, loss = 3.71013998\n",
      "Iteration 148, loss = 3.71000877\n",
      "Iteration 149, loss = 3.70988080\n",
      "Iteration 150, loss = 3.70975595\n",
      "Iteration 151, loss = 3.70963414\n",
      "Iteration 152, loss = 3.70951529\n",
      "Iteration 153, loss = 3.70939934\n",
      "Iteration 154, loss = 3.70928619\n",
      "Iteration 155, loss = 3.70917575\n",
      "Iteration 156, loss = 3.70906791\n",
      "Iteration 157, loss = 3.70896262\n",
      "Iteration 158, loss = 3.70885979\n",
      "Iteration 159, loss = 3.70875937\n",
      "Iteration 160, loss = 3.70866129\n",
      "Iteration 161, loss = 3.70856547\n",
      "Iteration 162, loss = 3.70847185\n",
      "Iteration 163, loss = 3.70838036\n",
      "Iteration 164, loss = 3.70829093\n",
      "Iteration 165, loss = 3.70820350\n",
      "Iteration 166, loss = 3.70811803\n",
      "Iteration 167, loss = 3.70803445\n",
      "Iteration 168, loss = 3.70795272\n",
      "Iteration 169, loss = 3.70787277\n",
      "Iteration 170, loss = 3.70779456\n",
      "Iteration 171, loss = 3.70771804\n",
      "Iteration 172, loss = 3.70764316\n",
      "Iteration 173, loss = 3.70756987\n",
      "Iteration 174, loss = 3.70749813\n",
      "Iteration 175, loss = 3.70742789\n",
      "Iteration 176, loss = 3.70735912\n",
      "Iteration 177, loss = 3.70729177\n",
      "Iteration 178, loss = 3.70722581\n",
      "Iteration 179, loss = 3.70716119\n",
      "Iteration 180, loss = 3.70709789\n",
      "Iteration 181, loss = 3.70703586\n",
      "Iteration 182, loss = 3.70697507\n",
      "Iteration 183, loss = 3.70691549\n",
      "Iteration 184, loss = 3.70685709\n",
      "Iteration 185, loss = 3.70679983\n",
      "Iteration 186, loss = 3.70674370\n",
      "Iteration 187, loss = 3.70668865\n",
      "Iteration 188, loss = 3.70663466\n",
      "Iteration 189, loss = 3.70658171\n",
      "Iteration 190, loss = 3.70652977\n",
      "Iteration 191, loss = 3.70647881\n",
      "Iteration 192, loss = 3.70642882\n",
      "Iteration 193, loss = 3.70637975\n",
      "Iteration 194, loss = 3.70633161\n",
      "Iteration 195, loss = 3.70628435\n",
      "Iteration 196, loss = 3.70623797\n",
      "Iteration 197, loss = 3.70619243\n",
      "Iteration 198, loss = 3.70614773\n",
      "Iteration 199, loss = 3.70610383\n",
      "Iteration 200, loss = 3.70606072\n",
      "Iteration 201, loss = 3.70601839\n",
      "Iteration 202, loss = 3.70597681\n",
      "Iteration 203, loss = 3.70593597\n",
      "Iteration 204, loss = 3.70589585\n",
      "Iteration 205, loss = 3.70585643\n",
      "Iteration 206, loss = 3.70581770\n",
      "Iteration 207, loss = 3.70577964\n",
      "Iteration 208, loss = 3.70574224\n",
      "Iteration 209, loss = 3.70570548\n",
      "Iteration 210, loss = 3.70566934\n",
      "Iteration 211, loss = 3.70563382\n",
      "Iteration 212, loss = 3.70559890\n",
      "Iteration 213, loss = 3.70556457\n",
      "Iteration 214, loss = 3.70553080\n",
      "Iteration 215, loss = 3.70549761\n",
      "Iteration 216, loss = 3.70546495\n",
      "Iteration 217, loss = 3.70543284\n",
      "Iteration 218, loss = 3.70540125\n",
      "Iteration 219, loss = 3.70537018\n",
      "Iteration 220, loss = 3.70533961\n",
      "Iteration 221, loss = 3.70530953\n",
      "Iteration 222, loss = 3.70527993\n",
      "Iteration 223, loss = 3.70525080\n",
      "Iteration 224, loss = 3.70522214\n",
      "Iteration 225, loss = 3.70519393\n",
      "Iteration 226, loss = 3.70516616\n",
      "Iteration 227, loss = 3.70513883\n",
      "Iteration 228, loss = 3.70511192\n",
      "Iteration 229, loss = 3.70508543\n",
      "Iteration 230, loss = 3.70505935\n",
      "Iteration 231, loss = 3.70503366\n",
      "Iteration 232, loss = 3.70500837\n",
      "Iteration 233, loss = 3.70498346\n",
      "Iteration 234, loss = 3.70495893\n",
      "Iteration 235, loss = 3.70493476\n",
      "Iteration 236, loss = 3.70491096\n",
      "Iteration 237, loss = 3.70488751\n",
      "Iteration 238, loss = 3.70486441\n",
      "Iteration 239, loss = 3.70484165\n",
      "Iteration 240, loss = 3.70481923\n",
      "Iteration 241, loss = 3.70479713\n",
      "Iteration 242, loss = 3.70477535\n",
      "Iteration 243, loss = 3.70475389\n",
      "Iteration 244, loss = 3.70473274\n",
      "Iteration 245, loss = 3.70471189\n",
      "Iteration 246, loss = 3.70469134\n",
      "Iteration 247, loss = 3.70467108\n",
      "Iteration 248, loss = 3.70465111\n",
      "Iteration 249, loss = 3.70463142\n",
      "Iteration 250, loss = 3.70461201\n",
      "Iteration 251, loss = 3.70459286\n",
      "Iteration 252, loss = 3.70457398\n",
      "Iteration 253, loss = 3.70455537\n",
      "Iteration 254, loss = 3.70453701\n",
      "Iteration 255, loss = 3.70451890\n",
      "Iteration 256, loss = 3.70450104\n",
      "Iteration 257, loss = 3.70448342\n",
      "Iteration 258, loss = 3.70446604\n",
      "Iteration 259, loss = 3.70444889\n",
      "Iteration 260, loss = 3.70443198\n",
      "Iteration 261, loss = 3.70441529\n",
      "Iteration 262, loss = 3.70439882\n",
      "Iteration 263, loss = 3.70438257\n",
      "Iteration 264, loss = 3.70436653\n",
      "Iteration 265, loss = 3.70435071\n",
      "Iteration 266, loss = 3.70433509\n",
      "Iteration 267, loss = 3.70431968\n",
      "Iteration 268, loss = 3.70430446\n",
      "Iteration 269, loss = 3.70428944\n",
      "Iteration 270, loss = 3.70427462\n",
      "Iteration 271, loss = 3.70425998\n",
      "Iteration 272, loss = 3.70424553\n",
      "Iteration 273, loss = 3.70423127\n",
      "Iteration 274, loss = 3.70421718\n",
      "Iteration 275, loss = 3.70420327\n",
      "Iteration 276, loss = 3.70418954\n",
      "Iteration 277, loss = 3.70417598\n",
      "Iteration 278, loss = 3.70416259\n",
      "Iteration 279, loss = 3.70414936\n",
      "Iteration 280, loss = 3.70413630\n",
      "Iteration 281, loss = 3.70412339\n",
      "Iteration 282, loss = 3.70411065\n",
      "Iteration 283, loss = 3.70409806\n",
      "Iteration 284, loss = 3.70408562\n",
      "Iteration 285, loss = 3.70407333\n",
      "Iteration 286, loss = 3.70406119\n",
      "Iteration 287, loss = 3.70404920\n",
      "Iteration 288, loss = 3.70403735\n",
      "Iteration 289, loss = 3.70402564\n",
      "Iteration 290, loss = 3.70401407\n",
      "Iteration 291, loss = 3.70400264\n",
      "Iteration 292, loss = 3.70399134\n",
      "Iteration 293, loss = 3.70398017\n",
      "Iteration 294, loss = 3.70396914\n",
      "Iteration 295, loss = 3.70395823\n",
      "Iteration 296, loss = 3.70394745\n",
      "Iteration 297, loss = 3.70393679\n",
      "Iteration 298, loss = 3.70392626\n",
      "Iteration 299, loss = 3.70391584\n",
      "Iteration 300, loss = 3.70390555\n",
      "Iteration 301, loss = 3.70389537\n",
      "Iteration 302, loss = 3.70388531\n",
      "Iteration 303, loss = 3.70387536\n",
      "Iteration 304, loss = 3.70386552\n",
      "Iteration 305, loss = 3.70385580\n",
      "Iteration 306, loss = 3.70384618\n",
      "Iteration 307, loss = 3.70383667\n",
      "Iteration 308, loss = 3.70382726\n",
      "Iteration 309, loss = 3.70381796\n",
      "Iteration 310, loss = 3.70380876\n",
      "Iteration 311, loss = 3.70379966\n",
      "Iteration 312, loss = 3.70379066\n",
      "Iteration 313, loss = 3.70378176\n",
      "Iteration 314, loss = 3.70377296\n",
      "Iteration 315, loss = 3.70376425\n",
      "Iteration 316, loss = 3.70375563\n",
      "Iteration 317, loss = 3.70374711\n",
      "Iteration 318, loss = 3.70373867\n",
      "Iteration 319, loss = 3.70373033\n",
      "Iteration 320, loss = 3.70372208\n",
      "Iteration 321, loss = 3.70371391\n",
      "Iteration 322, loss = 3.70370583\n",
      "Iteration 323, loss = 3.70369783\n",
      "Iteration 324, loss = 3.70368992\n",
      "Iteration 325, loss = 3.70368209\n",
      "Iteration 326, loss = 3.70367434\n",
      "Iteration 327, loss = 3.70366667\n",
      "Iteration 328, loss = 3.70365908\n",
      "Iteration 329, loss = 3.70365157\n",
      "Iteration 330, loss = 3.70364414\n",
      "Iteration 331, loss = 3.70363678\n",
      "Iteration 332, loss = 3.70362949\n",
      "Iteration 333, loss = 3.70362228\n",
      "Iteration 334, loss = 3.70361515\n",
      "Iteration 335, loss = 3.70360808\n",
      "Iteration 336, loss = 3.70360109\n",
      "Iteration 337, loss = 3.70359417\n",
      "Iteration 338, loss = 3.70358731\n",
      "Iteration 339, loss = 3.70358052\n",
      "Iteration 340, loss = 3.70357380\n",
      "Iteration 341, loss = 3.70356715\n",
      "Iteration 342, loss = 3.70356056\n",
      "Iteration 343, loss = 3.70355404\n",
      "Iteration 344, loss = 3.70354758\n",
      "Iteration 345, loss = 3.70354119\n",
      "Iteration 346, loss = 3.70353485\n",
      "Iteration 347, loss = 3.70352858\n",
      "Iteration 348, loss = 3.70352237\n",
      "Iteration 349, loss = 3.70351622\n",
      "Iteration 350, loss = 3.70351012\n",
      "Iteration 351, loss = 3.70350409\n",
      "Iteration 352, loss = 3.70349811\n",
      "Iteration 353, loss = 3.70349219\n",
      "Iteration 354, loss = 3.70348632\n",
      "Iteration 355, loss = 3.70348051\n",
      "Iteration 356, loss = 3.70347476\n",
      "Iteration 357, loss = 3.70346906\n",
      "Iteration 358, loss = 3.70346341\n",
      "Iteration 359, loss = 3.70345782\n",
      "Iteration 360, loss = 3.70345227\n",
      "Iteration 361, loss = 3.70344678\n",
      "Iteration 362, loss = 3.70344134\n",
      "Iteration 363, loss = 3.70343595\n",
      "Iteration 364, loss = 3.70343061\n",
      "Iteration 365, loss = 3.70342532\n",
      "Iteration 366, loss = 3.70342007\n",
      "Iteration 367, loss = 3.70341488\n",
      "Iteration 368, loss = 3.70340973\n",
      "Iteration 369, loss = 3.70340463\n",
      "Iteration 370, loss = 3.70339957\n",
      "Iteration 371, loss = 3.70339456\n",
      "Iteration 372, loss = 3.70338959\n",
      "Iteration 373, loss = 3.70338467\n",
      "Iteration 374, loss = 3.70337979\n",
      "Iteration 375, loss = 3.70337496\n",
      "Iteration 376, loss = 3.70337017\n",
      "Iteration 377, loss = 3.70336542\n",
      "Iteration 378, loss = 3.70336071\n",
      "Iteration 379, loss = 3.70335604\n",
      "Iteration 380, loss = 3.70335142\n",
      "Iteration 381, loss = 3.70334683\n",
      "Iteration 382, loss = 3.70334228\n",
      "Iteration 383, loss = 3.70333778\n",
      "Iteration 384, loss = 3.70333331\n",
      "Iteration 385, loss = 3.70332888\n",
      "Iteration 386, loss = 3.70332449\n",
      "Iteration 387, loss = 3.70332014\n",
      "Iteration 388, loss = 3.70331582\n",
      "Iteration 389, loss = 3.70331154\n",
      "Iteration 390, loss = 3.70330730\n",
      "Iteration 391, loss = 3.70330309\n",
      "Iteration 392, loss = 3.70329892\n",
      "Iteration 393, loss = 3.70329479\n",
      "Iteration 394, loss = 3.70329068\n",
      "Iteration 395, loss = 3.70328662\n",
      "Iteration 396, loss = 3.70328258\n",
      "Iteration 397, loss = 3.70327858\n",
      "Iteration 398, loss = 3.70327462\n",
      "Iteration 399, loss = 3.70327068\n",
      "Iteration 400, loss = 3.70326678\n",
      "Iteration 401, loss = 3.70326291\n",
      "Iteration 402, loss = 3.70325908\n",
      "Iteration 403, loss = 3.70325527\n",
      "Iteration 404, loss = 3.70325150\n",
      "Iteration 405, loss = 3.70324775\n",
      "Iteration 406, loss = 3.70324404\n",
      "Iteration 407, loss = 3.70324036\n",
      "Iteration 408, loss = 3.70323670\n",
      "Iteration 409, loss = 3.70323308\n",
      "Iteration 410, loss = 3.70322948\n",
      "Iteration 411, loss = 3.70322592\n",
      "Iteration 412, loss = 3.70322238\n",
      "Iteration 413, loss = 3.70321887\n",
      "Iteration 414, loss = 3.70321539\n",
      "Iteration 415, loss = 3.70321193\n",
      "Iteration 416, loss = 3.70320851\n",
      "Iteration 417, loss = 3.70320511\n",
      "Iteration 418, loss = 3.70320174\n",
      "Iteration 419, loss = 3.70319839\n",
      "Iteration 420, loss = 3.70319507\n",
      "Iteration 421, loss = 3.70319177\n",
      "Iteration 422, loss = 3.70318850\n",
      "Iteration 423, loss = 3.70318526\n",
      "Iteration 424, loss = 3.70318204\n",
      "Iteration 425, loss = 3.70317885\n",
      "Iteration 426, loss = 3.70317568\n",
      "Iteration 427, loss = 3.70317254\n",
      "Iteration 428, loss = 3.70316942\n",
      "Iteration 429, loss = 3.70316632\n",
      "Iteration 430, loss = 3.70316325\n",
      "Iteration 431, loss = 3.70316020\n",
      "Iteration 432, loss = 3.70315717\n",
      "Iteration 433, loss = 3.70315417\n",
      "Iteration 434, loss = 3.70315118\n",
      "Iteration 435, loss = 3.70314823\n",
      "Iteration 436, loss = 3.70314529\n",
      "Iteration 437, loss = 3.70314238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 438, loss = 3.70313948\n",
      "Iteration 439, loss = 3.70313661\n",
      "Iteration 440, loss = 3.70313376\n",
      "Iteration 441, loss = 3.70313093\n",
      "Iteration 442, loss = 3.70312813\n",
      "Iteration 443, loss = 3.70312534\n",
      "Iteration 444, loss = 3.70312257\n",
      "Iteration 445, loss = 3.70311983\n",
      "Iteration 446, loss = 3.70311710\n",
      "Iteration 447, loss = 3.70311439\n",
      "Iteration 448, loss = 3.70311171\n",
      "Iteration 449, loss = 3.70310904\n",
      "Iteration 450, loss = 3.70310639\n",
      "Iteration 451, loss = 3.70310376\n",
      "Iteration 452, loss = 3.70310115\n",
      "Iteration 453, loss = 3.70309856\n",
      "Iteration 454, loss = 3.70309599\n",
      "Iteration 455, loss = 3.70309344\n",
      "Iteration 456, loss = 3.70309090\n",
      "Iteration 457, loss = 3.70308838\n",
      "Iteration 458, loss = 3.70308588\n",
      "Iteration 459, loss = 3.70308340\n",
      "Iteration 460, loss = 3.70308094\n",
      "Iteration 461, loss = 3.70307849\n",
      "Iteration 462, loss = 3.70307606\n",
      "Iteration 463, loss = 3.70307365\n",
      "Iteration 464, loss = 3.70307125\n",
      "Iteration 465, loss = 3.70306887\n",
      "Iteration 466, loss = 3.70306651\n",
      "Iteration 467, loss = 3.70306416\n",
      "Iteration 468, loss = 3.70306183\n",
      "Iteration 469, loss = 3.70305952\n",
      "Iteration 470, loss = 3.70305722\n",
      "Iteration 471, loss = 3.70305494\n",
      "Iteration 472, loss = 3.70305267\n",
      "Iteration 473, loss = 3.70305042\n",
      "Iteration 474, loss = 3.70304819\n",
      "Iteration 475, loss = 3.70304597\n",
      "Iteration 476, loss = 3.70304376\n",
      "Iteration 477, loss = 3.70304157\n",
      "Iteration 478, loss = 3.70303940\n",
      "Iteration 479, loss = 3.70303724\n",
      "Iteration 480, loss = 3.70303509\n",
      "Iteration 481, loss = 3.70303296\n",
      "Iteration 482, loss = 3.70303084\n",
      "Iteration 483, loss = 3.70302874\n",
      "Iteration 484, loss = 3.70302665\n",
      "Iteration 485, loss = 3.70302458\n",
      "Iteration 486, loss = 3.70302252\n",
      "Iteration 487, loss = 3.70302047\n",
      "Iteration 488, loss = 3.70301844\n",
      "Iteration 489, loss = 3.70301642\n",
      "Iteration 490, loss = 3.70301441\n",
      "Iteration 491, loss = 3.70301242\n",
      "Iteration 492, loss = 3.70301043\n",
      "Iteration 493, loss = 3.70300847\n",
      "Iteration 494, loss = 3.70300651\n",
      "Iteration 495, loss = 3.70300457\n",
      "Iteration 496, loss = 3.70300264\n",
      "Iteration 497, loss = 3.70300072\n",
      "Iteration 498, loss = 3.70299882\n",
      "Iteration 499, loss = 3.70299693\n",
      "Iteration 500, loss = 3.70299505\n",
      "Iteration 501, loss = 3.70299318\n",
      "Iteration 502, loss = 3.70299132\n",
      "Iteration 503, loss = 3.70298948\n",
      "Iteration 504, loss = 3.70298765\n",
      "Iteration 505, loss = 3.70298583\n",
      "Iteration 506, loss = 3.70298402\n",
      "Iteration 507, loss = 3.70298222\n",
      "Iteration 508, loss = 3.70298044\n",
      "Iteration 509, loss = 3.70297866\n",
      "Iteration 510, loss = 3.70297690\n",
      "Iteration 511, loss = 3.70297515\n",
      "Iteration 512, loss = 3.70297340\n",
      "Iteration 513, loss = 3.70297167\n",
      "Iteration 514, loss = 3.70296995\n",
      "Iteration 515, loss = 3.70296825\n",
      "Iteration 516, loss = 3.70296655\n",
      "Iteration 517, loss = 3.70296486\n",
      "Iteration 518, loss = 3.70296318\n",
      "Iteration 519, loss = 3.70296152\n",
      "Iteration 520, loss = 3.70295986\n",
      "Iteration 521, loss = 3.70295821\n",
      "Iteration 522, loss = 3.70295658\n",
      "Iteration 523, loss = 3.70295495\n",
      "Iteration 524, loss = 3.70295334\n",
      "Iteration 525, loss = 3.70295173\n",
      "Iteration 526, loss = 3.70295013\n",
      "Iteration 527, loss = 3.70294855\n",
      "Iteration 528, loss = 3.70294697\n",
      "Iteration 529, loss = 3.70294540\n",
      "Iteration 530, loss = 3.70294384\n",
      "Iteration 531, loss = 3.70294230\n",
      "Iteration 532, loss = 3.70294076\n",
      "Iteration 533, loss = 3.70293923\n",
      "Iteration 534, loss = 3.70293771\n",
      "Iteration 535, loss = 3.70293620\n",
      "Iteration 536, loss = 3.70293469\n",
      "Iteration 537, loss = 3.70293320\n",
      "Iteration 538, loss = 3.70293171\n",
      "Iteration 539, loss = 3.70293024\n",
      "Iteration 540, loss = 3.70292877\n",
      "Iteration 541, loss = 3.70292731\n",
      "Iteration 542, loss = 3.70292586\n",
      "Iteration 543, loss = 3.70292442\n",
      "Iteration 544, loss = 3.70292299\n",
      "Iteration 545, loss = 3.70292157\n",
      "Iteration 546, loss = 3.70292015\n",
      "Iteration 547, loss = 3.70291874\n",
      "Iteration 548, loss = 3.70291734\n",
      "Iteration 549, loss = 3.70291595\n",
      "Iteration 550, loss = 3.70291457\n",
      "Iteration 551, loss = 3.70291319\n",
      "Iteration 552, loss = 3.70291183\n",
      "Iteration 553, loss = 3.70291047\n",
      "Iteration 554, loss = 3.70290912\n",
      "Iteration 555, loss = 3.70290777\n",
      "Iteration 556, loss = 3.70290644\n",
      "Iteration 557, loss = 3.70290511\n",
      "Iteration 558, loss = 3.70290379\n",
      "Iteration 559, loss = 3.70290247\n",
      "Iteration 560, loss = 3.70290117\n",
      "Iteration 561, loss = 3.70289987\n",
      "Iteration 562, loss = 3.70289858\n",
      "Iteration 563, loss = 3.70289730\n",
      "Iteration 564, loss = 3.70289602\n",
      "Iteration 565, loss = 3.70289475\n",
      "Iteration 566, loss = 3.70289349\n",
      "Iteration 567, loss = 3.70289223\n",
      "Iteration 568, loss = 3.70289099\n",
      "Iteration 569, loss = 3.70288975\n",
      "Iteration 570, loss = 3.70288851\n",
      "Iteration 571, loss = 3.70288728\n",
      "Iteration 572, loss = 3.70288606\n",
      "Iteration 573, loss = 3.70288485\n",
      "Iteration 574, loss = 3.70288365\n",
      "Iteration 575, loss = 3.70288245\n",
      "Iteration 576, loss = 3.70288125\n",
      "Iteration 577, loss = 3.70288007\n",
      "Iteration 578, loss = 3.70287889\n",
      "Iteration 579, loss = 3.70287771\n",
      "Iteration 580, loss = 3.70287655\n",
      "Iteration 581, loss = 3.70287538\n",
      "Iteration 582, loss = 3.70287423\n",
      "Iteration 583, loss = 3.70287308\n",
      "Iteration 584, loss = 3.70287194\n",
      "Iteration 585, loss = 3.70287080\n",
      "Iteration 586, loss = 3.70286968\n",
      "Iteration 587, loss = 3.70286855\n",
      "Iteration 588, loss = 3.70286743\n",
      "Iteration 589, loss = 3.70286632\n",
      "Iteration 590, loss = 3.70286522\n",
      "Iteration 591, loss = 3.70286412\n",
      "Iteration 592, loss = 3.70286303\n",
      "Iteration 593, loss = 3.70286194\n",
      "Iteration 594, loss = 3.70286086\n",
      "Iteration 595, loss = 3.70285978\n",
      "Iteration 596, loss = 3.70285871\n",
      "Iteration 597, loss = 3.70285765\n",
      "Iteration 598, loss = 3.70285659\n",
      "Iteration 599, loss = 3.70285553\n",
      "Iteration 600, loss = 3.70285449\n",
      "Iteration 601, loss = 3.70285345\n",
      "Iteration 602, loss = 3.70285241\n",
      "Iteration 603, loss = 3.70285138\n",
      "Iteration 604, loss = 3.70285035\n",
      "Iteration 605, loss = 3.70284933\n",
      "Iteration 606, loss = 3.70284832\n",
      "Iteration 607, loss = 3.70284731\n",
      "Iteration 608, loss = 3.70284630\n",
      "Iteration 609, loss = 3.70284530\n",
      "Iteration 610, loss = 3.70284431\n",
      "Iteration 611, loss = 3.70284332\n",
      "Iteration 612, loss = 3.70284234\n",
      "Iteration 613, loss = 3.70284136\n",
      "Iteration 614, loss = 3.70284039\n",
      "Iteration 615, loss = 3.70283942\n",
      "Iteration 616, loss = 3.70283845\n",
      "Iteration 617, loss = 3.70283750\n",
      "Iteration 618, loss = 3.70283654\n",
      "Iteration 619, loss = 3.70283559\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "#setting up variable that will store confusion matrices\n",
    "confusion_matrices_test4 = []\n",
    "\n",
    "#We iterate over datasets for each fold\n",
    "for dataset in model4_data_indexes:\n",
    "    #From the list of all indexes we get only the ones for a given fold\n",
    "    train_indexes=dataset[0]\n",
    "    test_indexes=dataset[1]\n",
    "\n",
    "    #We fit the model using data with indexes for a given fold\n",
    "    clf4.fit(X_data.iloc[train_indexes], y_data.iloc[train_indexes])\n",
    "    #Predict values on the test data\n",
    "    y_pred4 = clf4.predict(X_data.iloc[test_indexes])\n",
    "    \n",
    "    #calculating multilabel_confusion_matrix\n",
    "    cm = multilabel_confusion_matrix(y_data.iloc[test_indexes], y_pred4)\n",
    "    \n",
    "    #setting up variable for cell-by-cell summation\n",
    "    res = np.matrix([[0, 0], [0, 0]])  \n",
    "    \n",
    "    #cell-by-cell summation of the confusion matrices\n",
    "    for item in cm:\n",
    "        single_cm = np.matrix(item)\n",
    "        res += single_cm\n",
    "    \n",
    "    #adding summed confussion_matrix to the variable with the results\n",
    "    confusion_matrices_test4.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold index 0\n",
      "[[154  55]\n",
      " [ 78 112]]\n",
      "Fold index 1\n",
      "[[176  45]\n",
      " [ 69 109]]\n",
      "Fold index 2\n",
      "[[175  57]\n",
      " [ 58 102]]\n"
     ]
    }
   ],
   "source": [
    "#printing resulted confusion matrices\n",
    "for fold, cm in enumerate(confusion_matrices_test4):\n",
    "    print(\"Fold index\", fold)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the precision, recall and f1-scores on the test data for each fold and model. Give the unaggregated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold index 0\n",
      "Precision: 0.6396396396396397\n",
      "Recall: 0.6794258373205742\n",
      "f1-score: 0.6589327146171694\n",
      "Fold index 1\n",
      "Precision: 0.746606334841629\n",
      "Recall: 0.746606334841629\n",
      "f1-score: 0.746606334841629\n",
      "Fold index 2\n",
      "Precision: 0.7544642857142857\n",
      "Recall: 0.728448275862069\n",
      "f1-score: 0.7412280701754387\n"
     ]
    }
   ],
   "source": [
    "#Calculating statistics for model3\n",
    "for fold, cm in enumerate(confusion_matrices_test3):\n",
    "    #we did not want to iterate again over models, so we are calculating scores manually, based on the confusion matrices\n",
    "    tp = cm[0,0]\n",
    "    fp = cm[1,0]\n",
    "    fn = cm[0,1]\n",
    "    tn = cm[1,1]\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"Fold index\", fold)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"f1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold index 0\n",
      "Precision: 0.6637931034482759\n",
      "Recall: 0.7368421052631579\n",
      "f1-score: 0.6984126984126984\n",
      "Fold index 1\n",
      "Precision: 0.7183673469387755\n",
      "Recall: 0.7963800904977375\n",
      "f1-score: 0.7553648068669526\n",
      "Fold index 2\n",
      "Precision: 0.7510729613733905\n",
      "Recall: 0.7543103448275862\n",
      "f1-score: 0.7526881720430106\n"
     ]
    }
   ],
   "source": [
    "#Calculating statistics for model4\n",
    "for fold, cm in enumerate(confusion_matrices_test4):\n",
    "    #we did not want to iterate again over models, so we are calculating scores manually, based on the confusion matrices\n",
    "    tp = cm[0,0]\n",
    "    fp = cm[1,0]\n",
    "    fn = cm[0,1]\n",
    "    tn = cm[1,1]\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"Fold index\", fold)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"f1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute accuracy scores on training and test data (give explicitly the result for each fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in the train data:\n",
      "Fold index 0\n",
      "Accuracy: 0.8065739570164349\n",
      "Fold index 1\n",
      "Accuracy: 0.7509481668773704\n",
      "Fold index 2\n",
      "Accuracy: 0.7431077694235589\n",
      "\n",
      "Accuracy in the test data:\n",
      "Fold index 0\n",
      "Accuracy: 0.631578947368421\n",
      "Fold index 1\n",
      "Accuracy: 0.7192982456140351\n",
      "Fold index 2\n",
      "Accuracy: 0.6989795918367347\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for train model3\n",
    "print(\"Accuracy in the train data:\")\n",
    "for fold, cm in enumerate(confusion_matrices_train3):\n",
    "    #we did not want to iterate again over models, so we are calculating scores manually, based on the confusion matrices\n",
    "    tp = cm[0,0]\n",
    "    fp = cm[1,0]\n",
    "    fn = cm[0,1]\n",
    "    tn = cm[1,1]\n",
    "    accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "\n",
    "    print(\"Fold index\", fold)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Calculating accuracy for test model3\n",
    "print(\"\\nAccuracy in the test data:\")\n",
    "for fold, cm in enumerate(confusion_matrices_test3):\n",
    "    #we did not want to iterate again over models, so we are calculating scores manually, based on the confusion matrices\n",
    "    tp = cm[0,0]\n",
    "    fp = cm[1,0]\n",
    "    fn = cm[0,1]\n",
    "    tn = cm[1,1]\n",
    "    accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "\n",
    "    print(\"Fold index\", fold)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in the train data:\n",
      "Fold index 0\n",
      "Accuracy: 0.7724399494310998\n",
      "Fold index 1\n",
      "Accuracy: 0.7332490518331226\n",
      "Fold index 2\n",
      "Accuracy: 0.7280701754385965\n",
      "\n",
      "Accuracy in the test data:\n",
      "Fold index 0\n",
      "Accuracy: 0.6666666666666666\n",
      "Fold index 1\n",
      "Accuracy: 0.7142857142857143\n",
      "Fold index 2\n",
      "Accuracy: 0.7066326530612245\n"
     ]
    }
   ],
   "source": [
    "#Calculating accuracy for train model4\n",
    "print(\"Accuracy in the train data:\")\n",
    "for fold, cm in enumerate(confusion_matrices_train4):\n",
    "    #we did not want to iterate again over models, so we are calculating scores manually, based on the confusion matrices\n",
    "    tp = cm[0,0]\n",
    "    fp = cm[1,0]\n",
    "    fn = cm[0,1]\n",
    "    tn = cm[1,1]\n",
    "    accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "\n",
    "    print(\"Fold index\", fold)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Calculating accuracy for test model4\n",
    "print(\"\\nAccuracy in the test data:\")\n",
    "for fold, cm in enumerate(confusion_matrices_test4):\n",
    "    #we did not want to iterate again over models, so we are calculating scores manually, based on the confusion matrices\n",
    "    tp = cm[0,0]\n",
    "    fp = cm[1,0]\n",
    "    fn = cm[0,1]\n",
    "    tn = cm[1,1]\n",
    "    accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "\n",
    "    print(\"Fold index\", fold)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to turn numbers into insights, please comment on your findings. Motivate the answers to the following questions using the metrics and the findings in the **questions 2 through 5** of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) What is, in your opinion, the best model? Motivate your answer with the findings above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:<br>\n",
    "According to our findings, We believe that Regression is the best model as we achieved the best accuracy, of around 75% on average as on the other hand comparing with other models the accuracy wasn't so high.\n",
    "<br>\n",
    "\n",
    "The difference in the accuracy between models is also caused by the fact that each task the learning problem was defined in a different way. In the Neural Network part our target feature was a vector and it was counted as a correct answer only, when the predicted vector fully matched the actual vector. That is the reason why the accuracy on these models was so small. In the evaluation part we could see that after summing confusion matrices cell-by-cell, the  accuracy on the \"animal type\" level increased.\u2029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Does any model suffer from underfitting or overfitting? Motivate your answer with the findings above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:<br>\n",
    "In the decision trees exercise we found out that Tree 2 was prone to \"overfitting\" as it reduces its ability to generalize well on data that is unseen and at the same time the tree was also quite complex. It was caused by the fact that the minimum sampling size for each split was one.\n",
    "<br>\n",
    "\n",
    "We also found out in Neural Networks exercise for some set of parameters models tend to \"overfit\", We saw that loss function was low on the training data, but it did not increase the accuracy of the model when checked with the testing data. That may indicate that the model overfit the training data and could not generalize well.\n",
    "<br>\n",
    "\n",
    "In case of SVM exercise we observed that some of the SVM models we trained may \"underfit\". We compared the accuracy of each model on a training dataset vs test dataset, and we found out that in 3 cases the accuracy on the train set was much lower than on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 - Clustering (8 points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) For this question, use the extracted data set you created in the preprocessing step (sampled_data). Drop all the columns expect \"VegetationR\", \"UseR\", \"FishingR\", \"RoadDistanceR\", \"BuildingR\", \"RoadDistanceR\", and \"PollutionR\". Use a dendogram to find the overview of the clusters that you can extract for the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VegetationR      UseR  FishingR  RoadDistanceR  BuildingR  PollutionR\n",
      "0     0.000000  0.577350  0.769800       0.192450   0.192450         0.0\n",
      "1     0.336861  0.000000  0.000000       0.421076   0.842152         0.0\n",
      "2     1.000000  0.000000  0.000000       0.000000   0.000000         0.0\n",
      "3     0.436436  0.654654  0.436436       0.000000   0.436436         0.0\n",
      "4     0.000000  0.522233  0.696311       0.348155   0.348155         0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Copy the sampled_data for further using\n",
    "clustering_sample_data = sampled_data.copy()\n",
    "\n",
    "#Filter the columns from the sampled_data\n",
    "clustering_sample_data = clustering_sample_data.filter([\"VegetationR\", \"UseR\", \"FishingR\", \"RoadDistanceR\", \"BuildingR\", \"PollutionR\"])\n",
    "\n",
    "#Dataframe to conduct clustering\n",
    "clustering_sample_data\n",
    "\n",
    "#normalize the regression_sample_data and renamed to regression_data_scaled\n",
    "clustering_data_scaled = normalize(clustering_sample_data)\n",
    "\n",
    "#Create a new dataframe of the regression_data_scaled\n",
    "clustering_data_scaled = pd.DataFrame(clustering_data_scaled, columns=clustering_sample_data.columns)\n",
    "print(clustering_data_scaled.head())\n",
    "\n",
    "\n",
    "#plotting dendogram\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Dendrogram\")\n",
    "dend = shc.dendrogram(shc.linkage(clustering_data_scaled, method='ward'))\n",
    "\n",
    "#we can see how many clusters are there on the base of the y-value\n",
    "#This function fancy_dendrogram signifies the points where the clusters are merged and shows the distance at each point\n",
    "#I thinkt it can be shown better , but I did not get it \n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('Dendrogram.png')\n",
    "\n",
    "#saving the dataset\n",
    "#clustering_data_scaled.to_csv('clustering_data_scaled.csv')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What does the vertical and horizontal axis show in the dendogram? Why the distance between the clusters in the dendogram generally decreases, when we go from top to down in the dendogram?\n",
    "\n",
    "\n",
    "**Explanation:** <br>\n",
    "The vertical line means the similarity scale/distance between clusters\n",
    "\n",
    "The horizontal line shows all the instances from the dataset\n",
    "\n",
    "Because the clusters are merged in order of the closest distance. It results in that each cluster searches for the closest cluster to merge, creates new cluster, and keep searching another cluster until everyone merges. Therefore, in each step there stays the less close clusters, and corresponding to this, the distance between clusters to be merged increases. This distance indicates the degree of similarity, and increased distances impliy that clusters are being less similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Split the diagram at 3 and find the number the clusters at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n3 Clusters can be observed\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting the dendogram with a splitline\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Dendrograms\")\n",
    "dend = shc.dendrogram(shc.linkage(clustering_data_scaled, method='ward'))\n",
    "plt.axhline(y=3, color='b', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('Dendrogram_split.png')\n",
    "\n",
    "\"\"\"\n",
    "3 Clusters can be observed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Using agglomerative clustering with the number of clusters found in the previous section and a scatter diagram, show the discovered cluster for \"VegetationR\" and \"UseR\" in different colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#execute AgglomerativeClustering\n",
    "# the number of cluster found from the above is 3, thus n_cluster(the number of cluster) is 3\n",
    "# affinity \n",
    "# linkage : criterien which distances should be considered by clustering and ward indicates that \n",
    "\n",
    "#Clustering\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "cluster.fit_predict(clustering_data_scaled)\n",
    "\n",
    "#plotting clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "#plot is scattered by\n",
    "# x-axis = VegetationR\n",
    "# y-axis = UseR\n",
    "# c = cluster.lables_ list of the cluster-index of each instances which are represented with dots\n",
    "\n",
    "plt.scatter(clustering_data_scaled['VegetationR'], clustering_data_scaled['UseR'], c=cluster.labels_)\n",
    "plt.ylabel(\"VUseR\")\n",
    "plt.xlabel(\"VegetationR\")\n",
    "plt.title(\"Clustering\")\n",
    "\n",
    "#saving the plot\n",
    "#plt.savefig('Clustering.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}